| original | translation |
|----------|-------------|
|  LAWYER IN AMERICAN POPULAR CULTURE<br/><br/>As human beings we struggle between good and bad—both internally and within a community of others who struggle as well. A society's popular culture reflects such basic human concerns and can be seen through the records it keeps. Undeniably, American popular culture has been well recorded. By looking at contemporary commentary, literature, and film we are able to see how the important issues of the times—our society's struggles to define what's right and wrong—have been reflected throughout our history. And what better venue to illustrate the eternal struggle between good and bad than the legal profession, which by definition exists to ensure that the rule of law is upheld, that good prevails.<br/><br/>Lawyers enter the legal profession intending to preserve justice and champion individual rights while at the same time ensuring the common good—at least they re supposed to. These are lofty goals considering that lawyers are no less "human" than anyone else, prone to the same abuse of power. By defining the different sides of a particular issue— or aspects of a profession—writers, journalists, artists, and filmmakers provide the reading and viewing public with materials that can both entertain us and make us think. As far as the legal profession is concerned, we see a good lawyer as a reflection of people's hopes, and a bad lawyer as a reflection of people's worst fears. Given the vital importance of the integrity of the law in America, and our natural cynicism when it comes to entrusting our future with an individual, is it any wonder that over the course of this country's history, the legal system in its entirety is more often than not viewed as a slew of rascals, cither distorting the law in their own self-interest or sidelining common justice in order to protect criminals and maintain deep pockets. We are especially interested in recognizing the bad, self-serving lawyer because our deepest wish is that if we need a lawyer, we will get one of the good ones!<br/><br/>Judging from the historical record, the trivialization of the lawyer in popular culture appears to be a time-honored theme, stretching as far back as the beginning of the modern period, when the process of consolidating a fragmented legal system into a coherent whole began. A late-seventeenth-century anonymous "legal coat of arms" depicts allegorically the purported values and interests of law professionals. The scene presents a fox, hardly a symbol of trustworthiness, surrounded by two figures of Questionable character, at least one of them a wealthy client. Following a theme that reappears consistently throughout the history of popular attitudes toward lawyers, the fox spews forth long reams of legal rhetoric in broken Latin, underscoring lawyers' incapacity to "speak the truth" or engage in common-sense dialogue. And as if to drive the satiric dagger deeper still, the reason for such slyness is plain and simple: the deep loyalty to material well-being rather than to the principle of social justice or the defense of the common man. Thus the designs' motto of "DUM VIVO THRIVO," which translates into "Where I live, I thrive." | ПРАВИТЕЛСТВО В АМЕРИКАНСКА ПОПУЛЯРНА КУЛТУРА<br/><br/>Като човешки същества ние се борим между доброто и лошото – както вътрешно, така и в рамките на една общност от други, които също се борят. Популярната култура на едно общество отразява такива основни човешки притеснения и може да се види през записите, които пази. Безспорно американската популярна култура е добре документирана. Разглеждайки съвременните коментари, литература и филми, ние сме в състояние да видим как важните въпроси на времето – борбите на нашето общество да определи кое е правилно и грешно – са отразени през цялата ни история. И какво по-добро място за илюстриране на вечната борба между доброто и лошото от юридическата професия, която по дефиниция съществува, за да гарантира, че върховенството на закона се поддържа, че доброто надделява.<br/><br/>Адвокатите навлизат в юридическата професия с цел запазване на правосъдието и отстояване на индивидуалните права, като в същото време се гарантира общото благо – поне така се предполага. Това са възвишени цели, като се има предвид, че адвокатите са не по-малко "човешки" от всеки друг, склонни към същата злоупотреба с власт. Чрез определяне на различните страни на определен въпрос - или аспекти на дадена професия - писатели, журналисти, художници и режисьори предоставят на четенето и гледането на обществеността материали, които могат да ни забавляват и да ни накарат да мислим. Що се отнася до юридическата професия, ние виждаме добрия адвокат като отражение на надеждите на хората, а лошия адвокат като отражение на най-лошите страхове на хората. Като се има предвид жизненоважното значение на целостта на закона в Америка и нашия естествен цинизъм, когато става въпрос за поверяване на нашето бъдеще с индивид, чудно ли е, че в хода на историята на тази страна, правната система в нейната цялост по-често се разглежда като убита от негодници, които изопачават закона в свой собствен интерес или заобикалят общото правосъдие, за да защитят престъпниците и да поддържат дълбоки джобове. Ние сме особено заинтересовани да разпознаем лошия, самообслужващ се адвокат, защото най-съкровеното ни желание е, че ако имаме нужда от адвокат, ще получим един от добрите!<br/><br/>Съдейки по историческите данни, тривиализацията на адвоката в популярната култура изглежда е тема, почитана във времето, простираща се още от началото на модерния период, когато започва процесът на консолидиране на фрагментирана правна система в едно съгласувано цяло. Анонимен "легален герб" от края на 17 век изобразява алегорично предполагаемите ценности и интереси на юристите. Сцената представя лисица, едва ли символ на благонадеждност, заобиколена от две фигури с подозрителен характер, поне една от които е богат клиент. Следвайки тема, която се появява последователно през цялата история на популярните нагласи към адвокатите, лисицата бълва дълги купища правна реторика на развален латински, подчертавайки неспособността на адвокатите да "говорят истината" или да участват в диалог със здравия разум. И като че ли, за да задвижи сатиричната кама още по-дълбоко, причината за такава хитрост е ясна и проста: дълбоката лоялност към материалното благосъстояние, а не към принципа на социалната справедливост или защитата на обикновения човек. По този начин мотото на дизайните на "DUM VIVO THRIVO", което се превежда като "Където живея, аз процъфтявам". |
| Do the Templars control the world today?<br/><br/>I meet and talk to people in very different situations who are convinced that the Knights Templar in some guise or other control the world. How do they come to this view?<br/><br/>A few months ago, I was talking to a young British Muslim and mentioned this blog. "Well, of course, they totally run the world, right?" I thought he was joking. He was university educated, very bright and well read. But no. He meant it. 100%.<br/><br/>Similarly, I've come across people who argue that Pope Francis, as a Jesuit, must be part of a Templar plot because the Jesuits are really secret Templars.<br/><br/>Let me run through some of the recent theories I've discovered online about Templars running the world:<br/><br/>Templars control us from Switzerland<br/><br/>Haven't you ever noticed how similar the Swiss and Templar flags are?<br/><br/>Swiss neutrality is not a result of loving peace but because they are too busy orchestrating wars through which the Templars control us | Тамплиерите контролират ли света днес?<br/><br/>Срещам се и разговарям с хора в много различни ситуации, които са убедени, че Рицарите Тамплиери в един или друг облик контролират света.<br/><br/>Преди няколко месеца говорих с млад британски мюсюлманин и споменах този блог. "Е, разбира се, те напълно управляват света, нали?" Мислех, че се шегува. Той беше университетски образован, много умен и добре четен. Но не. Той го мислеше. 100%.<br/><br/>По същия начин съм срещал хора, които твърдят, че папа Франциск, като йезуит, трябва да е част от заговор на тамплиерите, защото йезуитите са наистина тайни тамплиери.<br/><br/>Нека да прегледам някои от последните теории, които открих онлайн за тамплиерите, управляващи света:<br/><br/>Тамплиерите ни контролират от Швейцария<br/><br/>Не си ли забелязал колко си приличат швейцарското и тамплиерското знамета?<br/><br/>Швейцарският неутралитет не е резултат от любящ мир, а защото те са твърде заети да организират войни, чрез които тамплиерите ни контролират. |
| Rally is a dog sport that builds on obedience training and teaches agility skills. Participants move from station to station working on different skills and patterns through teamwork between handler and dog. There are several levels of Rally obedience. This class will be a prerequisite for the next level offered in the summer. Dogs must have attended at least one full obedience course of 6 to 8 classes before enrolling. Bring veterinarian papers with vaccination proof the first night of class. Bring your dog the first night. Dogs 16 weeks and up. No class 6-25-18. | Ралито е кучешки спорт, който се основава на обучение за послушание и учи на умения за ловкост. Участниците се движат от станция на станция, работейки върху различни умения и модели чрез работа в екип между водача и кучето. Има няколко нива на рали послушание. Този клас ще бъде предпоставка за следващото ниво, предлагано през лятото. Кучетата трябва да са посещавали поне един пълен курс на послушание от 6 до 8 класа, преди да се запишат. Носете ветеринарни документи с доказателство за ваксинация през първата нощ на класа. Вземете кучето си първата нощ. Кучета 16 седмици и нагоре. Без клас 6-25-18. |
| Ahah, thanks. Since I've collected everything for the home instance so far, I'm adding that. Everything but the treasure chest thing, anyway. Hooray for having cleared my bank out of some valuable cruft the other day, I didn't have to toss cash at it!It also comes down to usability, a salvage-o-matic provides different levels of convenience depending on how much you intend to use it, because the action of salvaging is repeatable, up to thousands of times a day if you were so inclined.<br/><br/>Same for an infinite harvesting tool, you can run around the open world harvesting for 8 hours a day if you wish.<br/><br/>These home nodes are novelty items, not convenience items. They provide exactly one use every 24 hours, incredibly limited usability. And essentially they save you from tapping your "O" key and buying up to 12 T1 – T3 light scraps once a day. Which, arguably, I think is actually the more convenient option.<br/><br/>Now if these worked like regular nodes, where they refreshed every hour, then I would consider them convenience items. And they'd work similarly to salvage-o-matics and infinite tools in that what you get out of them is essentially what you're willing to put into them. I think very few players would actually be disciplined enough to swap to their Home character and mine them every hour on the hour.<br/><br/>But as novelty items, that makes it no different from spending 200g on one skin versus a free to apply skin. If that's what you're into, go for it.<br/><br/>But a skin is something you would actually get use from considering GW2 endgame is basically dress up wars 2. The harvesting tools and salvage tools are great convenience items.<br/><br/>The node packs, OTOH, are a waste of time and money. Going to the TP and buying 200 scraps at once rather than 5 minutes a day for 2 months to get the same thing is silly. I don't care if you buy them, but my original point is it's a fair comparison to make with the amount of gold/gems they cost.<br/><br/>Well, it's the Basic Cloth Rack, there really isn't any reason to believe it would be any different from the Basic Lumber and Basic Ore Nodes packs: a pittance of the lowest three tiers every 24 hoursIf they would offer a bank for the home instance, than it would be for convenience yes. But nodes, no. A node is simply for profit. I can imagine that it could offer some convenience IF it was certain what you will get. That is not the case. So again: no, this is not for convenience.<br/><br/>I bought it immediately when it came out. Sure, it'll never pay for itself, but I like having that extra source of cloth and the idea of my mule just wandering over each day and stealing clothes off some poor merchant's rack is hilarious. XDAccording to the wiki this does NOT count toward Daily GathererAt least in the case of the cloth rack, it seems to me that helps people who have only high level characters get some low-level cloth without buying it off the TP, since loot drops will mostly be higher level stuffIndeed. It is still a convenient way to get a bunch of low level crafting materials though. The daily gathering part was more to the nodes as a whole in the home instance, seeing as we have had the exact same thread every single time one of these were released.<br/><br/>Low level cloth items are harder to get due to scaling. High level characters usually don't get low enough stuff to salvage into the lower tier materials.<br/><br/>I really thought I'll have 3 of each when I bought it. I mean, all of the others stuff like that works that way, and costs 1000 gems. I'm really disappointed can we ask for a refound or something ? I'm so tired of all RNG mechanics in this, and now even the stuff we buy on TP provides us RNG based results…There is no waypoint rezzing in real life,<br/>but there are people who will help you get back up when you are downed<br/>- PalwaJokoANet, please upgrade my Cloth Rack so it also gives out Linen and Silk, kthx. | Ах, благодаря. Тъй като съм събрал всичко за домашния случай до този момент, добавям това. Всичко, освен сандъка със съкровището, така или иначе. Ура за това, че изчистих банката си от някакъв ценен боклук онзи ден, не трябваше да хвърлям пари в брой! Също така се свежда до използваемост, saving-o-matic осигурява различни нива на удобство в зависимост от това колко възнамерявате да го използвате, защото действието на salvaging е повторяемо, до хиляди пъти на ден, ако сте били толкова склонни.<br/><br/>Същото важи и за безкраен инструмент за прибиране на реколтата, можете да тичате около събирането на реколтата в отворен свят по 8 часа на ден, ако желаете.<br/><br/>Тези домашни възли са елементи на новост, а не на удобство. Те осигуряват точно една употреба на всеки 24 часа, невероятно ограничена използваемост. И по същество те ви спестяват от подслушване на вашия "O" ключ и закупуване на до 12 T1 – T3 леки отпадъци веднъж на ден. Което, може би, мисля, всъщност е по-удобният вариант.<br/><br/>Ако тези работиха като обикновени възли, където се опресняваха на всеки час, тогава бих ги смятал за удобни предмети. И те биха работили подобно на спасителната-о-матика и безкрайните инструменти в това, че това, което се получава от тях, е по същество това, което сте готови да вложите в тях. Мисля, че много малко играчи всъщност биха били достатъчно дисциплинирани, за да разменят домашния си характер и да ги добиват на всеки час.<br/><br/>Но като новост, това не го прави по-различно от това да похарчиш 200 грама за една кожа, срещу свободното нанасяне на кожа.<br/><br/>Но кожата е нещо, което всъщност ще се използва от обмислянето на GW2 ендшпил е основно обличане на войни 2. Инструментите за прибиране на реколтата и спасителните инструменти са много удобни предмети.<br/><br/>Пакетите от възли, OTOH, са загуба на време и пари. Отиването на TP и купуването на 200 парчета наведнъж, а не 5 минути на ден в продължение на 2 месеца, за да се получи едно и също нещо, е глупаво. Не ме интересува дали ще ги купите, но първоначалната ми мисъл е, че е справедливо да се направи сравнение с количеството злато/скъпоценности, които струват.<br/><br/>Е, това е Basic Cloth Rack, наистина няма причина да се смята, че ще бъде по-различно от пакетите Basic Lumber и Basic Ore Nodes: подаяние от най-ниските три нива на всеки 24 часаАко те биха предложили банка за домашната инстанция, отколкото би било за удобство да. Но възли, не. Възелът е просто за печалба. Мога да си представя, че може да предложи някакво удобство, ако е сигурно какво ще получите. Това не е така. Така че отново: не, това не е за удобство.<br/><br/>Купих го веднага, когато излезе. Разбира се, никога няма да се изплати, но ми харесва да имам този допълнителен източник на плат и идеята, че моето муле просто се скита всеки ден и краде дрехи от багажник на някой беден търговец е смешна. XDСпоред уикито това НЕ се брои към Daily GathererПоне в случая с закачалката за платове, струва ми се, че помага на хората, които имат само знаци от високо ниво, да получат някаква кърпа от ниско ниво, без да я купуват от TP, тъй като капките за плячка най-вече ще бъдат неща от по-високо нивоНаистина. Това все още е удобен начин да получите куп ниско ниво занаятчийски материали все пак. Ежедневната събирателна част беше повече за възлите като цяло в домашната инстанция, тъй като сме имали точно една и съща нишка всеки път, когато една от тези бяха освободени.<br/><br/>Платнени предмети от ниско ниво са по-трудни за получаване поради мащабиране. Героите от високо ниво обикновено не получават достатъчно ниски неща, за да се спасят в по-ниските материали.<br/><br/>Наистина мислех, че ще имам по 3 от всеки, когато го купя. Искам да кажа, всички други неща като това работи по този начин, и струва 1000 скъпоценни камъни. Аз съм наистина разочарован може ли да поискаме повторно основаване или нещо такова ? Толкова съм уморен от всички RNG механици в това, а сега дори нещата, които купуваме на TP, ни осигуряват резултати, базирани на RNG... В реалния живот няма точка на пречупване, но има хора, които ще ви помогнат да се изправите, когато сте свалени<br/>- PalwaJokoANet, моля надстройте ми кърпа Rack така че също така дава бельо и коприна, kthx. |
| I enjoy reading Corey Quinn's Last week in AWS newsletter. And also really like his podcast Screaming in the cloud. This week Corey talks with Jay Gordon from Mongodb. While Jay seems somewhat of an advocate of multicloud, Corey is decidedly critical. Which makes for a great interview!<br/><br/>Corey also wrote a piece The Myth of cloud agnosticism. I like any writing that dubs a popular trope as a "myth" because it's an opportunity to poke holes in optimism.<br/><br/>It is through this process that we become realistic, which is crucial to being reliable in operations and engineering.<br/><br/>Corey argues that multicloud, with respect to multiple infrastructure providers is usually a crappy idea. That's because the cloud providers are evolving, your application is evolving, and it costs you in terms of feature velocity. What's more it provides dubious instant uptime in the DR realm.<br/><br/>The topic reminds me of similar myths in computer science… the myth of cross platform development or<br/>the myth of the cross platform databases the myth of object relational modeling.<br/><br/>As always your mileage may vary. Here are my questions. Hope they can help provide perspective, and critical thinking around this.<br/><br/>1. Do you plan to use multiple cloud providers for infrastructure? And deploy your application twice?<br/>2. Do you plan to use multiple SaaS providers?<br/>3. Does hybrid cloud make sense? That's an option where you deploy a data link to a public cloud, keeping some assets in your own datacenter.<br/>4. Are their feature parallels across your chosen clouds? Or are there feature mismatches?<br/>5. Your cloud providers have independent service level agreements. Are they consistent or not?<br/><br/>6. What does the outage history look like for each of your providers?<br/>7. What is the potential for fatfinger outage on each platform? For example one may be unduly complicated and prone to mistakes, based on API or dashboard interface.<br/>8. Is one cloud more complicated to implement? For example Amazon Web Services while being more feature rich, is also much more complicated to deploy than a Digital Ocean setup.<br/>9. You can see your backups on both platforms. Have you done restores on both? Regularly? Recently?<br/>10. Do you have time to automate everything twice? For example you may need to rewrite your ansible playbooks for each platform<br/><br/>11. What is driving your business to embrace the idea of multicloud?<br/>12. Do you have time to rewrite scripts twice? one-off and user-data scripts alike?<br/>13. Do you have time to firedrill twice? Smoketest twice?<br/>14. Will different clouds fail in different ways? For example one might be weak around it's network. Another might be weak around it's database service, and a third might encounter multi-tenant traffic congestion (disk or network).<br/>15. When one cloud doesn't support a feature, Ex: lifecycle policies on S3 buckets, do you need to build it for the other cloud?<br/><br/>16. Will deploying multicloud encourage abstraction layers Ex: object relational modelers (ORM) which heavily slow down performance?<br/>17. Have you tested performance on both clouds?<br/>18. Is cloud #2 a temporary disaster recovery solution or an on-going load balancing solution via geo-dns?<br/>19. If you go hybrid cloud, how does that impact security, firewalls, and access controls?<br/>20. How do you monitor your object stores (S3), scanning for open buckets? Do you rewrite this code for the other API?<br/><br/>21. What are the disaster types you're planning for?<br/>22. What is the cost of maintaining your application on multiple platforms?<br/>23. What is the cost of building infra for multiple platforms?<br/>24. What is the cost of debugging & troubleshooting on multiple platforms?<br/>25. How does multcloud complicate deployments?<br/><br/>26. Does multicloud complicate GDPR and other compliance questions?<br/>27. How does multicloud complicate your billing and budget management?<br/>28. What about microservices? How will these multiple platforms play across two clouds?<br/>29. Is the community around each cloud equally active?<br/>30. If you deploy with an infrastructure as code language like Terraform, is there an active community there for both of your chosen clouds?<br/><br/>31. Does each provider support customers well? What are their respective reputations?<br/>32. Is each cloud provider equally solvent & invested in the business? Will they be around in a year? five years? ten years?<br/>33. What complications arise when migrating to or from this provider?<br/><br/>EKS is a service to run kubernetes, so you don't have to install the software, or manage or patch it. Just like GKS on Google, kubernetes as a service is really the way to go if you want to build kubernetes apps on AWS.<br/><br/>So where do we get started? AWS docs are still coming together, so it's not easy. I would start with Jerry Hargrove's amazing EKS diagram. If a picture is worth a thousand words, this one is work 10,000!<br/><br/>1. Build your EKS cluster<br/><br/>I already did this in Terraform. There aren't a lot of howtos, so I wrote one.<br/><br/>Basically you setup the service role, the cluster, then the worker nodes. Once you've done that you're ready to run the demo app.<br/><br/>2. Build your app spec<br/><br/>These are very similar to ECS tasks. You'll need to make slight changes. mountPoints become VolumeMounts, links get removed, and workingDirectory becomes workingDir and so on. Most of these changes are obvious, but the json syntax is obviously the biggest bear you'll wrestle with.<br/><br/>It's not if, but when to move to the cloud, how to get there, and how fast will be the transition?<br/><br/>Here are my thoughts on what to start thinking about.<br/><br/>1. Ramp up team, skills & paradigm thinking<br/><br/>Teams with experience in traditional datacenters have certain ways of architecting solutions, and thinking about problems. For example they may choose NFS servers to host objects, where in the cloud you will use object storage such as S3.<br/><br/>S3 has all sorts of new features, like lifecycle policies, and super super redundant eleven 9's of durability. But your applications may need to be retrofitted to work with it, and your devs may need to learn about new features and functionality.<br/><br/>What about networking? This changes a lot in the cloud, with VPCs, and virtual appliances like NATs and Gateways. And what about security groups?<br/><br/>Interacting with this new world of cloud resources, requires new skillsets and new ways of thinking. So priority one will be getting your engineering teams learning, and upgrading skills. I wrote a piece about this how do I migrate my skills to the cloud?<br/><br/>2. Adapt to a new security model<br/><br/>With the old style datacenter, you typically have a firewall, and everything gets blocked & controlled. The new world of cloud computing uses security groups. These can be applied at the network level, across your VPC, or at the server level. And of course you can have many security groups with overlapping jurisdictions. Here's how you setup a VPC with Terraform<br/><br/>So understanding how things work in the public cloud is quite new and challenging. There are ingress and egress rules, ways to audit with network flow logs, and more.<br/><br/>However again, it's one thing to have the features available, it's quite another to put them to proper use.<br/><br/>3. Adapt to fragile components & networks<br/><br/>While the public cloud collectively is extremely resilient, the individual components such as EC2 instances are decidedly not reliable. It's expected that they can and will die frequently. It's your job as the customer to build things in a self-healing way.<br/><br/>That means VPCs with multiple subnets, across availability zones (multi-az). And that means redundant instances for everything. What's more you front your servers with load balancers (classic or application). These themselves are redundant.<br/><br/>Whether you are building a containerized application and deploying on ECS or a traditional auto-scaling webserver with database backend, you'll need to plan for failure. And that means code that detects, and reacts to such failures without downtime to the end user.<br/><br/>So there's a learning curve. Both for your operations teams who have previously called Rackspace to get a new server provisioned. And also for your business, learning what incurs an outage, and the tricky finicky sides to managing your public cloud through code.<br/><br/>5. Audit, log & monitor<br/><br/>As you automate more and more pieces, you may have less confidence in the overall scope of your deployments. How many servers am I using right now? How many S3 buckets? What about elastic IPs?<br/><br/>As your automation can itself spinup new temporary environments, those resource counts will change from moment to moment. Even a spike in user engagement or a sudden flash sale, can change your cloud footprint in an instant.<br/><br/>That's where heavy use of logging such as ELK (elasticsearch, logstash and kibana) can really help. Sure AWS offers CloudWatch and CloudTrail, but again you must put it all to good use.<br/><br/>I've been on both sides of the fence, at times interviewing candidates, and other times the candidate looking to impress to win a new role.<br/><br/>Here are my suggestions…<br/><br/>Devops Pipeline<br/><br/>Jenkins isn't the only build server, but it's been around a long time, so it's everywhere. You can also do well with CircleCI or Travis. Or even Amazon's own CodeBuild & CodePipeline.<br/><br/>You should also be comfortable with a configuration management system. Ansible is my personal favorite but obviously there is lots of Puppet & Chef out there too. Talk about a playbook you wrote, how it configures the server, installs packages, edits configs and restarts services.<br/><br/>Bonus points if you can talk about handling deployments with autoscaling groups. Those dynamic environments can't easily be captured in static host manifests, so talk about how you handle that.<br/><br/>Of course you should also be strong with Git, bitbucket or codecommit. Talk about how you create a branch, what's gitflow and when/how do you tag a release.<br/><br/>Also be ready to talk about how a code checkin can trigger a post commit hook, which then can go and build your application, or new infra to test your code.<br/><br/>CloudFormation or Terraform<br/><br/>I'm partial to Terraform. Terraform is MacOSX or iPhone to CloudFormation as Android or Windows. Why do I say that? Well it's more polished and a nicer language to write in. CloudFormation is downright ugly. But hey both get the job done.<br/><br/>AWS Services<br/><br/>There are lots of them. But the core services, are what you should be ready to talk about. CloudWatch for centralized logging. How does it integrate with ECS or EKS?<br/><br/>Route53, how do you create a zone? How do you do geo load balancing? How does it integrate with CertificateManager? Can Terraform build these things?<br/><br/>EC2 is the basic compute service. Tell me what happens when an instance dies? When it boots? What is a user-data script? How would you use one? What's an AMI? How do you build them?<br/><br/>What about virtual networking? What is a VPC? And a private subnet? What's a public subnet? How do you deploy a NAT? WHat's it for? How do security groups work?<br/><br/>What are S3 buckets? Talk about infraquently accessed? How about glacier? What are lifecycle policies? How do you do cross region replication? How do you setup cloudfront? What's a distribution?<br/><br/>What types of load balancers are there? Classic & Application are the main ones. How do they differ? ALB is smarter, it can integrate with ECS for example. What are some settings I should be concerned with? What about healthchecks?<br/><br/>What is Autoscaling? How do I setup EC2 instances to do this? What's an autoscaling group? Target? How does it work with ECS? What about EKS?<br/><br/>Devops isn't about writing application code, but you're surely going to be writing jobs. What language do you like? Python and shell scripting are a start. What about Lambda? Talk about frameworks to deploy applications.<br/><br/>Databases<br/><br/>You should have some strong database skills even if you're not the day-to-day DBA. Amazon RDS certainly makes administering a bit easier most of the time. But upgrade often require downtime, and unfortunately that's wired into the service. I see mostly Postgresql, MySQL & Aurora. Get comfortable tuning SQL queries and optimizing. Analyze your slow query log and provide an output.<br/><br/>Amazon's analytics offering is getting stronger. The purpose built Redshift is everywhere these days. It may use a postgresql driver, but there's a lot more under the hood. You also may want to look at SPectrum, which provides a EXTERNAL TABLE type interface, to query data directly from S3.<br/><br/>Not on Redshift yet? Well you can use Athena as an interface directly onto your data sitting in S3. Even quicker.<br/><br/>For larger data analysis or folks that have systems built around the technology, Hadoop deployments or EMR may be good to know as well. At least be able to talk intelligently about it.<br/><br/>Questions<br/><br/>Have you written any CloudFormation templates or Terraform code? For example how do you create a VPC with private & public subnets, plus bastion box with Terraform? What gotches do you run into?<br/><br/>If you are given a design document, how do you proceed from there? How do you build infra around those requirements? What is your first step? What questions would you ask about the doc?<br/><br/>What do you know about Nodejs? Or Python? Why do you prefer that language?<br/><br/>If you were asked to store 500 terrabytes of data on AWS and were going to do analysis of the data what would be your first choice? Why? Let's say you evaluated S3 and Athena, and found the performance wasn't there, what would you move to? Redshift? How would you load the data?<br/><br/>Describe a multi-az VPC setup that you recommend. How do you deploy multiple subnets in a high availability arragement?<br/><br/>Here are a few of the lessons I learned in the process of building code for AWS. It's not easy but when you get there you can enjoy the vistas. They're pretty amazing.<br/><br/>Don't pass credentials<br/><br/>As you build your applications, there are moments where components need to use AWS in some way. Your webserver needs to use S3 or your ELK box needs to use CloudWatch. Maybe you want to do an RDS backup, or list EC2 instances.<br/><br/>However it's not safe to pass your access_key and secret_access_key around. Those should be for your desktop only. So how best to handle this in the cloud?<br/><br/>IAM roles to the rescue. These are collections of privileges. The cool thing is they can be assigned at the INSTANCE LEVEL. Meaning your whole server has permissions to use said resources.<br/><br/>Do this by first creating a role with the privileges you want. Create a json policy document which outlines the specific rules as you see fit. Then create an instance profile for that role.<br/><br/>When you create your ec2 instance in Terraform, you'll specify that instance profile. Either by ARN or if Terraform created it, by resource ID.<br/><br/>Keep passwords out of code<br/><br/>Even though we know it should not happen, sometimes it does. We need to be vigilant to stay on top of this problem. There are projects like Pivotal's credential scan. This can be used to check your source files for passwords.<br/><br/>What about something like RDS? You're going to need to specify a password in your Terraform code right? Wrong! You can define a variable with no default as follows:<br/><br/>variable "my_rds_pass" {<br/>description = "password for rds database"<br/>}<br/><br/>When Terraform comes upon this variable in your code, but sees there is no "default" value, it will prompt you when you do "$ terraform apply"<br/><br/>Versioning your code<br/><br/>When you first start building terraform code, chances are you create a directory, and some tf files, then do your "$ terraform apply". When you watch that infra build for the first time, it's exciting!<br/><br/>After you add more components, your code gets more complex. Hopefully you've created a git repo to house your code. You can check & commit the files, so you have them in a safe place. But of course there's more to the equation than this.<br/><br/>How do you handle multiple environments, dev, stage & production all using the same code?<br/><br/>That's where modules come in. Now at the beginning you may well have a module that looks like this:<br/><br/>Etc and so on. That's the first step in the right direction, however if you change your source code, all of your environments will now be using that code. They will get it as soon as you do "$ terraform apply" for each. That's fine, but it doesn't scale well.<br/><br/>Ultimately you want to manage your code like other software projects. So as you make changes, you'll want to tag it.<br/><br/>Cool! Now each dev, stage and prod can reference a different version. So you are free to work on the infra without interrupting stage or prod. When you're ready to promote that code, checkin, tag and update stage.<br/><br/>You could go a step further to be more agile, and have a post-commit hook that triggers the stage terraform apply. This though requires you to build solid infra tests. Checkout testinfra and terratest.<br/><br/>Managing RDS backups<br/><br/>My recent discovery is even more serious! Terraform wants to build infra. And it wants to be able to later destroy that infra. In the case of databases, obviously the previous state is one you want to keep. You want that to be perpetual, beyond the infra build. Obvious, no?<br/><br/>Apparently not to the folks at Amazon. When you destroy an RDS instance it will destroy all the old backups you created. I have no idea why anyone would want this. Certainly not as a default behavior. What's worse you can't copy those backups elsewhere. Why not? They're probably sitting in S3 anyway!<br/><br/>While you can take a final backup when you destroy an RDS instance, that's wondeful and I recommend it. However that's not enough. I highly suggest you take matters into your own hands. Build a script that calls pg_dump yourself, and copy those .sql or .dump files to S3 for safe keeping.<br/><br/>When to use force_destroy on S3 buckets<br/><br/>As with RDS, when you create S3 buckets with your infra, you want to be able to cleanup later. But the trouble is that once you create a bucket, you'll likely fill it with objects and files.<br/><br/>What then happens is when you go to do "$ terraform destroy" it will fail with an error. This makes sense as a default behavior. We don't want data disappearing without our knowledge.<br/><br/>However you do want to be able to cleanup. So what to do? Two things.<br/><br/>Firstly, create a process, perhaps a lambda job or other bucket replication to regularly sync your s3 bucket to your permanent bucket archive location. Run that every fifteen minutes or as often as you need.<br/><br/>Then add a force_destroy line to your s3 bucket resource. Here's an example s3 bucket for storing load balancer logs:<br/><br/>When you see headlines like this, your first instinct as a CTO is probably, "Am I at risk?" And then "What are the chances of this happening to me?"<br/><br/>Truth can be stranger than fiction. Our efforts as devops should be towards mitigating risk, and reducing potential for these kinds of things to happen.<br/><br/>1. Use aws instance profiles instead<br/><br/>Those credentials that aws provides, are great for enabling the awscli. That's because you control your desktop tightly. Don't you?<br/><br/>But passing them around in your application code is prone to trouble. Eventually they'll end up in a git repo. Not good!<br/><br/>The solution is applying aws IAM permissions at the instance level. That's right, you can grant an instance permissions to read or write an s3 bucket, describe instances, create & write to dynamodb, or anything else in aws. The entire cloud is api configurable. You create a custom policy for your instance, and attach it to a named instance profile.<br/><br/>When you spinup your EC2 instance, or later modify it, you attach that instance profile, and voila! The instance has those permissions! No messy credentials required!<br/><br/>3. blah blah<br/><br/>Hey, while you're at it, why not add a post commit hook to your code repo in git. Have it run the credentials scan each time code is committed. And when it finds trouble, it should email out the whole team.<br/><br/>ECS is Amazon's Elastic Container Service. That's greek for how you get docker containers running in the cloud. It's sort of like Kubernetes without all the bells and whistles.<br/><br/>It takes a bit of getting used to, but This terraform how to, should get you moving. You need an EC2 host to run your containers on, you need a task that defines your container image & resources, and lastly a service which tells ECS which cluster to run on and registers with ALB if you have one.<br/><br/>For each of these sections, create files: roles.tf, instance.tf, task.tf, service.tf, alb.tf. What I would recommend is create the first file roles.tf, then do:<br/><br/>$ terraform init<br/>$ terraform plan<br/>$ terraform apply<br/><br/>Then move on to instance.tf and do the terraform apply. One by one, next task, then service then finally alb. This way if you encounter errors, you can troubleshoot minimally, rather than digging through five files for the culprit.<br/><br/>I recommend deploying in the public subnets for your first run, to avoid complexity of jump box, and private IPs for ecs instance etc.<br/><br/>Good luck!<br/><br/>May the terraform force be with you!<br/><br/>First setup roles<br/><br/>Roles are a really brilliant part of the aws stack. Inside of IAM or identity access and management, you can create roles. These are collections of privileges. I'm allowed to use this S3 bucket, but not others. I can use EC2, but not Athena. And so forth. There are some special policies already created just for ECS and you'll need roles to use them.<br/><br/>These roles will be applied at the instance level, so your ecs host doesn't have to pass credentials around. Clean. Secure. Smart!<br/><br/>Setup your ecs host instance<br/><br/>Next you need EC2 instances on which to run your docker containers. Turns out AWS has already built AMIs just for this purpose. They call them ECS Optimized Images. There is one unique AMI id for each region. So be sure you're using the right one for your setup.<br/><br/>The other thing that your instance needs to do is echo the cluster name to /etc/ecs/ecs.config. You can see us doing that in the user_data script section.<br/><br/>Lastly we're configuring our instance inside of an auto-scaling group. That's so we can easily add more instances dynamically to scale up or down as necessary.<br/><br/>Setup your task definition<br/><br/>The third thing you need is a task. This one will spinup a generic nginx container. It's a nice way to demonstrate things. For your real world usage, you'll replace the image line with a docker image that you've pushed to ECR. I'll leave that as an exercise. Once you have the cluster working, you should get the hang of things.<br/><br/>Note the portmappings, memory and CPU. All things you might expect to see in a docker-compose.yml file. So these tasks should look somewhat familiar.<br/><br/>Setup your service definition<br/><br/>The fourth thing you need to do is setup a service. The task above is a manifest, describing your containers needs. It is now registered, but nothing is running.<br/><br/>When you apply the service your container will startup. What I like to do is, ssh into the ecs host box. Get comfortable. Then issue $ watch "docker ps". This will repeatedly run "docker ps" every two seconds. Once you have that running, do your terraform apply for this service piece.<br/><br/>As you watch, you'll see ECS start your container, and it will suddenly appear in your watch terminal. It will first show "starting". Once it is started, it should say "healthy".<br/><br/>Setup your application load balancer<br/><br/>The above will all work by itself. However for a real-world use case, you'll want to have an ALB. This one has only a simple HTTP port 80 listener. These are much simpler than setting up 443 for SSL, so baby steps first.<br/><br/>Once you have the ALB going, new containers will register with the target group, to let the alb know about them. In "docker ps" you'll notice they are running on a lot of high numbered ports. These are the hostPorts which are dynamically assigned. The container ports are all 80.<br/><br/>You will also want to add a domain name, so that as your infra changes, and if you rebuild your ALB, the name of your application doesn't vary. Route53 will adjust as terraform changes are applied. Pretty cool.<br/><br/>ECS is Amazon's elastic container service. If you have a dockerized app, this is one way to get it deployed in the cloud. It is basically an Amazon bootleg Kubernetes clone. And not nearly as feature rich! 🙂<br/><br/>That said, ECS does work, and it will allow you to get your application going on Amazon. Soon enough EKS (Amazon's Kubernetes service) will be production, and we'll all happily switch.<br/><br/>Meantime, if you're struggling with the weird errors, and when it is silently failing, I have some help here for you. Hopefully these various error cases are ones you've run into, and this helps you solve them.<br/><br/>Why is my container in a stopped state?<br/><br/>Containers can fail for a lot of different reasons. The litany of causes I found were:<br/><br/>When ecs repeatedly fails, it leaves around stopped containers. These eat up system resources, without much visible feedback. "df -k" or "df -m" doesn't show you volumes filled up. *BUT* there are logical volumes which can fill.<br/><br/>3. My container gets killed before fully started<br/><br/>When a service is run, ECS wants to have *all* of the containers running together. Just like when you use docker-compose. If one container fails, ecs-agent may decide to kill the entire service, and restart. So you may see weird things happening in "docker logs" for one container, simply because another failed. What to do?<br/><br/>First look at your task definition, and set "essential = false". That way if one fails, the other will still run. So you can eliminate the working container as a cause.<br/><br/>Next thing is remember some containers may startup almost instantly, like nginx for example. Because it is a very small footprint, it can start in a second or two. So if *it* depends on another container that is slow, nginx will fail. That's because in the strange world of docker discovery, that other container doesn't even exist yet. While nginx references it, it says hey, I don't see the upstream server you are pointing to.<br/><br/>Solution? Be sure you have a "links" section in your task definition. This tells ecs-agent, that one container depends on another (think of the depends_on flag in docker-compose).<br/><br/>4. Understanding container ordering<br/><br/>As you are building your ecs manifest aka task definition, you want to run through your docker-compose file carefully. Review the links, essential flags and depends_on settings. Then be sure to mirror those in your ECS task.<br/><br/>When in doubt, reduce the scope of your problem. That is define *only one* container, then start the service. Once that container works, add a second. When you get that working as well, add a third or other container.<br/><br/>This approach allows you to eliminate interconnecting dependencies, and related problems. | Приятно ми е да чета последната седмица на Кори Куин в бюлетина на AWS. И също така наистина харесвам подкаста му Screaming in the cloud. Тази седмица Кори разговаря с Джей Гордън от Mongodb. Докато Джей изглежда донякъде застъпник на мултиоблака, Кори определено е критичен. Което прави едно страхотно интервю!<br/><br/>Кори също е написал парче Митът за облачния агностицизъм. Харесва ми всяко писане, което дублира популярна тропа като "мит", защото това е възможност да се пробият дупки в оптимизма.<br/><br/>Именно чрез този процес ние ставаме реалистични, което е от решаващо значение, за да бъдем надеждни в операциите и инженерството.<br/><br/>Кори твърди, че мултиоблакът, по отношение на множество доставчици на инфраструктура, обикновено е скапана идея. Това е така, защото доставчиците на облак се развиват, приложението ви се развива и това ви струва по отношение на скоростта на функции. Нещо повече, тя осигурява съмнително незабавно време за работа в царството на ДР.<br/><br/>Темата ми напомня за подобни митове в компютърните науки... митът за крос платформата или митът за крос платформата бази данни, митът за обектното релационно моделиране.<br/><br/>Както винаги вашият пробег може да варира. Ето моите въпроси. Надявам се, че те могат да помогнат да се осигури перспектива, и критично мислене около това.<br/><br/>1. Планирате ли да използвате множество доставчици на облак за инфраструктура? И да разположите приложението си два пъти?<br/>2. Планирате ли да използвате множество SaaS доставчици?<br/>3. има ли смисъл хибриден облак? Това е опция, при която разгръщате връзка за данни към публичен облак, като запазвате някои активи в собствения си център за данни.<br/>4. са техните характеристики паралели в избраните от вас облаци? или има функция несъответствия?<br/>5. Вашите доставчици на облачни услуги имат независими споразумения за ниво на обслужване. Последователни ли са или не?<br/><br/>6. Как изглежда историята на прекъсванията за всеки от вашите доставчици?<br/>7. Какъв е потенциалът за прекъсване на fatfinger на всяка платформа? Например един може да бъде ненужно сложен и склонен към грешки, въз основа на API или интерфейс на таблото.<br/>8. Един облак по-сложен ли е за внедряване? Например Amazon Web Services, докато е по-богат на функции, също е много по-сложен за разполагане от настройката Digital Ocean.<br/>9. Можете да видите резервните копия и на двете платформи. Правили ли сте възстановявания и на двете? Редовно? Наскоро?<br/>10. Имате ли време да автоматизирате всичко два пъти? Например може да се наложи да пренапишете вашите asible playbooks за всяка платформа<br/><br/>11. Какво кара вашия бизнес да приеме идеята за мултиоблака?<br/>12. Имате ли време да пренапише скриптове два пъти? еднократни и потребителски данни скриптове, така?<br/>13.Имаш ли време да стреляш два пъти?<br/>14. Ще се провалят ли различни облаци по различни начини? Например един може да е слаб около мрежата си. Друг може да е слаб около услугата за бази данни, а трети може да се натъкне на задръствания с множество наематели (диск или мрежа).<br/>15. Когато един облак не поддържа функция, Ex: правила за жизнения цикъл на S3 кофи, трябва ли да го изградите за другия облак?<br/><br/>16. Разгръщането на multicloud ще насърчи абстракционните слоеве Ex: обектни релационни модели (ORM), които силно забавят производителността?<br/>17. Тествали ли сте производителността и на двата облака?<br/>18. Дали облак # 2 е временно решение за възстановяване при бедствия или текущо решение за балансиране на натоварването чрез гео-днове?<br/>19. Ако отидете хибриден облак, как това се отразява на сигурността, защитните стени и контролите за достъп?<br/>20. Как наблюдавате обектите си (S3), сканирайки за отворени кофи? Преписвате ли този код за другия API?<br/><br/>21. Какви са видовете бедствия, които планирате?<br/>22. Каква е цената за поддържане на вашето приложение на множество платформи?<br/>23. Каква е цената за изграждане на инфра за множество платформи?<br/>24. Каква е цената на отстраняване на грешки и отстраняване на неизправности на множество платформи?<br/>25. Как multcloud усложнява разполагането?<br/><br/>26. Дали multicloud усложнява GDPR и други въпроси за съответствие?<br/>27. Как multicloud усложнява фактурирането и управлението на бюджета?<br/>28. Какво ще кажете за микроуслугите? Как ще играят тези множество платформи през два облака?<br/>29. Дали общността около всеки облак е еднакво активна?<br/>30. Ако се разположите с инфраструктура като кодов език като Terraform, има ли активна общност и за двата избрани облака?<br/><br/>31. Дали всеки доставчик поддържа клиентите добре? Какви са съответните им репутации?<br/>32. Дали всеки доставчик на облачни услуги е еднакво платежоспособен и инвестиран в бизнеса? Ще бъдат ли около една година? пет години? десет години?<br/>33. Какви усложнения възникват при мигриране към или от този доставчик?<br/><br/>EKS е услуга, за да стартирате kubernetes, така че не е нужно да инсталирате софтуера, или да го управлявате или закърпите. Точно като GKS в Google, kubernetes като услуга е наистина начинът да отидете, ако искате да изградите kubernetes приложения на AWS.<br/><br/>И така, откъде да започнем? Документите на AWS все още се събират, така че не е лесно. Бих започнал с невероятната диаграма EKS на Джери Харгроув. Ако една снимка струва хиляда думи, това е работа 10 000!<br/><br/>1. Изградете своя EKS клъстер<br/><br/>Вече го направих в Terraform.Няма много Howtos, така че написах един.<br/><br/>По принцип настройвате обслужващата роля, клъстера, след това възлите на работниците. След като сте направили, че сте готови да стартирате демо приложението.<br/><br/>2. Изграждане на вашия ап спец<br/><br/>Това са много подобни на ECS задачи. Ще трябва да направите леки промени. mountPoints стават VolumeMounts, връзките се премахват и workDirectory става workingDir и така нататък. Повечето от тези промени са очевидни, но синтаксисът на json очевидно е най-голямата мечка, с която ще се борите.<br/><br/>Не е ако, а кога да се преместим в облака, как да стигнем до там и колко бързо ще бъде преходът?<br/><br/>Ето моите мисли за какво да започнем да мислим.<br/><br/>1. Ramp up екип, умения и парадигма мислене<br/><br/>Екипите с опит в традиционните центрове за данни имат определени начини за проектиране на решения и мислене за проблеми. Например те могат да изберат NFS сървъри за хостване на обекти, където в облака ще използвате обектно съхранение като S3.<br/><br/>S3 има всякакви нови функции, като например правила за жизнения цикъл и супер супер излишни единадесет 9's на трайност. Но вашите приложения може да се наложи да бъдат модернизирани, за да работят с него, и вашите devs може да се наложи да научат за нови функции и функционалност.<br/><br/>Какво ще кажете за работа в мрежа? Това се променя много в облака, с VPCs, и виртуални уреди като NATs и Gateways. А какво ще кажете за групи за сигурност?<br/><br/>Взаимодействието с този нов свят на облачни ресурси изисква нови умения и нови начини на мислене. Така че приоритет едно ще бъде да накарате инженерните си екипи да се учат и да усъвършенстват уменията си. Написах статия за това как да мигрирам уменията си в облака?<br/><br/>2. Адаптиране към нов модел за сигурност<br/><br/>При стария център за данни обикновено имате защитна стена и всичко се блокира и контролира. Новият свят на изчислителните облаци използва групи за защита. Те могат да се прилагат на мрежово ниво, през вашия VPC или на сървърно ниво. И разбира се, можете да имате много групи за сигурност с припокриващи се юрисдикции. Ето как се настройва VPC с Terraform<br/><br/>Така че разбирането как работят нещата в публичния облак е съвсем ново и предизвикателно. Има правила за влизане и излизане, начини за одит с мрежови потоци и др.<br/><br/>Въпреки това отново, това е едно нещо, за да има функции на разположение, това е съвсем друго да ги постави за правилна употреба.<br/><br/>3. Адаптиране към крехки компоненти и мрежи<br/><br/>Докато публичният облак колективно е изключително устойчив, отделните компоненти като EC2 инстанциите определено не са надеждни. Очаква се, че те могат и ще умират често. Вашата работа като клиент е да изграждате нещата по самовъзстановяващ се начин.<br/><br/>Това означава VPC-та с множество подмрежи, през зоните на наличност (multi-az). А това означава излишни инстанции за всичко. Какво повече ви пред сървърите си с балансьори на натоварване (класика или приложение). Самите те са излишни.<br/><br/>Независимо дали изграждате контейнеризирано приложение и внедрявате на ECS или традиционен уеб сървър за автоматично мащабиране с бекенд на база данни, ще трябва да планирате неуспех. А това означава код, който открива и реагира на такива повреди без престой на крайния потребител.<br/><br/>И двете са за оперативните ви екипи, които преди това са се обаждали на Rackspace, за да получат нов сървър. А също и за вашия бизнес, научавайки какво води до прекъсване, и трудните фини страни за управление на вашия публичен облак чрез код.<br/><br/>5. Одит, лог & монитор<br/><br/>Тъй като автоматизирате все повече и повече парчета, може да имате по-малко доверие в цялостния обхват на вашите внедрявания. Колко сървъра използвам в момента? Колко S3 кофи? Какво ще кажете за еластични IP-та?<br/><br/>Тъй като самата автоматизация може да създаде нови временни среди, броят на ресурсите ще се променя от момент на момент. Дори и скок в потребителската ангажираност или внезапна флаш продажба, могат да променят вашия облак отпечатък в един миг.<br/><br/>Това е мястото, където тежката употреба на сеч като ELK (elasticsearch, logstash и kibana) наистина може да помогне. Разбира се, AWS предлага CloudWatch и CloudTrail, но отново трябва да го използвате добре.<br/><br/>Бил съм и от двете страни на оградата, понякога интервюирам кандидати, а друг път кандидатът иска да впечатли, за да спечели нова роля.<br/><br/>Ето и моите предложения...<br/><br/>Тръбопровод Devops<br/><br/>Дженкинс не е единственият сървър за изграждане, но е бил наоколо дълго време, така че е навсякъде. Можете също да се справите добре с CircleCI или Травис. Или дори със собствения CodeBuild & CodePipeline на Amazon.<br/><br/>Също така трябва да се чувствате комфортно със система за управление на конфигурацията. Ansible е моят личен фаворит, но очевидно има и много Puppet & Chef там. Говорете за playbook, който сте написали, как конфигурира сървъра, инсталира пакети, редактира конфигурациите и рестартира услугите.<br/><br/>Бонус точки, ако можете да говорите за работа с внедрявания с групи за автоматично мащабиране. Тези динамични среди не могат лесно да бъдат уловени в статични манифести на хоста, така че говорете за това как се справяте с това.<br/><br/>Разбира се, вие също трябва да сте силни с Git, bitbucket или codecommit. Говорете за това как създавате клон, какво е gitflow и кога / как да маркирате издание.<br/><br/>Също така бъдете готови да говорите за това как проверка на кода може да задейства кука за пост къмит, която след това може да отиде и да изгради вашето приложение или нова инфра, за да тества вашия код.<br/><br/>CloudFormation или Тераформ<br/><br/>Пристрастен съм към Terraform. Terraform е MacOSX или iPhone към CloudFormation като Android или Windows. Защо казвам това? Ами това е по-полиран и по-хубав език за писане. CloudFormation е направо грозен. Но хей и двете си свърши работата.<br/><br/>Услуги на AWS<br/><br/>Има много от тях. Но основните услуги са това, за което трябва да сте готови да говорите. CloudWatch за централизирано регистриране. Как се интегрира с ECS или EKS?<br/><br/>Route53, как се създава зона? Как се балансира гео натоварването? Как се интегрира с CertificateManager? Може ли Terraform да изгради тези неща?<br/><br/>EC2 е основната изчислителна услуга. Кажете ми какво се случва, когато една инстанция умре? Когато се зареди? Какво е скрипт за потребителски данни? Как бихте използвали такъв? Какво е AMI? Как ги изграждате?<br/><br/>Какво ще кажете за виртуална мрежа? Какво е VPC? И частна подмрежа? Какво е публична подмрежа? Как се разполага NAT? За какво е? Как работят групите за сигурност?<br/><br/>Какво представляват кофите S3? Говорим за инфраструктурен достъп? Какво ще кажете за ледника? Какви са политиките за жизнения цикъл? Как се прави кръстосана репликация на региона? Как се настройва cloudfront? Какво е разпределение?<br/><br/>Какви са видовете балансьори на натоварването? Classic & Application са основните. Как се различават? ALB е по-умен, може да се интегрира с ECS например. Какви са някои настройки, с които трябва да се занимавам? Какво ще кажете за здравните проверки?<br/><br/>Какво е Autoscaling? Как да настроя екземпляри на EC2, за да направя това? Какво е група за автоматично мащабиране? Target? Как работи с ECS? Какво ще кажете за EKS?<br/><br/>Devops не е за писане на приложния код, но със сигурност ще се пише работни места. Какъв език ви харесва? Python и shell скриптове са начало. Какво ще кажете за Lambda? Говорете за рамки за разполагане на приложения.<br/><br/>Бази данни<br/><br/>Трябва да имате някои силни умения за бази данни, дори и да не сте ден за ден DBA. Amazon RDS със сигурност прави администрирането малко по-лесно през повечето време. Но ъпгрейдът често изисква престой и за съжаление това е свързано с услугата. Виждам най-вече Postgresql, MySQL & Aurora. Получете удобно настройване на SQL заявките и оптимизиране. Анализирайте бавния дневник на заявките и осигурете изход.<br/><br/>Аналитичното предлагане на Amazon става все по-силно. Целта, изградена Redshift, е навсякъде в наши дни. Може да използва драйвер postgresql, но има много повече под капака. Също така може да искате да погледнете SPectrum, който осигурява интерфейс тип EXTERNAL TABLE, за да задавате заявки за данни директно от S3.<br/><br/>Все още не е на Redshift? Ами можете да използвате Athena като интерфейс директно върху вашите данни, седящи в S3. Още по-бързо.<br/><br/>За по-голям анализ на данни или хора, които имат системи, изградени около технологията, Hadoop внедрявания или EMR може да бъде добре да се знае, както добре. Най-малко да може да се говори интелигентно за това.<br/><br/>Въпроси<br/><br/>Написали ли сте някакви шаблони за CloudFormation или Terraform code? Например как се създава VPC с частни и публични подмрежи, плюс бастион кутия с Terraform? Какви гащета срещате?<br/><br/>Ако ви бъде даден проектен документ, как ще продължите от там? Как ще изградите инфра около тези изисквания? Каква е първата ви стъпка? Какви въпроси бихте задали за доктора?<br/><br/>Какво знаеш за Нодейс или Питон, защо предпочиташ този език?<br/><br/>Ако сте били помолени да съхранявате 500 терабайта данни на AWS и ще правите анализ на данните, какъв би бил първият ви избор? Защо? Да кажем, че сте оценили S3 и Athena и сте открили, че изпълнението не е там, към какво бихте се преместили? Redshift? Как ще заредите данните?<br/><br/>Опишете настройката за мулти-аз VPC, която препоръчвате. Как да разположите множество подмрежи при висока наличност?<br/><br/>Ето някои от уроците, които научих в процеса на изграждане на код за AWS. Не е лесно, но когато стигнете там, можете да се насладите на гледките. Те са доста невероятни.<br/><br/>Не подавай акредитивни писма.<br/><br/>Докато изграждате приложенията си, има моменти, в които компонентите трябва да използват AWS по някакъв начин. Вашият уеб сървър трябва да използва S3 или вашата ELK кутия трябва да използва CloudWatch. Може би искате да направите резервно копие на RDS или да изброите екземпляри на EC2.<br/><br/>Въпреки това не е безопасно да предавате вашия access_key и secret_access_key наоколо. Те трябва да са само за вашия работен плот. Така че как най-добре да се справяте с това в облака?<br/><br/>Роли на IAM за спасяване. Това са колекции от привилегии. Готиното е, че те могат да бъдат присвоени на ИНСТАНЦИОННО НИВО. Това означава, че целият ви сървър има разрешения за използване на споменатите ресурси.<br/><br/>Направете това, като първо създадете роля с привилегиите, които искате. Създайте документ за политиката на json, който очертава конкретните правила, както сметнете за добре. След това създайте профил на инстанция за тази роля.<br/><br/>Когато създавате вашия ec2 екземпляр в Terraform, ще укажете този профил на екземпляра. Или чрез ARN, или ако Terraform го е създал, чрез ID на ресурса.<br/><br/>Пазете паролите извън кода<br/><br/>Въпреки че знаем, че не трябва да се случва, понякога се случва. Трябва да сме бдителни, за да останем на върха на този проблем. Има проекти като сканирането на идентификационните данни на Pivotal. Това може да се използва за проверка на изходните ви файлове за пароли.<br/><br/>Какво ще кажете за нещо като RDS? Ще трябва да зададете парола във вашия Terraform код нали? Грешно! Можете да дефинирате променлива без подразбиране, както следва:<br/><br/>Променлива "my_rds_pass"<br/>Описание на "парола за RDS база данни"<br/>- Да.<br/><br/>Когато Terraform попадне на тази променлива във вашия код, но види, че няма стойност "по подразбиране", тя ще ви подкани, когато направите "$ terraform apply"<br/><br/>Версии на вашия код<br/><br/>Когато за първи път започнете да изграждате тераформен код, шансовете са да създадете директория и някои tf файлове, след което да направите своя "$ terraform apply". Когато гледате това инфра изграждане за първи път, това е вълнуващо!<br/><br/>След като добавите още компоненти, кодът ви става по-сложен. Надяваме се, че сте създали git repo, за да присвоите кода си. Можете да проверите & къмитнете файловете, така че да са на сигурно място. Но разбира се, уравнението е повече от това.<br/><br/>Как се справяте с множество среди, dev, етап & производство всички с помощта на един и същ код?<br/><br/>Сега в началото може да имате модул, който изглежда така:<br/><br/>И т.н. Това е първата стъпка в правилната посока, но ако промените изходния си код, всички ваши среди ще използват този код. Те ще го получат веднага щом направите "$ terraform apply" за всеки. Това е добре, но не се мащабира добре.<br/><br/>В крайна сметка искате да управлявате кода си като други софтуерни проекти. Така че, докато правите промени, ще искате да го маркирате.<br/><br/>Готино! Сега всеки dev, етап и prod може да препраща към различна версия. Така че сте свободни да работите върху инфра без да прекъсвате етап или prod. Когато сте готови да популяризирате този код, проверете, маркирайте и актуализирайте етап.<br/><br/>Може да се направи още една крачка напред, за да бъде по-пъргав, и да има пост-комисионна кука, която задейства сцената тераформа прилага. Това обаче изисква от вас да се изгради солидна инфра тестове. Checkout testinfra и terratest.<br/><br/>Управление на RDS архиви<br/><br/>Скорошното ми откритие е още по-сериозно! Terraform иска да изгради инфра. И иска да може по-късно да унищожи тази инфра. В случая с базите данни, очевидно предишното състояние е това, което искате да запазите. Искаш това да е вечно, отвъд инфра строежа.<br/><br/>Очевидно не на хората в Amazon. Когато унищожите RDS инстанция, тя ще унищожи всички стари архиви, които сте създали. Нямам представа защо някой би искал това. Със сигурност не като поведение по подразбиране. Което е по-лошо, не можете да копирате тези архиви другаде. И без това сигурно седят в S3!<br/><br/>Въпреки че можете да вземете последно резервно копие, когато унищожите RDS инстанция, това е страхотно и аз го препоръчвам. Но това не е достатъчно. Силно препоръчвам да вземете нещата в свои ръце. Изградете скрипт, който извиква pg_dump себе си, и копирайте тези .sql или .dump файлове в S3 за безопасно съхранение.<br/><br/>Кога да използвате force_destroy на S3 кофи<br/><br/>Както при RDS, когато създавате S3 кофи с вашата инфра, искате да можете да почистите по-късно. Но проблемът е, че след като създадете кофа, вероятно ще я напълните с обекти и файлове.<br/><br/>Това, което се случва тогава е, че когато отидете да направите "$ terraform destroy" ще се провали с грешка. Това има смисъл като поведение по подразбиране. Не искаме данните да изчезнат без нашето знание.<br/><br/>Както и да е, искаш да можеш да чистиш.<br/><br/>Първо, създайте процес, може би ламбда работа или друга репликация на кофа, за да синхронизирате редовно кофата си s3 с постоянното място на архива на кофата. Стартирайте го на всеки петнадесет минути или толкова често, колкото ви е необходимо.<br/><br/>След това добавете force_destroy ред към вашия s3 кофа ресурс. Ето един пример s3 кофа за съхранение на натоварване балансьор трупи:<br/><br/>Когато видите заглавия като това, първият ви инстинкт като CTO вероятно е: "Изложен ли съм на риск?" И след това "Какви са шансовете това да се случи с мен?"<br/><br/>Истината може да бъде по-странна от измислицата. Нашите усилия като devops трябва да бъдат към смекчаване на риска и намаляване на потенциала за такива неща да се случат.<br/><br/>1. Вместо това използвайте aws instance профили<br/><br/>Тези пълномощия, които aws предоставя, са чудесни за активиране на awscli. Това е така, защото вие контролирате вашия работен плот плътно. нали?<br/><br/>Но предаването им в кода на приложението ви е склонно към неприятности. В крайна сметка те ще се окажат в git repo. Не е добре!<br/><br/>Решението е прилагане на aws IAM разрешения на ниво инстанция. Точно така, можете да дадете на екземпляр разрешения за четене или писане на s3 кофа, описване на инстанции, създаване и писане на dynamodb, или нещо друго в aws. Целият облак е api конфигурируем. Създавате правила по избор за вашата инстанция и я прикачвате към именуван профил на инстанция.<br/><br/>Когато превъртите вашата EC2 инстанция, или по-късно я модифицирате, прикачвате този профил на инстанцията и voila! Инстанцията има тези разрешения! Не са необходими разхвърляни идентификационни данни!<br/><br/>3. бла бла<br/><br/>Хей, докато сте в него, защо да не добавите пост къмит кука към вашия код репо в git. Накарайте го да стартира сканирането на идентификационните данни всеки път, когато кодът е ангажиран. И когато намери проблеми, трябва да изпрати имейл на целия екип.<br/><br/>ECS е Elastic Container Service на Amazon. Това е гръцки за това как се получават докер контейнери, работещи в облака. Това е нещо като Kubernetes без всички звънци и свирки.<br/><br/>Отнема малко време да свикнеш, но тази тераформа как да, би трябвало да те накара да се движиш. Имате нужда от EC2 хост, за да стартирате контейнерите си, имате нужда от задача, която определя изображението и ресурсите на контейнера ви, и накрая услуга, която казва на ECS кой клъстер да стартира и регистрира с ALB, ако имате такъв.<br/><br/>За всеки от тези раздели създайте файлове: roles.tf, instance.tf, task.tf, service.tf, alb.tf. Това, което бих препоръчал, е да създадете първите файлови roles.tf, след което направете:<br/><br/>$ тераформ инит<br/>Тераформен план за $<br/>$ тераформ се прилагат<br/><br/>След това преминете към instance.tf и направете тераформата. Една по една, следваща задача, след това сервизно обслужване и накрая alb. По този начин, ако срещнете грешки, можете да отстраните минимално, вместо да копаете през пет файла за виновника.<br/><br/>Препоръчвам разполагане в публичните подмрежи за първия си ход, за да се избегне сложността на скок кутия, и частни IP адреси за ecs инстанция и т.н.<br/><br/>Успех!<br/><br/>Нека тераформната сила бъде с теб!<br/><br/>Първи настройки на ролите<br/><br/>Ролите са наистина брилянтна част от стека aws. Вътре в IAM или достъпа и управлението на идентичността, можете да създавате роли. Това са колекции от привилегии. Позволено ми е да използвам тази кофа S3, но не и други. Мога да използвам EC2, но не и Athena. И така нататък. Има някои специални политики, които вече са създадени само за ECS и ще ви трябват роли, за да ги използвате.<br/><br/>Тези роли ще се прилагат на ниво инстанция, така че вашият ecs домакин не трябва да предава идентификационни данни наоколо. Чисто. Сигурно. Умно!<br/><br/>Настройване на ecs хост инстанция<br/><br/>След това се нуждаете от EC2 инстанции, на които да стартирате вашите контейнери за докер. Оказва се, че AWS вече е изградила AMIs само за тази цел. Наричат ги ECS оптимизирани изображения. Има един уникален AMI идентификатор за всеки регион. Така че се уверете, че използвате правилната за вашата настройка.<br/><br/>Другото нещо, което вашата инстанция трябва да направи, е да повтори името на клъстера на /etc/ecs/ecs.config. Можете да видите, че правим това в секцията user_data script.<br/><br/>Накрая конфигурираме нашата инстанция вътре в група за автоматично мащабиране. Това е така, за да можем лесно да добавяме повече инстанции динамично, за да увеличаваме или намаляваме, ако е необходимо.<br/><br/>Настройване на дефиницията на задачата<br/><br/>Третото нещо, от което се нуждаете, е задача. Това ще създаде генеричен контейнер за nginx. Това е хубав начин да демонстрирате нещата. За вашето реално използване на света ще замените линията на изображението с докер, който сте изтласкали до ECR. Ще го оставя като упражнение, след като клъстерът работи, трябва да свикнеш с нещата.<br/><br/>Обърнете внимание на portmappings, памет и CPU. Всички неща, които може да очаквате да видите в docker-compose.yml файл. Така че тези задачи трябва да изглеждат малко познати.<br/><br/>Настройване на дефиницията на услугата<br/><br/>Четвъртото нещо, което трябва да направите, е да настроите услуга. Задачата по-горе е манифест, описващ нуждите на вашите контейнери. Сега е регистрирана, но нищо не работи.<br/><br/>Когато приложите услугата, която контейнерът ви ще стартира. Това, което обичам да правя, е да се включа в приемника на ecs. Настанете се удобно. След това издавайте $ часовник "docker ps". Това многократно ще стартира "docker ps" на всеки две секунди. След като имате това тичане, направете своя тераформ прилага за тази услуга парче.<br/><br/>Докато гледате, ще видите, че ECS стартира контейнера ви и той внезапно ще се появи в терминала на часовника ви. Първо ще покаже "стартиране". След като бъде стартиран, трябва да каже "здравословен".<br/><br/>Настройване на балансьора на натоварването на приложението<br/><br/>Всичко по-горе ще работи от само себе си. Въпреки това за реалния свят случай употреба, вие ще искате да имате ALB. Този има само един прост HTTP порт 80 слушател. Те са много по-прости, отколкото създаването на 443 за SSL, така бебе стъпки първо.<br/><br/>След като имате ALB става, нови контейнери ще се регистрират с целевата група, за да уведомите алб знаят за тях. В "докер ps" ще забележите, те се изпълняват на много високо номерирани портове. Това са hostPorts, които са динамично присвоени. Контейнерните портове са всичките 80.<br/><br/>Също така ще искате да добавите име на домейн, така че с промените в инфраструктурата и ако възстановите ALB, името на вашето приложение да не се променя. Route53 ще се коригира с прилагането на тераформни промени. Доста готино.<br/><br/>ECS е еластичен контейнер услуга на Amazon. Ако имате докеризирано приложение, това е един от начините да го разгърнат в облака. Това е основно Amazon контрабанден клонинг Kubernetes. И не е толкова богат на функции!<br/><br/>Това каза, ECS не работи, и това ще ви позволи да получите вашата кандидатура става на Amazon. Достатъчно скоро EKS (Kubernetes услуга на Amazon) ще бъде производство, и ние всички ще щастливо да превключвате.<br/><br/>Междувременно, ако се борите със странните грешки и когато те тихомълком пропадат, имам някаква помощ за вас. Надявам се, че тези различни случаи на грешки са тези, които сте срещнали, и това ви помага да ги разрешите.<br/><br/>Защо контейнерът ми е в спряно състояние?<br/><br/>Контейнерите могат да се провалят по много различни причини. Литанията на причините, които открих, бяха:<br/><br/>Когато ecs многократно се проваля, той оставя около спрени контейнери. Те изяждат системните ресурси, без много видима обратна връзка. "df -k" или "df -m" не ви показва обеми, запълнени. *BUT * има логически обеми, които могат да се запълнят.<br/><br/>3. контейнерът ми е убит преди да е започнал напълно<br/><br/>Когато една услуга се изпълнява, ECS иска да има *всички * от контейнерите, работещи заедно. Точно както когато използвате docker-compose. Ако един контейнер не успее, ecs-агент може да реши да убие цялата услуга и да рестартира. Така че може да видите странни неща, които се случват в "докер трупи" за един контейнер, просто защото друг не успя. Какво да правя?<br/><br/>Първо погледнете дефиницията на задачата си и задайте "основно ? невярно". По този начин, ако едното се провали, другото все още ще се изпълнява. Така че можете да елиминирате работния контейнер като причина.<br/><br/>Следващото нещо е да запомните, че някои контейнери могат да се стартират почти мигновено, като например nginx. Тъй като това е много малък отпечатък, той може да започне след секунда или две. Така че, ако *той * зависи от друг контейнер, който е бавен, nginx ще се провали. Това е така, защото в странния свят на докерското откритие, този друг контейнер дори още не съществува. Докато nginx го споменава, той казва хей, не виждам сървъра нагоре по веригата, към който сочите.<br/><br/>Решение? Уверете се, че имате раздел "връзки" в дефиницията на задачата си. Това казва на ecs-agent, че един контейнер зависи от друг (помислете за флага depends_on в docker-compose).<br/><br/>4. Разбиране на поръчването на контейнери<br/><br/>Докато изграждате вашия ecs манифест, известен още като дефиниция на задачата, искате да изпълните внимателно файла си за докер-композиране. Прегледайте връзките, основните флагове и depens_on настройките. След това не забравяйте да огледате тези във вашата ECS задача.<br/><br/>Когато се съмнявате, намалете обхвата на проблема си. Това е дефиниране на *само един * контейнер, след което стартирайте услугата. След като този контейнер работи, добавете секунда. Когато получите, че работи, както и, добавете трети или друг контейнер.<br/><br/>Този подход ви позволява да елиминирате взаимосвързаните зависимости и свързаните с тях проблеми. |
| How did you set the due date for those tasks? Are they in Inbox or other custom lists?<br/><br/>oilexxxi<br/>DEV<br/><br/>The tasks are in different lists, inbox and others and almost all of them are repeated tasks. So I don't have to set a due date every time.<br/><br/>uladzimirku<br/><br/>Hello,<br/><br/>Are they not showing in the calendar view (Tomorrow)?<br/><br/>oilexxxi<br/>DEV<br/><br/>The issue is not about calendar. It's abot the view, the option in the menu.<br/><br/>uladzimirku<br/><br/>Have you finished the previous recurrences of those repeat tasks? If not, the next recurrences cannot be shown in the list view. If the none show tasks are not all repeat tasks, please provide the date&time settings. We will look into it for you soon. | Как сте задали крайния срок за тези задачи? Дали са в списъка "Входящи" или в други списъци по избор?<br/><br/>Олиоxxxi<br/>ДЕВ<br/><br/>Задачите са в различни списъци, папка "Входящи" и други и почти всички от тях са повтарящи се задачи. Така че не е нужно да задавам краен срок всеки път.<br/><br/>уладзимирку<br/><br/>Ало.<br/><br/>Не се ли показват в изгледа на календара (Утре)?<br/><br/>Олиоxxxi<br/>ДЕВ<br/><br/>Проблемът не е в календара, а в изгледа, опцията в менюто.<br/><br/>уладзимирку<br/><br/>Завършихте ли предишните повторения на тези повтарящи се задачи? Ако не, следващите повторения не могат да бъдат показани в изгледа на списъка. Ако задачите без показване не са всички повтарящи се задачи, моля, представете настройките за дата и час. Ние ще разгледаме скоро. |
| What Is Assisted Living Vs Nursing Homes<br/><br/>ContentsPlanning & Advice Senior Living Articles Nursing Home Care vs Assisted Living. What are my options? My mother loves her apartment and her community, plus, she has many strong friendships there. Her doctor says she may have had some small strokes over the years and has osteoporosis…What's the difference between Assisted Living and Nursing Home? Assisted living facilities are designed for individuals who are fairly independent and can get through most of the day by themselves. They receive general help with activities like bathing, dressing, and preparing food, and make autonomous decisions about.<br/><br/>Separately, consumer representatives at a hurricane workshop Thursday in …<br/><br/>Apr 20, 2016 … When you have an aging patient or loved one who can no longer receive the care they need at home, either after an incident or if their overall health is declining, two senior care options you may consider are skilled nursing facilities ( also called nursing homes) and assisted living communities. Here, we …<br/><br/>Assisted Living Well Contents Chuck'' ware was the consummate advocate Service that provides professional Form close bonds with their neighbors Jersey from the alf Well-appointed assisted living facilities often But to those who knew him well, Charles "chuck'' ware was the consummate advocate, a man whose work touched countless lives. He passed away recently … Former audiologist Marcia<br/><br/>What won't be discussed with FPL or other utilities is the prioritization of service for nursing homes and assisted living facilities. After Hurricane Irma, eight patients died at the Rehabilitation Center at Hollywood Hills when the air …<br/><br/>At some point, support from family, friends, and local programs may not be enough. People who require help full-time might move to a residential facility that provides many or all of the long-term care services they need. Facility-based long -term care services include: board and care homes, assisted living facilities, nursing …<br/><br/>Differences in between Nursing Homes and Assisted Living are: Nursing homes offer skilled nursing and Assisted living offers independence<br/><br/>Medicare and long-term care basics · Nursing homes and assisted living facilities · Home care · Home modifications to continue living at home · Respite care · ‹ Previous Page. Resources if you need dental coverage · Next page ›. medicare and long-term care basics. Back to Top. Register for a free account. Register. | Какво се подпомага живот срещу старчески домове<br/><br/>ContentsPlanning & Advice Senior Living Articles Nursing Home Care vs Assisted Living. Какви са моите възможности? Майка ми обича апартамента си и нейната общност, плюс това, тя има много силни приятелства там. Докторът й казва, че може да е имала някои малки инсулти през годините и да има остеопороза... Каква е разликата между асистирания живот и старческия дом? Съоръженията за подпомагане на живота са предназначени за лица, които са доста независими и могат да се справят сами през по-голямата част от деня. Те получават обща помощ за дейности като къпане, обличане и приготвяне на храна и вземат самостоятелни решения.<br/><br/>Отделно, представители на потребителите на ураганна работилница в четвъртък в...<br/><br/>20 апр. 2016 г. ... Когато имате застаряващ пациент или любим човек, който вече не може да получи грижите, от които се нуждае у дома, или след инцидент, или ако цялостното им здраве намалява, две опции за старши грижи, които може да считате, са квалифицирани медицински заведения (наричани още старчески домове) и подпомагани живи общности. Ето, ние...<br/><br/>Подпомогнат Living Well Contents Чък "фаянс" е ненадминат адвокат Service, която осигурява професионална форма близки връзки с техните съседи Джърси от алф Добре назначени подпомагани жилищни съоръжения често Но за тези, които го познават добре, Чарлз "Chuck" фаянс е ненадминат адвокат, човек, чиято работа докосна безброй животи. Той почина наскоро ... Бившият аудиолог Марша<br/><br/>Това, което няма да бъде обсъдено с FPL или други комунални услуги, е приоритизирането на услугите за старчески домове и помощни жилищни съоръжения. След урагана Ирма, осем пациенти загинаха в рехабилитационния център в Холивуд Хилс, когато въздухът ...<br/><br/>В даден момент подкрепата от семейството, приятелите и местните програми може да не е достатъчна. Хората, които се нуждаят от помощ на пълно работно време, могат да се преместят в жилище, което осигурява много или всички услуги за дългосрочни грижи, от които се нуждаят. Услугите за дългосрочни грижи, базирани на съоръжения, включват: пансиони и домове за грижи, помощни средства за живот, медицински сестри ...<br/><br/>Разликите между старчески домове и подпомогнат живот са: старчески домове предлагат квалифицирани медицински сестри и подпомогнат живот предлага независимост<br/><br/>Medicare and long-term care basics (Медицински грижи и основи за дългосрочни грижи) & Nbsp; Домове за възрастни и помощни заведения & Nbsp; Домашни грижи & Nbsp; Домашни модификации, за да продължат да живеят у дома & Nbsp; & Nbsp; & Nbsp; Предишна страница. Ресурси, ако имате нужда от стоматологично покритие & Nbsp; Следваща страница & Nbsp;. medicare и дългосрочни грижи основи. Обратно в началото. Регистрирайте се за безплатен акаунт. Регистрирайте се. |
| ...designed and built.<br/>I want exactly same as this app but cover Arabic and English both languages.<br/>[log masuk untuk melihat URL]<br/>Then you provide english table and I provide Arabic terms.<br/>Can you give prototype first?<br/>but I want to add option to search geographically and select marriage type. There are difftentLooking for a native English transcriber for this work. Total length of audio is 9 hours. Deadline 3 days. We need first ...transcpost accountHello freelancers,<br/>I want a freelancer to write me around 70...blog knowledge please bid.<br/>I have around 3000 videos to edit. Kindly give me your best proposal per video.<br/>I am looking to hire for long term as there are many more videos as well which needs to edited.<br/>Details will be shared in message with the freelancers.<br/>Only people who can provide a sample of my current work can only bid if freelancer will ignore<br/><br/>I want to build app similar to this:<br/>[log masuk untuk melihat URL]<br/>But it should be available for multiple content creators instead of only 1. [log masuk untuk melihat URL] 100 creators<br/>It should be properly integrated with payment gateway.<br/>UI should be really good with seamless navigation.<br/>There shouldn't be any issues | ...проектиран и построен.<br/>Искам точно същото като това приложение, но обхващат арабски и английски и двата езика.<br/>[log masuk untuk мелихат URL]<br/>След това ти осигуряваш английска маса, а аз - арабски термини.<br/>Можеш ли първо да дадеш прототип?<br/>но искам да добавя опция за търсене географски и изберете тип брак. Има difftentLooking за родния английски транскриптор за тази работа. Общата дължина на аудио е 9 часа. Deadline 3 дни. Нуждаем се първо ...transcpost accountHello freelancers,<br/>Искам един фрийлансър да ми напише около 70... блог знания, моля наддавайте.<br/>Имам около 3000 видеоклипа за редактиране. Моля, дайте ми най-доброто си предложение за видео.<br/>Търся да наема за дългосрочен план, тъй като има още много видеоклипове, които трябва да се редактират.<br/>Подробностите ще бъдат споделени в съобщение с фрийлансърите.<br/>Само хора, които могат да предоставят извадка от текущата ми работа, могат да наддават само ако фрийлансърът ще игнорира<br/><br/>Искам да създам приложение, подобно на това:<br/>[log masuk untuk мелихат URL]<br/>Но тя трябва да бъде достъпна за множество създатели на съдържание, вместо само 1. [log masuk untuk melihat URL] 100 създатели<br/>Тя трябва да бъде правилно интегрирана с платежен шлюз.<br/>UI трябва да бъде наистина добър с безпроблемна навигация.<br/>Не трябва да има никакви проблеми. |
