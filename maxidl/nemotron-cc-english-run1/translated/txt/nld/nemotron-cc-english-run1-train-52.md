| original | translation |
|----------|-------------|
|  LAWYER IN AMERICAN POPULAR CULTURE<br/><br/>As human beings we struggle between good and badâ€”both internally and within a community of others who struggle as well. A society's popular culture reflects such basic human concerns and can be seen through the records it keeps. Undeniably, American popular culture has been well recorded. By looking at contemporary commentary, literature, and film we are able to see how the important issues of the timesâ€”our society's struggles to define what's right and wrongâ€”have been reflected throughout our history. And what better venue to illustrate the eternal struggle between good and bad than the legal profession, which by definition exists to ensure that the rule of law is upheld, that good prevails.<br/><br/>Lawyers enter the legal profession intending to preserve justice and champion individual rights while at the same time ensuring the common goodâ€”at least they re supposed to. These are lofty goals considering that lawyers are no less "human" than anyone else, prone to the same abuse of power. By defining the different sides of a particular issueâ€” or aspects of a professionâ€”writers, journalists, artists, and filmmakers provide the reading and viewing public with materials that can both entertain us and make us think. As far as the legal profession is concerned, we see a good lawyer as a reflection of people's hopes, and a bad lawyer as a reflection of people's worst fears. Given the vital importance of the integrity of the law in America, and our natural cynicism when it comes to entrusting our future with an individual, is it any wonder that over the course of this country's history, the legal system in its entirety is more often than not viewed as a slew of rascals, cither distorting the law in their own self-interest or sidelining common justice in order to protect criminals and maintain deep pockets. We are especially interested in recognizing the bad, self-serving lawyer because our deepest wish is that if we need a lawyer, we will get one of the good ones!<br/><br/>Judging from the historical record, the trivialization of the lawyer in popular culture appears to be a time-honored theme, stretching as far back as the beginning of the modern period, when the process of consolidating a fragmented legal system into a coherent whole began. A late-seventeenth-century anonymous "legal coat of arms" depicts allegorically the purported values and interests of law professionals. The scene presents a fox, hardly a symbol of trustworthiness, surrounded by two figures of Questionable character, at least one of them a wealthy client. Following a theme that reappears consistently throughout the history of popular attitudes toward lawyers, the fox spews forth long reams of legal rhetoric in broken Latin, underscoring lawyers' incapacity to "speak the truth" or engage in common-sense dialogue. And as if to drive the satiric dagger deeper still, the reason for such slyness is plain and simple: the deep loyalty to material well-being rather than to the principle of social justice or the defense of the common man. Thus the designs' motto of "DUM VIVO THRIVO," which translates into "Where I live, I thrive." | Advocaat in de Amerikaanse volkscultuur<br/><br/>Als mensen worstelen we tussen goed en slecht - zowel intern als binnen een gemeenschap van anderen die ook worstelen. De populaire cultuur van een samenleving weerspiegelt dergelijke fundamentele menselijke zorgen en is te zien aan de gegevens die het bewaart. Ongetwijfeld is de Amerikaanse populaire cultuur goed opgenomen. Door te kijken naar hedendaagse commentaren, literatuur en film, kunnen we zien hoe de belangrijke kwesties van de tijd - de strijd van onze samenleving om te definiÃ«ren wat goed en fout is - zijn weerspiegeld in onze geschiedenis. En wat is een betere plaats om de eeuwige strijd tussen goed en kwaad te illustreren dan de juridische beroep, die per definitie bestaat om ervoor te zorgen dat de rechtsstaat wordt gehandhaafd, dat het goede de overhand heeft.<br/><br/>Advocaten betreden het juridische beroep met de intentie om gerechtigheid te behouden en individuele rechten te verdedigen, terwijl ze tegelijkertijd het algemeen welzijn waarborgen - althans dat moeten ze opnieuw doen. Dit zijn verheven doelen gezien het feit dat advocaten niet minder "menselijk" zijn dan wie dan ook, gevoelig voor hetzelfde machtsmisbruik. Door de verschillende kanten van een bepaald onderwerp - of aspecten van een beroep - te definiÃ«ren, bieden schrijvers, journalisten, kunstenaars en filmmakers het lezen en bekijken van het publiek materiaal dat ons zowel kan vermaken als ons kan laten denken. Wat de juridische beroepen betreft, zien we een goede advocaat als een weerspiegeling van de hoop van de mensen, en een slechte advocaat als een weerspiegeling van de ergste angsten van de mensen. Gezien het vitale belang van de integriteit van de wet in Amerika, en ons natuurlijke cynisme als het gaat om het toevertrouwen van onze toekomst aan een individu, is het geen wonder dat in de loop van de geschiedenis van dit land, het juridische systeem in zijn geheel vaak wordt gezien als een sleur van schurken, citer verdraaien van de wet in hun eigen belang of het handhaven van diepe gemeenschappelijke gerechtigheid om criminele belangen te beschermen. We zijn vooral geÃ¯nteresseerd in het herkennen van de slechte, zelfbedienende advocaat, want onze diepste wens is dat als we een advocaat nodig hebben, we een van de goede zullen krijgen!<br/><br/>Te oordelen naar het historische verslag, lijkt de trivialisering van de advocaat in de populaire cultuur een gevierd thema te zijn, dat zich uitstrekt tot aan het begin van de moderne periode, toen het proces van het consolideren van een gefragmenteerd rechtssysteem tot een samenhangend geheel begon. Een late zeventiende-eeuwse anonieme "legaal wapen" toont allegorisch de vermeende waarden en belangen van juridische professionals. De scÃ¨ne presenteert een vos, nauwelijks een symbool van betrouwbaarheid, omringd door twee figuren van twijfelachtig karakter, ten minste een van hen een rijke klant. Naar aanleiding van een thema dat consequent weer opduikt in de geschiedenis van populaire houdingen tegenover advocaten, spuwt de vos lange trossen juridische retoriek uit in het gebroken Latijn, onderstreept het onvermogen van advocaten om "de waarheid te spreken" of een dialoog met gemeenschappelijk verstand aan te gaan. En alsof de satirische dolk nog dieper drijft, is de reden voor dergelijke sluwheid duidelijk en eenvoudig: de diepe loyaliteit aan het materiÃ«le welzijn in plaats van aan het principe van sociale rechtvaardigheid of de verdediging van de gewone man. Het motto van de ontwerpen is "DUM VIVO THRIVO", wat vertaald wordt als "Waar ik woon, gedij ik." |
| Do the Templars control the world today?<br/><br/>I meet and talk to people in very different situations who are convinced that the Knights Templar in some guise or other control the world. How do they come to this view?<br/><br/>A few months ago, I was talking to a young British Muslim and mentioned this blog. "Well, of course, they totally run the world, right?" I thought he was joking. He was university educated, very bright and well read. But no. He meant it. 100%.<br/><br/>Similarly, I've come across people who argue that Pope Francis, as a Jesuit, must be part of a Templar plot because the Jesuits are really secret Templars.<br/><br/>Let me run through some of the recent theories I've discovered online about Templars running the world:<br/><br/>Templars control us from Switzerland<br/><br/>Haven't you ever noticed how similar the Swiss and Templar flags are?<br/><br/>Swiss neutrality is not a result of loving peace but because they are too busy orchestrating wars through which the Templars control us | Beheersen de Tempeliers de wereld vandaag?<br/><br/>Ik ontmoet en praat met mensen in heel verschillende situaties die ervan overtuigd zijn dat de Tempeliers op de een of andere manier de wereld beheersen. Hoe komen ze tot deze visie?<br/><br/>Een paar maanden geleden sprak ik met een jonge Britse moslim en noemde deze blog. "Wel, natuurlijk, ze runnen de wereld helemaal, toch?" Ik dacht dat hij een grapje maakte. Hij was universiteitsopgeleid, zeer helder en goed gelezen. Maar nee. Hij meende het. 100%.<br/><br/>Op dezelfde manier ben ik mensen tegengekomen die beweren dat paus Franciscus, als jezuÃ¯et, deel moet uitmaken van een Templar-plot omdat de jezuÃ¯eten echt geheime Templars zijn.<br/><br/>Laat me enkele van de recente theorieÃ«n die ik online heb ontdekt over Tempeliers die de wereld regeren, doornemen:<br/><br/>Tempeliers controleren ons vanuit Zwitserland<br/><br/>Heb je ooit gemerkt hoe vergelijkbaar de Zwitserse en de Tempeliersvlag zijn?<br/><br/>De Zwitserse neutraliteit is niet het resultaat van liefdevolle vrede, maar omdat ze te druk bezig zijn met het orkestreren van oorlogen waardoor de Tempeliers ons controleren. |
| Rally is a dog sport that builds on obedience training and teaches agility skills. Participants move from station to station working on different skills and patterns through teamwork between handler and dog. There are several levels of Rally obedience. This class will be a prerequisite for the next level offered in the summer. Dogs must have attended at least one full obedience course of 6 to 8 classes before enrolling. Bring veterinarian papers with vaccination proof the first night of class. Bring your dog the first night. Dogs 16 weeks and up. No class 6-25-18. | Rally is een hondensport die voortbouwt op gehoorzaamheidstraining en behendigheidsvaardigheden leert. Deelnemers bewegen van station naar station en werken aan verschillende vaardigheden en patronen door teamwork tussen handler en hond. Er zijn verschillende niveaus van Rally gehoorzaamheid. Deze klasse zal een voorwaarde zijn voor het volgende niveau dat in de zomer wordt aangeboden. Honden moeten minstens Ã©Ã©n volledige gehoorzaamheidscursus van 6 tot 8 klassen hebben bijgewoond voordat ze zich inschrijven. Breng dierenartspapieren met vaccinatiebewijs op de eerste nacht van de klas. Breng uw hond de eerste nacht. Honden 16 weken en hoger. Geen klasse 6-25-18. |
| Ahah, thanks. Since I've collected everything for the home instance so far, I'm adding that. Everything but the treasure chest thing, anyway. Hooray for having cleared my bank out of some valuable cruft the other day, I didn't have to toss cash at it!It also comes down to usability, a salvage-o-matic provides different levels of convenience depending on how much you intend to use it, because the action of salvaging is repeatable, up to thousands of times a day if you were so inclined.<br/><br/>Same for an infinite harvesting tool, you can run around the open world harvesting for 8 hours a day if you wish.<br/><br/>These home nodes are novelty items, not convenience items. They provide exactly one use every 24 hours, incredibly limited usability. And essentially they save you from tapping your "O" key and buying up to 12 T1 â€“ T3 light scraps once a day. Which, arguably, I think is actually the more convenient option.<br/><br/>Now if these worked like regular nodes, where they refreshed every hour, then I would consider them convenience items. And they'd work similarly to salvage-o-matics and infinite tools in that what you get out of them is essentially what you're willing to put into them. I think very few players would actually be disciplined enough to swap to their Home character and mine them every hour on the hour.<br/><br/>But as novelty items, that makes it no different from spending 200g on one skin versus a free to apply skin. If that's what you're into, go for it.<br/><br/>But a skin is something you would actually get use from considering GW2 endgame is basically dress up wars 2. The harvesting tools and salvage tools are great convenience items.<br/><br/>The node packs, OTOH, are a waste of time and money. Going to the TP and buying 200 scraps at once rather than 5 minutes a day for 2 months to get the same thing is silly. I don't care if you buy them, but my original point is it's a fair comparison to make with the amount of gold/gems they cost.<br/><br/>Well, it's the Basic Cloth Rack, there really isn't any reason to believe it would be any different from the Basic Lumber and Basic Ore Nodes packs: a pittance of the lowest three tiers every 24 hoursIf they would offer a bank for the home instance, than it would be for convenience yes. But nodes, no. A node is simply for profit. I can imagine that it could offer some convenience IF it was certain what you will get. That is not the case. So again: no, this is not for convenience.<br/><br/>I bought it immediately when it came out. Sure, it'll never pay for itself, but I like having that extra source of cloth and the idea of my mule just wandering over each day and stealing clothes off some poor merchant's rack is hilarious. XDAccording to the wiki this does NOT count toward Daily GathererAt least in the case of the cloth rack, it seems to me that helps people who have only high level characters get some low-level cloth without buying it off the TP, since loot drops will mostly be higher level stuffIndeed. It is still a convenient way to get a bunch of low level crafting materials though. The daily gathering part was more to the nodes as a whole in the home instance, seeing as we have had the exact same thread every single time one of these were released.<br/><br/>Low level cloth items are harder to get due to scaling. High level characters usually don't get low enough stuff to salvage into the lower tier materials.<br/><br/>I really thought I'll have 3 of each when I bought it. I mean, all of the others stuff like that works that way, and costs 1000 gems. I'm really disappointed can we ask for a refound or something ? I'm so tired of all RNG mechanics in this, and now even the stuff we buy on TP provides us RNG based resultsâ€¦There is no waypoint rezzing in real life,<br/>but there are people who will help you get back up when you are downed<br/>- PalwaJokoANet, please upgrade my Cloth Rack so it also gives out Linen and Silk, kthx. | Ahah, bedankt. Aangezien ik tot nu toe alles heb verzameld voor de thuisinstantie, voeg ik dat toe. Alles behalve het schatkist ding, hoe dan ook. Hooray omdat ik laatst mijn bank uit een waardevol cruft heb geruimd, hoefde ik er geen contant geld op te gooien! Het komt ook neer op bruikbaarheid, een salvage-o-matic biedt verschillende niveaus van gemak, afhankelijk van hoeveel u van plan bent om het te gebruiken, omdat de actie van het redden herhaalbaar is, tot duizenden keren per dag als je zo geneigd was.<br/><br/>Hetzelfde geldt voor een oneindige oogstgereedschap, je kunt 8 uur per dag rondrennen in de open wereld oogsten als je dat wilt.<br/><br/>Deze thuisknopen zijn nieuwigheidsartikelen, geen gemaksartikelen. Ze bieden precies Ã©Ã©n gebruik elke 24 uur, ongelooflijk beperkte bruikbaarheid. En in wezen besparen ze u van het tikken op uw "O" -sleutel en het kopen van tot 12 T1 - T3 lichtschroot eenmaal per dag. Waarschijnlijk denk ik dat dit de meest geschikte optie is.<br/><br/>Als deze nu werkten als reguliere knooppunten, waar ze elk uur vernieuwd werden, dan zou ik ze als handige items beschouwen. En ze zouden op dezelfde manier werken als salvage-o-matica en oneindige hulpmiddelen, omdat wat je eruit haalt, in wezen is wat je bereid bent erin te stoppen. Ik denk dat heel weinig spelers gedisciplineerd genoeg zouden zijn om te ruilen voor hun thuiskarakter en ze elk uur per uur te minen.<br/><br/>Maar als nieuwigheid items, dat maakt het niet anders dan het uitgeven van 200g op een huid versus een gratis huid aan te brengen. Als dat is wat je bent in, ga voor het.<br/><br/>Maar een huid is iets dat je eigenlijk zou krijgen gebruik van het overwegen van GW2 endgame is in principe dress up oorlogen 2. De oogst gereedschappen en berging gereedschappen zijn geweldig gemak items.<br/><br/>De node packs, OTOH, zijn een verspilling van tijd en geld. Naar de TP gaan en 200 schroot in Ã©Ã©n keer kopen in plaats van 5 minuten per dag gedurende 2 maanden om hetzelfde te krijgen is dom. Het kan me niet schelen of je ze koopt, maar mijn oorspronkelijke punt is dat het een eerlijke vergelijking is met de hoeveelheid goud / edelstenen die ze kosten.<br/><br/>Nou, het is het Basic Cloth Rack, er is echt geen reden om te geloven dat het helemaal anders zou zijn dan de Basic Lumber en Basic Ore Nodes-pakketten: een kleine hoeveelheid van de laagste drie niveaus elke 24 uurAls ze een bank zouden aanbieden voor de thuisinstantie, dan zou het voor het gemak ja zijn. Maar knooppunten, nee. Een knooppunt is gewoon voor de winst. Ik kan me voorstellen dat het wat gemak zou kunnen bieden ALS het zeker was wat je zult krijgen. Dat is niet het geval. Dus nogmaals: nee, dit is niet voor het gemak.<br/><br/>Ik kocht het meteen toen het uitkwam. Zeker, het zal nooit voor zichzelf betalen, maar ik vind het leuk om die extra bron van doek te hebben en het idee dat mijn ezel elke dag ronddwaalt en kleren steelt van een arme handelaar is hilarisch. Volgens de wiki telt dit NIET in de richting van Daily GathererTenminste in het geval van het doekrek, lijkt het me dat het mensen helpt die alleen op hoog niveau personages hebben om wat doek op laag niveau te krijgen zonder het van de TP te kopen, omdat buitdruppels meestal hoger zullen zijn. Het is nog steeds een handige manier om een bos van laag niveau ambachtelijke materialen te krijgen. Het dagelijkse verzamelen deel was meer aan de knooppunten als geheel in de thuisinstantie, gezien het feit dat we precies dezelfde draad elke keer hebben gehad als een van deze werden vrijgegeven.<br/><br/>Laag niveau doek items zijn moeilijker te krijgen als gevolg van schalen. Hoog niveau karakters meestal niet laag genoeg spullen te redden in de lagere niveau materialen.<br/><br/>Ik dacht echt dat ik er 3 van elk zou hebben toen ik het kocht. Ik bedoel, al die andere dingen zoals dat werkt op die manier, en kost 1000 edelstenen. Ik ben echt teleurgesteld kunnen we vragen om een hervonden of zoiets? Ik ben zo moe van alle RNG-mechanica in dit, en nu zelfs de dingen die we kopen op TP geeft ons RNG-gebaseerde resultaten... Er is geen waypoint rezzing in het echte leven, maar er zijn mensen die je zullen helpen om weer op te staan wanneer je neergeschoten bent<br/>- PalwaJokoANet, upgrade alstublieft mijn doekrek zodat het ook Linnen en Zijde, kthx geeft. |
| I enjoy reading Corey Quinn's Last week in AWS newsletter. And also really like his podcast Screaming in the cloud. This week Corey talks with Jay Gordon from Mongodb. While Jay seems somewhat of an advocate of multicloud, Corey is decidedly critical. Which makes for a great interview!<br/><br/>Corey also wrote a piece The Myth of cloud agnosticism. I like any writing that dubs a popular trope as a "myth" because it's an opportunity to poke holes in optimism.<br/><br/>It is through this process that we become realistic, which is crucial to being reliable in operations and engineering.<br/><br/>Corey argues that multicloud, with respect to multiple infrastructure providers is usually a crappy idea. That's because the cloud providers are evolving, your application is evolving, and it costs you in terms of feature velocity. What's more it provides dubious instant uptime in the DR realm.<br/><br/>The topic reminds me of similar myths in computer scienceâ€¦ the myth of cross platform development or<br/>the myth of the cross platform databases the myth of object relational modeling.<br/><br/>As always your mileage may vary. Here are my questions. Hope they can help provide perspective, and critical thinking around this.<br/><br/>1. Do you plan to use multiple cloud providers for infrastructure? And deploy your application twice?<br/>2. Do you plan to use multiple SaaS providers?<br/>3. Does hybrid cloud make sense? That's an option where you deploy a data link to a public cloud, keeping some assets in your own datacenter.<br/>4. Are their feature parallels across your chosen clouds? Or are there feature mismatches?<br/>5. Your cloud providers have independent service level agreements. Are they consistent or not?<br/><br/>6. What does the outage history look like for each of your providers?<br/>7. What is the potential for fatfinger outage on each platform? For example one may be unduly complicated and prone to mistakes, based on API or dashboard interface.<br/>8. Is one cloud more complicated to implement? For example Amazon Web Services while being more feature rich, is also much more complicated to deploy than a Digital Ocean setup.<br/>9. You can see your backups on both platforms. Have you done restores on both? Regularly? Recently?<br/>10. Do you have time to automate everything twice? For example you may need to rewrite your ansible playbooks for each platform<br/><br/>11. What is driving your business to embrace the idea of multicloud?<br/>12. Do you have time to rewrite scripts twice? one-off and user-data scripts alike?<br/>13. Do you have time to firedrill twice? Smoketest twice?<br/>14. Will different clouds fail in different ways? For example one might be weak around it's network. Another might be weak around it's database service, and a third might encounter multi-tenant traffic congestion (disk or network).<br/>15. When one cloud doesn't support a feature, Ex: lifecycle policies on S3 buckets, do you need to build it for the other cloud?<br/><br/>16. Will deploying multicloud encourage abstraction layers Ex: object relational modelers (ORM) which heavily slow down performance?<br/>17. Have you tested performance on both clouds?<br/>18. Is cloud #2 a temporary disaster recovery solution or an on-going load balancing solution via geo-dns?<br/>19. If you go hybrid cloud, how does that impact security, firewalls, and access controls?<br/>20. How do you monitor your object stores (S3), scanning for open buckets? Do you rewrite this code for the other API?<br/><br/>21. What are the disaster types you're planning for?<br/>22. What is the cost of maintaining your application on multiple platforms?<br/>23. What is the cost of building infra for multiple platforms?<br/>24. What is the cost of debugging & troubleshooting on multiple platforms?<br/>25. How does multcloud complicate deployments?<br/><br/>26. Does multicloud complicate GDPR and other compliance questions?<br/>27. How does multicloud complicate your billing and budget management?<br/>28. What about microservices? How will these multiple platforms play across two clouds?<br/>29. Is the community around each cloud equally active?<br/>30. If you deploy with an infrastructure as code language like Terraform, is there an active community there for both of your chosen clouds?<br/><br/>31. Does each provider support customers well? What are their respective reputations?<br/>32. Is each cloud provider equally solvent & invested in the business? Will they be around in a year? five years? ten years?<br/>33. What complications arise when migrating to or from this provider?<br/><br/>EKS is a service to run kubernetes, so you don't have to install the software, or manage or patch it. Just like GKS on Google, kubernetes as a service is really the way to go if you want to build kubernetes apps on AWS.<br/><br/>So where do we get started? AWS docs are still coming together, so it's not easy. I would start with Jerry Hargrove's amazing EKS diagram. If a picture is worth a thousand words, this one is work 10,000!<br/><br/>1. Build your EKS cluster<br/><br/>I already did this in Terraform. There aren't a lot of howtos, so I wrote one.<br/><br/>Basically you setup the service role, the cluster, then the worker nodes. Once you've done that you're ready to run the demo app.<br/><br/>2. Build your app spec<br/><br/>These are very similar to ECS tasks. You'll need to make slight changes. mountPoints become VolumeMounts, links get removed, and workingDirectory becomes workingDir and so on. Most of these changes are obvious, but the json syntax is obviously the biggest bear you'll wrestle with.<br/><br/>It's not if, but when to move to the cloud, how to get there, and how fast will be the transition?<br/><br/>Here are my thoughts on what to start thinking about.<br/><br/>1. Ramp up team, skills & paradigm thinking<br/><br/>Teams with experience in traditional datacenters have certain ways of architecting solutions, and thinking about problems. For example they may choose NFS servers to host objects, where in the cloud you will use object storage such as S3.<br/><br/>S3 has all sorts of new features, like lifecycle policies, and super super redundant eleven 9's of durability. But your applications may need to be retrofitted to work with it, and your devs may need to learn about new features and functionality.<br/><br/>What about networking? This changes a lot in the cloud, with VPCs, and virtual appliances like NATs and Gateways. And what about security groups?<br/><br/>Interacting with this new world of cloud resources, requires new skillsets and new ways of thinking. So priority one will be getting your engineering teams learning, and upgrading skills. I wrote a piece about this how do I migrate my skills to the cloud?<br/><br/>2. Adapt to a new security model<br/><br/>With the old style datacenter, you typically have a firewall, and everything gets blocked & controlled. The new world of cloud computing uses security groups. These can be applied at the network level, across your VPC, or at the server level. And of course you can have many security groups with overlapping jurisdictions. Here's how you setup a VPC with Terraform<br/><br/>So understanding how things work in the public cloud is quite new and challenging. There are ingress and egress rules, ways to audit with network flow logs, and more.<br/><br/>However again, it's one thing to have the features available, it's quite another to put them to proper use.<br/><br/>3. Adapt to fragile components & networks<br/><br/>While the public cloud collectively is extremely resilient, the individual components such as EC2 instances are decidedly not reliable. It's expected that they can and will die frequently. It's your job as the customer to build things in a self-healing way.<br/><br/>That means VPCs with multiple subnets, across availability zones (multi-az). And that means redundant instances for everything. What's more you front your servers with load balancers (classic or application). These themselves are redundant.<br/><br/>Whether you are building a containerized application and deploying on ECS or a traditional auto-scaling webserver with database backend, you'll need to plan for failure. And that means code that detects, and reacts to such failures without downtime to the end user.<br/><br/>So there's a learning curve. Both for your operations teams who have previously called Rackspace to get a new server provisioned. And also for your business, learning what incurs an outage, and the tricky finicky sides to managing your public cloud through code.<br/><br/>5. Audit, log & monitor<br/><br/>As you automate more and more pieces, you may have less confidence in the overall scope of your deployments. How many servers am I using right now? How many S3 buckets? What about elastic IPs?<br/><br/>As your automation can itself spinup new temporary environments, those resource counts will change from moment to moment. Even a spike in user engagement or a sudden flash sale, can change your cloud footprint in an instant.<br/><br/>That's where heavy use of logging such as ELK (elasticsearch, logstash and kibana) can really help. Sure AWS offers CloudWatch and CloudTrail, but again you must put it all to good use.<br/><br/>I've been on both sides of the fence, at times interviewing candidates, and other times the candidate looking to impress to win a new role.<br/><br/>Here are my suggestionsâ€¦<br/><br/>Devops Pipeline<br/><br/>Jenkins isn't the only build server, but it's been around a long time, so it's everywhere. You can also do well with CircleCI or Travis. Or even Amazon's own CodeBuild & CodePipeline.<br/><br/>You should also be comfortable with a configuration management system. Ansible is my personal favorite but obviously there is lots of Puppet & Chef out there too. Talk about a playbook you wrote, how it configures the server, installs packages, edits configs and restarts services.<br/><br/>Bonus points if you can talk about handling deployments with autoscaling groups. Those dynamic environments can't easily be captured in static host manifests, so talk about how you handle that.<br/><br/>Of course you should also be strong with Git, bitbucket or codecommit. Talk about how you create a branch, what's gitflow and when/how do you tag a release.<br/><br/>Also be ready to talk about how a code checkin can trigger a post commit hook, which then can go and build your application, or new infra to test your code.<br/><br/>CloudFormation or Terraform<br/><br/>I'm partial to Terraform. Terraform is MacOSX or iPhone to CloudFormation as Android or Windows. Why do I say that? Well it's more polished and a nicer language to write in. CloudFormation is downright ugly. But hey both get the job done.<br/><br/>AWS Services<br/><br/>There are lots of them. But the core services, are what you should be ready to talk about. CloudWatch for centralized logging. How does it integrate with ECS or EKS?<br/><br/>Route53, how do you create a zone? How do you do geo load balancing? How does it integrate with CertificateManager? Can Terraform build these things?<br/><br/>EC2 is the basic compute service. Tell me what happens when an instance dies? When it boots? What is a user-data script? How would you use one? What's an AMI? How do you build them?<br/><br/>What about virtual networking? What is a VPC? And a private subnet? What's a public subnet? How do you deploy a NAT? WHat's it for? How do security groups work?<br/><br/>What are S3 buckets? Talk about infraquently accessed? How about glacier? What are lifecycle policies? How do you do cross region replication? How do you setup cloudfront? What's a distribution?<br/><br/>What types of load balancers are there? Classic & Application are the main ones. How do they differ? ALB is smarter, it can integrate with ECS for example. What are some settings I should be concerned with? What about healthchecks?<br/><br/>What is Autoscaling? How do I setup EC2 instances to do this? What's an autoscaling group? Target? How does it work with ECS? What about EKS?<br/><br/>Devops isn't about writing application code, but you're surely going to be writing jobs. What language do you like? Python and shell scripting are a start. What about Lambda? Talk about frameworks to deploy applications.<br/><br/>Databases<br/><br/>You should have some strong database skills even if you're not the day-to-day DBA. Amazon RDS certainly makes administering a bit easier most of the time. But upgrade often require downtime, and unfortunately that's wired into the service. I see mostly Postgresql, MySQL & Aurora. Get comfortable tuning SQL queries and optimizing. Analyze your slow query log and provide an output.<br/><br/>Amazon's analytics offering is getting stronger. The purpose built Redshift is everywhere these days. It may use a postgresql driver, but there's a lot more under the hood. You also may want to look at SPectrum, which provides a EXTERNAL TABLE type interface, to query data directly from S3.<br/><br/>Not on Redshift yet? Well you can use Athena as an interface directly onto your data sitting in S3. Even quicker.<br/><br/>For larger data analysis or folks that have systems built around the technology, Hadoop deployments or EMR may be good to know as well. At least be able to talk intelligently about it.<br/><br/>Questions<br/><br/>Have you written any CloudFormation templates or Terraform code? For example how do you create a VPC with private & public subnets, plus bastion box with Terraform? What gotches do you run into?<br/><br/>If you are given a design document, how do you proceed from there? How do you build infra around those requirements? What is your first step? What questions would you ask about the doc?<br/><br/>What do you know about Nodejs? Or Python? Why do you prefer that language?<br/><br/>If you were asked to store 500 terrabytes of data on AWS and were going to do analysis of the data what would be your first choice? Why? Let's say you evaluated S3 and Athena, and found the performance wasn't there, what would you move to? Redshift? How would you load the data?<br/><br/>Describe a multi-az VPC setup that you recommend. How do you deploy multiple subnets in a high availability arragement?<br/><br/>Here are a few of the lessons I learned in the process of building code for AWS. It's not easy but when you get there you can enjoy the vistas. They're pretty amazing.<br/><br/>Don't pass credentials<br/><br/>As you build your applications, there are moments where components need to use AWS in some way. Your webserver needs to use S3 or your ELK box needs to use CloudWatch. Maybe you want to do an RDS backup, or list EC2 instances.<br/><br/>However it's not safe to pass your access_key and secret_access_key around. Those should be for your desktop only. So how best to handle this in the cloud?<br/><br/>IAM roles to the rescue. These are collections of privileges. The cool thing is they can be assigned at the INSTANCE LEVEL. Meaning your whole server has permissions to use said resources.<br/><br/>Do this by first creating a role with the privileges you want. Create a json policy document which outlines the specific rules as you see fit. Then create an instance profile for that role.<br/><br/>When you create your ec2 instance in Terraform, you'll specify that instance profile. Either by ARN or if Terraform created it, by resource ID.<br/><br/>Keep passwords out of code<br/><br/>Even though we know it should not happen, sometimes it does. We need to be vigilant to stay on top of this problem. There are projects like Pivotal's credential scan. This can be used to check your source files for passwords.<br/><br/>What about something like RDS? You're going to need to specify a password in your Terraform code right? Wrong! You can define a variable with no default as follows:<br/><br/>variable "my_rds_pass" {<br/>description = "password for rds database"<br/>}<br/><br/>When Terraform comes upon this variable in your code, but sees there is no "default" value, it will prompt you when you do "$ terraform apply"<br/><br/>Versioning your code<br/><br/>When you first start building terraform code, chances are you create a directory, and some tf files, then do your "$ terraform apply". When you watch that infra build for the first time, it's exciting!<br/><br/>After you add more components, your code gets more complex. Hopefully you've created a git repo to house your code. You can check & commit the files, so you have them in a safe place. But of course there's more to the equation than this.<br/><br/>How do you handle multiple environments, dev, stage & production all using the same code?<br/><br/>That's where modules come in. Now at the beginning you may well have a module that looks like this:<br/><br/>Etc and so on. That's the first step in the right direction, however if you change your source code, all of your environments will now be using that code. They will get it as soon as you do "$ terraform apply" for each. That's fine, but it doesn't scale well.<br/><br/>Ultimately you want to manage your code like other software projects. So as you make changes, you'll want to tag it.<br/><br/>Cool! Now each dev, stage and prod can reference a different version. So you are free to work on the infra without interrupting stage or prod. When you're ready to promote that code, checkin, tag and update stage.<br/><br/>You could go a step further to be more agile, and have a post-commit hook that triggers the stage terraform apply. This though requires you to build solid infra tests. Checkout testinfra and terratest.<br/><br/>Managing RDS backups<br/><br/>My recent discovery is even more serious! Terraform wants to build infra. And it wants to be able to later destroy that infra. In the case of databases, obviously the previous state is one you want to keep. You want that to be perpetual, beyond the infra build. Obvious, no?<br/><br/>Apparently not to the folks at Amazon. When you destroy an RDS instance it will destroy all the old backups you created. I have no idea why anyone would want this. Certainly not as a default behavior. What's worse you can't copy those backups elsewhere. Why not? They're probably sitting in S3 anyway!<br/><br/>While you can take a final backup when you destroy an RDS instance, that's wondeful and I recommend it. However that's not enough. I highly suggest you take matters into your own hands. Build a script that calls pg_dump yourself, and copy those .sql or .dump files to S3 for safe keeping.<br/><br/>When to use force_destroy on S3 buckets<br/><br/>As with RDS, when you create S3 buckets with your infra, you want to be able to cleanup later. But the trouble is that once you create a bucket, you'll likely fill it with objects and files.<br/><br/>What then happens is when you go to do "$ terraform destroy" it will fail with an error. This makes sense as a default behavior. We don't want data disappearing without our knowledge.<br/><br/>However you do want to be able to cleanup. So what to do? Two things.<br/><br/>Firstly, create a process, perhaps a lambda job or other bucket replication to regularly sync your s3 bucket to your permanent bucket archive location. Run that every fifteen minutes or as often as you need.<br/><br/>Then add a force_destroy line to your s3 bucket resource. Here's an example s3 bucket for storing load balancer logs:<br/><br/>When you see headlines like this, your first instinct as a CTO is probably, "Am I at risk?" And then "What are the chances of this happening to me?"<br/><br/>Truth can be stranger than fiction. Our efforts as devops should be towards mitigating risk, and reducing potential for these kinds of things to happen.<br/><br/>1. Use aws instance profiles instead<br/><br/>Those credentials that aws provides, are great for enabling the awscli. That's because you control your desktop tightly. Don't you?<br/><br/>But passing them around in your application code is prone to trouble. Eventually they'll end up in a git repo. Not good!<br/><br/>The solution is applying aws IAM permissions at the instance level. That's right, you can grant an instance permissions to read or write an s3 bucket, describe instances, create & write to dynamodb, or anything else in aws. The entire cloud is api configurable. You create a custom policy for your instance, and attach it to a named instance profile.<br/><br/>When you spinup your EC2 instance, or later modify it, you attach that instance profile, and voila! The instance has those permissions! No messy credentials required!<br/><br/>3. blah blah<br/><br/>Hey, while you're at it, why not add a post commit hook to your code repo in git. Have it run the credentials scan each time code is committed. And when it finds trouble, it should email out the whole team.<br/><br/>ECS is Amazon's Elastic Container Service. That's greek for how you get docker containers running in the cloud. It's sort of like Kubernetes without all the bells and whistles.<br/><br/>It takes a bit of getting used to, but This terraform how to, should get you moving. You need an EC2 host to run your containers on, you need a task that defines your container image & resources, and lastly a service which tells ECS which cluster to run on and registers with ALB if you have one.<br/><br/>For each of these sections, create files: roles.tf, instance.tf, task.tf, service.tf, alb.tf. What I would recommend is create the first file roles.tf, then do:<br/><br/>$ terraform init<br/>$ terraform plan<br/>$ terraform apply<br/><br/>Then move on to instance.tf and do the terraform apply. One by one, next task, then service then finally alb. This way if you encounter errors, you can troubleshoot minimally, rather than digging through five files for the culprit.<br/><br/>I recommend deploying in the public subnets for your first run, to avoid complexity of jump box, and private IPs for ecs instance etc.<br/><br/>Good luck!<br/><br/>May the terraform force be with you!<br/><br/>First setup roles<br/><br/>Roles are a really brilliant part of the aws stack. Inside of IAM or identity access and management, you can create roles. These are collections of privileges. I'm allowed to use this S3 bucket, but not others. I can use EC2, but not Athena. And so forth. There are some special policies already created just for ECS and you'll need roles to use them.<br/><br/>These roles will be applied at the instance level, so your ecs host doesn't have to pass credentials around. Clean. Secure. Smart!<br/><br/>Setup your ecs host instance<br/><br/>Next you need EC2 instances on which to run your docker containers. Turns out AWS has already built AMIs just for this purpose. They call them ECS Optimized Images. There is one unique AMI id for each region. So be sure you're using the right one for your setup.<br/><br/>The other thing that your instance needs to do is echo the cluster name to /etc/ecs/ecs.config. You can see us doing that in the user_data script section.<br/><br/>Lastly we're configuring our instance inside of an auto-scaling group. That's so we can easily add more instances dynamically to scale up or down as necessary.<br/><br/>Setup your task definition<br/><br/>The third thing you need is a task. This one will spinup a generic nginx container. It's a nice way to demonstrate things. For your real world usage, you'll replace the image line with a docker image that you've pushed to ECR. I'll leave that as an exercise. Once you have the cluster working, you should get the hang of things.<br/><br/>Note the portmappings, memory and CPU. All things you might expect to see in a docker-compose.yml file. So these tasks should look somewhat familiar.<br/><br/>Setup your service definition<br/><br/>The fourth thing you need to do is setup a service. The task above is a manifest, describing your containers needs. It is now registered, but nothing is running.<br/><br/>When you apply the service your container will startup. What I like to do is, ssh into the ecs host box. Get comfortable. Then issue $ watch "docker ps". This will repeatedly run "docker ps" every two seconds. Once you have that running, do your terraform apply for this service piece.<br/><br/>As you watch, you'll see ECS start your container, and it will suddenly appear in your watch terminal. It will first show "starting". Once it is started, it should say "healthy".<br/><br/>Setup your application load balancer<br/><br/>The above will all work by itself. However for a real-world use case, you'll want to have an ALB. This one has only a simple HTTP port 80 listener. These are much simpler than setting up 443 for SSL, so baby steps first.<br/><br/>Once you have the ALB going, new containers will register with the target group, to let the alb know about them. In "docker ps" you'll notice they are running on a lot of high numbered ports. These are the hostPorts which are dynamically assigned. The container ports are all 80.<br/><br/>You will also want to add a domain name, so that as your infra changes, and if you rebuild your ALB, the name of your application doesn't vary. Route53 will adjust as terraform changes are applied. Pretty cool.<br/><br/>ECS is Amazon's elastic container service. If you have a dockerized app, this is one way to get it deployed in the cloud. It is basically an Amazon bootleg Kubernetes clone. And not nearly as feature rich! ðŸ™‚<br/><br/>That said, ECS does work, and it will allow you to get your application going on Amazon. Soon enough EKS (Amazon's Kubernetes service) will be production, and we'll all happily switch.<br/><br/>Meantime, if you're struggling with the weird errors, and when it is silently failing, I have some help here for you. Hopefully these various error cases are ones you've run into, and this helps you solve them.<br/><br/>Why is my container in a stopped state?<br/><br/>Containers can fail for a lot of different reasons. The litany of causes I found were:<br/><br/>When ecs repeatedly fails, it leaves around stopped containers. These eat up system resources, without much visible feedback. "df -k" or "df -m" doesn't show you volumes filled up. *BUT* there are logical volumes which can fill.<br/><br/>3. My container gets killed before fully started<br/><br/>When a service is run, ECS wants to have *all* of the containers running together. Just like when you use docker-compose. If one container fails, ecs-agent may decide to kill the entire service, and restart. So you may see weird things happening in "docker logs" for one container, simply because another failed. What to do?<br/><br/>First look at your task definition, and set "essential = false". That way if one fails, the other will still run. So you can eliminate the working container as a cause.<br/><br/>Next thing is remember some containers may startup almost instantly, like nginx for example. Because it is a very small footprint, it can start in a second or two. So if *it* depends on another container that is slow, nginx will fail. That's because in the strange world of docker discovery, that other container doesn't even exist yet. While nginx references it, it says hey, I don't see the upstream server you are pointing to.<br/><br/>Solution? Be sure you have a "links" section in your task definition. This tells ecs-agent, that one container depends on another (think of the depends_on flag in docker-compose).<br/><br/>4. Understanding container ordering<br/><br/>As you are building your ecs manifest aka task definition, you want to run through your docker-compose file carefully. Review the links, essential flags and depends_on settings. Then be sure to mirror those in your ECS task.<br/><br/>When in doubt, reduce the scope of your problem. That is define *only one* container, then start the service. Once that container works, add a second. When you get that working as well, add a third or other container.<br/><br/>This approach allows you to eliminate interconnecting dependencies, and related problems. | Ik vind het leuk om Corey Quinn's Last week in AWS newsletter te lezen. En ook echt zoals zijn podcast Schreeuwen in de cloud. Deze week praat Corey met Jay Gordon van Mongodb. Hoewel Jay een beetje een voorstander van multicloud lijkt, is Corey beslist kritisch. Wat een geweldig interview maakt!<br/><br/>Corey schreef ook een stuk The Myth of cloud agnosticism. Ik hou van elk schrijven dat een populaire trope dubs als een "mythe" omdat het een kans is om gaten te prikken in optimisme.<br/><br/>Het is door dit proces dat we realistisch worden, wat cruciaal is om betrouwbaar te zijn in operaties en engineering.<br/><br/>Corey betoogt dat multicloud, met betrekking tot meerdere infrastructuurproviders, meestal een slecht idee is. Dat komt omdat de cloudproviders evolueren, uw applicatie evolueert en het u kost in termen van functiesnelheid. Wat meer is, het biedt twijfelachtige instant uptime in de DR-wereld.<br/><br/>Het onderwerp doet me denken aan soortgelijke mythen in de informatica... de mythe van cross-platform ontwikkeling of de mythe van de cross-platform databases de mythe van object relationele modellering.<br/><br/>Zoals altijd kan uw kilometerstand variÃ«ren. Hier zijn mijn vragen. Ik hoop dat ze kunnen helpen om perspectief te bieden, en kritisch denken rond dit.<br/><br/>1. Bent u van plan om meerdere cloudproviders te gebruiken voor infrastructuur? En uw applicatie twee keer in te zetten?<br/>2. Bent u van plan om meerdere SaaS-providers te gebruiken?<br/>3. Heeft hybride cloud zin? Dat is een optie waarbij u een datalink naar een openbare cloud implementeert, waarbij sommige assets in uw eigen datacenter worden bewaard.<br/>4. Zijn hun functie parallellen over uw gekozen wolken? Of zijn er functie mismatches?<br/>5. Uw cloudproviders hebben onafhankelijke service level agreements. Zijn ze consistent of niet?<br/><br/>6. Hoe ziet de storingsgeschiedenis eruit voor elk van uw aanbieders?<br/>7. Wat is het potentieel voor vetvingerstoring op elk platform? Bijvoorbeeld, kan men te ingewikkeld en gevoelig voor fouten zijn, op basis van API of dashboardinterface.<br/>8. Is Ã©Ã©n cloud ingewikkelder te implementeren? Amazon Web Services is bijvoorbeeld rijker aan functies, maar is ook veel ingewikkelder te implementeren dan een Digital Ocean-installatie.<br/>9. U kunt uw back-ups op beide platforms zien. Heb je op beide hersteld? Regelmatig? Onlangs?<br/>10. Heb je tijd om alles twee keer te automatiseren? Misschien moet je bijvoorbeeld je ansible playbooks voor elk platform herschrijven<br/><br/>11. Wat drijft uw bedrijf om het idee van multicloud te omarmen?<br/>12. Heb je tijd om scripts twee keer te herschrijven? eenmalige en gebruiker-data scripts hetzelfde?<br/>13. Heb je tijd om twee keer te firedrillen? Rooktest twee keer?<br/>14. Zullen verschillende clouds op verschillende manieren falen? Bijvoorbeeld, een kan zwak zijn rond het netwerk. Een andere kan zwak zijn rond de database service, en een derde kan tegenkomen multi-tenant verkeersopstoppingen (schijf of netwerk).<br/>15. Wanneer Ã©Ã©n cloud een functie, bijv. levenscyclusbeleid op S3-emmers, niet ondersteunt, moet u deze voor de andere cloud bouwen?<br/><br/>16. Zal het inzetten van multicloud abstractielagen aanmoedigen Ex: object relationele modellers (ORM) die de prestaties sterk vertragen?<br/>17. Heb je de prestaties op beide wolken getest?<br/>18. Is cloud #2 een tijdelijke disaster recovery oplossing of een lopende load balancing oplossing via geo-dns?<br/>19. Als je hybride cloud gebruikt, hoe beÃ¯nvloedt dat dan de beveiliging, firewalls en toegangscontroles?<br/>20. Hoe bewaak je je objectwinkels (S3), scan je voor open emmers? Herschrijf je deze code voor de andere API?<br/><br/>21. Voor welke soorten rampen ben je van plan?<br/>22. Wat zijn de kosten van het onderhouden van uw applicatie op meerdere platforms?<br/>23. Wat zijn de kosten van het bouwen van infra voor meerdere platforms?<br/>24. Wat zijn de kosten van het debuggen en oplossen van problemen op meerdere platforms?<br/>25. Hoe bemoeilijkt multicloud implementaties?<br/><br/>26. Bemoeilijkt multicloud de GDPR en andere nalevingsvragen?<br/>27. Hoe bemoeilijkt multicloud uw facturering en budgetbeheer?<br/>28. Hoe zit het met microservices? Hoe spelen deze meerdere platforms over twee clouds heen?<br/>29. Is de gemeenschap rond elke cloud even actief?<br/>30. Als u met een infrastructuur als codetaal zoals Terraform implementeert, is er dan een actieve community voor beide van uw gekozen clouds?<br/><br/>31. Ondersteunt elke provider klanten goed? Wat zijn hun respectieve reputaties?<br/>32. Is elke cloud provider even solvent & geÃ¯nvesteerd in het bedrijf? Zullen ze rond in een jaar zijn? vijf jaar? tien jaar?<br/>33. Welke complicaties ontstaan bij de migratie naar of van deze provider?<br/><br/>EKS is een service om kubernetes uit te voeren, dus u hoeft de software niet te installeren of te beheren of te patchen. Net als GKS op Google is kubernetes as a service echt de manier om te gaan als u kubernetes-apps op AWS wilt bouwen.<br/><br/>Dus waar beginnen we? AWS-documenten komen nog steeds samen, dus het is niet gemakkelijk. Ik zou beginnen met Jerry Hargrove's verbazingwekkende EKS-diagram. Als een foto duizend woorden waard is, is dit werk 10.000!<br/><br/>1. Bouw uw EKS-cluster<br/><br/>Ik heb dit al in Terraform gedaan. Er zijn niet veel howto's, dus heb ik er een geschreven.<br/><br/>In principe stel je de servicerol in, het cluster, dan de worker-knooppunten. Zodra je klaar bent, ben je klaar om de demo-app uit te voeren.<br/><br/>2. Bouw uw app-spec<br/><br/>Deze zijn zeer vergelijkbaar met ECS-taken. U moet kleine wijzigingen aanbrengen. mountPoints worden VolumeMounts, links worden verwijderd en workingDirectory wordt workingDir enzovoort. De meeste van deze veranderingen zijn duidelijk, maar de json syntaxis is duidelijk de grootste beer waar je mee worstelt.<br/><br/>Het is niet als, maar wanneer om te verhuizen naar de cloud, hoe er te komen, en hoe snel zal de overgang zijn?<br/><br/>Hier zijn mijn gedachten over waar ik aan moet denken.<br/><br/>1. Versterk team, vaardigheden en paradigmadenken<br/><br/>Teams met ervaring in traditionele datacenters hebben bepaalde manieren om oplossingen te ontwerpen en na te denken over problemen. Ze kunnen bijvoorbeeld NFS-servers kiezen om objecten te hosten, waar je in de cloud objectopslag zoals S3 gebruikt.<br/><br/>S3 heeft allerlei nieuwe functies, zoals levenscyclusbeleid en super super redundante 9's duurzaamheid. Maar uw toepassingen moeten mogelijk worden aangepast om ermee te werken, en uw ontwikkelaars moeten mogelijk meer te weten komen over nieuwe functies en functionaliteit.<br/><br/>Hoe zit het met netwerken? Dit verandert veel in de cloud, met VPC's en virtuele apparaten zoals NAT's en Gateways. En hoe zit het met beveiligingsgroepen?<br/><br/>Interactie met deze nieuwe wereld van cloudbronnen vereist nieuwe vaardigheden en nieuwe manieren van denken. Dus prioriteit zal zijn om uw engineeringteams te laten leren en vaardigheden te upgraden. Ik schreef hierover een stuk hoe ik mijn vaardigheden naar de cloud kan migreren?<br/><br/>2. Aanpassen aan een nieuw beveiligingsmodel<br/><br/>Met het oude datacenter heb je meestal een firewall en wordt alles geblokkeerd en gecontroleerd. De nieuwe wereld van cloud computing maakt gebruik van beveiligingsgroepen. Deze kunnen op netwerkniveau, op uw VPC of op serverniveau worden toegepast. En natuurlijk kun je veel beveiligingsgroepen hebben met overlappende jurisdicties. Hier is hoe je een VPC instelt met Terraform<br/><br/>Dus begrijpen hoe dingen werken in de publieke cloud is vrij nieuw en uitdagend. Er zijn in- en uitstapregels, manieren om te controleren met netwerkstroomlogboeken en meer.<br/><br/>Maar nogmaals, het is een ding om de functies beschikbaar te hebben, het is een heel ander om ze op de juiste manier te gebruiken.<br/><br/>3. Aan te passen aan kwetsbare componenten & netwerken<br/><br/>Terwijl de publieke cloud collectief extreem veerkrachtig is, zijn de afzonderlijke componenten zoals EC2-instanties beslist niet betrouwbaar. Er wordt verwacht dat ze vaak kunnen en zullen sterven. Het is jouw taak als klant om dingen op een zelfgenezende manier op te bouwen.<br/><br/>Dat betekent VPC's met meerdere subnets, over beschikbaarheidszones (multi-az). En dat betekent redundante instances voor alles. Wat meer is, je staat je servers voor met load balancers (klassiek of applicatie). Deze zelf zijn redundant.<br/><br/>Of u nu een gecontaineriseerde applicatie bouwt en implementeert op ECS of een traditionele webserver met automatische schalen met databasebackend, u moet plannen voor mislukking. En dat betekent code die dergelijke storingen detecteert en reageert zonder downtime voor de eindgebruiker.<br/><br/>Dus er is een leercurve. Beide voor uw operatieteams die eerder Rackspace hebben gebeld om een nieuwe server te voorzien. En ook voor uw bedrijf, leren wat een storing veroorzaakt, en de lastige finicky kanten van het beheren van uw openbare cloud door middel van code.<br/><br/>5. Audit, log & monitor<br/><br/>Naarmate je meer en meer stukken automatiseert, heb je mogelijk minder vertrouwen in de algehele reikwijdte van je implementaties. Hoeveel servers gebruik ik op dit moment? Hoeveel S3 buckets? Hoe zit het met elastische IP's?<br/><br/>Omdat uw automatisering zelf nieuwe tijdelijke omgevingen kan opstarten, zullen die resourcetellingen van moment tot moment veranderen. Zelfs een piek in gebruikersbetrokkenheid of een plotselinge flash-verkoop kan uw cloud-voetafdruk in een oogwenk veranderen.<br/><br/>Dat is waar zwaar gebruik van logging zoals ELK (elasticsearch, logstash en kibana) echt kan helpen. Zeker AWS biedt CloudWatch en CloudTrail, maar opnieuw moet je het allemaal goed gebruiken.<br/><br/>Ik ben aan beide kanten van het hek geweest, soms interviewde ik kandidaten, en soms wilde de kandidaat indruk maken om een nieuwe rol te winnen.<br/><br/>Dit zijn mijn suggesties...<br/><br/>Devops Pipeline<br/><br/>Jenkins is niet de enige build server, maar het is al een lange tijd, dus het is overal. Je kunt het ook goed doen met CircleCI of Travis. Of zelfs Amazon's eigen CodeBuild & CodePipeline.<br/><br/>Je moet ook comfortabel zijn met een configuratie management systeem. Ansible is mijn persoonlijke favoriet, maar natuurlijk zijn er ook veel Puppet & Chef er. Praat over een playbook dat je hebt geschreven, hoe het de server configureert, pakketten installeert, configuraties bewerkt en services opnieuw opstart.<br/><br/>Bonuspunten als je kunt praten over het afhandelen van implementaties met autoscaling-groepen. Die dynamische omgevingen kunnen niet gemakkelijk worden vastgelegd in statische hostmanifesten, dus praat over hoe je dat aanpakt.<br/><br/>Natuurlijk moet je ook sterk zijn met Git, bitbucket of codecommit. Praat over hoe je een branch maakt, wat gitflow is en wanneer/hoe je een release tagt.<br/><br/>Wees ook klaar om te praten over hoe een code checkin kan triggeren een post commit hook, die vervolgens kan gaan en bouwen van uw applicatie, of nieuwe infra om uw code te testen.<br/><br/>CloudFormation of Terraform<br/><br/>Ik ben gedeeltelijk aan Terraform. Terraform is MacOSX of iPhone aan CloudFormation als Android of Windows. Waarom zeg ik dat? Nou, het is meer gepolijst en een leukere taal om in te schrijven. CloudFormation is ronduit lelijk. Maar hey, beide krijgen de klus gedaan.<br/><br/>AWS Services<br/><br/>Er zijn veel van hen. Maar de kerndiensten, zijn waar je klaar voor moet zijn om over te praten. CloudWatch voor gecentraliseerde logging. Hoe integreert het met ECS of EKS?<br/><br/>Route53, hoe creÃ«er je een zone? Hoe doe je geo load balancing? Hoe integreert het met CertificateManager? Kan Terraform deze dingen bouwen?<br/><br/>EC2 is de basis rekenservice. Vertel me wat er gebeurt als een instantie sterft? Wanneer het opstart? Wat is een gebruikersgegevensscript? Hoe zou je er een gebruiken? Wat is een AMI? Hoe bouw je ze?<br/><br/>Hoe zit het met virtueel netwerken? Wat is een VPC? En een particulier subnet? Wat is een openbaar subnet? Hoe implementeer je een NAT? Waar is het voor? Hoe werken beveiligingsgroepen?<br/><br/>Wat zijn S3 emmers? Praat over infrasequently accessed? Hoe zit het met gletsjer? Wat zijn lifecycle policies? Hoe doe je cross-region replicatie? Hoe stel je cloudfront in? Wat is een distributie?<br/><br/>Welke soorten load balancers zijn er? Classic & Application zijn de belangrijkste. Hoe verschillen ze? ALB is slimmer, het kan bijvoorbeeld integreren met ECS. Wat zijn enkele instellingen waar ik me zorgen over moet maken? Hoe zit het met healthchecks?<br/><br/>Wat is Autoscaling? Hoe stel ik EC2-instances in om dit te doen? Wat is een autoscalinggroep? Doel? Hoe werkt het met ECS? Hoe zit het met EKS?<br/><br/>Devops gaat niet over het schrijven van applicatiecode, maar je gaat zeker banen schrijven. Welke taal vind je leuk? Python en shell scripting zijn een begin. Hoe zit het met Lambda? Praat over frameworks om applicaties te implementeren.<br/><br/>Databases<br/><br/>U moet een aantal sterke databasevaardigheden hebben, zelfs als u niet de dagelijkse DBA bent. Amazon RDS maakt het beheer van de meeste van de tijd zeker een beetje gemakkelijker. Maar upgrade vereist vaak downtime, en helaas is dat in de service bekabeld. Ik zie meestal Postgresql, MySQL & Aurora. Krijg comfortabele tuning SQL-query's en optimalisatie. Analyseer uw trage querylog en geef een output.<br/><br/>Het analytics-aanbod van Amazon wordt steeds sterker. De speciaal gebouwde Redshift is tegenwoordig overal. Het kan een postgresql-driver gebruiken, maar er is veel meer onder de motorkap. U kunt ook kijken naar SPectrum, dat een EXTERNAL TABLE type interface biedt, om gegevens rechtstreeks van S3 op te vragen.<br/><br/>Nog niet op Redshift? Nou je kunt Athena gebruiken als een interface direct op uw gegevens zittend in S3. Nog sneller.<br/><br/>Voor grotere gegevensanalyse of mensen die systemen hebben gebouwd rond de technologie, kunnen Hadoop-implementaties of EMR ook goed zijn om te weten. In ieder geval in staat zijn om er intelligent over te praten.<br/><br/>Vragen<br/><br/>Heb je CloudFormation-sjablonen of Terraform-code geschreven? Hoe maak je bijvoorbeeld een VPC met private & publieke subnets, plus bastion box met Terraform? Waar loop je tegenaan?<br/><br/>Als je een ontwerpdocument krijgt, hoe ga je dan verder? Hoe bouw je infra rond die vereisten? Wat is je eerste stap? Welke vragen zou je over de doc stellen?<br/><br/>Wat weet je van Nodejs? Of Python? Waarom geef je de voorkeur aan die taal?<br/><br/>Als u werd gevraagd om 500 terrabytes gegevens op te slaan op AWS en zou gaan om de analyse van de gegevens te doen wat uw eerste keuze zou zijn? Waarom? Laten we zeggen dat je S3 en Athena geÃ«valueerd, en vond de prestaties was er niet, wat zou je verhuizen naar? Redshift? Hoe zou je de gegevens laden?<br/><br/>Beschrijf een multi-az VPC-configuratie die u aanbeveelt. Hoe implementeer je meerdere subnetten in een high availability arragement?<br/><br/>Hier zijn enkele van de lessen die ik heb geleerd tijdens het bouwen van code voor AWS. Het is niet gemakkelijk, maar als je er bent, kun je genieten van de uitzichten. Ze zijn vrij geweldig.<br/><br/>Geen inloggegevens doorgeven<br/><br/>Tijdens het bouwen van uw toepassingen zijn er momenten waarop componenten AWS op de een of andere manier moeten gebruiken. Uw webserver moet S3 gebruiken of uw ELK-box moet CloudWatch gebruiken. Misschien wilt u een RDS-back-up maken, of EC2-instanties vermelden.<br/><br/>Het is echter niet veilig om uw access_key en secret_access_key door te geven. Die zouden alleen voor uw bureaublad moeten zijn. Dus hoe dit het beste te behandelen in de cloud?<br/><br/>IAM-rollen voor de redding. Dit zijn verzamelingen van privileges. Het coole is dat ze kunnen worden toegewezen op het INSTANCE-NIVEAU. Dit betekent dat uw hele server machtigingen heeft om deze middelen te gebruiken.<br/><br/>Doe dit door eerst een rol te maken met de rechten die u wilt. Maak een json-beleidsdocument dat de specifieke regels schetst zoals u dat wilt. Maak vervolgens een instantieprofiel voor die rol.<br/><br/>Wanneer u uw ec2-instance in Terraform maakt, geeft u dat instance-profiel op. Ofwel door RNA of als Terraform het heeft gemaakt, door resource-ID.<br/><br/>Wachtwoorden buiten code houden<br/><br/>Hoewel we weten dat het niet mag gebeuren, soms wel. We moeten waakzaam zijn om op de hoogte te blijven van dit probleem. Er zijn projecten zoals Pivotal's inlogscan. Dit kan worden gebruikt om uw bronbestanden te controleren op wachtwoorden.<br/><br/>Hoe zit het met iets als RDS? U moet een wachtwoord opgeven in uw Terraform-code? Verkeerd! U kunt een variabele als volgt definiÃ«ren zonder standaard:<br/><br/>variabele "mijn_rds_pass" {<br/>Beschrijving = "wachtwoord voor rds database"<br/>}<br/><br/>Wanneer Terraform op deze variabele in je code komt, maar ziet dat er geen "standaard" waarde is, zal het je vragen wanneer je "$ terraform toepassen" doet.<br/><br/>Versie van uw code<br/><br/>Wanneer je voor het eerst begint met het bouwen van terraform code, is de kans groot dat je een map maakt en wat tf-bestanden, doe dan je "$ terraform van toepassing". Wanneer je die infra build voor de eerste keer ziet, is het spannend!<br/><br/>Nadat u meer componenten toevoegt, wordt uw code complexer. Hopelijk hebt u een git repo gemaakt om uw code te huisvesten. U kunt de bestanden controleren en committen, zodat u ze op een veilige plaats hebt. Maar natuurlijk is er meer aan de vergelijking dan dit.<br/><br/>Hoe ga je om met meerdere omgevingen, dev, stage & productie allemaal met dezelfde code?<br/><br/>Dat is waar modules binnenkomen. Nu aan het begin heb je misschien wel een module die er zo uitziet:<br/><br/>Etc en ga zo maar door. Dat is de eerste stap in de goede richting, maar als je je broncode wijzigt, zullen al je omgevingen nu die code gebruiken. Ze zullen het krijgen zodra je "$ terraform toepassen" voor elk doet. Dat is prima, maar het schaalt niet goed.<br/><br/>Uiteindelijk wil je je code net als andere softwareprojecten beheren. Dus als je wijzigingen aanbrengt, wil je het labelen.<br/><br/>Cool! Nu kan elke dev, podium en prod verwijzen naar een andere versie. Zo bent u vrij om te werken aan de infra zonder onderbreking podium of prod. Wanneer u klaar bent om die code te promoten, checkin, tag en update podium.<br/><br/>Je zou een stap verder kunnen gaan om wendbaarder te zijn, en een post-commit haak hebben die de terraform van toepassing triggert. Dit vereist echter dat je solide infratests bouwt. Checkout testinfra en terratest.<br/><br/>RDS-back-ups beheren<br/><br/>Mijn recente ontdekking is nog serieuzer! Terraform wil infra bouwen. En het wil die infra later kunnen vernietigen. In het geval van databases is natuurlijk de vorige staat die je wilt behouden. Je wilt dat het voor altijd is, buiten de infra build.<br/><br/>Blijkbaar niet voor de mensen bij Amazon. Wanneer je een RDS-exemplaar vernietigt, vernietigt het alle oude back-ups die je hebt gemaakt. Ik heb geen idee waarom iemand dit zou willen. Zeker niet als standaardgedrag. Wat erger is, je kunt die back-ups niet elders kopiÃ«ren. Ze zitten waarschijnlijk toch in S3.<br/><br/>Hoewel u een definitieve back-up kunt nemen wanneer u een RDS-instantie vernietigt, is dat geweldig en ik raad het aan. Maar dat is niet genoeg. Ik stel voor dat u de zaken in eigen handen neemt. Bouw zelf een script dat pg_dump aanroept en kopieer die .sql- of .dump-bestanden naar S3 voor een veilige bewaring.<br/><br/>Wanneer force_destroy op S3-emmers moet worden gebruikt<br/><br/>Net als bij RDS, wanneer u S3-emmers maakt met uw infra, wilt u later opruimen. Maar het probleem is dat zodra u een emmer maakt, u deze waarschijnlijk zult vullen met objecten en bestanden.<br/><br/>Wat er dan gebeurt is dat wanneer je gaat doen "$ terraform vernietigen" het zal mislukken met een fout. Dit is logisch als een standaard gedrag. We willen niet dat gegevens verdwijnen zonder onze kennis.<br/><br/>Maar je wilt in staat zijn om op te ruimen. Dus wat te doen? Twee dingen.<br/><br/>Ten eerste, maak een proces, misschien een lambda-taak of andere emmerreplicatie om uw s3 emmer regelmatig te synchroniseren met uw permanente emmerarchieflocatie. Voer dat elke vijftien minuten of zo vaak als u nodig hebt.<br/><br/>Voeg vervolgens een force_destroy regel toe aan uw s3 bucket resource. Hier is een voorbeeld s3 bucket voor het opslaan van load balancer logs:<br/><br/>Als je zulke krantenkoppen ziet, is je eerste instinct als CTO waarschijnlijk: "Ben ik in gevaar?" En dan "Wat zijn de kansen dat dit mij overkomt?"<br/><br/>Waarheid kan vreemder zijn dan fictie. Onze inspanningen als devops moeten gericht zijn op het verminderen van risico's en het verminderen van het potentieel voor dit soort dingen om te gebeuren.<br/><br/>1. Gebruik in plaats daarvan aws-instantieprofielen<br/><br/>Die inloggegevens die aws biedt, zijn geweldig voor het inschakelen van de awscli. Dat komt omdat je je desktop strak bestuurt. Nietwaar?<br/><br/>Maar ze doorgeven in uw applicatiecode is gevoelig voor problemen. Uiteindelijk zullen ze eindigen in een git repo. Niet goed!<br/><br/>De oplossing is het toepassen van aws IAM-machtigingen op het instance-niveau. Dat klopt, u kunt een instance machtigingen verlenen om een s3 bucket te lezen of te schrijven, instances te beschrijven, te maken en te schrijven naar dynamodb, of iets anders in aws. De hele cloud is API-configureerbaar. U maakt een aangepast beleid voor uw exemplaar en voegt het toe aan een benoemd exemplaarprofiel.<br/><br/>Wanneer u uw EC2-exemplaar spin-up, of later wijzigt, voegt u dat exemplaarprofiel toe, en voila! Het exemplaar heeft die machtigingen! Geen rommelige referenties vereist!<br/><br/>3e blah blah<br/><br/>Hey, terwijl je op het, waarom niet een post commit hook toe te voegen aan uw code repo in git. Laat het uitvoeren van de inloggegevens scan elke keer code is gecommitteerd. En wanneer het problemen vindt, moet het e-mail het hele team.<br/><br/>ECS is Amazon's Elastic Container Service. Dat is Grieks voor hoe je docker containers draait in de cloud. Het is een soort van Kubernetes zonder alle klokken en fluitjes.<br/><br/>Het duurt een beetje wennen, maar deze terraform hoe te, moet je bewegen. Je hebt een EC2-host nodig om je containers te laten draaien, je hebt een taak nodig die je containerafbeelding en -bronnen definieert, en ten slotte een service die ECS vertelt op welke cluster je moet draaien en je registreert bij ALB als je er een hebt.<br/><br/>Voor elk van deze secties, maak bestanden: roles.tf, instance.tf, task.tf, service.tf, alb.tf. Wat ik zou aanraden is het maken van de eerste bestand roles.tf, dan doen:<br/><br/>$ terraform init<br/>$ terraform plan<br/>$ terraform toepassen<br/><br/>Ga dan naar instance.tf en doe de terraform van toepassing. EÃ©n voor Ã©Ã©n, volgende taak, dan service dan uiteindelijk alb. Op deze manier kunt u als u fouten tegenkomt, problemen minimaal oplossen, in plaats van door vijf bestanden voor de boosdoener te graven.<br/><br/>Ik raad aan om te implementeren in de publieke subnetten voor uw eerste run, om complexiteit van jumpbox te voorkomen, en privÃ©-IP's voor ecs instance etc.<br/><br/>Succes.<br/><br/>Moge de terraform kracht met je zijn!<br/><br/>Eerste set-up rollen<br/><br/>Rollen zijn een echt briljant onderdeel van de aws stack. Binnen IAM of identiteitstoegang en -beheer kun je rollen maken. Dit zijn verzamelingen van privileges. Ik mag deze S3-emmer gebruiken, maar niet anderen. Ik kan EC2 gebruiken, maar niet Athena. En ga zo maar door. Er zijn enkele speciale beleidsregels die alleen voor ECS zijn gemaakt en je hebt rollen nodig om ze te gebruiken.<br/><br/>Deze rollen worden toegepast op het instantieniveau, zodat uw ecs-host geen inloggegevens hoeft door te geven. Schoon. Veilig. Slim!<br/><br/>Uw ecs host instance instellen<br/><br/>Vervolgens heb je EC2-instances nodig om je docker-containers uit te voeren. Het blijkt dat AWS hiervoor al AMI's heeft gebouwd. Ze noemen ze ECS-geoptimaliseerde afbeeldingen. Er is Ã©Ã©n unieke AMI-id voor elke regio. Zorg er dus voor dat u de juiste gebruikt voor uw setup.<br/><br/>Het andere wat uw instantie moet doen is de clusternaam echo naar /etc/ecs/ecs.config. U kunt zien dat we dat doen in de sectie user_data script.<br/><br/>Tenslotte configureren we onze instance binnen een auto-scaling groep. Zo kunnen we eenvoudig meer instances dynamisch toevoegen om op of neer te schalen als dat nodig is.<br/><br/>Uw taakdefinitie instellen<br/><br/>Het derde wat je nodig hebt is een taak. Deze zal een generieke nginx-container draaien. Het is een leuke manier om dingen te demonstreren. Voor uw echte wereldgebruik vervangt u de afbeeldingslijn met een docker-image dat u naar ECR hebt geduwd. Als je de cluster eenmaal hebt laten werken, moet je de boel ophangen.<br/><br/>Let op de portmappings, het geheugen en de CPU. Alle dingen die je zou verwachten te zien in een docker-compose.yml bestand. Dus deze taken moeten er enigszins bekend uitzien.<br/><br/>Uw servicedefinitie instellen<br/><br/>Het vierde wat je moet doen is een service instellen. De bovenstaande taak is een manifest, waarin je je containerbehoeften beschrijft. Het is nu geregistreerd, maar niets loopt.<br/><br/>Wanneer u de service toepast, zal uw container opstarten. Wat ik graag doe, is ssh in de ecs-hostbox. Ga comfortabel zitten. Vervolgens geeft $ de "docker ps" uit. Dit zal elke twee seconden herhaaldelijk "docker ps" uitvoeren. Als je dat eenmaal hebt gedaan, moet je je terraform aanvragen voor dit servicestuk.<br/><br/>Terwijl u kijkt, ziet u ECS uw container starten, en het zal plotseling in uw horlogeterminal verschijnen. Het zal voor het eerst "starten" tonen. Zodra het is gestart, moet het "gezond" zeggen.<br/><br/>Uw applicatie load balancer instellen<br/><br/>Het bovenstaande werkt allemaal vanzelf. Maar voor een real-world use case, je wilt een ALB hebben. Deze heeft alleen een eenvoudige HTTP-poort 80 luisteraar. Deze zijn veel eenvoudiger dan het instellen van 443 voor SSL, dus baby stappen eerst.<br/><br/>Zodra je de ALB hebt gaan, zullen nieuwe containers zich registreren bij de doelgroep, om de alb erover te laten weten. In "docker ps" zul je merken dat ze op veel hooggenummerde poorten draaien. Dit zijn de hostPorts die dynamisch zijn toegewezen. De containerpoorten zijn allemaal 80.<br/><br/>U wilt ook een domeinnaam toevoegen, zodat als uw infra verandert, en als u uw ALB herbouwt, de naam van uw toepassing niet varieert. Route53 zal aanpassen als terraform wijzigingen worden toegepast. Heel cool.<br/><br/>ECS is Amazon's elastische containerservice. Als je een docked-app hebt, is dit een manier om het in de cloud te implementeren. Het is in principe een Amazon-bootleg Kubernetes-kloon. En niet zo rijk aan functies!<br/><br/>Dat gezegd hebbende, ECS werkt, en het stelt u in staat om uw applicatie op Amazon te laten draaien. Binnenkort zal EKS (Amazon's Kubernetes service) de productie zijn, en we zullen allemaal gelukkig overstappen.<br/><br/>Ondertussen, als je worstelt met de vreemde fouten, en als het stil faalt, heb ik hier wat hulp voor je. Hopelijk zijn deze verschillende foutgevallen die je tegenkomt, en dit helpt je om ze op te lossen.<br/><br/>Waarom bevindt mijn container zich in een gestopte toestand?<br/><br/>Containers kunnen om veel verschillende redenen falen. De litanie van oorzaken die ik vond waren:<br/><br/>Wanneer ecs herhaaldelijk faalt, laat het gestopte containers achter. Deze verbruiken systeembronnen, zonder veel zichtbare feedback. "df -k" of "df -m" toont u geen gevulde volumes. * MAAR* er zijn logische volumes die kunnen vullen.<br/><br/>3. Mijn container wordt gedood alvorens volledig te beginnen<br/><br/>Wanneer een service wordt uitgevoerd, wil ECS *alle* van de containers samen laten draaien. Net als wanneer u docker-compose gebruikt. Als Ã©Ã©n container faalt, kan ecs-agent besluiten om de hele service te doden en opnieuw te starten. Dus je kunt vreemde dingen zien gebeuren in "docker logs" voor een container, gewoon omdat een andere mislukte. Wat te doen?<br/><br/>Kijk eerst naar je taakdefinitie en stel "essentieel = vals" in. Als de ene faalt, zal de andere nog steeds draaien. Zo kun je de werkcontainer als oorzaak verwijderen.<br/><br/>Het volgende is om te onthouden dat sommige containers bijna onmiddellijk kunnen opstarten, zoals nginx bijvoorbeeld. Omdat het een zeer kleine voetafdruk is, kan het in een seconde of twee beginnen. Dus als *it* afhankelijk is van een andere container die traag is, zal nginx falen. Dat komt omdat in de vreemde wereld van docker discovery, die andere container nog niet eens bestaat. Terwijl nginx ernaar verwijst, zegt het hey, ik zie de upstream-server die je aanwijst niet.<br/><br/>Oplossing? Zorg ervoor dat je een "links" sectie hebt in je taakdefinitie. Dit vertelt ecs-agent, dat de ene container afhankelijk is van de andere (denk aan de depends_on vlag in docker-compose).<br/><br/>4. Het begrijpen van containerbestelling<br/><br/>Terwijl u uw ecs manifest aka taakdefinitie bouwt, wilt u zorgvuldig door uw docker-compose-bestand lopen. Controleer de koppelingen, essentiÃ«le vlaggen en afhankelijke_instellingen. Zorg er dan voor dat u die in uw ECS-taak weerspiegelt.<br/><br/>Als je twijfelt, verminder dan de reikwijdte van je probleem. Dat is *slechts Ã©Ã©n* container definiÃ«ren, dan start de service. Zodra die container werkt, voeg een seconde toe. Wanneer je dat ook doet, voeg een derde of andere container toe.<br/><br/>Deze aanpak stelt u in staat om onderling verbonden afhankelijkheden en gerelateerde problemen te elimineren. |
| How did you set the due date for those tasks? Are they in Inbox or other custom lists?<br/><br/>oilexxxi<br/>DEV<br/><br/>The tasks are in different lists, inbox and others and almost all of them are repeated tasks. So I don't have to set a due date every time.<br/><br/>uladzimirku<br/><br/>Hello,<br/><br/>Are they not showing in the calendar view (Tomorrow)?<br/><br/>oilexxxi<br/>DEV<br/><br/>The issue is not about calendar. It's abot the view, the option in the menu.<br/><br/>uladzimirku<br/><br/>Have you finished the previous recurrences of those repeat tasks? If not, the next recurrences cannot be shown in the list view. If the none show tasks are not all repeat tasks, please provide the date&time settings. We will look into it for you soon. | Hoe heb je de vervaldatum voor die taken ingesteld? Zijn ze in Postvak IN of andere aangepaste lijsten?<br/><br/>Oliexxxi<br/>DEV<br/><br/>De taken zijn in verschillende lijsten, inbox en anderen en bijna allemaal zijn herhaalde taken. Dus ik hoef niet elke keer een vervaldatum in te stellen.<br/><br/>Uladzimirku<br/><br/>Hallo.<br/><br/>Worden ze niet weergegeven in de kalenderweergave (Morgen)?<br/><br/>Oliexxxi<br/>DEV<br/><br/>Het gaat niet om de kalender, maar om de weergave, de optie in het menu.<br/><br/>Uladzimirku<br/><br/>Hebt u de vorige herhalingen van die herhalingstaken voltooid? Zo niet, dan kunnen de volgende herhalingen niet worden weergegeven in de lijstweergave. Als de taken die niet worden weergegeven niet allemaal herhalingstaken zijn, geef dan de datum- en tijdinstellingen op. We zullen ze binnenkort voor u bekijken. |
| What Is Assisted Living Vs Nursing Homes<br/><br/>ContentsPlanning & Advice Senior Living Articles Nursing Home Care vs Assisted Living. What are my options? My mother loves her apartment and her community, plus, she has many strong friendships there. Her doctor says she may have had some small strokes over the years and has osteoporosisâ€¦What's the difference between Assisted Living and Nursing Home? Assisted living facilities are designed for individuals who are fairly independent and can get through most of the day by themselves. They receive general help with activities like bathing, dressing, and preparing food, and make autonomous decisions about.<br/><br/>Separately, consumer representatives at a hurricane workshop Thursday in â€¦<br/><br/>Apr 20, 2016 â€¦ When you have an aging patient or loved one who can no longer receive the care they need at home, either after an incident or if their overall health is declining, two senior care options you may consider are skilled nursing facilities ( also called nursing homes) and assisted living communities. Here, we â€¦<br/><br/>Assisted Living Well Contents Chuck'' ware was the consummate advocate Service that provides professional Form close bonds with their neighbors Jersey from the alf Well-appointed assisted living facilities often But to those who knew him well, Charles "chuck'' ware was the consummate advocate, a man whose work touched countless lives. He passed away recently â€¦ Former audiologist Marcia<br/><br/>What won't be discussed with FPL or other utilities is the prioritization of service for nursing homes and assisted living facilities. After Hurricane Irma, eight patients died at the Rehabilitation Center at Hollywood Hills when the air â€¦<br/><br/>At some point, support from family, friends, and local programs may not be enough. People who require help full-time might move to a residential facility that provides many or all of the long-term care services they need. Facility-based long -term care services include: board and care homes, assisted living facilities, nursing â€¦<br/><br/>Differences in between Nursing Homes and Assisted Living are: Nursing homes offer skilled nursing and Assisted living offers independence<br/><br/>Medicare and long-term care basics Â· Nursing homes and assisted living facilities Â· Home care Â· Home modifications to continue living at home Â· Respite care Â· â€¹ Previous Page. Resources if you need dental coverage Â· Next page â€º. medicare and long-term care basics. Back to Top. Register for a free account. Register. | Wat wordt bijgestaan Living Vs Nursing Homes<br/><br/>ContentsPlanning & Advice Senior Living Articles Verpleegkundige Thuiszorg vs Geassisteerd Leven. Wat zijn mijn opties? Mijn moeder houdt van haar appartement en haar gemeenschap, plus, ze heeft veel sterke vriendschappen daar. Haar arts zegt dat ze in de loop der jaren misschien een paar kleine beroertes heeft gehad en osteoporose heeft... Wat is het verschil tussen Assisted Living en Nursing Home? Geassisteerde woonfaciliteiten zijn ontworpen voor individuen die vrij onafhankelijk zijn en het grootste deel van de dag zelf kunnen doorkomen. Ze krijgen algemene hulp met activiteiten zoals baden, aankleden en bereiden van voedsel, en maken autonome beslissingen over.<br/><br/>Afzonderlijk, consumentenvertegenwoordigers op een orkaan workshop donderdag in ...<br/><br/>Apr 20, 2016 ... Als je een verouderende patiÃ«nt of geliefde hebt die niet langer de zorg kan krijgen die ze thuis nodig hebben, hetzij na een incident of als hun algehele gezondheid afneemt, zijn er twee opties voor oudere zorg die je kunt overwegen: geschoolde verpleeghuizen (ook wel verpleeghuizen genoemd) en geassisteerde woongemeenschappen. Hier, we...<br/><br/>Chuck's ware was de consummate advocate Service die professionele vorm nauwe banden met hun buren Jersey biedt van de alf Well-appointed assisted living faciliteiten vaak Maar voor degenen die hem goed kende, Charles "chuck" 'ware was de consummate advocate, een man wiens werk raakte talloze levens. Hij is onlangs overleden ... Voormalig audioloog Marcia<br/><br/>Wat niet zal worden besproken met FPL of andere nutsbedrijven is de prioritering van service voor verpleeghuizen en begeleide woonvoorzieningen. Na orkaan Irma stierven acht patiÃ«nten in het Rehabilitation Center in Hollywood Hills toen de lucht ...<br/><br/>Op een gegeven moment is ondersteuning van familie, vrienden en lokale programma's misschien niet genoeg. Mensen die fulltime hulp nodig hebben, kunnen verhuizen naar een residentiÃ«le faciliteit die veel of alle langdurige zorgdiensten biedt die ze nodig hebben. Op de faciliteit gebaseerde langdurige zorgdiensten omvatten: verpleeghuizen en verpleeghuizen, geassisteerde woonvoorzieningen, verpleegkundige ...<br/><br/>Verschillen tussen verpleeghuizen en begeleid wonen zijn: verpleeghuizen bieden bekwame verpleegkundigen en begeleid wonen biedt onafhankelijkheid<br/><br/>Medicare en langdurige zorg basisprincipes Â· Verpleeghuizen en begeleide woonvoorzieningen Â· Thuiszorg Â· Huiswijzigingen om thuis te blijven wonen Â· Verlofzorg Â· â€¹ Vorige pagina. Bronnen als u tandheelkundige dekking nodig hebt Â· Volgende pagina â€º. medicacare en langdurige zorg basis. Terug naar boven. Registreer voor een gratis account. Registreer. |
| ...designed and built.<br/>I want exactly same as this app but cover Arabic and English both languages.<br/>[log masuk untuk melihat URL]<br/>Then you provide english table and I provide Arabic terms.<br/>Can you give prototype first?<br/>but I want to add option to search geographically and select marriage type. There are difftentLooking for a native English transcriber for this work. Total length of audio is 9 hours. Deadline 3 days. We need first ...transcpost accountHello freelancers,<br/>I want a freelancer to write me around 70...blog knowledge please bid.<br/>I have around 3000 videos to edit. Kindly give me your best proposal per video.<br/>I am looking to hire for long term as there are many more videos as well which needs to edited.<br/>Details will be shared in message with the freelancers.<br/>Only people who can provide a sample of my current work can only bid if freelancer will ignore<br/><br/>I want to build app similar to this:<br/>[log masuk untuk melihat URL]<br/>But it should be available for multiple content creators instead of only 1. [log masuk untuk melihat URL] 100 creators<br/>It should be properly integrated with payment gateway.<br/>UI should be really good with seamless navigation.<br/>There shouldn't be any issues | ...ontworpen en gebouwd.<br/>Ik wil precies hetzelfde als deze app, maar dekken Arabisch en Engels beide talen.<br/>[log masuk untuk melihat URL]<br/>Dan geef je Engelse tafel en geef ik Arabische termen.<br/>Kun je eerst een prototype geven?<br/>maar ik wil optie toevoegen om geografisch te zoeken en het huwelijkstype te selecteren. Er zijn difftentOp zoek naar een native English transcriber voor dit werk. Totale lengte van audio is 9 uur. Deadline 3 dagen. We hebben eerst nodig ...transcpost accountHallo freelancers,<br/>Ik wil een freelancer om me te schrijven rond 70... blogkennis gelieve te bieden.<br/>Ik heb ongeveer 3000 video's te bewerken. Geef me vriendelijk uw beste voorstel per video.<br/>Ik ben op zoek naar een lange termijn huren, want er zijn veel meer video's ook die moeten worden bewerkt.<br/>Details worden in een bericht gedeeld met de freelancers.<br/>Alleen mensen die een voorbeeld van mijn huidige werk kunnen bieden kunnen alleen bieden als freelancer zal negeren<br/><br/>Ik wil een app bouwen die vergelijkbaar is met dit:<br/>[log masuk untuk melihat URL]<br/>Maar het moet beschikbaar zijn voor meerdere content creators in plaats van alleen 1. [log masuk untuk melihat URL] 100 creators<br/>Het moet goed worden geÃ¯ntegreerd met de betalingsgateway.<br/>UI moet echt goed zijn met naadloze navigatie.<br/>Er zouden geen problemen moeten zijn |
