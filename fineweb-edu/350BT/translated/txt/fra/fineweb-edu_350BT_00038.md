| original | translation |
|----------|-------------|
| Artificial intelligence (AI), the computerized capability of doing tasks, which until recently was thought to be the exclusive domain of human intelligence, has demonstrated great strides in the past decade. The abilities to play games, provide piloting for an automobile, and respond to spoken language are remarkable successes. How are the challenges and opportunities of medicine different from these challenges and how can we best apply these data-driven techniques to patient care and outcomes? A New England Journal of Medicine paper published in 1980 suggested that more well-defined “specialized” tasks of medical care were more amenable to computer assistance, while the breadth of approach required for defining a problem and narrowing down the problem space was less so, and perhaps, unachievable. On the other hand, one can argue that the modern version of AI, which uses data-driven approaches, will be the most useful in tackling tasks such as outcome prediction that are often difficult for clinicians and patients. The ability today to collect large volumes of data about a single individual (eg, through a wearable device) and the accumulation of large datasets about multiple persons receiving medical care has the potential to apply to the care of individuals. As these techniques of analysis, enumeration, aggregation, and presentation are brought to bear in medicine, the question arises as to their utility and applicability in that domain. Early efforts in decision support were found to be helpful; as the systems proliferated, later experiences have shown difficulties such as alert fatigue and physician burnout becoming more prevalent. Will something similar arise from data-driven predictions? Will empowering patients by equipping them with information gained from data analysis help? Patients, providers, technology, and policymakers each have a role to play in the development and utilization of AI in medicine. Some of the challenges, opportunities, and tradeoffs implicit here are presented as a dialog between a clinician (SJN) and an informatician (QZT).J Med Internet Res 2019;21(11):e16272<br/>Drs Nelson and Zeng-Treitler work together at the Biomedical Informatics Center at George Washington University. In the following we present a hypothetical dialogue which grew out of discussions they had as they considered their differing viewpoints of how artificial intelligence (AI) has developed and where it is going. While Dr Zeng-Treitler’s view of the future of AI is highly optimistic, Dr Nelson's opinion is more cautious. Dr Nelson was a practicing academic internist who became involved in informatics many years ago. He collaborated with Scott Blois on RECONSIDER (an early clinical decision support system) and on the Unified Medical Language System (UMLS) project. He eventually moved to the National Library of Medicine as Head of Medical Subject Headings. While at the National Library of Medicine, he fathered RxNorm, while continuing his work on UMLS and projects involving UMLS. Dr Zeng-Treitler has a background in computer science and obtained her PhD in medical informatics from Columbia University. She has led a number of projects in clinical data mining, natural language processing, and consumer health informatics. During the past few years, her team has been actively investigating the use of AI techniques in clinical research including development of a novel explainable deep learning approach.<br/>Dr Zeng-Treitler (The "Optimist"):<br/>After decades of promises and disappointment, thanks to the seemingly unbounded computing resources and novel, data-driven methods, AI technology has finally arrived. From Jeopardy and Siri to face identification and autonomous vehicles, data-driven approaches have made the leap from laboratory experiments to applications that are transforming our lives outside health care. In some cases, these approaches have come close to passing the Turing Test—a test of a machine’s ability to exhibit supposed human-like intelligence; machines can now perform some complex tasks such as image recognition and authentic game play as well as or better than humans would. Some would argue that the requisite approach is decidedly nonhuman. However, whatever the means to achieving these innovations, such successes have not been followed by analogous successes in health care.<br/>One dramatic example of this disparity of accomplishment is AlphaZero, a computer game engine that mastered chess, Shogi, and Go. Even before the arrival of the current generation of data-driven artifacts, chess engines have been shown to be able to play at a level superior to that of chess champions. Players of Go (a board game that is thought to be much more complex than chess), however, believed that computers were no match for high-level professionals in this game. This belief was shattered first by AlphaGo, which soundly defeated the reigning world champion of Go. Then came AlphaZero. The news is no longer that such approaches can beat the champions of Go, chess, or Shogi. Rather, the remarkable fact is that AlphaZero did not learn from human experiences and that it defeated the best prior chess engines such as Stockfish. AlphaZero triumphed by playing more games against itself than had ever been played by all human players. This is not an approach we could readily duplicate in health care.<br/>Dr Nelson (The "Cautious" One):<br/>Is winning a game, with defined rules and objectives, really the best test of human intelligence? In hindsight, the answer is “No.” For example, sophisticated chess playing programs have existed for nearly 50 years; from such programs, we learned how to organize computing resources to apply simple algorithms in a scalable way. Put differently, we did not learn anything about chess or how humans, even experts, play it. Instead, we learned that a supposed intelligence-requiring task was susceptible to a computational approach. We need to ask where and how such an approach is applicable in health care.<br/>For example, when doing tasks that are generally thought to be human and creative, can the machine recognize when it is out of its depth? Sometimes, humans have the ability to do so. However, if we can define the realm closely enough, I agree that the machines can do wonders. So, how do we define the realm?<br/>In Blois’ seminal paper on Clinical Judgment and Computers , he described the world of a physician’s thought process when seeing a patient, with the diagram shown in . Point A for a physician would be where the patient walks in the door to be seen for the first time. The nature of the complaint, the context in which the complaint occurs, and all of the myriad possibilities are present. As the problem definition moves toward Point B, a computer is better able to manage the information and knowledge necessary for high-quality care. One way in which we can think about defining the realm is that we are moving toward Point B. Some computer scientists have argued that Point A is just about managing facts, but, as Blois observed, it is more about relevance—something that has proven difficult to replicate computationally.<br/>It is indeed important to define the realm for an AI application. Many tasks in health care are much more complex than game play, and we have not witnessed the triumphs of analogous approaches in the biomedical domain as have been achieved in game play. Quite a few studies have been applying the latest deep learning technology (a key AI method) to biomedical datasets [- ]. The specific applications included image processing, natural language processing, and risk prediction. Deep learning, compared with traditional statistical and machine learning methods, has often shown modest improvements rather than breakthroughs [ - ].<br/>Whatever the details of these approaches, they apply nearly unbounded computing resources to very large amounts of data, something that has yet to happen in health care. Therefore, these approaches might prove helpful, but we do not know for sure yet.<br/>For example, a simple question posed by a colleague is beyond our current capabilities: Given a patient who starts out with a feature of metabolic syndrome, which feature of the syndrome will he or she tend to exhibit next? Simplistically, this is exactly the kind of challenge that a data-driven approach should help with, and yet, it is currently “over the horizon” due to the insufficient data that were collected in the past.<br/>Data are a key challenge when applying data-driven approaches to patient care. To begin with, biomedical data are highly complex. There many different types of data including image, text, numerical values, categorical classifications, and DNA sequences, representing tens of thousands of lab tests, procedures, diagnoses, medications, genetic markers, etc. Each data type also has its own characteristics; for example, a laboratory test value may need to be interpreted in the context of age, gender, and current conditions. However, diagnostic codes for different diseases have varying levels of accuracies.<br/>In biomedical data analysis, there is also the paradox of having too much and not enough data at the same time. On one hand, there are a tremendous amount of medical record, social media, and literature data. Efforts like the Million Veterans Project  have also collected a huge amount of DNA data. Using devices for tasks like activity tracking and continuous glucose monitoring generates more data than our current medical record systems can digest. On the other hand, the health record of a patient is an open system with much missing information in contrast with the closed system of a chess or Go game, where all data are available. Patients are observed at irregular intervals (eg, at clinic visits or during hospitalization) and are never subjected to all possible tests or treatments. Sometimes, death is the only definitive outcome.<br/>I agree that data types are multiple and complex. Simple solutions are insufficient, and the proliferation of irrelevant data in a record, not to mention the current cut-and-paste or fill-in-the-template fad, obscures what is important.<br/>One of the major difficulties with medical data is not just that it is not enough, but also that it is theory laden, that is, very few pieces of data are recorded routinely. A lot of data in observations are gathered only when the clinician has thought it is appropriate, that is, when diseases are tested for their absence or presence. If there is no reason to do the test, the test is not performed. Only a few tests are ever performed routinely; a transcribed set of physical observations (as is done in physical examination) is rarely recorded in enough detail (not to mention the failure to observe, which often occurs) to provide sufficient data for a more comprehensive analysis. For that reason alone, studies based on the recorded observations are often incomplete and potentially misleading. However, for predictions, observations not made may be the critical ones. Think about the patient with metabolic syndrome mentioned above. What data are we missing?<br/>Similarly, the results of clinical trials are not a complete picture. Even though participants have been selected, often excluding many individuals because of complicating conditions, the data collected on the participants are designed for testing certain hypotheses, with narrowly defined outcomes. A common criticism is that such trials are so artificial that they are irrelevant.<br/>The lack of integrated and standardized datasets is another issue. Although we can find many large datasets, they are often incomplete and difficult to link to other information. For example, environmental exposure, diet, physical activity, and genetic profile are among the common missing pieces of information when we examine the records about an individual patient. Detailed clinical trial datasets tend to lack long-term follow-up. Privacy issues and monetary incentives are also obstacles in data integration efforts.<br/>Real semantic interoperability to integrate and standardize datasets requires support in both terminology and how that terminology is used. Currently, human intervention is often required to interpret what one system is saying for use in another system. This situation is unfortunate; we can hope that over time, the necessary connections will take place (think of how the United States went from operator assistance on every telephone call to the automatic switching that takes place today). Such a change can only happen when many people see the need for and implement a common standard.<br/>In addition, the notion of “large” in the context of health care data is only relative. Think, instead, of many experiments undertaken by Google; if they desire, the amount of data that can be used to develop and test a model is orders of magnitude greater than that available in health care.<br/>In the domains where data-driven approaches have demonstrated success, there are outcomes that can be judged by human experts or machines themselves. For example, bilingual speakers can tell if natural language translation is working well, and the outcome of board or computer games can be easily determined. This allows easier simulation or annotation of data for machine learning. Such a task is much harder in the biomedical domains; investigation of causes or treatments of diseases in humans involve costly and long-term studies. In some cases, ethical concerns prohibit the experiments; for example, the introduction of potentially harmful genetic mutations into healthy human subjects is out of the question. We lack long-term outcome data for many treatments.<br/>I am not sure that there ever will be such a gold standard without a completely arbitrary definition. Variation between individuals is also a major obstacle. Although we perform studies using multiple subjects to account for biologic variability, our results are only approximate in their relevance to a given individual. For example, assuring genetic diversity in clinical trials is challenging, to say the least. Even the simplest tasks can be staggeringly multifactorial; for example, the information content of genetic testing for warfarin metabolism can be outweighed by whether the patient had lettuce for lunch.<br/>To expand on this observation, suppose you have an automobile that is not working appropriately. Today, you consult the sensors and the computer readout to give you very precise information about what is going wrong. The automobile has a specific design, with specific parameters that can be measured. All of the vehicles of the same year make and model can be assumed to be alike in those important aspects. It is important to realize that every human (with the exception of identical twins) is genetically unique. In that way, people are very different from automobiles or other mechanical devices. To compound the complexity with which the cause of a human problem can be addressed, what the individual experiences throughout their life is unique. Although we have nice abstractions or methods of identifying individuals who share some common characteristics (whether the presence or absence of a disease, the response or lack thereof to a medication, the similar environment, or other considerations), these are only a shorthand notation. With 7 billion persons currently living in this world, the problem appears almost open-ended. Too often in data analysis, we look at diagnostic codes as having a deep meaning. These are accepted without any recognition of the degree of uncertainty of the diagnosis. All our data may be helpful and useful, but we need to continue to view them with a large grain of salt. The fact that Google Translate works as well as it does gives us hope, but as complex as natural language translation is, it is simpler than some clinical tasks.<br/>Despite these challenges, applying data-driven approaches has the potential to transform health care. Today’s health care is labor intensive, from scheduling and triage to diagnosis and treatment. Many tasks currently undertaken by humans can be carried out by intelligent software solutions supported by sufficient data. For instance, improved voice recognition and summarization technology might help reduce the amount of time patients and clinicians spend on paperwork. Improved decision support tools ought to be able to help patients decide about the appropriateness of seeking care. An accurate assessment of short- and long-term risks and benefits will inform treatment selection and lifestyle changes.<br/>To provide another use case, there is evidence that type II diabetes may be reversible, but it is hard to apply this knowledge to an individual patient. Given the patient in front of me, what should I do, or recommend, and with what expectation? Demographics, genomics, comorbidities, psyche, competing risks, and other medications, all play a role. How, in a given person, do I reconcile all the possibilities?<br/>To develop these useful AI tools, we need better data, technology, and policy. To accumulate comprehensive, life-time data, patients must be in control and should be incentivized to share their data for research and care. Insurance, pharmaceutical, and medical institutions change over time. Currently, there are barriers for individuals to be the center of collecting the data on themselves. The barriers are present in data entry, collection, and storage; for example, some personalized health record products are tethered to an institution, while others require extensive transcribing efforts by patients or caregivers. Nevertheless, without patient consent and collaboration, gathering and linking longitudinal environmental, genetic, clinical, and behavioral data are neither feasible nor ethical. The current conditions are a huge barrier to any attempt to use data-driven approaches that have worked outside health care.<br/>Efforts including PatienstLikeMe  and the All of Us Research Project of the National Institutes of Health [ ] are examples of innovative approaches to curate bigger and better datasets. Most patients, however, are not engaged in such efforts. Patients are inherently motivated to improve their own health, but naturally have concerns regarding privacy and often do not see immediate benefits of participating in long-term studies. Appropriate incentives (eg, discounts for routine preventive care) coupled with security and authentication technologies are needed to entice a large and diverse population of patients to gather and share their data. The health care industry today owns parts of patient data and has limited motivation to purchase data from their customers. As the value of data increases, patients will become more valued as a partner.<br/>I agree that patients will need to assume the responsibility of carrying and sharing the information about themselves. However, experience tells us that not everyone is able or willing to do so. It will need cultural and political climate changes to encourage that development.<br/>When we can collect data that are not directly what the philosophers would call “theory-laden,” we may be able to refine our crude methods of patient diagnosis and care. I look forward to that day. If patients are the carrier of those data, it will be easier to obtain and use for analysis.<br/>We also need to design and implement methods specifically for handling very large and “messy” clinical data. For example, we need to understand the context of missing data and errors to get a better picture of ground truth. A lab result may be missed because there is no indication for it, practice preference, an alternative method of assessing, or a failure of data entry. Imagine how much more difficult a chess game will be, if a human player or a chess engine could only observe some squares on the board at irregular time intervals with some error or distortion of the observation.<br/>Further, we do not have an operational definition of “ground truth” in health care; a simple proposal is that one feature of ground truth is that it has predictive value—something that will be valued by clinicians and patients alike.<br/>Google has demonstrated that they can use lots of data to predict likely values for missing data in other areas ; however, it is yet to be determined whether this might work in medicine, but it is probably worth a trial. Irrespective of whether we can use large volumes of data to impute missing values, exploring how to handle the problem of absent observations is crucial, especially whenever we try to apply the results of data-driven approaches to individual patients.<br/>Another thought is that data that are missing, for any reason, are an observation in itself; the fact that the data were not obtained and recorded may be important. Think of the finding that the day and time of a test were more predictive of outcome than the result of the test . We know that the data that are missing will have some predictive value.<br/>On a different note, explanation of the data-driven models is critical to not only their adoption but also their impact . Predicting that a patient will have certain adverse events in the next several days or years is desirable. It may be argued that it is even more important to know the modifiable factors that can reduce risk and enhance outcome. Since deep learning models can be highly nonlinear, we have the opportunity to discover novel and complex patterns.<br/>I agree that explaining the prediction is critical; it is something that separates health care from, say, recognizing whether an image is a dog or a cat. However, I think you meant to say predicting a patient will probably have some adverse outcome. Nothing in life is certain except that it will end. However, we can say “it appears this behavior or finding will likely have an effect on your future” and hopefully be able to express some degree of confidence in that prediction.<br/>Learning how to express the confidence in a prediction is also important. How many folks really understand the statistics behind the predictions that occur today? What are the underlying assumptions behind any probabilistic model? It is more likely that with more frequent use and familiarity with the use of measures derived for AI models will lead to their acceptance.<br/>I agree. These are all steps to be taken in order to optimize the use of big data through AI to improve medical care.<br/>As a parting thought, we need to be cautious about how intrusive data-driven approaches might be in the care process. Although McDonald  demonstrated that performance in care improves with reminders [ ], the later experience has been one of too many reminders, leading to alert fatigue. When caregivers choose to override and ignore helpful information because of overload, have we accomplished anything?<br/>I hope that careful design of systems and consideration of clinical workflow will alleviate the problem of excessive intrusiveness. Although it is tempting to just “let AI do it,” the recent experiences with the Boeing 737 MAX demonstrate that there is danger in doing so. Neither AI nor a pilot alone is the optimal strategy in flying. In health care, involving patients more extensively in their care, together with AI and providers, may ultimately be an approach that works.<br/>Conflicts of Interest<br/>- Blois MS. Clinical Judgment and Computers. N Engl J Med 1980 Jul 24;303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Deep learning for healthcare: review, opportunities and challenges. Brief Bioinform 2018 Nov 27;19(6):1236-1246 [FREE Full text] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. Can machine-learning improve cardiovascular risk prediction using routine clinical data? PLoS ONE 2017 Apr 4;12(4):e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT. Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records. Sci Rep 2016 May 17;6(1):26094 [FREE Full text] [CrossRef] [Medline]<br/>- Quach K. The register. 2019. IBM Watson Health cuts back drug discovery 'artificial intelligence' after lackluster sales URL: https://www.theregister.co.uk/2019/04/18/ibm_watson_health [accessed 2019-10-23]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Scalable and accurate deep learning with electronic health records. NPJ Digit Med 2018 May 8;1(1):18 [FREE Full text] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, et al. Deep Learning in Medical Imaging: General Overview. Korean J Radiol 2017;18(4):570. [CrossRef]<br/>- U.S Department of Veterans Affairs. Million Veteran Program (MVP) URL: https://www.research.va.gov/mvp/ [accessed 2019-10-23]<br/>- Patientslikeme. URL: https://www.patientslikeme.com [accessed 2019-10-23]<br/>- All of Us Research Program. URL: https://allofus.nih.gov [accessed 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. The unreasonable effectiveness of data. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Biases in electronic health record data due to processes within the healthcare system: retrospective observational study. BMJ 2018 Apr 30:k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, Müller H. Causability and explainabilty of artificial intelligence in medicine. WIREs Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Protocol-Based Computer Reminders, the Quality of Care and the Non-Perfectibility of Man. N Engl J Med 1976 Dec 09;295(24):1351-1355. [CrossRef]<br/>&#124;AI: artificial intelligence&#124;<br/>&#124;UMLS: Unified Medical Language System&#124;<br/>Edited by G Eysenbach; submitted 15.09.19; peer-reviewed by A Holzinger; comments to author 14.10.19; revised version received 15.10.19; accepted 20.10.19; published 27.11.19Copyright<br/>©Qing Zeng-Treitler, Stuart J Nelson. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included. | L'intelligence artificielle (IA), la capacité informatisée de faire des tâches, qui jusqu'à récemment était considérée comme le domaine exclusif de l'intelligence humaine, a démontré de grands progrès au cours de la dernière décennie. Les capacités à jouer à des jeux, à piloter une voiture et à répondre au langage parlé sont des succès remarquables. En quoi les défis et les opportunités de la médecine sont-ils différents de ces défis et comment pouvons-nous mieux appliquer ces techniques axées sur les données aux soins et aux résultats des patients? Un article du New England Journal of Medicine publié en 1980 suggérait que des tâches de soins médicaux « spécialisées » plus bien définies étaient plus adaptées à l’assistance informatique, tandis que l’ampleur de l’approche requise pour définir un problème et réduire l’espace du problème l’était moins, et peut-être, irréalisable. D’autre part, on peut soutenir que la version moderne de l’IA, qui utilise des approches axées sur les données, sera la plus utile pour s’attaquer à des tâches telles que la prédiction des résultats qui sont souvent difficiles pour les cliniciens et les patients. La capacité actuelle de collecter de grandes quantités de données sur un seul individu (par exemple, par le biais d’un dispositif portable) et l’accumulation de vastes ensembles de données sur plusieurs personnes recevant des soins médicaux peuvent s’appliquer aux soins prodigués aux individus. Au fur et à mesure que ces techniques d'analyse, d'énumération, d'agrégation et de présentation sont appliquées en médecine, la question se pose de leur utilité et de leur applicabilité dans ce domaine. Les premiers efforts d'aide à la décision se sont révélés utiles; à mesure que les systèmes prolifèrent, des expériences ultérieures ont montré que des difficultés telles que la fatigue d'alerte et l'épuisement professionnel des médecins deviennent plus fréquentes. Est-ce que des prédictions basées sur les données permettront aux patients de se doter d’informations tirées de l’analyse des données? Les patients, les fournisseurs, la technologie et les décideurs ont chacun un rôle à jouer dans le développement et l’utilisation de l’IA en médecine. Certains des défis, des opportunités et des compromis implicites ici sont présentés comme un dialogue entre un clinicien (SJN) et un informaticien (QZT).<br/>Les Drs Nelson et Zeng-Treitler travaillent ensemble au Centre d’informatique biomédicale de l’Université George Washington. Dans ce qui suit, nous présentons un dialogue hypothétique qui est né des discussions qu’ils ont eues alors qu’ils considéraient leurs points de vue divergents sur la façon dont l’intelligence artificielle (IA) s’est développée et où elle va. Bien que l'opinion du Dr Zeng-Treitler sur l'avenir de l'IA soit très optimiste, l'opinion du Dr Nelson est plus prudente. Le Dr Nelson était un interniste universitaire pratiquant qui s'est impliqué dans l'informatique il y a de nombreuses années. Il a collaboré avec Scott Blois sur RECONSIDER (un système d'aide à la décision clinique précoce) et sur le projet de système unifié de langage médical (UMLS). Pendant son séjour à la Bibliothèque nationale de médecine, il a engendré RxNorm, tout en poursuivant ses travaux sur UMLS et les projets impliquant UMLS. Le Dr Zeng-Treitler a une formation en informatique et a obtenu son doctorat en informatique médicale de l'Université Columbia. Elle a dirigé un certain nombre de projets dans l’exploration de données cliniques, le traitement du langage naturel et l’informatique de la santé des consommateurs. Au cours des dernières années, son équipe a activement étudié l’utilisation des techniques d’IA dans la recherche clinique, y compris le développement d’une nouvelle approche d’apprentissage profond explicable.<br/>Dr Zeng-Treitler (L'"Optimist") :<br/>Après des décennies de promesses et de déceptions, grâce à des ressources informatiques apparemment illimitées et à de nouvelles méthodes axées sur les données, la technologie de l’IA est enfin arrivée. De Jeopardy à Siri en passant par l’identification et les véhicules autonomes, les approches basées sur les données ont fait le saut des expériences de laboratoire aux applications qui transforment nos vies en dehors des soins de santé. Dans certains cas, ces approches sont proches de passer le test de Turing – un test de la capacité d’une machine à présenter une prétendue intelligence humaine; les machines peuvent maintenant effectuer certaines tâches complexes telles que la reconnaissance d’images et le jeu authentique ainsi que ou mieux que les humains. Certains diront que l'approche requise n'est décidément pas humaine, mais quels que soient les moyens d'atteindre ces innovations, de tels succès n'ont pas été suivis de succès analogues dans le domaine des soins de santé.<br/>Un exemple dramatique de cette disparité d'accomplissement est AlphaZero, un moteur de jeu informatique qui maîtrise les échecs, Shogi et Go. Même avant l'arrivée de la génération actuelle d'artefacts basés sur les données, il a été démontré que les moteurs d'échecs pouvaient jouer à un niveau supérieur à celui des champions d'échecs. Les joueurs de Go (un jeu de plateau qui est considéré comme beaucoup plus complexe que les échecs), cependant, croyaient que les ordinateurs n'étaient pas de taille pour les professionnels de haut niveau dans ce jeu. Cette croyance a d'abord été brisée par AlphaGo, qui a vaincu le champion du monde en titre de Go. Puis est venu AlphaZero. La nouvelle n'est plus que de telles approches peuvent battre les champions de Go, d'échecs ou de Shogi. Au contraire, le fait remarquable est qu'AlphaZero n'a pas appris des expériences humaines et qu'il a vaincu les meilleurs moteurs d'échecs antérieurs tels que Stockfish.AlphaZero a triomphé en jouant plus de jeux contre lui-même que tous les joueurs humains. Ce n'est pas une approche que nous pourrions facilement dupliquer dans les soins de santé.<br/>Dr Nelson (Le « prudent ») :<br/>Gagner un jeu, avec des règles et des objectifs définis, est-il vraiment le meilleur test de l’intelligence humaine ? Avec le recul, la réponse est « Non ». Par exemple, des programmes de jeu d’échecs sophistiqués existent depuis près de 50 ans; à partir de ces programmes, nous avons appris à organiser les ressources informatiques pour appliquer des algorithmes simples d’une manière évolutive. Autrement dit, nous n’avons rien appris sur les échecs ni sur la façon dont les humains, même les experts, y jouent, mais nous avons appris qu’une tâche supposée nécessitant une intelligence était susceptible d’une approche computationnelle. Nous devons nous demander où et comment une telle approche est applicable dans les soins de santé.<br/>Par exemple, lorsque vous effectuez des tâches qui sont généralement considérées comme humaines et créatives, la machine peut-elle reconnaître quand elle est hors de sa profondeur? Parfois, les humains ont la capacité de le faire. Cependant, si nous pouvons définir le royaume assez étroitement, je suis d'accord que les machines peuvent faire des merveilles. Alors, comment définissons-nous le royaume?<br/>Dans l'article fondateur de Blois sur le jugement clinique et les ordinateurs, il a décrit le monde du processus de pensée d'un médecin lorsqu'il voit un patient, avec le diagramme montré dans . Le point A pour un médecin serait l'endroit où le patient entre dans la porte pour être vu pour la première fois. La nature de la plainte, le contexte dans lequel la plainte se produit et toutes les myriades de possibilités sont présentes. Au fur et à mesure que la définition du problème se déplace vers le point B, un ordinateur est mieux en mesure de gérer les informations et les connaissances nécessaires à des soins de haute qualité. Une façon dont nous pouvons penser à définir le royaume est que nous nous dirigeons vers le point B. Certains informaticiens ont fait valoir que le point A ne concerne que la gestion des faits, mais, comme l’a observé Blois, il s’agit plus de pertinence – quelque chose qui s’est avéré difficile à reproduire par calcul.<br/>Il est en effet important de définir le domaine d'une application d'IA. De nombreuses tâches dans les soins de santé sont beaucoup plus complexes que le jeu, et nous n'avons pas assisté aux triomphes d'approches analogues dans le domaine biomédical comme cela a été réalisé dans le jeu. De nombreuses études ont appliqué les dernières technologies d'apprentissage profond (une méthode clé de l'IA) aux ensembles de données biomédicales [- ]. Les applications spécifiques comprenaient le traitement d'images, le traitement du langage naturel et la prédiction des risques. L'apprentissage profond, par rapport aux méthodes statistiques et d'apprentissage automatique traditionnelles, a souvent montré des améliorations modestes plutôt que des percées.<br/>Quels que soient les détails de ces approches, elles appliquent des ressources informatiques presque illimitées à de très grandes quantités de données, ce qui n'a pas encore eu lieu dans le domaine des soins de santé. Par conséquent, ces approches pourraient s'avérer utiles, mais nous ne le savons pas encore avec certitude.<br/>Par exemple, une simple question posée par un collègue est au-delà de nos capacités actuelles: Étant donné un patient qui commence avec une caractéristique du syndrome métabolique, quelle caractéristique du syndrome aura-t-il tendance à exposer ensuite? Simpliquement, c'est exactement le genre de défi qu'une approche axée sur les données devrait aider, et pourtant, il est actuellement "à l'horizon" en raison de l'insuffisance des données qui ont été collectées dans le passé.<br/>Les données sont un défi clé lors de l'application d'approches axées sur les données aux soins aux patients. Pour commencer, les données biomédicales sont très complexes. Il existe de nombreux types de données, y compris des images, du texte, des valeurs numériques, des classifications catégorielles et des séquences d'ADN, représentant des dizaines de milliers de tests de laboratoire, de procédures, de diagnostics, de médicaments, de marqueurs génétiques, etc. Chaque type de données a également ses propres caractéristiques. Par exemple, une valeur de test de laboratoire peut devoir être interprétée dans le contexte de l'âge, du sexe et des conditions actuelles. Cependant, les codes de diagnostic pour différentes maladies ont des niveaux variables de précision.<br/>Dans l'analyse des données biomédicales, il y a aussi le paradoxe d'avoir trop et pas assez de données en même temps. D'une part, il y a une énorme quantité de données sur les dossiers médicaux, les médias sociaux et la littérature. L’utilisation d’appareils pour des tâches comme le suivi des activités et la surveillance continue de la glycémie génère plus de données que nos systèmes de dossiers médicaux actuels ne peuvent les digérer. D'autre part, le dossier de santé d'un patient est un système ouvert avec beaucoup d'informations manquantes par rapport au système fermé d'un jeu d'échecs ou Go, où toutes les données sont disponibles. Les patients sont observés à intervalles irréguliers (par exemple, lors de visites à la clinique ou pendant l'hospitalisation) et ne sont jamais soumis à tous les tests ou traitements possibles. Parfois, la mort est le seul résultat définitif.<br/>Je suis d'accord que les types de données sont multiples et complexes. Les solutions simples sont insuffisantes, et la prolifération de données non pertinentes dans un enregistrement, sans parler de la mode actuelle de couper-coller ou de remplir-dans-la-modèle, obscurcit ce qui est important.<br/>L’une des principales difficultés avec les données médicales n’est pas seulement qu’elles ne suffisent pas, mais aussi qu’elles sont chargées en théorie, c’est-à-dire que très peu de données sont enregistrées régulièrement. Beaucoup de données dans les observations ne sont recueillies que lorsque le clinicien a pensé qu'il est approprié, c'est-à-dire lorsque les maladies sont testées pour leur absence ou leur présence. S'il n'y a aucune raison de faire le test, le test n'est pas effectué. Seuls quelques tests sont effectués régulièrement; un ensemble transcrit d'observations physiques (comme cela est fait dans l'examen physique) est rarement enregistré avec suffisamment de détails (sans parler de l'inobservation, qui se produit souvent) pour fournir des données suffisantes pour une analyse plus complète. Pour cette seule raison, les études basées sur les observations enregistrées sont souvent incomplètes et potentiellement trompeuses. Cependant, pour les prédictions, les observations non faites peuvent être les plus critiques. Pensez au patient avec le syndrome métabolique mentionné ci-dessus. Quelles données manquons-nous ?<br/>De même, les résultats des essais cliniques ne sont pas un tableau complet. Même si les participants ont été sélectionnés, excluant souvent de nombreuses personnes en raison de conditions compliquantes, les données recueillies sur les participants sont conçues pour tester certaines hypothèses, avec des résultats étroitement définis. Une critique courante est que de tels procès sont si artificiels qu'ils ne sont pas pertinents.<br/>Le manque d'ensembles de données intégrés et normalisés est un autre problème. Bien que nous puissions trouver de nombreux ensembles de données de grande taille, ils sont souvent incomplets et difficiles à relier à d'autres informations. Par exemple, l'exposition à l'environnement, le régime alimentaire, l'activité physique et le profil génétique font partie des éléments d'information manquants courants lorsque nous examinons les dossiers d'un patient. Les questions de protection de la vie privée et les incitations monétaires sont également des obstacles dans les efforts d'intégration des données.<br/>L'interopérabilité sémantique réelle pour intégrer et normaliser les ensembles de données nécessite un support à la fois dans la terminologie et dans la façon dont cette terminologie est utilisée. Actuellement, une intervention humaine est souvent nécessaire pour interpréter ce qu'un système dit pour une utilisation dans un autre système. Cette situation est regrettable; nous pouvons espérer qu'avec le temps, les connexions nécessaires auront lieu (pensez à la façon dont les États-Unis sont passés de l'assistance de l'opérateur à chaque appel téléphonique à la commutation automatique qui a lieu aujourd'hui). Un tel changement ne peut se produire que lorsque beaucoup de gens voient la nécessité et mettent en œuvre une norme commune.<br/>De plus, la notion de « grande » dans le contexte des données sur les soins de santé n'est que relative. Pensez plutôt à de nombreuses expériences menées par Google; s'ils le souhaitent, la quantité de données pouvant être utilisée pour développer et tester un modèle est supérieure à celle disponible dans les soins de santé.<br/>Dans les domaines où les approches basées sur les données ont démontré leur succès, il y a des résultats qui peuvent être jugés par des experts humains ou des machines elles-mêmes. Par exemple, les locuteurs bilingues peuvent dire si la traduction en langage naturel fonctionne bien, et le résultat des jeux de plateau ou informatiques peut être facilement déterminé. Cela permet une simulation ou une annotation plus facile des données pour l'apprentissage automatique. Une telle tâche est beaucoup plus difficile dans les domaines biomédicaux; l'étude des causes ou des traitements des maladies chez l'homme implique des études coûteuses et à long terme. Dans certains cas, les préoccupations éthiques interdisent les expériences. Par exemple, l'introduction de mutations génétiques potentiellement nocives chez des sujets humains en bonne santé est hors de question. Nous manquons de données sur les résultats à long terme pour de nombreux traitements.<br/>Je ne suis pas sûr qu'il y ait jamais un tel étalon-or sans une définition complètement arbitraire. La variation entre les individus est également un obstacle majeur. Bien que nous fassions des études utilisant plusieurs sujets pour rendre compte de la variabilité biologique, nos résultats ne sont qu’approximatifs dans leur pertinence pour un individu donné. Par exemple, assurer la diversité génétique dans les essais cliniques est difficile, c’est le moins qu’on puisse dire. Même les tâches les plus simples peuvent être incroyablement multifactorielles; par exemple, le contenu informationnel des tests génétiques pour le métabolisme de la warfarine peut être compensé par le fait que le patient ait mangé de la laitue pour le déjeuner.<br/>Pour développer cette observation, supposons que vous ayez une voiture qui ne fonctionne pas correctement. Aujourd'hui, vous consultez les capteurs et la lecture de l'ordinateur pour vous donner des informations très précises sur ce qui ne va pas. La voiture a un design spécifique, avec des paramètres spécifiques qui peuvent être mesurés. Tous les véhicules de la même marque et du même modèle peuvent être considérés comme identiques dans ces aspects importants. Il est important de se rendre compte que chaque humain (à l'exception des jumeaux identiques) est génétiquement unique. De cette façon, les gens sont très différents des automobiles ou d'autres dispositifs mécaniques. Pour aggraver la complexité avec laquelle la cause d'un problème humain peut être abordée, ce que l'individu expérimente tout au long de sa vie est unique. Bien que nous ayons de belles abstractions ou des méthodes pour identifier les individus qui partagent certaines caractéristiques communes (si la présence ou l'absence d'une maladie, la réponse ou l'absence de celle-ci à un médicament, l'environnement similaire, ou d'autres considérations), ce ne sont qu'une notation abrégée. Avec 7 milliards de personnes vivant actuellement dans ce monde, le problème semble presque sans fin. Trop souvent, dans l'analyse des données, nous considérons les codes de diagnostic comme ayant une signification profonde. Ils sont acceptés sans aucune reconnaissance du degré d'incertitude du diagnostic. Toutes nos données peuvent être utiles et utiles, mais nous devons continuer à les voir avec un gros grain de sel. Le fait que Google Translate fonctionne aussi bien qu'il le fait nous donne de l'espoir, mais aussi complexe que la traduction en langage naturel est, il est plus simple que certaines tâches cliniques.<br/>Malgré ces défis, l'application d'approches axées sur les données a le potentiel de transformer les soins de santé. Les soins de santé d'aujourd'hui exigent beaucoup de travail, de la planification et du triage au diagnostic et au traitement. De nombreuses tâches actuellement entreprises par l'homme peuvent être effectuées par des solutions logicielles intelligentes soutenues par des données suffisantes. Par exemple, une technologie améliorée de reconnaissance vocale et de résumé pourrait aider à réduire le temps que les patients et les cliniciens consacrent à la paperasserie. Une évaluation précise des risques et des avantages à court et à long terme éclairera le choix du traitement et les changements de mode de vie.<br/>Pour fournir un autre cas d'utilisation, il existe des preuves que le diabète de type II peut être réversible, mais il est difficile d'appliquer ces connaissances à un patient individuel. Compte tenu du patient en face de moi, que dois-je faire, ou recommander, et avec quelles attentes? La démographie, la génomique, les comorbidités, la psyché, les risques concurrents et d'autres médicaments jouent tous un rôle. Comment, chez une personne donnée, puis-je concilier toutes les possibilités?<br/>Pour développer ces outils d'IA utiles, nous avons besoin de meilleures données, de meilleures technologies et de meilleures politiques. Pour accumuler des données complètes et à vie, les patients doivent être en contrôle et devraient être incités à partager leurs données pour la recherche et les soins. Les institutions d'assurance, pharmaceutiques et médicales changent au fil du temps. Actuellement, il existe des obstacles pour que les individus soient le centre de collecte des données sur eux-mêmes. Les obstacles sont présents dans la saisie, la collecte et le stockage des données; par exemple, certains produits de dossiers de santé personnalisés sont attachés à un établissement, tandis que d'autres nécessitent des efforts considérables de transcription par les patients ou les soignants. Néanmoins, sans le consentement et la collaboration du patient, la collecte et la liaison de données environnementales, génétiques, cliniques et comportementales longitudinales ne sont ni réalisables ni éthiques. Les conditions actuelles sont un obstacle énorme à toute tentative d'utiliser des approches axées sur les données qui ont fonctionné en dehors des soins de santé.<br/>Les efforts, y compris PatienstLikeMe et le projet de recherche All of Us des National Institutes of Health [ ] sont des exemples d’approches innovantes pour organiser des ensembles de données plus grands et de meilleure qualité. Les patients sont intrinsèquement motivés pour améliorer leur propre santé, mais ont naturellement des préoccupations concernant la vie privée et ne voient souvent pas les avantages immédiats de participer à des études à long terme. Des incitations appropriées (par exemple, des réductions pour les soins préventifs de routine) associées à des technologies de sécurité et d'authentification sont nécessaires pour inciter une population nombreuse et diversifiée de patients à recueillir et à partager leurs données. L'industrie des soins de santé possède aujourd'hui une partie des données sur les patients et a une motivation limitée pour acheter des données auprès de leurs clients. À mesure que la valeur des données augmente, les patients deviendront plus valorisés en tant que partenaires.<br/>Je suis d'accord que les patients devront assumer la responsabilité de transporter et de partager l'information sur eux-mêmes. Cependant, l'expérience nous dit que tout le monde n'est pas capable ou désireux de le faire. Il faudra des changements culturels et politiques pour encourager ce développement.<br/>Lorsque nous pourrons recueillir des données qui ne sont pas directement ce que les philosophes appelleraient « chargées de théorie », nous pourrons peut-être affiner nos méthodes brutes de diagnostic et de soins aux patients. Si les patients sont porteurs de ces données, il sera plus facile de les obtenir et de les utiliser à des fins d’analyse.<br/>Nous devons également concevoir et mettre en œuvre des méthodes spécifiques pour traiter des données cliniques très volumineuses et « désordonnées ». Par exemple, nous devons comprendre le contexte des données manquantes et des erreurs pour obtenir une meilleure image de la vérité au sol. Un résultat de laboratoire peut être manqué parce qu'il n'y a pas d'indication, de préférence de pratique, d'une méthode alternative d'évaluation ou d'un échec de saisie des données. Imaginez à quel point une partie d'échecs sera difficile, si un joueur humain ou un moteur d'échecs ne pouvait observer que quelques cases sur le plateau à des intervalles de temps irréguliers avec une erreur ou une distorsion de l'observation.<br/>En outre, nous n'avons pas de définition opérationnelle de la «vérité fondamentale» dans les soins de santé; une proposition simple est qu'une caractéristique de la vérité fondamentale est qu'elle a une valeur prédictive - quelque chose qui sera apprécié par les cliniciens et les patients.<br/>Google a démontré qu'ils peuvent utiliser beaucoup de données pour prédire les valeurs probables des données manquantes dans d'autres domaines; Cependant, il reste à déterminer si cela pourrait fonctionner en médecine, mais cela vaut probablement la peine d'être essayé. Indépendamment de la question de savoir si nous pouvons utiliser de grands volumes de données pour imputer les valeurs manquantes, il est crucial d’explorer la façon de traiter le problème des observations absentes, en particulier chaque fois que nous essayons d’appliquer les résultats des approches axées sur les données à des patients individuels.<br/>Une autre pensée est que les données manquantes, pour une raison quelconque, sont une observation en soi; le fait que les données n'ont pas été obtenues et enregistrées peut être important. Pensez à la constatation que le jour et l'heure d'un test étaient plus prédictifs du résultat que le résultat du test. Nous savons que les données manquantes auront une certaine valeur prédictive.<br/>Sur une note différente, l'explication des modèles basés sur les données est essentielle non seulement pour leur adoption, mais aussi pour leur impact. Prédire qu'un patient aura certains événements indésirables dans les prochains jours ou les prochaines années est souhaitable. On peut faire valoir qu'il est encore plus important de connaître les facteurs modifiables qui peuvent réduire le risque et améliorer les résultats. Étant donné que les modèles d'apprentissage profond peuvent être très non linéaires, nous avons l'occasion de découvrir des modèles nouveaux et complexes.<br/>Je suis d'accord que l'explication de la prédiction est essentielle; c'est quelque chose qui sépare les soins de santé de, par exemple, reconnaître si une image est un chien ou un chat. Cependant, je pense que vous vouliez dire prédire qu'un patient aura probablement un résultat défavorable. Rien dans la vie n'est certain, sauf qu'il finira. Cependant, nous pouvons dire "il semble que ce comportement ou cette découverte aura probablement un effet sur votre avenir" et nous espérons être en mesure d'exprimer un certain degré de confiance dans cette prédiction.<br/>Apprendre à exprimer la confiance dans une prédiction est également important. Combien de personnes comprennent vraiment les statistiques derrière les prédictions qui se produisent aujourd'hui? Quelles sont les hypothèses sous-jacentes derrière tout modèle probabiliste? Il est plus probable qu’avec une utilisation plus fréquente et une familiarité avec l’utilisation de mesures dérivées pour les modèles d’IA, elles seront acceptées.<br/>Je suis d’accord. Ce sont toutes des mesures à prendre afin d’optimiser l’utilisation des mégadonnées grâce à l’IA pour améliorer les soins médicaux.<br/>En guise de réflexion, nous devons être prudents quant à la façon dont les approches axées sur les données peuvent être intrusives dans le processus de soins. Bien que McDonald ait démontré que la performance dans les soins s’améliore avec les rappels, l’expérience ultérieure a été l’un des trop nombreux rappels, conduisant à une fatigue alerte. Lorsque les soignants choisissent de passer outre et d'ignorer les informations utiles en raison de la surcharge, avons-nous accompli quelque chose?<br/>J'espère qu'une conception minutieuse des systèmes et la prise en compte du flux de travail clinique résoudront le problème de l'intrusion excessive. Bien qu'il soit tentant de simplement "laisser l'IA le faire", les expériences récentes avec le Boeing 737 MAX démontrent qu'il y a un danger à le faire. Ni l'IA ni un pilote seul n'est la stratégie optimale en vol. Dans les soins de santé, impliquer davantage les patients dans leurs soins, avec l’IA et les fournisseurs, peut finalement être une approche qui fonctionne.<br/>Conflits d'intérêts<br/>- Blois MS. Jugement clinique et ordinateurs. N Engl J Med 1980 Jul 24; 303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT Deep learning for healthcare: review, opportunities and challenges. Brief Bioinform 2018 Nov 27;19(6):1236-1246 [Gratuit Texte intégral] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. L'apprentissage automatique peut-il améliorer la prédiction du risque cardiovasculaire en utilisant des données cliniques de routine? PLoS ONE 2017 Apr 4;12(4):e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT Deep Patient: Une représentation non supervisée pour prédire l'avenir des patients à partir des dossiers de santé électroniques. Sci Rep 2016 May 17;6(1):26094 [Gratuit Texte intégral] [CrossRef] [Medline]<br/>IBM Watson Health réduit la découverte de médicaments «intelligence artificielle» après des ventes ternes URL: https://www.theregister.co.uk/2019/04/18/ibm_watson_health [consulté le 23/10/2019]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Apprentissage profond évolutif et précis avec des dossiers de santé électroniques. NPJ Digit Med 2018 mai 8;1(1):18 [Texte intégral GRATUIT] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, et al. Deep Learning en imagerie médicale: Vue d'ensemble. Coréen J Radiol 2017;18(4):570. [CrossRef]<br/>- U.S. Department of Veterans Affairs. Million Veteran Program (MVP) URL: https://www.research.va.gov/mvp/ [consulté le 2019-10-23]<br/>- Patientslikeme. URL: https://www.patientslikeme.com [consulté le 23/10/2019]<br/>- All of Us Research Program. URL: https://allofus.nih.gov [consulté le 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. L'efficacité déraisonnable des données. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Biais dans les données de dossiers de santé électroniques en raison de processus au sein du système de santé: étude observationnelle rétrospective. BMJ 2018 Apr 30:k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, M-ller H. Causabilité et explication de l'intelligence artificielle en médecine. WIREs Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Rappels informatiques basés sur le protocole, la qualité des soins et la non-perfectibilité de l'homme. N Engl J Med 1976 déc 09;295(24):1351-1355. [CrossRef]<br/>AI : Intelligence Artificielle<br/>UMLS : Système de langage médical unifié<br/>Edité par G Eysenbach; soumis le 15.09.19; revu par des pairs par A Holzinger; commentaires à l'auteur 14.10.19; version révisée reçue le 15.10.19; accepté le 20.10.19; publié le 27.11.19Copyright<br/>Initialement publié dans le Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>Il s'agit d'un article en libre accès distribué sous les termes de la licence Creative Commons Attribution (https://creativecommons.org/licenses/by/4.0/), qui permet une utilisation, une distribution et une reproduction sans restriction sur tout support, à condition que l'œuvre originale, publiée pour la première fois dans le Journal of Medical Internet Research, soit correctement citée. Les informations bibliographiques complètes, un lien vers la publication originale sur http://www.jmir.org/, ainsi que ces informations sur les droits d'auteur et la licence doivent être incluses. |
| The Story of Selena Quintanilla: A Biography Book for Young Readers (The Story Of: A Biography Series for New Readers) (Paperback)<br/>Most titles are on our shelves or available within 1-5 days.<br/>Discover the life Selena Quintanilla—a story about breaking down barriers in music, for kids ages 6 to 9<br/>Selena Quintanilla was the queen of Tejano music. Before she became a star, Selena was a charismatic young girl who loved singing and performing. She made a lot of sacrifices to become a famous musician, rehearsing her songs and dance moves for hours at a time. Her hard work paid off—she became the first 15-year-old girl to win a Tejano music award and went on to break many records during her career. This Selena biography explores how she went from being a talented girl growing up in Texas to a fashion icon and a world-famous singer.<br/>What sets this Selena book apart:<br/>- Core curriculum—Kids will learn the Who, What, Where, When, Why, and How of Selena’s life, and take a quick quiz to test their knowledge.<br/>- Short chapters—This Selena kids’ book is broken up into brief chapters that make it fun and easy for new readers to discover details about the singer’s life.<br/>- Her lasting legacy—Kids will find out how Selena changed the world of music and why she continues to be a role model for many women and people of color around the globe.<br/>How will Selena’s big spirit and passion for music inspire the child in your life?<br/>About the Author<br/>GLORIA ARJONA teaches Spanish at the California Institute of Technology and is the author of Posadas Unknown Calaveras and ¡Lotería!. She’s also a musician who sings and plays guitar. Learn more at GloriaArjona.com.<br/>“Finally, a Selena book for new readers, one that is told concisely and honestly, and is eminently readable” —Joe Nick Patoski, author of Selena: Como La Flor<br/>“What a wonderful story to inspire girls to follow their dreams. A story that many girls will identify with, especially those from traditional and multicultural families. I liked all the little sidebar lessons throughout the book. Gloria is a very talented teacher.” —Genevieve B. Southgate, director of community programs, Bowers Museum<br/>“Selena Quintanilla’s youthful talent and positive drive are brought to life in Prof. Arjona’s latest book, this one geared to young readers. A highly appealing read highlighting Selena’s flexibility in overcoming obstacles to achieving her dreams and her trailblazing contributions to music and her community. The Callisto Media format of encouraging critical, organized thought via questions, maps, timelines, and a glossary make this an enjoyable learning experience.” —Martin E. Delgado, community library manager<br/>“This is the story of Selena Quintanilla, and what a story it is! In a time where young readers, and young women, need role models more than ever, this book brilliantly depicts the profound humanity, bravery, and talent of a deeply inspiring Latina woman who relentlessly fought for her dream.” —Maite Zubiaurre, UCLA professor | L'histoire de Selena Quintanilla: Un livre de biographie pour les jeunes lecteurs (L'histoire de: Une série de biographie pour les nouveaux lecteurs)<br/>La plupart des titres sont sur nos étagères ou disponibles sous 1 à 5 jours.<br/>Découvrez la vie de Selena Quintanilla – une histoire sur l’élimination des barrières dans la musique, pour les enfants de 6 à 9 ans<br/>Selena Quintanilla était la reine de la musique Tejano. Avant de devenir une star, Selena était une jeune fille charismatique qui aimait chanter et se produire. Elle a fait beaucoup de sacrifices pour devenir une musicienne célèbre, répétant ses chansons et ses mouvements de danse pendant des heures. Son travail acharné a porté ses fruits. Elle est devenue la première fille de 15 ans à remporter un prix de musique Tejano et a battu de nombreux records au cours de sa carrière. Cette biographie de Selena explore comment elle est passée d'une fille talentueuse qui a grandi au Texas à une icône de la mode et à une chanteuse de renommée mondiale.<br/>Ce qui distingue ce livre de Selena:<br/>Les enfants apprendront le qui, quoi, où, quand, pourquoi et comment de la vie de Selena, et passeront un quiz rapide pour tester leurs connaissances.<br/>Ce livre pour enfants de Selena est divisé en courts chapitres qui rendent amusant et facile pour les nouveaux lecteurs de découvrir des détails sur la vie du chanteur.<br/>- Son héritage durable - Les enfants découvriront comment Selena a changé le monde de la musique et pourquoi elle continue d'être un modèle pour de nombreuses femmes et personnes de couleur à travers le monde.<br/>Comment le grand esprit et la passion de Selena pour la musique vont-ils inspirer l'enfant dans votre vie?<br/>À propos de l'auteur<br/>GLORIA ARJONA enseigne l'espagnol à l'Institut de technologie de Californie et est l'auteur de Posadas Unknown Calaveras et de "Loteria!". C'est aussi une musicienne qui chante et joue de la guitare. Pour en savoir plus, rendez-vous sur GloriaArjona.com.<br/>"Enfin, un livre Selena pour les nouveaux lecteurs, qui est raconté de manière concise et honnête, et est éminemment lisible" - Joe Nick Patoski, auteur de Selena: Como La Flor<br/>"Quelle histoire merveilleuse pour inspirer les filles à poursuivre leurs rêves. Une histoire à laquelle beaucoup de filles s'identifieront, en particulier celles des familles traditionnelles et multiculturelles. J'ai aimé toutes les petites leçons d'accompagnement tout au long du livre. Gloria est une enseignante très talentueuse. » – Geneviève B. Southgate, directrice des programmes communautaires, Bowers Museum<br/>« Le jeune talent et la motivation positive de Selena Quintanilla prennent vie dans le dernier livre du professeur Arjona, celui-ci s’adressant aux jeunes lecteurs. Une lecture très attrayante soulignant la flexibilité de Selena à surmonter les obstacles à la réalisation de ses rêves et ses contributions pionnières à la musique et à sa communauté. Le format Callisto Media qui encourage la pensée critique et organisée par le biais de questions, de cartes, de calendriers et d’un glossaire en fait une expérience d’apprentissage agréable. » – Martin E. Delgado, responsable de la bibliothèque communautaire<br/>"C'est l'histoire de Selena Quintanilla, et quelle histoire ! À une époque où les jeunes lecteurs et les jeunes femmes ont plus que jamais besoin de modèles, ce livre dépeint avec brio la profonde humanité, la bravoure et le talent d'une femme latine profondément inspirante qui s'est battue sans relâche pour son rêve. – Maite Zubiaurre, professeur à l’UCLA |
| Here's another reason for men to avoid packing on extra pounds over the holidays: A new study has found that losing weight reduces the risk of an aggressive form of prostate cancer.<br/>After tracking the weight of nearly 70,000 men between 1982 and 1992, researchers from the American Cancer Society and the Duke University Prostate Center found that men who lost more than 11 pounds had a lower risk for aggressive prostate cancer than men whose weight remained the same over a decade.<br/>Previous studies have found that obese men have a higher risk of developing aggressive prostate cancer. This study appears to be the first to indicate that recent weight loss can decrease that risk.<br/>In the study reported this month in Cancer Epidemiology, Biomarkers & Prevention, researchers analyzed the height and weight of the men in 1982 and 1992 and every three years after that until 2003. At that time, more than 5,200 of the men — more than 7 percent — had prostate cancer.<br/>Among those cases, about one in eight had a form of cancer that was aggressive but had not spread to other areas of the body. The study's major finding focused on those aggressive cases, with researchers concluding that those who lost 11 or more pounds were 42 percent less likely to develop that form of prostate cancer than those whose weight remained the same.<br/>"Whether it's exactly 40 percent, we don't know, but they lower their risk when they lose 11-plus pounds. We feel confident, at least in this population, that was real," said lead researcher Dr. Carmen Rodriguez.<br/>More than seven times as many men whose weight remained the same developed aggressive prostate cancer compared to those who lost 11 or more pounds.<br/>"No significant associations" were found regarding the effect of weight gain or loss on the most severe forms of prostate cancer, those that spread throughout the body, the study said.<br/>The number studied was small, the researchers acknowledged, because fewer than 15,000 men lost weight over the time period, and only 1,000 of those developed some form of prostate cancer.<br/>The 69,991 participants were part of a bigger cancer society study of 1.2 million Americans that began in 1982.<br/>Rodriguez said men should avoid putting on extra weight as they get older.<br/>"The main message for men is to not get overweight. If they are overweight, that's another reason to try to lose weight, just to decrease the risk for prostate cancer," said Rodriguez, who works for the Atlanta-based cancer society.<br/>Other than skin cancer, prostate cancer is the most commonly diagnosed cancer for men, and about one in six will get it during his lifetime. It is the second leading cause of cancer death for U.S. men.<br/>The study is considered the first of its kind to examine the role of weight change in the development of prostate cancer, said Dr. Ronald Ennis, director of radiation oncology at St. Luke's-Roosevelt Hospital Center in New York, who was not involved in the study.<br/>"This is one of the best studies" examining the role of weight on prostate cancer, Ennis said. "It does seem to be true that if you are overweight, you are at risk of getting more aggressive forms of prostate cancer and if you lose weight, you can decrease the risk." | Voici une autre raison pour les hommes d’éviter de prendre des kilos en trop pendant les vacances: une nouvelle étude a révélé que la perte de poids réduisait le risque d’une forme agressive de cancer de la prostate.<br/>Après avoir suivi le poids de près de 70 000 hommes entre 1982 et 1992, des chercheurs de l’American Cancer Society et du Duke University Prostate Center ont constaté que les hommes qui ont perdu plus de 11 livres avaient un risque plus faible de cancer de la prostate agressif que les hommes dont le poids est resté le même pendant une décennie.<br/>Des études antérieures ont montré que les hommes obèses ont un risque plus élevé de développer un cancer agressif de la prostate. Cette étude semble être la première à indiquer que la perte de poids récente peut diminuer ce risque.<br/>Dans l’étude publiée ce mois-ci dans Cancer Epidemiology, Biomarkers & Prevention, les chercheurs ont analysé la taille et le poids des hommes en 1982 et 1992 et tous les trois ans par la suite jusqu’en 2003. À cette époque, plus de 5 200 des hommes – plus de 7 pour cent – avaient un cancer de la prostate.<br/>Parmi ces cas, environ un sur huit avait une forme de cancer qui était agressive, mais ne s’était pas propagée à d’autres parties du corps. Les chercheurs ont conclu que ceux qui ont perdu 11 livres ou plus étaient 42% moins susceptibles de développer cette forme de cancer de la prostate que ceux dont le poids est resté le même.<br/>"Que ce soit exactement 40%, nous ne le savons pas, mais ils réduisent leur risque lorsqu'ils perdent plus de 11 livres. Nous sommes confiants, du moins dans cette population, c'était réel", a déclaré le Dr Carmen Rodriguez, chercheuse principale.<br/>Plus de sept fois plus d’hommes dont le poids est resté le même ont développé un cancer agressif de la prostate par rapport à ceux qui ont perdu 11 livres ou plus.<br/>"Aucune association significative" n'a été trouvée concernant l'effet du gain ou de la perte de poids sur les formes les plus graves de cancer de la prostate, celles qui se propagent dans tout le corps, a déclaré l'étude.<br/>Le nombre étudié était faible, ont reconnu les chercheurs, car moins de 15 000 hommes ont perdu du poids au cours de la période, et seulement 1 000 d’entre eux ont développé une forme de cancer de la prostate.<br/>Les 69 991 participants faisaient partie d'une plus grande étude sur la société du cancer de 1,2 million d'Américains qui a commencé en 1982.<br/>Rodriguez a déclaré que les hommes devraient éviter de prendre du poids supplémentaire à mesure qu'ils vieillissent.<br/>"Le message principal pour les hommes est de ne pas avoir de surpoids, c'est une autre raison d'essayer de perdre du poids, juste pour réduire le risque de cancer de la prostate", a déclaré Rodriguez, qui travaille pour la société du cancer basée à Atlanta.<br/>Autre que le cancer de la peau, le cancer de la prostate est le cancer le plus souvent diagnostiqué pour les hommes, et environ un sur six l'obtiendra au cours de sa vie. C'est la deuxième cause de décès par cancer pour les hommes américains.<br/>L'étude est considérée comme la première du genre à examiner le rôle du changement de poids dans le développement du cancer de la prostate, a déclaré le Dr Ronald Ennis, directeur de la radio-oncologie au centre hospitalier St. Luke's-Roosevelt à New York, qui n'a pas participé à l'étude.<br/>"C'est l'une des meilleures études" examinant le rôle du poids sur le cancer de la prostate, a déclaré Ennis. "Il semble être vrai que si vous êtes en surpoids, vous êtes à risque d'avoir des formes plus agressives de cancer de la prostate et si vous perdez du poids, vous pouvez réduire le risque." |
| If you have studied the OSI model with its 7 Layers that describe communication on computer network systems, you should know that the Ethernet standard lies in Layer 1 (Physical) and Layer 2 (Data-Link) of the OSI model.<br/>In this article we will focus on the physical (Layer 1) part of Ethernet, which mainly focuses on the wired physical medium (cabling) that is used to transport Ethernet frames in a network.<br/>Ethernet cables connect devices to computer networks, the “heart” of which is usually an Ethernet switch which has several interface ports for “plugging-in” the cables.<br/>Most of these Ethernet cables feature the standard RJ45 connector for plugging-in to a switch. However, Ethernet communication can be implemented also using Fiber-optic cabling which uses different types of connectors.<br/>Moreover, there are different types of Ethernet cables with varying bandwidths, speeds and types of construction. In this article we will discuss the “copper-made” cables which are the most popular ones in computer networks.<br/>The cables have labels indicating the standard used for manufacturing, ranging from category (cat) 3 to 7.<br/>Ethernet cables consist of several (usually 8) smaller wires (inside the main cable) which are separated in Twisted-pairs. This setup helps in cancelling-out electromagnetic interference between wires, thus allowing signals to travel longer distances inside the wires.<br/>Without the right cable (and of course without the right type of switch), you may experience slower speeds in the network between devices.<br/>Let’s now describe each Category of Ethernet Cables with their characteristics:<br/>&#124;Max Length&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m<br/>(55 m for 10Gbps)<br/>&#124;100 m&#124;&#124;100 m&#124;<br/>&#124;Max Speed&#124;&#124;10 Mbps&#124;&#124;100 Mbps&#124;&#124;1 Gbps&#124;&#124;10 Gbps&#124;&#124;10 Gbps&#124;&#124;>10 Gbps&#124;<br/>&#124;Frequency Bandwidth&#124;&#124;16 MHz&#124;&#124;100 MHz&#124;&#124;100 MHz&#124;&#124;250 MHz&#124;&#124;500 MHz&#124;&#124;600 MHz&#124;<br/>&#124;Shielded / Unshielded&#124;&#124;Unshielded&#124;&#124;Unshielded&#124;&#124;Unshielded&#124;&#124;Shielded or Unshielded&#124;&#124;Shielded&#124;&#124;Shielded&#124;<br/>1) Cat 3<br/>One of the oldest Ethernet cabling standards is category (cat) 3 (TIA/EIA-568-B). These cables allowed 10 Mbps transmission speeds with 16 MHz max bandwidth.<br/>Cat 3 ethernet cables feature unshielded twisted pair (UTP) cabling. With UTP cables, manufacturers twist insulated copper wires together inside a polyethylene jacket. Compared to shielded ethernet cables, UTP cables tend to include more crosstalk.<br/>Network connections commonly featured category 3 ethernet cables until the early 1990s, when category 5 cables replaced cat 3. While some older telephone systems may still use cat 3 cables, they have mostly become obsolete in the networking industry.<br/>2) Cat 5<br/>Cat 5 cables increased the bandwidth of Ethernet connections up to 100 MHz and offered transmission speeds up to 100 Mbps. With Cat 5 ethernet cables, users could access 100BASE-TX ethernet systems, referred to as fast ethernet.<br/>As with the category 3 cables, cat 5 cables still feature crosstalk and interference, due to the UTP design. These cables include four pairs of twisted wires (for a total of 8 wires).<br/>While cat 5 cables primarily provide connections for Ethernet applications, these cables also provide solutions for carrying other data signals, such as video and telephone. In fact, a single cat 5 cable can carry two standard phone lines and a 100BASE-TX connection.<br/>3) Cat 5e<br/>In 2001, the category 5e standard replaced category 5. The letter “e” in the name stands for enhanced.<br/>The cabling still uses unshielded twisted pairs. There are no physical differences between cat 5 and cat 5e cables. However, stricter standards in manufacturing Cat5e cables help minimize crosstalk and allow higher data transmissions than Cat5.<br/>Cat 5e cables also utilize two sets of twisted pairs of wires, resulting in faster speeds. While cat 5e ethernet cable still features 100 MHz bandwidth, these cables allow speeds up to 1000 Mbps (1 Gbps).<br/>While several additional standards have come after cat 5e, these cables remain in production. In fact, due to the lower cost of production and support for gigabit ethernet, cat 5e cables are the most used for network applications throughout the world.<br/>4) Cat 6<br/>Cat 6 ethernet cables helped address issues related to interference and crosstalk. These cables use thinner wires and superior insulation, resulting in a better signal-to-noise ratio.<br/>With these features, cat 6 cables provide a more effective option for adding cable in areas with more electromagnetic interference, such as a crowded server room.<br/>Thanks to the superior design, cat 6 provides improved bandwidth. These cables have a max bandwidth of 250 MHz and max transmission speeds up to 1000 Mbps (1 Gbps) at the 100m range. However, 10Gbps can be achieved in Cat6 in smaller distances (up to 55m).<br/>Some cat 6 cables include shielding while others remain unshielded. With shielding, these cables can provide transmission speeds up to 10 Gbps, but only for short distances as we said above.<br/>5) Cat 6a<br/>Category 6a ethernet cables improve the design of the cat 6 cables. The letter “a” stands for augmented. Unlike cat 6 cables, all cat 6a cables feature shielded cabling for reduced interference.<br/>With the enhancements to the design specifications, cat 6a cables maintain higher transmission speeds and 500 MHz max bandwidth, allowing speeds up to 10000 Mbps (10 Gbps) across longer cables.<br/>While these cables provide faster speeds, the design makes them less flexible. To eliminate crosstalk, these cables feature thicker sheathing, making the cables stiffer and more difficult to work.<br/>6) Cat 7<br/>One of the latest developments is Cat 7 Ethernet cables. Also called class F channel cables, these cables include stricter standards compared to previous categories. The individual wire pairs now include their own shielding, in addition to the outer shielding<br/>With these cables, you get 600 MHz max bandwidth and 10000 Mbps (10 Gbps) transmission speeds. However, by almost completely getting rid of crosstalk, cat 7 ethernet cables offer even greater reliability for 10 Gbps Ethernet connections.<br/>With connections less than 15 meters, cat 7 can support transmission speeds up to 100 Gbps. While the industry has released several new standards since cat 7, these cables are currently the top of the line option for demanding networking applications.<br/>- What is OSPF NSSA (Not So Stubby Area) and How is it Configured?<br/>- Comparison of BOOTP vs DHCP Protocols in Computer Networks<br/>- Pros and Cons of SD-WAN in Networks – Description and Discussion<br/>- Comparison of GNS3 vs EVE-NG vs Packet Tracer for Networks Simulation<br/>- Subnetting vs Supernetting – What’s the Difference? (Explanation Guide) | Si vous avez étudié le modèle OSI avec ses 7 couches qui décrivent la communication sur les systèmes de réseau informatique, vous devez savoir que la norme Ethernet se trouve dans la couche 1 (physique) et la couche 2 (liaison de données) du modèle OSI.<br/>Dans cet article, nous nous concentrerons sur la partie physique (couche 1) d'Ethernet, qui se concentre principalement sur le support physique câblé (câblage) utilisé pour transporter des trames Ethernet dans un réseau.<br/>Les câbles Ethernet relient les périphériques aux réseaux informatiques, dont le "cœur" est généralement un commutateur Ethernet qui dispose de plusieurs ports d'interface pour "brancher" les câbles.<br/>La plupart de ces câbles Ethernet sont équipés du connecteur standard RJ45 pour le branchement à un commutateur. Cependant, la communication Ethernet peut également être mise en œuvre à l'aide d'un câblage à fibre optique qui utilise différents types de connecteurs.<br/>De plus, il existe différents types de câbles Ethernet avec des largeurs de bande, des vitesses et des types de construction variables. Dans cet article, nous discuterons des câbles "fabriqués en cuivre" qui sont les plus populaires dans les réseaux informatiques.<br/>Les câbles ont des étiquettes indiquant la norme utilisée pour la fabrication, allant de la catégorie (chat) 3 à 7.<br/>Les câbles Ethernet se composent de plusieurs (généralement 8) fils plus petits (à l'intérieur du câble principal) qui sont séparés par des paires torsadées. Cette configuration aide à annuler les interférences électromagnétiques entre les fils, permettant ainsi aux signaux de parcourir de plus longues distances à l'intérieur des fils.<br/>Sans le bon câble (et bien sûr sans le bon type de commutateur), vous pouvez rencontrer des vitesses plus lentes dans le réseau entre les appareils.<br/>Décrivons maintenant chaque catégorie de câbles Ethernet avec leurs caractéristiques:<br/>Longueur max. 100 m x 100 m x 100 m x 100 m<br/>(55 m pour 10 Gbps)<br/>-100 m -100 m -<br/>Vitesse maximale : 10 Mbps – 100 Mbps – 1 Gbps – 10 Gbps – 10 Gbps – > 10 Gbps<br/>- Bande passante de fréquence: 16 MHz - 100 MHz - 100 MHz - 250 MHz - 500 MHz - 600 MHz -<br/>Non-blindé/Blindé/Blindé/Blindé/Blindé/Blindé/Blindé/Blindé/Blindé/Blindé/Blindé/Blindé/Blindé/Blindé<br/>1) Cat 3<br/>L'une des plus anciennes normes de câblage Ethernet est la catégorie (cat) 3 (TIA / EIA-568-B). Ces câbles permettaient des vitesses de transmission de 10 Mbps avec une bande passante maximale de 16 MHz.<br/>Les câbles Ethernet Cat 3 disposent d'un câblage à paires torsadées non blindées (UTP). Avec les câbles UTP, les fabricants tordent les fils de cuivre isolés ensemble à l'intérieur d'une gaine en polyéthylène. Comparés aux câbles Ethernet blindés, les câbles UTP ont tendance à inclure plus de diaphonie.<br/>Les connexions réseau comportaient généralement des câbles Ethernet de catégorie 3 jusqu'au début des années 1990, lorsque les câbles de catégorie 5 ont remplacé les câbles cat 3. Alors que certains systèmes téléphoniques plus anciens peuvent encore utiliser des câbles cat 3, ils sont pour la plupart devenus obsolètes dans l'industrie des réseaux.<br/>2) Cat 5<br/>Les câbles Cat 5 augmentaient la bande passante des connexions Ethernet jusqu'à 100 MHz et offraient des vitesses de transmission allant jusqu'à 100 Mbit/s. Avec les câbles Ethernet Cat 5, les utilisateurs pouvaient accéder aux systèmes Ethernet 100BASE-TX, appelés Ethernet rapide.<br/>Comme pour les câbles de catégorie 3, les câbles cat 5 présentent toujours une diaphonie et des interférences, en raison de la conception UTP. Ces câbles comprennent quatre paires de fils torsadés (pour un total de 8 fils).<br/>Alors que les câbles cat 5 fournissent principalement des connexions pour les applications Ethernet, ces câbles fournissent également des solutions pour transporter d'autres signaux de données, tels que la vidéo et le téléphone. En fait, un seul câble cat 5 peut transporter deux lignes téléphoniques standard et une connexion 100BASE-TX.<br/>3) Cat 5e<br/>En 2001, la norme de la catégorie 5e a remplacé la catégorie 5; la lettre « e » dans le nom signifie « amélioré ».<br/>Le câblage utilise toujours des paires torsadées non blindées. Il n'y a pas de différences physiques entre les câbles cat 5 et cat 5e. Cependant, des normes plus strictes dans la fabrication des câbles Cat5e aident à minimiser la diaphonie et permettent des transmissions de données plus élevées que Cat5.<br/>Les câbles Cat 5e utilisent également deux paires de fils torsadées, ce qui permet des vitesses plus rapides. Alors que le câble Ethernet Cat 5e dispose toujours d'une bande passante de 100 MHz, ces câbles permettent des vitesses allant jusqu'à 1000 Mbps (1 Gbps).<br/>Alors que plusieurs normes supplémentaires sont venues après cat 5e, ces câbles restent en production. En fait, en raison du coût inférieur de production et de soutien pour gigabit ethernet, les câbles cat 5e sont les plus utilisés pour les applications de réseau à travers le monde.<br/>4) Cat 6<br/>Les câbles Ethernet Cat 6 ont aidé à résoudre les problèmes liés aux interférences et à la diaphonie. Ces câbles utilisent des fils plus minces et une isolation supérieure, ce qui se traduit par un meilleur rapport signal/bruit.<br/>Avec ces caractéristiques, les câbles cat 6 offrent une option plus efficace pour ajouter des câbles dans les zones avec plus d'interférences électromagnétiques, comme une salle des serveurs bondée.<br/>Grâce à sa conception supérieure, cat 6 offre une bande passante améliorée. Ces câbles ont une bande passante maximale de 250 MHz et des vitesses de transmission maximales allant jusqu'à 1000 Mbit/s (1 Gbit/s) dans la plage de 100 m. Cependant, 10 Gbit/s peuvent être atteints dans Cat6 sur de plus petites distances (jusqu'à 55 m).<br/>Certains câbles cat 6 incluent un blindage tandis que d'autres restent non blindés. Avec un blindage, ces câbles peuvent fournir des vitesses de transmission allant jusqu'à 10 Gbps, mais seulement pour de courtes distances comme nous l'avons dit ci-dessus.<br/>5) Cat 6a<br/>Les câbles Ethernet de catégorie 6a améliorent la conception des câbles cat 6. La lettre "a" signifie augmenté. Contrairement aux câbles cat 6, tous les câbles cat 6a disposent d'un câblage blindé pour réduire les interférences.<br/>Grâce aux améliorations apportées aux spécifications de conception, les câbles cat 6a maintiennent des vitesses de transmission plus élevées et une bande passante maximale de 500 MHz, permettant des vitesses allant jusqu'à 10 000 Mbit/s (10 Gbit/s) sur des câbles plus longs.<br/>Bien que ces câbles offrent des vitesses plus rapides, leur conception les rend moins flexibles. Pour éliminer la diaphonie, ces câbles disposent d'un gainage plus épais, ce qui rend les câbles plus rigides et plus difficiles à travailler.<br/>6) Cat 7<br/>L'un des derniers développements est Cat 7 câbles Ethernet. Également appelés câbles de canal de classe F, ces câbles comprennent des normes plus strictes par rapport aux catégories précédentes. Les paires de fils individuels incluent maintenant leur propre blindage, en plus du blindage extérieur.<br/>Avec ces câbles, vous obtenez une bande passante maximale de 600 MHz et des vitesses de transmission de 10 000 Mbit/s (10 Gbit/s). Cependant, en vous débarrassant presque complètement de la diaphonie, les câbles Ethernet cat 7 offrent une fiabilité encore plus grande pour les connexions Ethernet 10 Gbit/s.<br/>Avec des connexions de moins de 15 mètres, cat 7 peut supporter des vitesses de transmission allant jusqu'à 100 Gbps. Alors que l'industrie a publié plusieurs nouvelles normes depuis cat 7, ces câbles sont actuellement l'option haut de gamme pour les applications réseau exigeantes.<br/>- Qu'est-ce que OSPF NSSA (Not So Stubby Area) et comment est-il configuré?<br/>- Comparaison des protocoles BOOTP vs DHCP dans les réseaux informatiques<br/>- Avantages et inconvénients du SD-WAN dans les réseaux - Description et discussion<br/>- Comparaison de GNS3 vs EVE-NG vs Packet Tracer pour la simulation de réseaux<br/>- Sous-réseau vs Supernetting - Quelle est la différence? (Guide d'explication) |
| Views: 4 Author: Site Editor Publish Time: 2022-06-09 Origin: Site<br/>So why should workers wear a portable gas detector and what does it do?<br/>In many industrial environments, workers need to be highly aware of exposure to toxic or combustible gases and vapours or a lack of oxygen. That’s why portable gas detectors and analysers are essential – so they can detect, measure, monitor and react to any gases in the immediate area around them. KELISAIKE SAFETY offers both single- and multi-gas mobile gas monitors that reliably detect a wide range of gases. All of our portable gas detectors and software are designed to make compliance and asset management as intuitive as possible, so you can implement a complete product solution that helps ensure safety at all times.<br/>Portable gas detectors are classed as a type of Personal Protective Equipment (PPE)<br/>They monitor gases in the workers breathing zone by displaying real-time gas levels of a variety of toxic, combustible, flammable gases<br/>They alert the worker of any possible threats which include combustion and oxygen displacement<br/>While portable gas detectors are available with various sensor configurations and features, they are all built with the same purpose - to protect human life! | Vues: 4 Auteur: Site Editor Publish Time: 2022-06-09 Origine: Site<br/>Alors, pourquoi les travailleurs devraient-ils porter un détecteur de gaz portable et que fait-il?<br/>Dans de nombreux environnements industriels, les travailleurs doivent être très conscients de l'exposition à des gaz et vapeurs toxiques ou combustibles ou d'un manque d'oxygène. C'est pourquoi les détecteurs et analyseurs de gaz portables sont essentiels - afin qu'ils puissent détecter, mesurer, surveiller et réagir à tous les gaz dans la zone immédiate autour d'eux. KELISAIKE SAFETY propose des moniteurs de gaz mobiles monogaz et multigaz qui détectent de manière fiable une large gamme de gaz. Tous nos détecteurs de gaz portables et logiciels sont conçus pour rendre la conformité et la gestion des actifs aussi intuitives que possible, afin que vous puissiez mettre en œuvre une solution produit complète qui contribue à assurer la sécurité à tout moment.<br/>Les détecteurs de gaz portables sont classés comme un type d'équipement de protection individuelle (EPI)<br/>Ils surveillent les gaz dans la zone de respiration des travailleurs en affichant les niveaux de gaz en temps réel d'une variété de gaz toxiques, combustibles et inflammables.<br/>Ils alertent le travailleur de toutes les menaces possibles, y compris la combustion et le déplacement de l'oxygène.<br/>Alors que les détecteurs de gaz portables sont disponibles avec différentes configurations et fonctionnalités de capteurs, ils sont tous construits dans le même but - pour protéger la vie humaine! |
| Salvador Dalí Biography<br/>The prints of Salvador Dalí are rooted in a rich past. In actuality, Dalí’s prints have a history that dates back to his early years of art school. The young Dalí was taught the fine art of engraving and etching by his mentor. Dalí gained a respect for the technical details of printmaking, a respect he would maintain throughout the rest of his life. The connection between Dalí and graphic prints is in fact intricate and protracted. In his lifetime, Dalí produced just around 1,700 graphic prints. A large number of them are hand-signed, limited-edition editions. Some are regarded as some of the best prints created in the 20th century.<br/>Dalí had the ability to experiment with a wide range of subjects through his print work, including etchings, engravings, mixed media, lithographs, and photo-litho. Dalí would produce beautiful suites or single prints. These suites frequently feature a book motif, with the prints acting as the artwork. Among the literary works Dal illustrated were Alice in Wonderland, Hamlet, and The Old Man and the Sea. Other times, similar suites would focus on different subjects, such as flowers (FlorDal), science fiction (Conquest of the Cosmos), or fine print production (Currier and Ives). Dal also produced single prints that showcased his flawless printmaking skills. Prints by Dalí that are among his best include Flower Man, Symphony Bicyclette, Dream Passage, and The Studio of Dalí.<br/>Although it might be speculated that Dalí produced many more prints than the “approved” ones we attribute to him today, Dal’s first prints appeared in the 1920s. His superb craftsmanship is seen in works like Head of a Young Girl and Immaculate Conception. The graphic piece Les Chants de Maldoror is among Dal’s best-known creations. The stories that separate the suites are a perfect match for the pre-surrealistic aspects of the book. A complete set of this suite is now in high demand. The majority of these early works were etchings and engravings; as Dalí’s printing skills improved, he expanded the range of his mediums and themes.<br/>The 1960s are often referred to as the “Golden Age” of Dalí’s prints. In fact, Dalí produced some of his most creative pieces during this decade. For an edition of The Divine Comedy, he finished one hundred wood block prints. This suite is regarded as a work of genius, and Dalí produced magnificent graphics to complement Virgil’s poetry. A fruitful collaboration with the American publishers Phyllis and Sidney Lucas also began throughout this decade. The Lucas’ and Dalí’s combined efforts would result in some of the most enduring Dal paintings ever. Prints like The Drawers of Memory, Fantastic Voyage, The Lucky Number of Salvador Daíi, The Studio of Dalí, and Departure of The Fishermen are examples of the prints that resulted from their collaboration. For Dalí, these were undoubtedly successful years. Over the course of this decade, Dal finished hundreds of photographs. His output was extraordinarily high. However, some of his best graphic creations remained to be seen.<br/>Dal returned to his melting clocks painting, his most well-known creation, in the 1970s. Some people believe that Dalí’s 1975 lithograph Changes In Great Masterpieces is his best creation overall. The collection consists of six images, five of which are Dalí’s interpretations of paintings by Rembrandt, Vermeer, Raphael, and Velasquez. The Persistence of Memory, Dalí’s own masterwork, is reinterpreted in the sixth picture.<br/>Together with his American publishers, Phyllis and Sidney Lucas, Mozart created this suite. Dalí updates his original piece by including a fourth melting clock. The broken clock creeps through the midst of the scene. The fourth clock, according to some, represents the fourth dimension, or time. Some people think that when Dal revised The Persistence of Memory, some 40 years after the original, he was considering his own transience and legacy and paying homage to the Dal of old.<br/>Changes in Great Masterpieces was only one of Dalí’s outstanding creations during the 1970s. In the suites Moses and Monotheism, Imagination and Objects of the Future, and Alchemy of The Philosophers, he produced some magnificent artwork. His two four-piece “puzzles,” The Rejuvenation of Time and The Puzzle of Life, are his largest lithographs. Ten Recipes of Immortality, a collection of three dimensional “pop-up” prints, is an example of how he expanded the scope of his graphic works into the third dimension. Although the 1960s may have been Dalí’s most productive decade, the 1970s appear to have been his most inventive and creative years as he explored new concepts and pushed himself even farther.<br/>In 1982, Dalí’s final prints were released. Dalí’s health had already started to deteriorate by this point, and his output had significantly decreased. However, Dalí was still able to create some excellent graphic prints despite his advanced age. Portrait of Autumn, which is bathed in gorgeous yellows, greens, and reds, is a glorification of the god Dionysus. Collectors of Dalí’s work see Chevalier Surealiste as a must-have piece, and it pays homage to one of Dalí’s heroes, Velasquez. Crucifixion is a superb example of Dalí’s artistry and a testament to his interest in Roman Catholicism.<br/>Dalí spent his entire life working as a printmaker. When evaluating his legacy, one must take into account the graphic arts creations he developed. Some of Dalí’s most artistic icons and imagery, as well as some of his best uses of his imagination, can be seen in these prints. | Salvador Dali Biographie<br/>Les estampes de Salvador Dali sont enracinées dans un riche passé. En réalité, les estampes de Dali ont une histoire qui remonte à ses premières années d'école d'art. Le jeune Dali a appris l'art de la gravure et de la gravure par son mentor. Dali a gagné un respect pour les détails techniques de l'impression, un respect qu'il maintiendra tout au long de sa vie. Le lien entre Dali et les impressions graphiques est en fait complexe et prolongé. Au cours de sa vie, Dali n’a produit qu’environ 1 700 tirages graphiques. Un grand nombre d’entre eux sont des éditions limitées signées à la main. Certains sont considérés comme parmi les meilleurs tirages créés au XXe siècle.<br/>Dali avait la capacité d'expérimenter avec un large éventail de sujets à travers son travail d'impression, y compris les gravures, gravures, techniques mixtes, lithographies, et photo-litho. Parmi les œuvres littéraires illustrées par Dal figurent Alice au pays des merveilles, Hamlet et Le vieil homme et la mer. D'autres fois, des suites similaires se concentraient sur différents sujets, tels que les fleurs (FlorDal), la science-fiction (Conquest of the Cosmos) ou la production de petits caractères (Currier et Ives). Parmi ses meilleures estampes, citons Flower Man, Symphony Bicyclette, Dream Passage et The Studio of Dali.<br/>Bien que l'on puisse spéculer que Dali a produit beaucoup plus d'estampes que celles "approuvées" que nous lui attribuons aujourd'hui, les premières estampes de Dal sont apparues dans les années 1920. Son superbe savoir-faire est vu dans des œuvres comme Head of a Young Girl et Immaculate Conception. La pièce graphique Les Chants de Maldoror fait partie des créations les plus connues de Dal. Les histoires qui séparent les suites correspondent parfaitement aux aspects pré-surréalistes du livre. Un ensemble complet de cette suite est maintenant très demandé. La majorité de ces premières œuvres étaient des gravures et des gravures; à mesure que les compétences d'impression de Dala se sont améliorées, il a élargi la gamme de ses médiums et de ses thèmes.<br/>Les années 1960 sont souvent qualifiées d'"âge d'or" des gravures de Dali. En fait, Dali a produit certaines de ses pièces les plus créatives au cours de cette décennie. Pour une édition de The Divine Comedy, il a terminé une centaine de gravures sur bois. Cette suite est considérée comme une œuvre de génie, et Dali a produit de magnifiques graphismes pour compléter la poésie de Virgile. Une collaboration fructueuse avec les éditeurs américains Phyllis et Sidney Lucas a également commencé tout au long de cette décennie. Les efforts conjugués de Lucas et de Dali aboutiront à certaines des peintures de Dal les plus durables de tous les temps. Des gravures comme The Drawers of Memory, Fantastic Voyage, The Lucky Number of Salvador Daci, The Studio of Dali et Departure of The Fishermen sont des exemples des gravures qui ont résulté de leur collaboration. Au cours de cette décennie, Dal a terminé des centaines de photographies. Sa production était extraordinairement élevée. Cependant, certaines de ses meilleures créations graphiques restaient à voir.<br/>Dal est revenu à sa peinture des horloges fondantes, sa création la plus connue, dans les années 1970. Certains croient que la lithographie de 1975 Changes In Great Masterpieces est sa meilleure création dans l'ensemble. La collection se compose de six images, dont cinq sont des interprétations de peintures de Rembrandt, Vermeer, Raphael et Velasquez. La persistance de la mémoire, chef-d'œuvre de Dali, est réinterprétée dans la sixième image.<br/>En collaboration avec ses éditeurs américains Phyllis et Sidney Lucas, Mozart a créé cette suite. Dali met à jour sa pièce originale en incluant une quatrième horloge de fonte. L'horloge cassée se glisse au milieu de la scène. La quatrième horloge, selon certains, représente la quatrième dimension, ou le temps. Certaines personnes pensent que lorsque Dal a révisé The Persistence of Memory, quelque 40 ans après l’original, il envisageait sa propre fugacité et son héritage et rendait hommage au Dal d’autrefois.<br/>Dans les suites Moïse et le monothéisme, l'imagination et les objets de l'avenir, et l'alchimie des philosophes, il a produit des œuvres magnifiques. Ses deux "puzzles" en quatre parties, The Rejuvenation of Time et The Puzzle of Life, sont ses plus grandes lithographies. Dix recettes de l'immortalité, une collection d'impressions "pop-up" en trois dimensions, est un exemple de la façon dont il a élargi la portée de ses œuvres graphiques à la troisième dimension. Bien que les années 1960 aient peut-être été la décennie la plus productive de Dali, les années 1970 semblent avoir été ses années les plus inventives et créatives alors qu'il explorait de nouveaux concepts et se poussait encore plus loin.<br/>En 1982, les derniers tirages de Dali sont publiés. La santé de Dali a déjà commencé à se détériorer à ce moment-là, et sa production a considérablement diminué. Cependant, Dali est toujours capable de créer d'excellentes impressions graphiques malgré son âge avancé. Portrait de l'automne, qui est baigné dans de magnifiques jaunes, verts et rouges, est une glorification du dieu Dionysos. Les collectionneurs de l'œuvre de Dali voient Chevalier Surealiste comme une pièce incontournable, et il rend hommage à l'un des héros de Dali, Velasquez. La crucifixion est un superbe exemple de l'art de Dali et un témoignage de son intérêt pour le catholicisme romain.<br/>Dali a passé toute sa vie à travailler comme graveur. Lors de l'évaluation de son héritage, il faut prendre en compte les créations d'arts graphiques qu'il a développées. Certaines des icônes et des images les plus artistiques de Dali, ainsi que certaines de ses meilleures utilisations de son imagination, peuvent être vues dans ces estampes. |
| English Language A Level<br/>&#124;Mode of study&#124;&#124;Academic A Level&#124;<br/>&#124;Campus&#124;&#124;English Bridge Campus&#124;<br/>&#124;Start date&#124;&#124;4 September 2023&#124;<br/>&#124;Course code&#124;&#124;ENG-AL (2325)&#124;<br/>A minimum of five GCSEs at grade 4 or above, including English Language and English Literature.<br/>Please note: You can study both English A level Literature and A level English Language because the courses are sufficiently distinct that there is no overlap or repetition of content. However, you cannot study A Level English Combined and A Level English Literature, or A Level English Combined and A Level English Language.<br/>What does the course involve?<br/>English is an exciting subject and we hope you’ll enjoy the lively debate and discussion. Whichever English course you choose, you’ll gain a great deal of academic prowess and the development of transferable skills.<br/>You will be taught to think analytically, synthesise information, and develop communication skills that are a prerequisite for a wide range of career paths.<br/>The important skill of learning to write coherently and critically will aid you in your other subjects and is invaluable in higher education.<br/>Language is one of the key features that define us as human beings and, on this course, you will explore how it works: how we learn language from infancy, how we use it as a social tool, and how it has evolved over time. You will learn about the origins of English, the various forms it has taken over the centuries, how it has spread across the globe and what it might look like in the future.<br/>You will also study the research of theorists in areas of language such as speech and gender, accents and dialects, and the language of technology. You will learn about grammar in order to explore the ways writers use language to communicate meaning in texts ranging from blogs to 17th-century journalism.<br/>The NEA (coursework) unit will allow you to write creatively and to undertake an investigation into an aspect of the course you have enjoyed.<br/>How is the course assessed?<br/>80% Exam and 20% Coursework. Two coursework tasks and two externally-assessed exams.<br/>This A Level will equip you with the necessary skills to go into practical professions such as journalism and creative writing as well as academic degrees such as law and media studies. It forms a good companion to A Levels in Psychology and Sociology because there is a degree of crossover with the social sciences. If you are thinking of studying English at university, it is perfectly acceptable to take both English Language and English Literature. English can be combined with a range of other subjects at university.<br/>English provides an excellent foundation for various Higher Education courses including law, medicine, English, linguistics and education. It can be combined with a range of other subjects at university. English offers increasing employability in a range of career areas, especially those that require developed communication skills. Students have gone on to careers in law, health and medicine, commerce and industry, marketing, politics and international relations, general management, as well as leading to more predictable areas like journalism, publishing, the media, education, theatre and public relations.<br/>The student magazine produced by students is part of the enrichment opportunities led by the English Department. Trips include theatre trips to London, Manchester and Stratford-upon-Avon and international trips include a visit to battlefields in France, university taster days, residentials and creative writing workshops. These are all optional but highly recommended. Aspiring Oxford and Cambridge applicants will benefit from our extensive range of activities to support you in making a competitive application including: small group subject tuition, Oxford and Cambridge conferences, visits and contacts with our link staff, access to summer schools, application support and essay competitions, supra-curricular activities and access to free university-level Massive Open Online Courses (MOOC).<br/>What do I do next?<br/>You can apply online via the APPLY NOW button and then add an additional two or three subjects to make up your academic programme. You can also apply for a second, alternative vocational programme of study via a separate application. If after reading this factsheet, you are still undecided about the course most suitable for you, please drop in to one of our Open Evenings, ring Admissions on 01743 260401 or email email@example.com<br/>A Level English Language (Law and Drama & Theatre)<br/>Previous school: Mary Webb School<br/>I came here because it was local to me and I enjoyed the pre-enrolment days which were well organised. English Language is a good A Level to have and it is super interesting to see how language has evolved and changed through time. The teachers are a great help and the resources are brilliant; there are plenty of text books.<br/>Are you an employer?<br/>See how an apprentice can help your business. | Langue anglaise A Level<br/>Mode d'étude Academic A Level<br/>Campus anglais Bridge Campus<br/>Date de début : 4 septembre 2023<br/>[Numéro du cours]ENG-AL (2325)<br/>Un minimum de cinq GCSE de 4e année ou plus, y compris la langue anglaise et la littérature anglaise.<br/>S'il vous plaît noter: Vous pouvez étudier l'anglais à la fois un niveau de littérature et un niveau de langue anglaise parce que les cours sont suffisamment distincts qu'il n'y a pas de chevauchement ou de répétition du contenu. Cependant, vous ne pouvez pas étudier A Level English Combined et A Level English Literature, ou A Level English Combined et A Level English Language.<br/>Qu'est-ce que le cours implique?<br/>L'anglais est un sujet passionnant et nous espérons que vous apprécierez le débat animé et la discussion. Quel que soit le cours d'anglais que vous choisissez, vous gagnerez beaucoup de prouesses académiques et le développement de compétences transférables.<br/>Vous apprendrez à penser analytiquement, à synthétiser des informations et à développer des compétences en communication qui sont une condition préalable à un large éventail de cheminements de carrière.<br/>La compétence importante d'apprendre à écrire de manière cohérente et critique vous aidera dans vos autres matières et est inestimable dans l'enseignement supérieur.<br/>La langue est l'une des caractéristiques clés qui nous définissent en tant qu'êtres humains et, dans ce cours, vous explorerez son fonctionnement: comment nous apprenons la langue dès l'enfance, comment nous l'utilisons comme un outil social et comment il a évolué au fil du temps. Vous apprendrez les origines de l'anglais, les différentes formes qu'il a prises au cours des siècles, comment il s'est répandu à travers le monde et à quoi il pourrait ressembler à l'avenir.<br/>Vous étudierez également la recherche des théoriciens dans des domaines tels que la parole et le genre, les accents et les dialectes, et le langage de la technologie. Vous apprendrez la grammaire afin d'explorer les façons dont les écrivains utilisent le langage pour communiquer le sens dans des textes allant des blogs au journalisme du 17ème siècle.<br/>L'unité NEA (cours) vous permettra d'écrire de manière créative et d'entreprendre une enquête sur un aspect du cours que vous avez apprécié.<br/>Comment le cours est-il évalué?<br/>80% Examen et 20% Cours. Deux tâches de cours et deux examens évalués en externe.<br/>Ce niveau A vous permettra d'acquérir les compétences nécessaires pour exercer des professions pratiques telles que le journalisme et la création littéraire, ainsi que des diplômes universitaires tels que le droit et les études des médias. Il forme un bon compagnon à A Levels en psychologie et sociologie parce qu'il y a un degré de croisement avec les sciences sociales. Si vous envisagez d'étudier l'anglais à l'université, il est parfaitement acceptable de prendre à la fois la langue anglaise et la littérature anglaise. L'anglais peut être combiné avec une gamme d'autres matières à l'université.<br/>L'anglais fournit une excellente base pour divers cours de l'enseignement supérieur, y compris le droit, la médecine, l'anglais, la linguistique et l'éducation. Il peut être combiné avec une gamme d'autres matières à l'université. L'anglais offre une employabilité croissante dans un éventail de domaines de carrière, en particulier ceux qui nécessitent des compétences de communication développées. Les étudiants ont poursuivi des carrières dans les domaines du droit, de la santé et de la médecine, du commerce et de l'industrie, du marketing, de la politique et des relations internationales, de la gestion générale, ainsi que dans des domaines plus prévisibles tels que le journalisme, l'édition, les médias, l'éducation, le théâtre et les relations publiques.<br/>Le magazine étudiant produit par les étudiants fait partie des opportunités d'enrichissement menées par le département d'anglais. Les voyages comprennent des voyages de théâtre à Londres, Manchester et Stratford-upon-Avon et des voyages internationaux comprennent une visite des champs de bataille en France, des jours de dégustation à l'université, des résidences et des ateliers d'écriture créative. Les candidats aspirants d'Oxford et de Cambridge bénéficieront de notre vaste gamme d'activités pour vous aider à faire une demande compétitive, y compris: les frais de scolarité en petit groupe, les conférences d'Oxford et de Cambridge, les visites et les contacts avec notre personnel de lien, l'accès aux écoles d'été, le soutien aux applications et les concours de dissertation, les activités supra-scolaires et l'accès à des cours en ligne massifs gratuits de niveau universitaire.<br/>Qu'est-ce que je fais ensuite ?<br/>Vous pouvez postuler en ligne via le bouton APPLIQUER MAINTENANT, puis ajouter deux ou trois matières supplémentaires pour constituer votre programme académique. Vous pouvez également postuler pour un deuxième programme d'études professionnelles alternatives via une demande distincte. Si après avoir lu cette fiche d'information, vous n'êtes toujours pas décidé sur le cours qui vous convient le mieux, s'il vous plaît venez à l'une de nos soirées ouvertes, ring Admissions au 01743 260401 ou par e-mail à l'adresse email: example.com<br/>Un niveau de langue anglaise (droit et théâtre et théâtre)<br/>École précédente: Mary Webb School<br/>Je suis venu ici parce que c'était local pour moi et j'ai apprécié les jours de pré-inscription qui étaient bien organisés. La langue anglaise est un bon niveau à avoir et il est super intéressant de voir comment la langue a évolué et changé au fil du temps. Les enseignants sont d'une grande aide et les ressources sont brillantes; il y a beaucoup de livres de texte.<br/>Vous êtes employeur ?<br/>Voyez comment un apprenti peut aider votre entreprise. |
| In a subproject carried out together with the City of Stockholm within the HazardSupport research project, SMHI has investigated how town planning affects a city’s climate. Scenarios have been produced for Stockholm’s growth up until 2030 and 2050, using summer 2014 as a reference point. These scenarios do not take ongoing climate change into account. Instead, they simply show how the densification and growth of Stockholm can be expected to affect the air temperature.<br/>The main conclusion from the scenarios is that the impact of densification on air temperature is relatively local. No significant effect on the average temperature during the summer is seen at a distance of more than about 2 km, despite extensive densification across large areas. This can be seen in the most central parts of Stockholm, for example, which are already built-up and where no significant reduction in green spaces can therefore be expected. No significant change in air temperature is seen in these areas.<br/>One reason why the densification and expansion of Stockholm has not had any significant impact on air temperature is the relatively rapid air exchange with nearby expanses of water and countryside. Within those areas that are densifying, average summer temperature increases of up to around 1.5°C are being seen. As expected, the biggest temperature increases are observed when natural environments or green areas are built on.<br/>Measures in the local area<br/>One consequence of the locally limited effect of changes in the urban environment is that measures should primarily be focused on direct effects within the local area. Examples of such measures include shady street trees and proximity to green spaces. For the same reason, measures such as green roofs that only indirectly affect the air temperature in the street environment can be expected to have a less significant impact.<br/>A comfort index can be used to summarise the effect of various climate parameters. One example of such an index is the Universal Thermal Climate Index (UTCI). This involves a higher level of ambition in relation to how climate planning is often carried out in today’s planning processes. | Dans le cadre d'un sous-projet mené conjointement avec la ville de Stockholm dans le cadre du projet de recherche HazardSupport, SMHI a étudié comment l'urbanisme affecte le climat d'une ville. Des scénarios ont été produits pour la croissance de Stockholm jusqu'en 2030 et 2050, en utilisant l'été 2014 comme point de référence. Ces scénarios ne tiennent pas compte du changement climatique en cours. Au lieu de cela, ils montrent simplement comment on peut s'attendre à ce que la densification et la croissance de Stockholm affectent la température de l'air.<br/>La principale conclusion des scénarios est que l'impact de la densification sur la température de l'air est relativement local. Aucun effet significatif sur la température moyenne pendant l'été n'est observé à une distance de plus de 2 km environ, malgré une densification étendue sur de vastes zones. C'est ce que l'on constate dans les parties les plus centrales de Stockholm, par exemple, qui sont déjà construites et où l'on ne peut donc pas s'attendre à une réduction significative des espaces verts.<br/>L'une des raisons pour lesquelles la densification et l'expansion de Stockholm n'ont pas eu d'impact significatif sur la température de l'air est l'échange d'air relativement rapide avec des étendues d'eau et de campagne voisines. Dans les zones qui se densifient, on observe des augmentations de température estivales moyennes allant jusqu’à environ 1,5 °C. Comme prévu, les plus fortes augmentations de température sont observées lorsque des environnements naturels ou des espaces verts sont construits.<br/>Mesures dans la région<br/>L'une des conséquences de l'effet localement limité des changements dans l'environnement urbain est que les mesures devraient être principalement axées sur les effets directs dans la zone locale, par exemple les arbres de rue ombragés et la proximité d'espaces verts. Pour la même raison, on peut s’attendre à ce que les mesures telles que les toits verts qui n’affectent que indirectement la température de l’air dans l’environnement de la rue aient un impact moins important.<br/>Un indice de confort peut être utilisé pour résumer l'effet de divers paramètres climatiques. Un exemple d'un tel indice est l'indice thermique universel du climat (UTCI). Cela implique un niveau d'ambition plus élevé par rapport à la façon dont la planification climatique est souvent réalisée dans les processus de planification d'aujourd'hui. |
