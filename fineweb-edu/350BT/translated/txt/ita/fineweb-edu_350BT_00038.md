| original | translation |
|----------|-------------|
| Artificial intelligence (AI), the computerized capability of doing tasks, which until recently was thought to be the exclusive domain of human intelligence, has demonstrated great strides in the past decade. The abilities to play games, provide piloting for an automobile, and respond to spoken language are remarkable successes. How are the challenges and opportunities of medicine different from these challenges and how can we best apply these data-driven techniques to patient care and outcomes? A New England Journal of Medicine paper published in 1980 suggested that more well-defined “specialized” tasks of medical care were more amenable to computer assistance, while the breadth of approach required for defining a problem and narrowing down the problem space was less so, and perhaps, unachievable. On the other hand, one can argue that the modern version of AI, which uses data-driven approaches, will be the most useful in tackling tasks such as outcome prediction that are often difficult for clinicians and patients. The ability today to collect large volumes of data about a single individual (eg, through a wearable device) and the accumulation of large datasets about multiple persons receiving medical care has the potential to apply to the care of individuals. As these techniques of analysis, enumeration, aggregation, and presentation are brought to bear in medicine, the question arises as to their utility and applicability in that domain. Early efforts in decision support were found to be helpful; as the systems proliferated, later experiences have shown difficulties such as alert fatigue and physician burnout becoming more prevalent. Will something similar arise from data-driven predictions? Will empowering patients by equipping them with information gained from data analysis help? Patients, providers, technology, and policymakers each have a role to play in the development and utilization of AI in medicine. Some of the challenges, opportunities, and tradeoffs implicit here are presented as a dialog between a clinician (SJN) and an informatician (QZT).J Med Internet Res 2019;21(11):e16272<br/>Drs Nelson and Zeng-Treitler work together at the Biomedical Informatics Center at George Washington University. In the following we present a hypothetical dialogue which grew out of discussions they had as they considered their differing viewpoints of how artificial intelligence (AI) has developed and where it is going. While Dr Zeng-Treitler’s view of the future of AI is highly optimistic, Dr Nelson's opinion is more cautious. Dr Nelson was a practicing academic internist who became involved in informatics many years ago. He collaborated with Scott Blois on RECONSIDER (an early clinical decision support system) and on the Unified Medical Language System (UMLS) project. He eventually moved to the National Library of Medicine as Head of Medical Subject Headings. While at the National Library of Medicine, he fathered RxNorm, while continuing his work on UMLS and projects involving UMLS. Dr Zeng-Treitler has a background in computer science and obtained her PhD in medical informatics from Columbia University. She has led a number of projects in clinical data mining, natural language processing, and consumer health informatics. During the past few years, her team has been actively investigating the use of AI techniques in clinical research including development of a novel explainable deep learning approach.<br/>Dr Zeng-Treitler (The "Optimist"):<br/>After decades of promises and disappointment, thanks to the seemingly unbounded computing resources and novel, data-driven methods, AI technology has finally arrived. From Jeopardy and Siri to face identification and autonomous vehicles, data-driven approaches have made the leap from laboratory experiments to applications that are transforming our lives outside health care. In some cases, these approaches have come close to passing the Turing Test—a test of a machine’s ability to exhibit supposed human-like intelligence; machines can now perform some complex tasks such as image recognition and authentic game play as well as or better than humans would. Some would argue that the requisite approach is decidedly nonhuman. However, whatever the means to achieving these innovations, such successes have not been followed by analogous successes in health care.<br/>One dramatic example of this disparity of accomplishment is AlphaZero, a computer game engine that mastered chess, Shogi, and Go. Even before the arrival of the current generation of data-driven artifacts, chess engines have been shown to be able to play at a level superior to that of chess champions. Players of Go (a board game that is thought to be much more complex than chess), however, believed that computers were no match for high-level professionals in this game. This belief was shattered first by AlphaGo, which soundly defeated the reigning world champion of Go. Then came AlphaZero. The news is no longer that such approaches can beat the champions of Go, chess, or Shogi. Rather, the remarkable fact is that AlphaZero did not learn from human experiences and that it defeated the best prior chess engines such as Stockfish. AlphaZero triumphed by playing more games against itself than had ever been played by all human players. This is not an approach we could readily duplicate in health care.<br/>Dr Nelson (The "Cautious" One):<br/>Is winning a game, with defined rules and objectives, really the best test of human intelligence? In hindsight, the answer is “No.” For example, sophisticated chess playing programs have existed for nearly 50 years; from such programs, we learned how to organize computing resources to apply simple algorithms in a scalable way. Put differently, we did not learn anything about chess or how humans, even experts, play it. Instead, we learned that a supposed intelligence-requiring task was susceptible to a computational approach. We need to ask where and how such an approach is applicable in health care.<br/>For example, when doing tasks that are generally thought to be human and creative, can the machine recognize when it is out of its depth? Sometimes, humans have the ability to do so. However, if we can define the realm closely enough, I agree that the machines can do wonders. So, how do we define the realm?<br/>In Blois’ seminal paper on Clinical Judgment and Computers , he described the world of a physician’s thought process when seeing a patient, with the diagram shown in . Point A for a physician would be where the patient walks in the door to be seen for the first time. The nature of the complaint, the context in which the complaint occurs, and all of the myriad possibilities are present. As the problem definition moves toward Point B, a computer is better able to manage the information and knowledge necessary for high-quality care. One way in which we can think about defining the realm is that we are moving toward Point B. Some computer scientists have argued that Point A is just about managing facts, but, as Blois observed, it is more about relevance—something that has proven difficult to replicate computationally.<br/>It is indeed important to define the realm for an AI application. Many tasks in health care are much more complex than game play, and we have not witnessed the triumphs of analogous approaches in the biomedical domain as have been achieved in game play. Quite a few studies have been applying the latest deep learning technology (a key AI method) to biomedical datasets [- ]. The specific applications included image processing, natural language processing, and risk prediction. Deep learning, compared with traditional statistical and machine learning methods, has often shown modest improvements rather than breakthroughs [ - ].<br/>Whatever the details of these approaches, they apply nearly unbounded computing resources to very large amounts of data, something that has yet to happen in health care. Therefore, these approaches might prove helpful, but we do not know for sure yet.<br/>For example, a simple question posed by a colleague is beyond our current capabilities: Given a patient who starts out with a feature of metabolic syndrome, which feature of the syndrome will he or she tend to exhibit next? Simplistically, this is exactly the kind of challenge that a data-driven approach should help with, and yet, it is currently “over the horizon” due to the insufficient data that were collected in the past.<br/>Data are a key challenge when applying data-driven approaches to patient care. To begin with, biomedical data are highly complex. There many different types of data including image, text, numerical values, categorical classifications, and DNA sequences, representing tens of thousands of lab tests, procedures, diagnoses, medications, genetic markers, etc. Each data type also has its own characteristics; for example, a laboratory test value may need to be interpreted in the context of age, gender, and current conditions. However, diagnostic codes for different diseases have varying levels of accuracies.<br/>In biomedical data analysis, there is also the paradox of having too much and not enough data at the same time. On one hand, there are a tremendous amount of medical record, social media, and literature data. Efforts like the Million Veterans Project  have also collected a huge amount of DNA data. Using devices for tasks like activity tracking and continuous glucose monitoring generates more data than our current medical record systems can digest. On the other hand, the health record of a patient is an open system with much missing information in contrast with the closed system of a chess or Go game, where all data are available. Patients are observed at irregular intervals (eg, at clinic visits or during hospitalization) and are never subjected to all possible tests or treatments. Sometimes, death is the only definitive outcome.<br/>I agree that data types are multiple and complex. Simple solutions are insufficient, and the proliferation of irrelevant data in a record, not to mention the current cut-and-paste or fill-in-the-template fad, obscures what is important.<br/>One of the major difficulties with medical data is not just that it is not enough, but also that it is theory laden, that is, very few pieces of data are recorded routinely. A lot of data in observations are gathered only when the clinician has thought it is appropriate, that is, when diseases are tested for their absence or presence. If there is no reason to do the test, the test is not performed. Only a few tests are ever performed routinely; a transcribed set of physical observations (as is done in physical examination) is rarely recorded in enough detail (not to mention the failure to observe, which often occurs) to provide sufficient data for a more comprehensive analysis. For that reason alone, studies based on the recorded observations are often incomplete and potentially misleading. However, for predictions, observations not made may be the critical ones. Think about the patient with metabolic syndrome mentioned above. What data are we missing?<br/>Similarly, the results of clinical trials are not a complete picture. Even though participants have been selected, often excluding many individuals because of complicating conditions, the data collected on the participants are designed for testing certain hypotheses, with narrowly defined outcomes. A common criticism is that such trials are so artificial that they are irrelevant.<br/>The lack of integrated and standardized datasets is another issue. Although we can find many large datasets, they are often incomplete and difficult to link to other information. For example, environmental exposure, diet, physical activity, and genetic profile are among the common missing pieces of information when we examine the records about an individual patient. Detailed clinical trial datasets tend to lack long-term follow-up. Privacy issues and monetary incentives are also obstacles in data integration efforts.<br/>Real semantic interoperability to integrate and standardize datasets requires support in both terminology and how that terminology is used. Currently, human intervention is often required to interpret what one system is saying for use in another system. This situation is unfortunate; we can hope that over time, the necessary connections will take place (think of how the United States went from operator assistance on every telephone call to the automatic switching that takes place today). Such a change can only happen when many people see the need for and implement a common standard.<br/>In addition, the notion of “large” in the context of health care data is only relative. Think, instead, of many experiments undertaken by Google; if they desire, the amount of data that can be used to develop and test a model is orders of magnitude greater than that available in health care.<br/>In the domains where data-driven approaches have demonstrated success, there are outcomes that can be judged by human experts or machines themselves. For example, bilingual speakers can tell if natural language translation is working well, and the outcome of board or computer games can be easily determined. This allows easier simulation or annotation of data for machine learning. Such a task is much harder in the biomedical domains; investigation of causes or treatments of diseases in humans involve costly and long-term studies. In some cases, ethical concerns prohibit the experiments; for example, the introduction of potentially harmful genetic mutations into healthy human subjects is out of the question. We lack long-term outcome data for many treatments.<br/>I am not sure that there ever will be such a gold standard without a completely arbitrary definition. Variation between individuals is also a major obstacle. Although we perform studies using multiple subjects to account for biologic variability, our results are only approximate in their relevance to a given individual. For example, assuring genetic diversity in clinical trials is challenging, to say the least. Even the simplest tasks can be staggeringly multifactorial; for example, the information content of genetic testing for warfarin metabolism can be outweighed by whether the patient had lettuce for lunch.<br/>To expand on this observation, suppose you have an automobile that is not working appropriately. Today, you consult the sensors and the computer readout to give you very precise information about what is going wrong. The automobile has a specific design, with specific parameters that can be measured. All of the vehicles of the same year make and model can be assumed to be alike in those important aspects. It is important to realize that every human (with the exception of identical twins) is genetically unique. In that way, people are very different from automobiles or other mechanical devices. To compound the complexity with which the cause of a human problem can be addressed, what the individual experiences throughout their life is unique. Although we have nice abstractions or methods of identifying individuals who share some common characteristics (whether the presence or absence of a disease, the response or lack thereof to a medication, the similar environment, or other considerations), these are only a shorthand notation. With 7 billion persons currently living in this world, the problem appears almost open-ended. Too often in data analysis, we look at diagnostic codes as having a deep meaning. These are accepted without any recognition of the degree of uncertainty of the diagnosis. All our data may be helpful and useful, but we need to continue to view them with a large grain of salt. The fact that Google Translate works as well as it does gives us hope, but as complex as natural language translation is, it is simpler than some clinical tasks.<br/>Despite these challenges, applying data-driven approaches has the potential to transform health care. Today’s health care is labor intensive, from scheduling and triage to diagnosis and treatment. Many tasks currently undertaken by humans can be carried out by intelligent software solutions supported by sufficient data. For instance, improved voice recognition and summarization technology might help reduce the amount of time patients and clinicians spend on paperwork. Improved decision support tools ought to be able to help patients decide about the appropriateness of seeking care. An accurate assessment of short- and long-term risks and benefits will inform treatment selection and lifestyle changes.<br/>To provide another use case, there is evidence that type II diabetes may be reversible, but it is hard to apply this knowledge to an individual patient. Given the patient in front of me, what should I do, or recommend, and with what expectation? Demographics, genomics, comorbidities, psyche, competing risks, and other medications, all play a role. How, in a given person, do I reconcile all the possibilities?<br/>To develop these useful AI tools, we need better data, technology, and policy. To accumulate comprehensive, life-time data, patients must be in control and should be incentivized to share their data for research and care. Insurance, pharmaceutical, and medical institutions change over time. Currently, there are barriers for individuals to be the center of collecting the data on themselves. The barriers are present in data entry, collection, and storage; for example, some personalized health record products are tethered to an institution, while others require extensive transcribing efforts by patients or caregivers. Nevertheless, without patient consent and collaboration, gathering and linking longitudinal environmental, genetic, clinical, and behavioral data are neither feasible nor ethical. The current conditions are a huge barrier to any attempt to use data-driven approaches that have worked outside health care.<br/>Efforts including PatienstLikeMe  and the All of Us Research Project of the National Institutes of Health [ ] are examples of innovative approaches to curate bigger and better datasets. Most patients, however, are not engaged in such efforts. Patients are inherently motivated to improve their own health, but naturally have concerns regarding privacy and often do not see immediate benefits of participating in long-term studies. Appropriate incentives (eg, discounts for routine preventive care) coupled with security and authentication technologies are needed to entice a large and diverse population of patients to gather and share their data. The health care industry today owns parts of patient data and has limited motivation to purchase data from their customers. As the value of data increases, patients will become more valued as a partner.<br/>I agree that patients will need to assume the responsibility of carrying and sharing the information about themselves. However, experience tells us that not everyone is able or willing to do so. It will need cultural and political climate changes to encourage that development.<br/>When we can collect data that are not directly what the philosophers would call “theory-laden,” we may be able to refine our crude methods of patient diagnosis and care. I look forward to that day. If patients are the carrier of those data, it will be easier to obtain and use for analysis.<br/>We also need to design and implement methods specifically for handling very large and “messy” clinical data. For example, we need to understand the context of missing data and errors to get a better picture of ground truth. A lab result may be missed because there is no indication for it, practice preference, an alternative method of assessing, or a failure of data entry. Imagine how much more difficult a chess game will be, if a human player or a chess engine could only observe some squares on the board at irregular time intervals with some error or distortion of the observation.<br/>Further, we do not have an operational definition of “ground truth” in health care; a simple proposal is that one feature of ground truth is that it has predictive value—something that will be valued by clinicians and patients alike.<br/>Google has demonstrated that they can use lots of data to predict likely values for missing data in other areas ; however, it is yet to be determined whether this might work in medicine, but it is probably worth a trial. Irrespective of whether we can use large volumes of data to impute missing values, exploring how to handle the problem of absent observations is crucial, especially whenever we try to apply the results of data-driven approaches to individual patients.<br/>Another thought is that data that are missing, for any reason, are an observation in itself; the fact that the data were not obtained and recorded may be important. Think of the finding that the day and time of a test were more predictive of outcome than the result of the test . We know that the data that are missing will have some predictive value.<br/>On a different note, explanation of the data-driven models is critical to not only their adoption but also their impact . Predicting that a patient will have certain adverse events in the next several days or years is desirable. It may be argued that it is even more important to know the modifiable factors that can reduce risk and enhance outcome. Since deep learning models can be highly nonlinear, we have the opportunity to discover novel and complex patterns.<br/>I agree that explaining the prediction is critical; it is something that separates health care from, say, recognizing whether an image is a dog or a cat. However, I think you meant to say predicting a patient will probably have some adverse outcome. Nothing in life is certain except that it will end. However, we can say “it appears this behavior or finding will likely have an effect on your future” and hopefully be able to express some degree of confidence in that prediction.<br/>Learning how to express the confidence in a prediction is also important. How many folks really understand the statistics behind the predictions that occur today? What are the underlying assumptions behind any probabilistic model? It is more likely that with more frequent use and familiarity with the use of measures derived for AI models will lead to their acceptance.<br/>I agree. These are all steps to be taken in order to optimize the use of big data through AI to improve medical care.<br/>As a parting thought, we need to be cautious about how intrusive data-driven approaches might be in the care process. Although McDonald  demonstrated that performance in care improves with reminders [ ], the later experience has been one of too many reminders, leading to alert fatigue. When caregivers choose to override and ignore helpful information because of overload, have we accomplished anything?<br/>I hope that careful design of systems and consideration of clinical workflow will alleviate the problem of excessive intrusiveness. Although it is tempting to just “let AI do it,” the recent experiences with the Boeing 737 MAX demonstrate that there is danger in doing so. Neither AI nor a pilot alone is the optimal strategy in flying. In health care, involving patients more extensively in their care, together with AI and providers, may ultimately be an approach that works.<br/>Conflicts of Interest<br/>- Blois MS. Clinical Judgment and Computers. N Engl J Med 1980 Jul 24;303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Deep learning for healthcare: review, opportunities and challenges. Brief Bioinform 2018 Nov 27;19(6):1236-1246 [FREE Full text] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. Can machine-learning improve cardiovascular risk prediction using routine clinical data? PLoS ONE 2017 Apr 4;12(4):e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT. Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records. Sci Rep 2016 May 17;6(1):26094 [FREE Full text] [CrossRef] [Medline]<br/>- Quach K. The register. 2019. IBM Watson Health cuts back drug discovery 'artificial intelligence' after lackluster sales URL: https://www.theregister.co.uk/2019/04/18/ibm_watson_health [accessed 2019-10-23]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Scalable and accurate deep learning with electronic health records. NPJ Digit Med 2018 May 8;1(1):18 [FREE Full text] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, et al. Deep Learning in Medical Imaging: General Overview. Korean J Radiol 2017;18(4):570. [CrossRef]<br/>- U.S Department of Veterans Affairs. Million Veteran Program (MVP) URL: https://www.research.va.gov/mvp/ [accessed 2019-10-23]<br/>- Patientslikeme. URL: https://www.patientslikeme.com [accessed 2019-10-23]<br/>- All of Us Research Program. URL: https://allofus.nih.gov [accessed 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. The unreasonable effectiveness of data. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Biases in electronic health record data due to processes within the healthcare system: retrospective observational study. BMJ 2018 Apr 30:k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, Müller H. Causability and explainabilty of artificial intelligence in medicine. WIREs Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Protocol-Based Computer Reminders, the Quality of Care and the Non-Perfectibility of Man. N Engl J Med 1976 Dec 09;295(24):1351-1355. [CrossRef]<br/>&#124;AI: artificial intelligence&#124;<br/>&#124;UMLS: Unified Medical Language System&#124;<br/>Edited by G Eysenbach; submitted 15.09.19; peer-reviewed by A Holzinger; comments to author 14.10.19; revised version received 15.10.19; accepted 20.10.19; published 27.11.19Copyright<br/>©Qing Zeng-Treitler, Stuart J Nelson. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included. | L’intelligenza artificiale (AI), la capacità computerizzata di svolgere compiti, che fino a poco tempo fa era considerata il dominio esclusivo dell’intelligenza umana, ha dimostrato grandi passi avanti nell’ultimo decennio. Le abilità di giocare, fornire pilotaggio per un'automobile, e rispondere al linguaggio parlato sono notevoli successi. In che modo le sfide e le opportunità della medicina sono diverse da queste sfide e come possiamo applicare al meglio queste tecniche basate sui dati alla cura dei pazienti e ai risultati? Un articolo del New England Journal of Medicine pubblicato nel 1980 suggeriva che compiti "specializzati" più ben definiti dell'assistenza medica erano più suscettibili all'assistenza informatica, mentre l'ampiezza dell'approccio richiesto per definire un problema e restringere lo spazio del problema era meno così, e forse, irraggiungibile. D'altra parte, si può sostenere che la versione moderna dell'IA, che utilizza approcci basati sui dati, sarà la più utile per affrontare compiti come la previsione dei risultati che sono spesso difficili per medici e pazienti. La capacità di raccogliere grandi volumi di dati su un singolo individuo (ad esempio, attraverso un dispositivo indossabile) e l'accumulo di grandi set di dati su più persone che ricevono cure mediche ha il potenziale di applicarsi alla cura degli individui. Come queste tecniche di analisi, enumerazione, aggregazione e presentazione sono portati a portare in medicina, la questione sorge quanto alla loro utilità e applicabilità in quel campo. Gli sforzi iniziali nel supporto decisionale si sono rivelati utili; con la proliferazione dei sistemi, le esperienze successive hanno mostrato difficoltà come la stanchezza di allerta e il burnout del medico diventando più prevalenti. Qualcosa di simile sorgerà dalle previsioni basate sui dati? Aiuta il potenziamento dei pazienti dotandoli delle informazioni ottenute dall'analisi dei dati? Pazienti, fornitori, tecnologia e responsabili politici hanno ciascuno un ruolo da svolgere nello sviluppo e nell'utilizzo dell'intelligenza artificiale in medicina. Alcune delle sfide, opportunità e compromessi impliciti qui sono presentati come un dialogo tra un clinico (SJN) e un informatico (QZT). J Med Internet Res 2019;21(11):e16272<br/>Nelson e Zeng-Treitler lavorano insieme al Centro di Informatica Biomedica della George Washington University. Di seguito presentiamo un dialogo ipotetico che è nato dalle discussioni che hanno avuto mentre consideravano i loro diversi punti di vista su come si è sviluppata l'intelligenza artificiale (AI) e dove sta andando. Mentre la visione del Dr. Zeng-Treitler del futuro dell'IA è altamente ottimista, l'opinione del Dr. Nelson è più cauta. Il Dr. Nelson era un internista accademico praticante che si è impegnato nell'informatica molti anni fa. Ha collaborato con Scott Blois a RECONSIDER (un sistema di supporto alle decisioni cliniche precoci) e al progetto Unified Medical Language System (UMLS). Alla fine si è trasferito alla National Library of Medicine come Head of Medical Subject Headings. Mentre era alla National Library of Medicine, ha generato RxNorm, continuando il suo lavoro su UMLS e progetti che coinvolgono UMLS. La dottoressa Zeng-Treitler ha un background in informatica e ha ottenuto il dottorato in informatica medica presso la Columbia University. Ha guidato una serie di progetti di data mining clinico, elaborazione del linguaggio naturale e informatica per la salute dei consumatori. Negli ultimi anni, il suo team ha studiato attivamente l'uso delle tecniche di intelligenza artificiale nella ricerca clinica, incluso lo sviluppo di un nuovo approccio di deep learning spiegabile.<br/>Dott. Zeng-Treitler (L'"Ottimista"):<br/>Dopo decenni di promesse e delusioni, grazie alle risorse di calcolo apparentemente illimitate e ai nuovi metodi basati sui dati, la tecnologia AI è finalmente arrivata. Da Jeopardy e Siri all’identificazione facciale e ai veicoli autonomi, gli approcci basati sui dati hanno fatto il salto dagli esperimenti di laboratorio alle applicazioni che stanno trasformando le nostre vite al di fuori dell’assistenza sanitaria. In alcuni casi, questi approcci si sono avvicinati al superamento del Test di Turing, un test della capacità di una macchina di esibire una presunta intelligenza simile all'uomo; le macchine possono ora eseguire alcuni compiti complessi come il riconoscimento delle immagini e il gioco autentico, così come o meglio di quanto farebbero gli esseri umani. Alcuni sostengono che l'approccio richiesto è decisamente non umano; tuttavia, qualunque sia il mezzo per raggiungere queste innovazioni, tali successi non sono stati seguiti da successi analoghi nell'assistenza sanitaria.<br/>Un esempio drammatico di questa disparità di realizzazione è AlphaZero, un motore di gioco per computer che ha padroneggiato gli scacchi, Shogi e Go. Anche prima dell'arrivo dell'attuale generazione di artefatti basati sui dati, i motori scacchistici hanno dimostrato di essere in grado di giocare a un livello superiore a quello dei campioni di scacchi. I giocatori di Go (un gioco da tavolo che si pensa sia molto più complesso degli scacchi), tuttavia, credevano che i computer non fossero compatibili con i professionisti di alto livello in questo gioco. Questa convinzione è stata prima infranta da AlphaGo, che ha sconfitto profondamente il campione del mondo in carica di Go. Poi è venuto AlphaZero. La notizia non è più che tali approcci possono battere i campioni di Go, scacchi, o Shogi. Piuttosto, il fatto notevole è che AlphaZero non ha imparato dalle esperienze umane e che ha sconfitto i migliori motori di scacchi precedenti come Stockfish. AlphaZero ha trionfato giocando più partite contro se stesso di quelle mai giocate da tutti i giocatori umani. Questo non è un approccio che potremmo facilmente duplicare nell'assistenza sanitaria.<br/>Dr. Nelson (Il "Cupido" Uno):<br/>Vincere una partita, con regole e obiettivi definiti, è davvero il miglior test dell'intelligenza umana? Con il senno di poi, la risposta è "No". Ad esempio, sofisticati programmi di gioco degli scacchi esistono da quasi 50 anni; da tali programmi, abbiamo imparato come organizzare le risorse di calcolo per applicare algoritmi semplici in modo scalabile. In altre parole, non abbiamo imparato nulla sugli scacchi o su come gli esseri umani, nemmeno gli esperti, li giocano. Invece, abbiamo imparato che un presunto compito che richiede intelligenza era suscettibile di un approccio computazionale. Dobbiamo chiederci dove e come tale approccio è applicabile nell'assistenza sanitaria.<br/>Ad esempio, quando si svolgono compiti che generalmente si pensa siano umani e creativi, la macchina può riconoscere quando è al di fuori della sua profondità? A volte, gli esseri umani hanno la capacità di farlo. Tuttavia, se possiamo definire il regno abbastanza da vicino, sono d'accordo che le macchine possono fare meraviglie. Quindi, come definiamo il regno?<br/>Nel documento di Blois sul giudizio clinico e i computer, ha descritto il mondo del processo di pensiero di un medico quando vede un paziente, con il diagramma mostrato in . Il punto A per un medico sarebbe dove il paziente entra nella porta per essere visto per la prima volta. La natura del reclamo, il contesto in cui si verifica il reclamo e tutte le miriadi di possibilità sono presenti. Come la definizione del problema si muove verso il punto B, un computer è in grado di gestire meglio le informazioni e le conoscenze necessarie per l'assistenza di alta qualità. Un modo in cui possiamo pensare di definire il regno è che ci stiamo muovendo verso il punto B. Alcuni informatici hanno sostenuto che il punto A riguarda solo la gestione dei fatti, ma, come ha osservato Blois, si tratta più di rilevanza – qualcosa che si è dimostrato difficile da replicare computazionalmente.<br/>Molti compiti nell'assistenza sanitaria sono molto più complessi del gioco, e non abbiamo assistito ai trionfi di approcci analoghi nel campo biomedico come sono stati raggiunti nel gioco. Alcuni studi hanno applicato la più recente tecnologia di deep learning (un metodo AI chiave) ai set di dati biomedici [- ]. Le applicazioni specifiche includevano l'elaborazione delle immagini, l'elaborazione del linguaggio naturale e la previsione del rischio. Il deep learning, rispetto ai metodi tradizionali di statistica e machine learning, ha spesso mostrato modesti miglioramenti piuttosto che scoperte.<br/>Qualunque siano i dettagli di questi approcci, applicano risorse di calcolo quasi illimitate a grandi quantità di dati, qualcosa che deve ancora accadere nell'assistenza sanitaria. Pertanto, questi approcci potrebbero rivelarsi utili, ma non lo sappiamo ancora con certezza.<br/>Ad esempio, una semplice domanda posta da un collega è al di là delle nostre attuali capacità: dato che un paziente inizia con una caratteristica della sindrome metabolica, quale caratteristica della sindrome tenderà a mostrare in seguito? Semplificando, questo è esattamente il tipo di sfida che un approccio basato sui dati dovrebbe aiutare, eppure, è attualmente "oltre l'orizzonte" a causa dei dati insufficienti che sono stati raccolti in passato.<br/>I dati sono una sfida fondamentale quando si applicano approcci basati sui dati alla cura dei pazienti. Per cominciare, i dati biomedici sono altamente complessi. Ci sono molti tipi diversi di dati tra cui immagini, testo, valori numerici, classificazioni categoriche e sequenze di DNA, che rappresentano decine di migliaia di test di laboratorio, procedure, diagnosi, farmaci, marcatori genetici, ecc. Ogni tipo di dati ha anche le proprie caratteristiche; ad esempio, un valore di test di laboratorio può dover essere interpretato nel contesto dell'età, del sesso e delle condizioni attuali. Tuttavia, i codici diagnostici per diverse malattie hanno diversi livelli di accuratezza.<br/>Nell'analisi dei dati biomedici, c'è anche il paradosso di avere troppi e non abbastanza dati allo stesso tempo. Da un lato, c'è una quantità enorme di record medici, social media e dati letterari. Sforzi come il Million Veterans Project hanno anche raccolto un'enorme quantità di dati sul DNA. L'utilizzo di dispositivi per attività come il monitoraggio delle attività e il monitoraggio continuo del glucosio genera più dati di quanto i nostri attuali sistemi di cartelle cliniche possano digerire. D'altra parte, il record di salute di un paziente è un sistema aperto con molte informazioni mancanti in contrasto con il sistema chiuso di una partita a scacchi o Go, dove tutti i dati sono disponibili. I pazienti sono osservati ad intervalli irregolari (ad esempio, alle visite cliniche o durante l'ospedalizzazione) e non sono mai sottoposti a tutti i possibili test o trattamenti. A volte, la morte è l'unico risultato definitivo.<br/>Sono d'accordo sul fatto che i tipi di dati sono molteplici e complessi. Le soluzioni semplici sono insufficienti e la proliferazione di dati irrilevanti in un record, per non parlare dell'attuale moda del taglio e dell'incollaggio o del riempimento nel modello, oscura ciò che è importante.<br/>Una delle maggiori difficoltà con i dati medici non è solo che non è sufficiente, ma anche che si tratta di teoria carica, cioè, pochissimi pezzi di dati vengono registrati di routine. Molti dati nelle osservazioni vengono raccolti solo quando il clinico ha ritenuto appropriato, cioè quando le malattie sono testate per la loro assenza o presenza. Se non c'è motivo di fare il test, il test non viene eseguito. Solo pochi test vengono mai eseguiti di routine; un insieme trascritto di osservazioni fisiche (come si fa nell'esame fisico) viene raramente registrato in modo sufficientemente dettagliato (per non parlare della mancanza di osservazione, che spesso si verifica) da fornire dati sufficienti per un'analisi più completa. Solo per questo motivo, gli studi basati sulle osservazioni registrate sono spesso incompleti e potenzialmente fuorvianti. Tuttavia, per le previsioni, le osservazioni non fatte possono essere quelle critiche. Pensate al paziente con sindrome metabolica di cui sopra. Quali dati ci mancano?<br/>Allo stesso modo, i risultati degli studi clinici non sono un quadro completo. Anche se i partecipanti sono stati selezionati, spesso escludendo molti individui a causa di condizioni complicate, i dati raccolti sui partecipanti sono progettati per testare alcune ipotesi, con risultati strettamente definiti. Una critica comune è che tali prove sono così artificiali che sono irrilevanti.<br/>La mancanza di set di dati integrati e standardizzati è un altro problema. Anche se possiamo trovare molti set di dati di grandi dimensioni, spesso sono incompleti e difficili da collegare ad altre informazioni. Ad esempio, l'esposizione ambientale, la dieta, l'attività fisica e il profilo genetico sono tra i comuni pezzi mancanti di informazioni quando esaminiamo le registrazioni su un singolo paziente. I set di dati di studi clinici dettagliati tendono a mancare di follow-up a lungo termine. I problemi di privacy e gli incentivi monetari sono anche ostacoli negli sforzi di integrazione dei dati.<br/>L'interoperabilità semantica reale per integrare e standardizzare i set di dati richiede il supporto sia nella terminologia che nel modo in cui viene utilizzata quella terminologia. Attualmente, l'intervento umano è spesso richiesto per interpretare ciò che un sistema sta dicendo per l'uso in un altro sistema. Questa situazione è sfortunata; possiamo sperare che nel tempo, le connessioni necessarie avranno luogo (pensate a come gli Stati Uniti sono passati dall'assistenza dell'operatore ad ogni chiamata telefonica alla commutazione automatica che avviene oggi). Un tale cambiamento può avvenire solo quando molte persone vedono la necessità di e implementare uno standard comune.<br/>Inoltre, la nozione di "grande" nel contesto dei dati sanitari è solo relativa. Pensate, invece, a molti esperimenti intrapresi da Google; se lo desiderano, la quantità di dati che può essere utilizzata per sviluppare e testare un modello è di ordine di grandezza maggiore di quella disponibile nell’assistenza sanitaria.<br/>Nei settori in cui gli approcci basati sui dati hanno dimostrato il successo, ci sono risultati che possono essere giudicati dagli esperti umani o dalle macchine stesse. Ad esempio, gli altoparlanti bilingui possono dire se la traduzione in linguaggio naturale sta funzionando bene e l'esito di giochi da tavolo o per computer può essere facilmente determinato. Ciò consente una simulazione o un'annotazione più semplice dei dati per l'apprendimento automatico. Tale compito è molto più difficile nei domini biomedici; l'indagine delle cause o dei trattamenti delle malattie negli esseri umani comporta studi costosi e a lungo termine. In alcuni casi, le preoccupazioni etiche vietano gli esperimenti; ad esempio, l'introduzione di mutazioni genetiche potenzialmente dannose in soggetti umani sani è fuori questione. Mancano dati di esito a lungo termine per molti trattamenti.<br/>Non sono sicuro che ci sarà mai un gold standard senza una definizione completamente arbitraria. La variazione tra individui è anche un ostacolo importante. Sebbene eseguiamo studi che utilizzano più soggetti per tenere conto della variabilità biologica, i nostri risultati sono solo approssimativi nella loro rilevanza per un dato individuo. Ad esempio, garantire la diversità genetica negli studi clinici è impegnativo, per dire il minimo. Anche i compiti più semplici possono essere sorprendentemente multifattoriali; ad esempio, il contenuto di informazioni dei test genetici per il metabolismo del warfarin può essere superato dal fatto che il paziente abbia avuto lattuga a pranzo.<br/>Per ampliare questa osservazione, supponiamo di avere un'automobile che non funziona correttamente. Oggi, si consultano i sensori e la lettura del computer per darvi informazioni molto precise su ciò che sta andando storto. L'automobile ha un design specifico, con parametri specifici che possono essere misurati. Tutti i veicoli dello stesso anno marca e modello possono essere presumibilmente uguali in quegli aspetti importanti. È importante rendersi conto che ogni essere umano (ad eccezione dei gemelli identici) è geneticamente unico. In questo modo, le persone sono molto diverse dalle automobili o da altri dispositivi meccanici. Per aggravare la complessità con cui la causa di un problema umano può essere affrontata, ciò che l'individuo sperimenta durante la sua vita è unico. Anche se abbiamo belle astrazioni o metodi per identificare gli individui che condividono alcune caratteristiche comuni (se la presenza o l'assenza di una malattia, la risposta o la mancanza di un farmaco, l'ambiente simile, o altre considerazioni), queste sono solo una notazione abbreviata. Con 7 miliardi di persone attualmente vivendo in questo mondo, il problema sembra quasi aperto. Troppo spesso nell'analisi dei dati, consideriamo i codici diagnostici come avendo un significato profondo. Questi sono accettati senza alcun riconoscimento del grado di incertezza della diagnosi. Tutti i nostri dati possono essere utili e utili, ma dobbiamo continuare a vederli con un granello di sale. Il fatto che Google Translate funzioni così bene ci dà speranza, ma per quanto sia complessa come la traduzione in linguaggio naturale, è più semplice di alcuni compiti clinici.<br/>Nonostante queste sfide, l'applicazione di approcci basati sui dati ha il potenziale per trasformare l'assistenza sanitaria. L'assistenza sanitaria di oggi è ad alta intensità di manodopera, dalla pianificazione e dalla selezione alla diagnosi e al trattamento. Molte attività attualmente svolte dagli esseri umani possono essere svolte da soluzioni software intelligenti supportate da dati sufficienti. Ad esempio, il miglioramento del riconoscimento vocale e della tecnologia di sintesi potrebbe aiutare a ridurre la quantità di tempo che i pazienti e i medici trascorrono sui documenti. Migliori strumenti di supporto decisionale dovrebbero essere in grado di aiutare i pazienti a decidere se cercare cure adeguate. Una valutazione accurata dei rischi e dei benefici a breve e lungo termine informerà la selezione del trattamento e i cambiamenti dello stile di vita.<br/>Per fornire un altro caso d'uso, ci sono prove che il diabete di tipo II può essere reversibile, ma è difficile applicare questa conoscenza a un singolo paziente. Dato il paziente di fronte a me, cosa dovrei fare, o raccomandare, e con quale aspettativa? La demografia, la genomica, le comorbidità, la psiche, i rischi concorrenti e altri farmaci, tutti giocano un ruolo. Come, in una data persona, riconciliare tutte le possibilità?<br/>Per sviluppare questi utili strumenti di intelligenza artificiale, abbiamo bisogno di dati, tecnologie e politiche migliori. Per accumulare dati completi e vitali, i pazienti devono avere il controllo e dovrebbero essere incentivati a condividere i loro dati per la ricerca e l'assistenza. Le istituzioni assicurative, farmaceutiche e mediche cambiano nel tempo. Attualmente, ci sono barriere per gli individui di essere al centro della raccolta dei dati su se stessi. Le barriere sono presenti nell'inserimento, nella raccolta e nello stoccaggio dei dati; ad esempio, alcuni prodotti di cartelle cliniche personalizzate sono collegati a un'istituzione, mentre altri richiedono sforzi estesi di trascrizione da parte dei pazienti o dei caregiver. Tuttavia, senza il consenso e la collaborazione del paziente, la raccolta e il collegamento di dati ambientali longitudinali, genetici, clinici e comportamentali non sono né fattibili né etici. Le condizioni attuali sono un enorme ostacolo a qualsiasi tentativo di utilizzare approcci basati sui dati che hanno funzionato al di fuori dell'assistenza sanitaria.<br/>Gli sforzi tra cui PatienstLikeMe e il progetto di ricerca All of Us del National Institutes of Health [ ] sono esempi di approcci innovativi per curare set di dati più grandi e migliori. La maggior parte dei pazienti, tuttavia, non sono impegnati in tali sforzi. I pazienti sono intrinsecamente motivati a migliorare la propria salute, ma naturalmente hanno preoccupazioni per quanto riguarda la privacy e spesso non vedono benefici immediati dalla partecipazione a studi a lungo termine. Sono necessari incentivi appropriati (ad esempio, sconti per le cure preventive di routine) accoppiati con tecnologie di sicurezza e autenticazione per attirare una popolazione numerosa e diversificata di pazienti a raccogliere e condividere i loro dati. Il settore sanitario oggi possiede parti dei dati dei pazienti e ha una motivazione limitata ad acquistare i dati dai loro clienti. Man mano che il valore dei dati aumenta, i pazienti diventeranno più apprezzati come partner.<br/>Concordo sul fatto che i pazienti dovranno assumersi la responsabilità di portare e condividere le informazioni su se stessi. Tuttavia, l'esperienza ci dice che non tutti sono in grado o disposti a farlo. Avrà bisogno di cambiamenti climatici culturali e politici per incoraggiare questo sviluppo.<br/>Quando possiamo raccogliere dati che non sono direttamente ciò che i filosofi chiamerebbero "caricati di teoria", potremmo essere in grado di perfezionare i nostri metodi grezzi di diagnosi e cura del paziente. Non vedo l'ora di quel giorno. Se i pazienti sono portatori di tali dati, sarà più facile ottenerli e utilizzarli per l'analisi.<br/>Dobbiamo anche progettare e implementare metodi specifici per la gestione di dati clinici molto grandi e "disordinati". Ad esempio, dobbiamo comprendere il contesto dei dati mancanti e degli errori per ottenere un quadro migliore della verità di base. Un risultato di laboratorio può essere mancato perché non vi è alcuna indicazione per esso, la preferenza pratica, un metodo alternativo di valutazione, o un fallimento di immissione dei dati. Immagina quanto sarà più difficile una partita a scacchi, se un giocatore umano o un motore di scacchi potessero osservare solo alcuni quadrati sulla scacchiera a intervalli di tempo irregolari con qualche errore o distorsione dell'osservazione.<br/>Inoltre, non abbiamo una definizione operativa di "verità di base" nell'assistenza sanitaria; una semplice proposta è che una caratteristica della verità di base è che ha un valore predittivo - qualcosa che sarà apprezzato sia dai clinici che dai pazienti.<br/>Google ha dimostrato di poter utilizzare un sacco di dati per prevedere i valori probabili per i dati mancanti in altre aree; tuttavia, non è ancora stato determinato se questo potrebbe funzionare in medicina, ma probabilmente vale la pena provare. Indipendentemente dal fatto che possiamo utilizzare grandi volumi di dati per imputare valori mancanti, esplorare come gestire il problema delle osservazioni assenti è cruciale, soprattutto quando cerchiamo di applicare i risultati di approcci basati sui dati ai singoli pazienti.<br/>Un altro pensiero è che i dati mancanti, per qualsiasi motivo, sono un’osservazione in sé; il fatto che i dati non siano stati ottenuti e registrati può essere importante. Pensate alla scoperta che il giorno e l'ora di un test erano più predittivi dell'esito rispetto al risultato del test. Sappiamo che i dati mancanti avranno un certo valore predittivo.<br/>Su una nota diversa, la spiegazione dei modelli basati sui dati è fondamentale non solo per la loro adozione ma anche per il loro impatto . Predire che un paziente avrà determinati eventi avversi nei prossimi giorni o anni è auspicabile. Si può sostenere che sia ancora più importante conoscere i fattori modificabili che possono ridurre il rischio e migliorare i risultati. Poiché i modelli di deep learning possono essere altamente non lineari, abbiamo l'opportunità di scoprire modelli nuovi e complessi.<br/>Sono d'accordo che spiegare la previsione è fondamentale; è qualcosa che separa l'assistenza sanitaria da, diciamo, riconoscere se un'immagine è un cane o un gatto. Tuttavia, penso che tu intendessi dire che prevedere un paziente probabilmente avrà qualche esito avverso. Nulla nella vita è certo tranne che finirà. Tuttavia, possiamo dire "sembra che questo comportamento o scoperta avrà probabilmente un effetto sul tuo futuro" e speriamo di essere in grado di esprimere un certo grado di fiducia in quella previsione.<br/>Imparare a esprimere la fiducia in una previsione è anche importante. Quante persone capiscono davvero le statistiche dietro le previsioni che si verificano oggi? Quali sono le ipotesi sottostanti dietro qualsiasi modello probabilistico? È più probabile che con un uso più frequente e familiarità con l'uso di misure derivate per i modelli di intelligenza artificiale porterà alla loro accettazione.<br/>Sono d'accordo. Queste sono tutte le misure da adottare per ottimizzare l'uso dei big data attraverso l'intelligenza artificiale per migliorare l'assistenza medica.<br/>Come pensiero di abbandono, dobbiamo essere cauti su quanto potrebbero essere invasivi gli approcci basati sui dati nel processo di cura. Sebbene McDonald abbia dimostrato che le prestazioni nella cura migliorano con i promemoria, l'esperienza successiva è stata uno dei troppi promemoria, portando ad avvertire la stanchezza. Quando i caregiver scelgono di ignorare e ignorare le informazioni utili a causa del sovraccarico, abbiamo realizzato qualcosa?<br/>Spero che un'attenta progettazione dei sistemi e la considerazione del flusso di lavoro clinico allevino il problema dell'eccessiva intrusività. Anche se è allettante "lasciare che l'IA lo faccia", le recenti esperienze con il Boeing 737 MAX dimostrano che c'è pericolo nel farlo. Né l'IA né un pilota da solo sono la strategia ottimale nel volo. Nell'assistenza sanitaria, il coinvolgimento più esteso dei pazienti nella loro cura, insieme all'intelligenza artificiale e ai fornitori, può in ultima analisi essere un approccio che funziona.<br/>Conflitti di interesse<br/>- Blois MS. Giudizio clinico e computer. N Engl J Med 1980 Lug 24;303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Deep learning for healthcare: recensione, opportunità e sfide. Breve Bioinforme 2018 Nov 27;19(6):1236-1246 [TESTO COMPLETO GRATUITO] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. Il machine learning può migliorare la previsione del rischio cardiovascolare utilizzando dati clinici di routine? PLoS ONE 2017 Apr 4;12(4):e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT. Paziente profondo: una rappresentazione non supervisionata per prevedere il futuro dei pazienti dalle cartelle cliniche elettroniche. Sci Rep 2016 maggio 17;6(1):26094 [TEXTO COMPLETO GRATUITO] [CrossRef] [Medline]<br/>- Quach K. Il registro. 2019. IBM Watson Health taglia indietro la scoperta di farmaci 'intelligenza artificiale' dopo vendite poco lucide URL: https://www.theregister.co.uk/2019/04/18/ibm_watson_health [consultato il 2019-10-23]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Apprendimento profondo scalabile e accurato con cartelle cliniche elettroniche. NPJ Digit Med 2018 8 maggio; 1(1):18 [Testo completo GRATUITO] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, et al. Deep Learning in Medical Imaging: Panoramica generale. Korean J Radiol 2017;18(4):570. [CrossRef]<br/>- U.S. Department of Veterans Affairs. Million Veteran Program (MVP) URL: https://www.research.va.gov/mvp/ [accessed 2019-10-23]<br/>- Patientslikeme. URL: https://www.patientslikeme.com [accessed 2019-10-23]<br/>- All of Us Programma di ricerca. URL: https://allofus.nih.gov [consultato il 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. L'irragionevole efficacia dei dati. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Pregiudizi nei dati delle cartelle cliniche elettroniche dovuti ai processi all'interno del sistema sanitario: studio osservazionale retrospettivo. BMJ 2018 Apr 30:k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, Müller H. Causabilità e spiegabilità dell'intelligenza artificiale in medicina. WIREs Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Protocollo-Based Computer Reminders, la qualità della cura e la non perfezione dell'uomo. N Engl J Med 1976 Dec 09; 295(24):1351-1355. [CrossRef]<br/>&#124;AI: intelligenza artificiale&#124;<br/>UMLS: Unified Medical Language System (Sistema Unificato di Linguaggio Medico)<br/>A cura di G Eysenbach; presentato il 15.09.19; peer-reviewed by A Holzinger; commenti all'autore 14.10.19; versione rivista ricevuta il 15.10.19; accettato il 20.10.19; pubblicato il 27.11.19Copyright<br/>© Qing Zeng-Treitler, Stuart J Nelson. Pubblicato originariamente sul Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>Questo è un articolo ad accesso aperto distribuito sotto i termini della Licenza di Attribuzione Creative Commons (https://creativecommons.org/licenses/by/4.0/), che consente l'uso, la distribuzione e la riproduzione senza restrizioni su qualsiasi supporto, a condizione che l'opera originale, pubblicata per la prima volta nel Journal of Medical Internet Research, sia correttamente citata. Le informazioni bibliografiche complete, un link alla pubblicazione originale su http://www.jmir.org/, così come queste informazioni sul copyright e sulla licenza devono essere incluse. |
| The Story of Selena Quintanilla: A Biography Book for Young Readers (The Story Of: A Biography Series for New Readers) (Paperback)<br/>Most titles are on our shelves or available within 1-5 days.<br/>Discover the life Selena Quintanilla—a story about breaking down barriers in music, for kids ages 6 to 9<br/>Selena Quintanilla was the queen of Tejano music. Before she became a star, Selena was a charismatic young girl who loved singing and performing. She made a lot of sacrifices to become a famous musician, rehearsing her songs and dance moves for hours at a time. Her hard work paid off—she became the first 15-year-old girl to win a Tejano music award and went on to break many records during her career. This Selena biography explores how she went from being a talented girl growing up in Texas to a fashion icon and a world-famous singer.<br/>What sets this Selena book apart:<br/>- Core curriculum—Kids will learn the Who, What, Where, When, Why, and How of Selena’s life, and take a quick quiz to test their knowledge.<br/>- Short chapters—This Selena kids’ book is broken up into brief chapters that make it fun and easy for new readers to discover details about the singer’s life.<br/>- Her lasting legacy—Kids will find out how Selena changed the world of music and why she continues to be a role model for many women and people of color around the globe.<br/>How will Selena’s big spirit and passion for music inspire the child in your life?<br/>About the Author<br/>GLORIA ARJONA teaches Spanish at the California Institute of Technology and is the author of Posadas Unknown Calaveras and ¡Lotería!. She’s also a musician who sings and plays guitar. Learn more at GloriaArjona.com.<br/>“Finally, a Selena book for new readers, one that is told concisely and honestly, and is eminently readable” —Joe Nick Patoski, author of Selena: Como La Flor<br/>“What a wonderful story to inspire girls to follow their dreams. A story that many girls will identify with, especially those from traditional and multicultural families. I liked all the little sidebar lessons throughout the book. Gloria is a very talented teacher.” —Genevieve B. Southgate, director of community programs, Bowers Museum<br/>“Selena Quintanilla’s youthful talent and positive drive are brought to life in Prof. Arjona’s latest book, this one geared to young readers. A highly appealing read highlighting Selena’s flexibility in overcoming obstacles to achieving her dreams and her trailblazing contributions to music and her community. The Callisto Media format of encouraging critical, organized thought via questions, maps, timelines, and a glossary make this an enjoyable learning experience.” —Martin E. Delgado, community library manager<br/>“This is the story of Selena Quintanilla, and what a story it is! In a time where young readers, and young women, need role models more than ever, this book brilliantly depicts the profound humanity, bravery, and talent of a deeply inspiring Latina woman who relentlessly fought for her dream.” —Maite Zubiaurre, UCLA professor | La storia di Selena Quintanilla: un libro di biografie per giovani lettori (La storia di: una serie di biografie per nuovi lettori) (Paperback)<br/>La maggior parte dei titoli sono sugli scaffali o disponibili entro 1-5 giorni.<br/>Scopri la vita di Selena Quintanilla, una storia sull'abbattimento delle barriere musicali, per bambini dai 6 ai 9 anni<br/>Selena Quintanilla era la regina della musica Tejano. Prima di diventare una star, Selena era una giovane ragazza carismatica che amava cantare e esibirsi. Ha fatto molti sacrifici per diventare una musicista famosa, provando le sue canzoni e le sue mosse di danza per ore alla volta. Il suo duro lavoro ha dato i suoi frutti: è diventata la prima ragazza di 15 anni a vincere un premio musicale Tejano e ha continuato a battere molti record durante la sua carriera. Questa biografia di Selena esplora come è passata da essere una ragazza di talento che cresce in Texas a un'icona della moda e una cantante di fama mondiale.<br/>Cosa distingue questo libro di Selena:<br/>- Curriculum di base: i bambini impareranno la vita di Selena: chi, cosa, dove, quando, perché e come, e faranno un rapido quiz per testare le loro conoscenze.<br/>Questo libro per bambini di Selena è suddiviso in brevi capitoli che rendono divertente e facile per i nuovi lettori scoprire dettagli sulla vita della cantante.<br/>I bambini scopriranno come Selena ha cambiato il mondo della musica e perché continua ad essere un modello per molte donne e persone di colore in tutto il mondo.<br/>In che modo il grande spirito e la passione di Selena per la musica ispireranno il bambino nella tua vita?<br/>Informazioni sull'autore<br/>GLORIA ARJONA insegna spagnolo al California Institute of Technology ed è l'autore di Posadas Unknown Calaveras e ¡Lotería!. È anche una musicista che canta e suona la chitarra. Scopri di più su GloriaArjona.com.<br/>“Finalmente, un libro di Selena per i nuovi lettori, uno che viene raccontato in modo conciso e onesto, ed è eminentemente leggibile” – Joe Nick Patoski, autore di Selena: Como La Flor<br/>"Che storia meravigliosa per ispirare le ragazze a seguire i loro sogni. Una storia con cui molte ragazze si identificheranno, specialmente quelle provenienti da famiglie tradizionali e multiculturali. Mi sono piaciute tutte le piccole lezioni sidebar in tutto il libro. Gloria è un’insegnante di grande talento.” —Genevieve B. Southgate, direttore dei programmi comunitari, Bowers Museum<br/>"Il talento giovanile di Selena Quintanilla e la sua spinta positiva prendono vita nell'ultimo libro del Prof. Arjona, questo rivolto ai giovani lettori. Una lettura molto accattivante che mette in evidenza la flessibilità di Selena nel superare gli ostacoli per realizzare i suoi sogni e i suoi contributi pionieristici alla musica e alla sua comunità. Il formato Callisto Media di incoraggiare il pensiero critico e organizzato attraverso domande, mappe, timeline e un glossario rendono questa un'esperienza di apprendimento piacevole ". - Martin E. Delgado, community library manager<br/>Questa è la storia di Selena Quintanilla, e che storia è! In un’epoca in cui i giovani lettori e le giovani donne hanno bisogno di modelli di riferimento più che mai, questo libro raffigura brillantemente la profonda umanità, il coraggio e il talento di una donna latina profondamente ispiratrice che ha combattuto senza sosta per il suo sogno. —Maite Zubiaurre, professore dell'UCLA |
| Here's another reason for men to avoid packing on extra pounds over the holidays: A new study has found that losing weight reduces the risk of an aggressive form of prostate cancer.<br/>After tracking the weight of nearly 70,000 men between 1982 and 1992, researchers from the American Cancer Society and the Duke University Prostate Center found that men who lost more than 11 pounds had a lower risk for aggressive prostate cancer than men whose weight remained the same over a decade.<br/>Previous studies have found that obese men have a higher risk of developing aggressive prostate cancer. This study appears to be the first to indicate that recent weight loss can decrease that risk.<br/>In the study reported this month in Cancer Epidemiology, Biomarkers & Prevention, researchers analyzed the height and weight of the men in 1982 and 1992 and every three years after that until 2003. At that time, more than 5,200 of the men — more than 7 percent — had prostate cancer.<br/>Among those cases, about one in eight had a form of cancer that was aggressive but had not spread to other areas of the body. The study's major finding focused on those aggressive cases, with researchers concluding that those who lost 11 or more pounds were 42 percent less likely to develop that form of prostate cancer than those whose weight remained the same.<br/>"Whether it's exactly 40 percent, we don't know, but they lower their risk when they lose 11-plus pounds. We feel confident, at least in this population, that was real," said lead researcher Dr. Carmen Rodriguez.<br/>More than seven times as many men whose weight remained the same developed aggressive prostate cancer compared to those who lost 11 or more pounds.<br/>"No significant associations" were found regarding the effect of weight gain or loss on the most severe forms of prostate cancer, those that spread throughout the body, the study said.<br/>The number studied was small, the researchers acknowledged, because fewer than 15,000 men lost weight over the time period, and only 1,000 of those developed some form of prostate cancer.<br/>The 69,991 participants were part of a bigger cancer society study of 1.2 million Americans that began in 1982.<br/>Rodriguez said men should avoid putting on extra weight as they get older.<br/>"The main message for men is to not get overweight. If they are overweight, that's another reason to try to lose weight, just to decrease the risk for prostate cancer," said Rodriguez, who works for the Atlanta-based cancer society.<br/>Other than skin cancer, prostate cancer is the most commonly diagnosed cancer for men, and about one in six will get it during his lifetime. It is the second leading cause of cancer death for U.S. men.<br/>The study is considered the first of its kind to examine the role of weight change in the development of prostate cancer, said Dr. Ronald Ennis, director of radiation oncology at St. Luke's-Roosevelt Hospital Center in New York, who was not involved in the study.<br/>"This is one of the best studies" examining the role of weight on prostate cancer, Ennis said. "It does seem to be true that if you are overweight, you are at risk of getting more aggressive forms of prostate cancer and if you lose weight, you can decrease the risk." | Ecco un altro motivo per gli uomini per evitare di mettere in valigia chili in più durante le vacanze: un nuovo studio ha scoperto che la perdita di peso riduce il rischio di una forma aggressiva di cancro alla prostata.<br/>Dopo aver monitorato il peso di quasi 70.000 uomini tra il 1982 e il 1992, i ricercatori dell'American Cancer Society e del Duke University Prostate Center hanno scoperto che gli uomini che hanno perso più di 11 chili avevano un rischio inferiore di cancro alla prostata aggressivo rispetto agli uomini il cui peso è rimasto lo stesso per un decennio.<br/>Precedenti studi hanno scoperto che gli uomini obesi hanno un rischio maggiore di sviluppare un cancro alla prostata aggressivo. Questo studio sembra essere il primo ad indicare che la perdita di peso recente può ridurre tale rischio.<br/>Nello studio riportato questo mese in Cancer Epidemiology, Biomarkers & Prevention, i ricercatori hanno analizzato l'altezza e il peso degli uomini nel 1982 e 1992 e ogni tre anni fino al 2003. A quel tempo, più di 5.200 degli uomini – più del 7% – avevano il cancro alla prostata.<br/>Tra questi casi, circa uno su otto aveva una forma di cancro che era aggressiva ma non si era diffusa ad altre aree del corpo. La principale scoperta dello studio si è concentrata su quei casi aggressivi, con i ricercatori che hanno concluso che coloro che hanno perso 11 chili o più avevano il 42% in meno di probabilità di sviluppare quella forma di cancro alla prostata rispetto a quelli il cui peso è rimasto lo stesso.<br/>"Se è esattamente il 40 per cento, non lo sappiamo, ma riducono il loro rischio quando perdono più di 11 chili. Ci sentiamo sicuri, almeno in questa popolazione, che era reale", ha detto il ricercatore principale Dr. Carmen Rodriguez.<br/>Più di sette volte più uomini il cui peso è rimasto lo stesso hanno sviluppato un cancro alla prostata aggressivo rispetto a quelli che hanno perso 11 chili o più.<br/>“Nessuna associazione significativa” è stata trovata per quanto riguarda l’effetto dell’aumento o della perdita di peso sulle forme più gravi di cancro alla prostata, quelle che si diffondono in tutto il corpo.<br/>Il numero studiato era piccolo, i ricercatori hanno riconosciuto, perché meno di 15.000 uomini hanno perso peso nel corso del periodo di tempo, e solo 1.000 di loro hanno sviluppato qualche forma di cancro alla prostata.<br/>I 69,991 partecipanti facevano parte di un più grande studio della società del cancro su 1,2 milioni di americani che ha avuto inizio nel 1982.<br/>Rodriguez ha detto che gli uomini dovrebbero evitare di aumentare di peso man mano che invecchiano.<br/>"Il messaggio principale per gli uomini è di non in sovrappeso. Se sono in sovrappeso, questo è un altro motivo per cercare di perdere peso, solo per ridurre il rischio di cancro alla prostata", ha detto Rodriguez, che lavora per la società del cancro con sede a Atlanta.<br/>Oltre al cancro della pelle, il cancro della prostata è il cancro più comunemente diagnosticato per gli uomini, e circa uno su sei lo otterrà durante la sua vita. È la seconda causa principale di morte per cancro per gli uomini degli Stati Uniti.<br/>Lo studio è considerato il primo del suo genere ad esaminare il ruolo del cambiamento di peso nello sviluppo del cancro alla prostata, ha detto il Dott. Ronald Ennis, direttore di radio oncologia presso il St. Luke's-Roosevelt Hospital Center di New York, che non è stato coinvolto nello studio.<br/>"Questo è uno dei migliori studi" esaminando il ruolo del peso sul cancro alla prostata, ha detto Ennis. “Sembra vero che se sei in sovrappeso, sei a rischio di ottenere forme più aggressive di cancro alla prostata e se perdi peso, puoi diminuire il rischio”. |
| If you have studied the OSI model with its 7 Layers that describe communication on computer network systems, you should know that the Ethernet standard lies in Layer 1 (Physical) and Layer 2 (Data-Link) of the OSI model.<br/>In this article we will focus on the physical (Layer 1) part of Ethernet, which mainly focuses on the wired physical medium (cabling) that is used to transport Ethernet frames in a network.<br/>Ethernet cables connect devices to computer networks, the “heart” of which is usually an Ethernet switch which has several interface ports for “plugging-in” the cables.<br/>Most of these Ethernet cables feature the standard RJ45 connector for plugging-in to a switch. However, Ethernet communication can be implemented also using Fiber-optic cabling which uses different types of connectors.<br/>Moreover, there are different types of Ethernet cables with varying bandwidths, speeds and types of construction. In this article we will discuss the “copper-made” cables which are the most popular ones in computer networks.<br/>The cables have labels indicating the standard used for manufacturing, ranging from category (cat) 3 to 7.<br/>Ethernet cables consist of several (usually 8) smaller wires (inside the main cable) which are separated in Twisted-pairs. This setup helps in cancelling-out electromagnetic interference between wires, thus allowing signals to travel longer distances inside the wires.<br/>Without the right cable (and of course without the right type of switch), you may experience slower speeds in the network between devices.<br/>Let’s now describe each Category of Ethernet Cables with their characteristics:<br/>&#124;Max Length&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m<br/>(55 m for 10Gbps)<br/>&#124;100 m&#124;&#124;100 m&#124;<br/>&#124;Max Speed&#124;&#124;10 Mbps&#124;&#124;100 Mbps&#124;&#124;1 Gbps&#124;&#124;10 Gbps&#124;&#124;10 Gbps&#124;&#124;>10 Gbps&#124;<br/>&#124;Frequency Bandwidth&#124;&#124;16 MHz&#124;&#124;100 MHz&#124;&#124;100 MHz&#124;&#124;250 MHz&#124;&#124;500 MHz&#124;&#124;600 MHz&#124;<br/>&#124;Shielded / Unshielded&#124;&#124;Unshielded&#124;&#124;Unshielded&#124;&#124;Unshielded&#124;&#124;Shielded or Unshielded&#124;&#124;Shielded&#124;&#124;Shielded&#124;<br/>1) Cat 3<br/>One of the oldest Ethernet cabling standards is category (cat) 3 (TIA/EIA-568-B). These cables allowed 10 Mbps transmission speeds with 16 MHz max bandwidth.<br/>Cat 3 ethernet cables feature unshielded twisted pair (UTP) cabling. With UTP cables, manufacturers twist insulated copper wires together inside a polyethylene jacket. Compared to shielded ethernet cables, UTP cables tend to include more crosstalk.<br/>Network connections commonly featured category 3 ethernet cables until the early 1990s, when category 5 cables replaced cat 3. While some older telephone systems may still use cat 3 cables, they have mostly become obsolete in the networking industry.<br/>2) Cat 5<br/>Cat 5 cables increased the bandwidth of Ethernet connections up to 100 MHz and offered transmission speeds up to 100 Mbps. With Cat 5 ethernet cables, users could access 100BASE-TX ethernet systems, referred to as fast ethernet.<br/>As with the category 3 cables, cat 5 cables still feature crosstalk and interference, due to the UTP design. These cables include four pairs of twisted wires (for a total of 8 wires).<br/>While cat 5 cables primarily provide connections for Ethernet applications, these cables also provide solutions for carrying other data signals, such as video and telephone. In fact, a single cat 5 cable can carry two standard phone lines and a 100BASE-TX connection.<br/>3) Cat 5e<br/>In 2001, the category 5e standard replaced category 5. The letter “e” in the name stands for enhanced.<br/>The cabling still uses unshielded twisted pairs. There are no physical differences between cat 5 and cat 5e cables. However, stricter standards in manufacturing Cat5e cables help minimize crosstalk and allow higher data transmissions than Cat5.<br/>Cat 5e cables also utilize two sets of twisted pairs of wires, resulting in faster speeds. While cat 5e ethernet cable still features 100 MHz bandwidth, these cables allow speeds up to 1000 Mbps (1 Gbps).<br/>While several additional standards have come after cat 5e, these cables remain in production. In fact, due to the lower cost of production and support for gigabit ethernet, cat 5e cables are the most used for network applications throughout the world.<br/>4) Cat 6<br/>Cat 6 ethernet cables helped address issues related to interference and crosstalk. These cables use thinner wires and superior insulation, resulting in a better signal-to-noise ratio.<br/>With these features, cat 6 cables provide a more effective option for adding cable in areas with more electromagnetic interference, such as a crowded server room.<br/>Thanks to the superior design, cat 6 provides improved bandwidth. These cables have a max bandwidth of 250 MHz and max transmission speeds up to 1000 Mbps (1 Gbps) at the 100m range. However, 10Gbps can be achieved in Cat6 in smaller distances (up to 55m).<br/>Some cat 6 cables include shielding while others remain unshielded. With shielding, these cables can provide transmission speeds up to 10 Gbps, but only for short distances as we said above.<br/>5) Cat 6a<br/>Category 6a ethernet cables improve the design of the cat 6 cables. The letter “a” stands for augmented. Unlike cat 6 cables, all cat 6a cables feature shielded cabling for reduced interference.<br/>With the enhancements to the design specifications, cat 6a cables maintain higher transmission speeds and 500 MHz max bandwidth, allowing speeds up to 10000 Mbps (10 Gbps) across longer cables.<br/>While these cables provide faster speeds, the design makes them less flexible. To eliminate crosstalk, these cables feature thicker sheathing, making the cables stiffer and more difficult to work.<br/>6) Cat 7<br/>One of the latest developments is Cat 7 Ethernet cables. Also called class F channel cables, these cables include stricter standards compared to previous categories. The individual wire pairs now include their own shielding, in addition to the outer shielding<br/>With these cables, you get 600 MHz max bandwidth and 10000 Mbps (10 Gbps) transmission speeds. However, by almost completely getting rid of crosstalk, cat 7 ethernet cables offer even greater reliability for 10 Gbps Ethernet connections.<br/>With connections less than 15 meters, cat 7 can support transmission speeds up to 100 Gbps. While the industry has released several new standards since cat 7, these cables are currently the top of the line option for demanding networking applications.<br/>- What is OSPF NSSA (Not So Stubby Area) and How is it Configured?<br/>- Comparison of BOOTP vs DHCP Protocols in Computer Networks<br/>- Pros and Cons of SD-WAN in Networks – Description and Discussion<br/>- Comparison of GNS3 vs EVE-NG vs Packet Tracer for Networks Simulation<br/>- Subnetting vs Supernetting – What’s the Difference? (Explanation Guide) | Se avete studiato il modello OSI con i suoi 7 livelli che descrivono la comunicazione su sistemi di rete di computer, si dovrebbe sapere che lo standard Ethernet si trova in Livello 1 (Fisico) e Livello 2 (Data-Link) del modello OSI.<br/>In questo articolo ci concentreremo sulla parte fisica (livello 1) di Ethernet, che si concentra principalmente sul mezzo fisico cablato (cablaggio) che viene utilizzato per trasportare i frame Ethernet in una rete.<br/>I cavi Ethernet collegano i dispositivi alle reti di computer, il cui "cuore" è di solito uno switch Ethernet che ha diverse porte di interfaccia per "collegare" i cavi.<br/>La maggior parte di questi cavi Ethernet sono dotati del connettore standard RJ45 per il collegamento a uno switch. Tuttavia, la comunicazione Ethernet può essere implementata anche utilizzando il cablaggio in fibra ottica che utilizza diversi tipi di connettori.<br/>Inoltre, ci sono diversi tipi di cavi Ethernet con diverse larghezze di banda, velocità e tipi di costruzione. In questo articolo parleremo dei cavi "in rame" che sono i più popolari nelle reti di computer.<br/>I cavi hanno etichette che indicano lo standard utilizzato per la produzione, che vanno dalla categoria (cat) 3 a 7.<br/>I cavi Ethernet sono costituiti da diversi (di solito 8) fili più piccoli (all'interno del cavo principale) che sono separati in coppie Twisted. Questa configurazione aiuta a cancellare le interferenze elettromagnetiche tra i fili, consentendo così ai segnali di percorrere distanze più lunghe all'interno dei fili.<br/>Senza il cavo giusto (e ovviamente senza il tipo di interruttore giusto), potresti sperimentare velocità più lente nella rete tra i dispositivi.<br/>Descriviamo ora ogni categoria di cavi Ethernet con le loro caratteristiche:<br/>&#124;Lunghezza massima&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m<br/>(55 m per 10 Gbps)<br/>&#124;100 m&#124;&#124;100 m&#124;<br/>&#124;Max Velocità&#124;&#124;10 Mbps&#124;&#124;100 Mbps&#124;&#124;1 Gbps&#124;&#124;10 Gbps&#124;&#124;10 Gbps&#124;&#124;>10 Gbps&#124;<br/>&#124;Larghezza di banda di frequenza&#124;&#124;16 MHz&#124;&#124;100 MHz&#124;&#124;100 MHz&#124;&#124;250 MHz&#124;&#124;500 MHz&#124;&#124;600 MHz&#124;<br/>&#124;Schiacciato / Non schermato&#124;&#124;Schiacciato&#124;&#124;Schiacciato&#124;&#124;Schiacciato&#124;&#124;Schiacciato&#124;Schiacciato&#124;Schiacciato&#124;Schiacciato&#124;Schiacciato&#124;Schiacciato&#124;<br/>1) Cat 3<br/>Uno dei più antichi standard di cablaggio Ethernet è la categoria (cat) 3 (TIA/EIA-568-B). Questi cavi consentivano velocità di trasmissione di 10 Mbps con larghezza di banda massima di 16 MHz.<br/>I cavi Ethernet Cat 3 sono dotati di cablaggio a coppia intrecciata (UTP) non schermato. Con i cavi UTP, i produttori ruotano i fili di rame isolati insieme all'interno di una giacca in polietilene. Rispetto ai cavi Ethernet schermati, i cavi UTP tendono a includere più diafonia.<br/>Le connessioni di rete presentavano comunemente cavi Ethernet di categoria 3 fino ai primi anni '90, quando i cavi di categoria 5 sostituirono i cavi cat 3. Mentre alcuni vecchi sistemi telefonici potrebbero ancora utilizzare cavi cat 3, sono per lo più diventati obsoleti nel settore delle reti.<br/>2) Cat 5<br/>I cavi Cat 5 hanno aumentato la larghezza di banda delle connessioni Ethernet fino a 100 MHz e hanno offerto velocità di trasmissione fino a 100 Mbps. Con i cavi Ethernet Cat 5, gli utenti hanno potuto accedere ai sistemi Ethernet 100BASE-TX, detti Fast Ethernet.<br/>Come per i cavi di categoria 3, i cavi cat 5 sono ancora dotati di diafonia e interferenze, grazie al design UTP. Questi cavi includono quattro coppie di fili intrecciati (per un totale di 8 fili).<br/>Mentre i cavi Cat 5 forniscono principalmente connessioni per applicazioni Ethernet, questi cavi forniscono anche soluzioni per il trasporto di altri segnali di dati, come video e telefono. Infatti, un singolo cavo cat 5 può trasportare due linee telefoniche standard e una connessione 100BASE-TX.<br/>3) Cat 5e<br/>Nel 2001, la norma di categoria 5e ha sostituito la categoria 5. La lettera "e" nel nome sta per enhanced.<br/>Il cablaggio utilizza ancora coppie intrecciate non schermate. Non ci sono differenze fisiche tra i cavi cat 5 e cat 5e. Tuttavia, gli standard più severi nella produzione dei cavi Cat5e aiutano a ridurre al minimo la diafonia e consentono trasmissioni di dati più elevate rispetto a Cat5.<br/>I cavi Cat 5e utilizzano anche due serie di coppie di fili intrecciati, con conseguente velocità più elevate. Mentre il cavo Ethernet Cat 5e ha ancora una larghezza di banda di 100 MHz, questi cavi consentono velocità fino a 1000 Mbps (1 Gbps).<br/>Mentre diversi standard aggiuntivi sono arrivati dopo cat 5e, questi cavi rimangono in produzione. Infatti, a causa dei costi di produzione più bassi e del supporto per Gigabit Ethernet, i cavi cat 5e sono i più utilizzati per le applicazioni di rete in tutto il mondo.<br/>4) Cat 6<br/>I cavi Ethernet Cat 6 hanno contribuito a risolvere i problemi legati alle interferenze e alla diafonia. Questi cavi utilizzano fili più sottili e un isolamento superiore, con un miglior rapporto segnale/rumore.<br/>Con queste caratteristiche, i cavi Cat 6 offrono un'opzione più efficace per l'aggiunta di cavi in aree con più interferenze elettromagnetiche, come una sala server affollata.<br/>Grazie al design superiore, Cat 6 offre una larghezza di banda migliorata. Questi cavi hanno una larghezza di banda massima di 250 MHz e velocità di trasmissione massime fino a 1000 Mbps (1 Gbps) nella gamma di 100 m. Tuttavia, 10 Gbps possono essere raggiunti in Cat6 a distanze più piccole (fino a 55 m).<br/>Alcuni cavi cat 6 includono schermatura mentre altri rimangono non schermati. Con schermatura, questi cavi possono fornire velocità di trasmissione fino a 10 Gbps, ma solo per brevi distanze come abbiamo detto sopra.<br/>5) Cat 6a<br/>I cavi Ethernet di categoria 6a migliorano il design dei cavi cat 6. La lettera "a" sta per aumentata. A differenza dei cavi cat 6, tutti i cavi cat 6a sono dotati di cablaggio schermato per ridurre le interferenze.<br/>Con i miglioramenti alle specifiche di progettazione, i cavi cat 6a mantengono velocità di trasmissione più elevate e una larghezza di banda massima di 500 MHz, consentendo velocità fino a 10000 Mbps (10 Gbps) su cavi più lunghi.<br/>Mentre questi cavi offrono velocità più elevate, il design li rende meno flessibili. Per eliminare la diafonia, questi cavi hanno una guaina più spessa, rendendo i cavi più rigidi e più difficili da lavorare.<br/>6) Cat 7<br/>Uno degli ultimi sviluppi sono i cavi Ethernet Cat 7. Chiamati anche cavi a canale di classe F, questi cavi includono standard più severi rispetto alle categorie precedenti. Le singole coppie di fili ora includono la propria schermatura, oltre alla schermatura esterna<br/>Con questi cavi, ottieni una larghezza di banda massima di 600 MHz e velocità di trasmissione di 10000 Mbps (10 Gbps). Tuttavia, eliminando quasi completamente la diafonia, i cavi Ethernet Cat 7 offrono una maggiore affidabilità per le connessioni Ethernet 10 Gbps.<br/>Con connessioni inferiori a 15 metri, cat 7 può supportare velocità di trasmissione fino a 100 Gbps. Mentre l'industria ha rilasciato diversi nuovi standard da cat 7, questi cavi sono attualmente l'opzione migliore per applicazioni di rete esigenti.<br/>Cos'è OSPF NSSA (Not So Stubby Area) e come si configura?<br/>- Confronto dei protocolli BOOTP vs DHCP nelle reti di computer<br/>- Pro e contro di SD-WAN in Reti – Descrizione e Discussione<br/>- Confronto di GNS3 vs EVE-NG vs Packet Tracer per la simulazione di rete<br/>- Subnetting vs Supernetting – Qual è la differenza? (Guida Spiegazione) |
| Views: 4 Author: Site Editor Publish Time: 2022-06-09 Origin: Site<br/>So why should workers wear a portable gas detector and what does it do?<br/>In many industrial environments, workers need to be highly aware of exposure to toxic or combustible gases and vapours or a lack of oxygen. That’s why portable gas detectors and analysers are essential – so they can detect, measure, monitor and react to any gases in the immediate area around them. KELISAIKE SAFETY offers both single- and multi-gas mobile gas monitors that reliably detect a wide range of gases. All of our portable gas detectors and software are designed to make compliance and asset management as intuitive as possible, so you can implement a complete product solution that helps ensure safety at all times.<br/>Portable gas detectors are classed as a type of Personal Protective Equipment (PPE)<br/>They monitor gases in the workers breathing zone by displaying real-time gas levels of a variety of toxic, combustible, flammable gases<br/>They alert the worker of any possible threats which include combustion and oxygen displacement<br/>While portable gas detectors are available with various sensor configurations and features, they are all built with the same purpose - to protect human life! | Visualizzazioni: 4 Autore: Site Editor Ora di pubblicazione: 2022-06-09 Origine: Site<br/>Quindi, perché i lavoratori dovrebbero indossare un rilevatore di gas portatile e cosa fa?<br/>In molti ambienti industriali, i lavoratori devono essere altamente consapevoli dell'esposizione a gas e vapori tossici o combustibili o della mancanza di ossigeno. Ecco perché i rilevatori e gli analizzatori di gas portatili sono essenziali - in modo che possano rilevare, misurare, monitorare e reagire a qualsiasi gas nell'area circostante. KELISAIKE SAFETY offre sia monitor mobili a gas singolo che multigas che rilevano in modo affidabile una vasta gamma di gas. Tutti i nostri rilevatori di gas portatili e software sono progettati per rendere la conformità e la gestione degli asset il più intuitivo possibile, in modo da poter implementare una soluzione di prodotto completa che aiuta a garantire la sicurezza in ogni momento.<br/>I rilevatori di gas portatili sono classificati come un tipo di Equipaggiamento di Protezione Individuale (EPI)<br/>Monitorano i gas nella zona di respirazione dei lavoratori visualizzando in tempo reale i livelli di gas di una varietà di gas tossici, combustibili e infiammabili<br/>Essi avvertono il lavoratore di eventuali minacce che includono la combustione e lo spostamento di ossigeno.<br/>Mentre i rilevatori di gas portatili sono disponibili con varie configurazioni e caratteristiche del sensore, sono tutti costruiti con lo stesso scopo: proteggere la vita umana! |
| Salvador Dalí Biography<br/>The prints of Salvador Dalí are rooted in a rich past. In actuality, Dalí’s prints have a history that dates back to his early years of art school. The young Dalí was taught the fine art of engraving and etching by his mentor. Dalí gained a respect for the technical details of printmaking, a respect he would maintain throughout the rest of his life. The connection between Dalí and graphic prints is in fact intricate and protracted. In his lifetime, Dalí produced just around 1,700 graphic prints. A large number of them are hand-signed, limited-edition editions. Some are regarded as some of the best prints created in the 20th century.<br/>Dalí had the ability to experiment with a wide range of subjects through his print work, including etchings, engravings, mixed media, lithographs, and photo-litho. Dalí would produce beautiful suites or single prints. These suites frequently feature a book motif, with the prints acting as the artwork. Among the literary works Dal illustrated were Alice in Wonderland, Hamlet, and The Old Man and the Sea. Other times, similar suites would focus on different subjects, such as flowers (FlorDal), science fiction (Conquest of the Cosmos), or fine print production (Currier and Ives). Dal also produced single prints that showcased his flawless printmaking skills. Prints by Dalí that are among his best include Flower Man, Symphony Bicyclette, Dream Passage, and The Studio of Dalí.<br/>Although it might be speculated that Dalí produced many more prints than the “approved” ones we attribute to him today, Dal’s first prints appeared in the 1920s. His superb craftsmanship is seen in works like Head of a Young Girl and Immaculate Conception. The graphic piece Les Chants de Maldoror is among Dal’s best-known creations. The stories that separate the suites are a perfect match for the pre-surrealistic aspects of the book. A complete set of this suite is now in high demand. The majority of these early works were etchings and engravings; as Dalí’s printing skills improved, he expanded the range of his mediums and themes.<br/>The 1960s are often referred to as the “Golden Age” of Dalí’s prints. In fact, Dalí produced some of his most creative pieces during this decade. For an edition of The Divine Comedy, he finished one hundred wood block prints. This suite is regarded as a work of genius, and Dalí produced magnificent graphics to complement Virgil’s poetry. A fruitful collaboration with the American publishers Phyllis and Sidney Lucas also began throughout this decade. The Lucas’ and Dalí’s combined efforts would result in some of the most enduring Dal paintings ever. Prints like The Drawers of Memory, Fantastic Voyage, The Lucky Number of Salvador Daíi, The Studio of Dalí, and Departure of The Fishermen are examples of the prints that resulted from their collaboration. For Dalí, these were undoubtedly successful years. Over the course of this decade, Dal finished hundreds of photographs. His output was extraordinarily high. However, some of his best graphic creations remained to be seen.<br/>Dal returned to his melting clocks painting, his most well-known creation, in the 1970s. Some people believe that Dalí’s 1975 lithograph Changes In Great Masterpieces is his best creation overall. The collection consists of six images, five of which are Dalí’s interpretations of paintings by Rembrandt, Vermeer, Raphael, and Velasquez. The Persistence of Memory, Dalí’s own masterwork, is reinterpreted in the sixth picture.<br/>Together with his American publishers, Phyllis and Sidney Lucas, Mozart created this suite. Dalí updates his original piece by including a fourth melting clock. The broken clock creeps through the midst of the scene. The fourth clock, according to some, represents the fourth dimension, or time. Some people think that when Dal revised The Persistence of Memory, some 40 years after the original, he was considering his own transience and legacy and paying homage to the Dal of old.<br/>Changes in Great Masterpieces was only one of Dalí’s outstanding creations during the 1970s. In the suites Moses and Monotheism, Imagination and Objects of the Future, and Alchemy of The Philosophers, he produced some magnificent artwork. His two four-piece “puzzles,” The Rejuvenation of Time and The Puzzle of Life, are his largest lithographs. Ten Recipes of Immortality, a collection of three dimensional “pop-up” prints, is an example of how he expanded the scope of his graphic works into the third dimension. Although the 1960s may have been Dalí’s most productive decade, the 1970s appear to have been his most inventive and creative years as he explored new concepts and pushed himself even farther.<br/>In 1982, Dalí’s final prints were released. Dalí’s health had already started to deteriorate by this point, and his output had significantly decreased. However, Dalí was still able to create some excellent graphic prints despite his advanced age. Portrait of Autumn, which is bathed in gorgeous yellows, greens, and reds, is a glorification of the god Dionysus. Collectors of Dalí’s work see Chevalier Surealiste as a must-have piece, and it pays homage to one of Dalí’s heroes, Velasquez. Crucifixion is a superb example of Dalí’s artistry and a testament to his interest in Roman Catholicism.<br/>Dalí spent his entire life working as a printmaker. When evaluating his legacy, one must take into account the graphic arts creations he developed. Some of Dalí’s most artistic icons and imagery, as well as some of his best uses of his imagination, can be seen in these prints. | Salvador Dalí Biografia<br/>Le stampe di Salvador Dalí sono radicate in un ricco passato. In realtà, le stampe di Dalí hanno una storia che risale ai suoi primi anni di scuola d'arte. Al giovane Dalí è stata insegnata la bella arte dell'incisione e dell'incisione dal suo mentore. Dalí si guadagnò un rispetto per i dettagli tecnici della stampa, un rispetto che avrebbe mantenuto per il resto della sua vita. Il legame tra Dalí e le stampe grafiche è infatti intricato e prolungato. Nel corso della sua vita, Dalí ha prodotto solo circa 1.700 stampe grafiche. Un gran numero di loro sono edizioni in edizione limitata firmate a mano. Alcune sono considerate alcune delle migliori stampe create nel XX secolo.<br/>Dalí aveva la capacità di sperimentare con una vasta gamma di soggetti attraverso il suo lavoro di stampa, tra cui incisioni, incisioni, supporti misti, litografie e foto-litho. Dalí avrebbe prodotto belle suite o stampe singole. Tra le opere letterarie illustrate figurano Alice nel paese delle meraviglie, Amleto e Il vecchio e il mare. Altre volte, suite simili si sarebbero concentrate su soggetti diversi, come i fiori (FlorDal), la fantascienza (Conquest of the Cosmos) o la produzione di stampe fine (Currier e Ives). Dal ha anche prodotto stampe singole che hanno mostrato le sue impeccabili capacità di stampa. Le stampe di Dalí che sono tra i suoi migliori includono Flower Man, Symphony Bicyclette, Dream Passage e Lo studio di Dalí.<br/>Sebbene si possa ipotizzare che Dalí abbia prodotto molte più stampe di quelle "approvate" che gli attribuiamo oggi, le prime stampe di Dal apparvero negli anni '20. La sua superba artigianalità è vista in opere come Head of a Young Girl e Immaculate Conception. Il pezzo grafico Les Chants de Maldoror è tra le creazioni più conosciute di Dal. Le storie che separano le suite sono una perfetta combinazione per gli aspetti pre-surrealistici del libro. Un set completo di questa suite è ora molto richiesto. La maggior parte di questi primi lavori erano incisioni e incisioni; con il miglioramento delle capacità di stampa di Dalí, ha ampliato la gamma dei suoi mezzi e temi.<br/>Gli anni '60 sono spesso definiti l'"età dell'oro" delle stampe di Dalí. Infatti, Dalí ha prodotto alcuni dei suoi pezzi più creativi durante questo decennio. Per un'edizione di La Divina Commedia, ha finito cento stampe in blocchi di legno. Questa suite è considerata un'opera di genio, e Dalí ha prodotto magnifiche grafiche a complemento della poesia di Virgilio. Una proficua collaborazione con gli editori americani Phyllis e Sidney Lucas è iniziata anche durante questo decennio. Gli sforzi combinati di Lucas e Dalí avrebbero portato ad alcuni dei dipinti di Dal più duraturi di sempre. Stampe come The Drawers of Memory, Fantastic Voyage, The Lucky Number of Salvador Daíi, The Studio of Dalí e Departure of The Fishermen sono esempi delle stampe che sono risultate dalla loro collaborazione. Per Dalí, questi sono stati indubbiamente anni di successo. Nel corso di questo decennio, Dal ha completato centinaia di fotografie. La sua produzione è stata straordinariamente alta. Tuttavia, alcune delle sue migliori creazioni grafiche sono rimaste da vedere.<br/>Dal tornò alla sua pittura degli orologi di fusione, la sua creazione più nota, negli anni '70. Alcuni credono che la litografia del 1975 di Dalí Changes In Great Masterpieces sia la sua migliore creazione in generale. La collezione è composta da sei immagini, cinque delle quali sono interpretazioni da parte di Dalí di dipinti di Rembrandt, Vermeer, Raffaello e Velasquez. La persistenza della memoria, capolavoro di Dalí, è reinterpretata nel sesto quadro.<br/>Insieme ai suoi editori americani, Phyllis e Sidney Lucas, Mozart ha creato questa suite. Dalí aggiorna il suo pezzo originale includendo un quarto orologio a fusione. L'orologio rotto si insinua nel mezzo della scena. Il quarto orologio, secondo alcuni, rappresenta la quarta dimensione, o tempo. Alcune persone pensano che quando Dal ha rivisto La persistenza della memoria, circa 40 anni dopo l'originale, stava considerando la propria transitorietà e l'eredità e rendendo omaggio al Dal di un tempo.<br/>Cambiamenti nei grandi capolavori è stata solo una delle creazioni eccezionali di Dalí durante gli anni '70. Nelle suite Moses e Monotheism, Imagination and Objects of the Future, e Alchemy of The Philosophers, ha prodotto alcune magnifiche opere d'arte. I suoi due "puzzle" in quattro pezzi, Il Ringiovanimento del Tempo e Il Puzzle della Vita, sono le sue più grandi litografie. Dieci ricette dell'immortalità, una raccolta di stampe "pop-up" tridimensionali, è un esempio di come ha ampliato l'ambito delle sue opere grafiche nella terza dimensione. Anche se gli anni '60 possono essere stati il decennio più produttivo di Dalí, gli anni '70 sembrano essere stati i suoi anni più inventivi e creativi mentre esplorava nuovi concetti e si spingeva ancora più lontano.<br/>Nel 1982 furono pubblicate le ultime stampe di Dalí. La salute di Dalí aveva già cominciato a deteriorarsi a questo punto, e la sua produzione era diminuita significativamente. Tuttavia, Dalí era ancora in grado di creare alcune stampe grafiche eccellenti nonostante la sua età avanzata. Ritratto di Autunno, che è bagnato di splendidi gialli, verdi e rossi, è una glorificazione del dio Dioniso. I collezionisti dell'opera di Dalí vedono Chevalier Surrealiste come un pezzo da non perdere, e rende omaggio a uno degli eroi di Dalí, Velasquez. La crocifissione è un eccellente esempio dell'arte di Dalí e una testimonianza del suo interesse per il cattolicesimo romano.<br/>Dalí ha trascorso tutta la sua vita lavorando come incisore. Quando si valuta la sua eredità, si deve prendere in considerazione le creazioni di arti grafiche che ha sviluppato. Alcune delle icone e delle immagini più artistiche di Dalí, così come alcuni dei suoi migliori usi della sua immaginazione, possono essere visti in queste stampe. |
| English Language A Level<br/>&#124;Mode of study&#124;&#124;Academic A Level&#124;<br/>&#124;Campus&#124;&#124;English Bridge Campus&#124;<br/>&#124;Start date&#124;&#124;4 September 2023&#124;<br/>&#124;Course code&#124;&#124;ENG-AL (2325)&#124;<br/>A minimum of five GCSEs at grade 4 or above, including English Language and English Literature.<br/>Please note: You can study both English A level Literature and A level English Language because the courses are sufficiently distinct that there is no overlap or repetition of content. However, you cannot study A Level English Combined and A Level English Literature, or A Level English Combined and A Level English Language.<br/>What does the course involve?<br/>English is an exciting subject and we hope you’ll enjoy the lively debate and discussion. Whichever English course you choose, you’ll gain a great deal of academic prowess and the development of transferable skills.<br/>You will be taught to think analytically, synthesise information, and develop communication skills that are a prerequisite for a wide range of career paths.<br/>The important skill of learning to write coherently and critically will aid you in your other subjects and is invaluable in higher education.<br/>Language is one of the key features that define us as human beings and, on this course, you will explore how it works: how we learn language from infancy, how we use it as a social tool, and how it has evolved over time. You will learn about the origins of English, the various forms it has taken over the centuries, how it has spread across the globe and what it might look like in the future.<br/>You will also study the research of theorists in areas of language such as speech and gender, accents and dialects, and the language of technology. You will learn about grammar in order to explore the ways writers use language to communicate meaning in texts ranging from blogs to 17th-century journalism.<br/>The NEA (coursework) unit will allow you to write creatively and to undertake an investigation into an aspect of the course you have enjoyed.<br/>How is the course assessed?<br/>80% Exam and 20% Coursework. Two coursework tasks and two externally-assessed exams.<br/>This A Level will equip you with the necessary skills to go into practical professions such as journalism and creative writing as well as academic degrees such as law and media studies. It forms a good companion to A Levels in Psychology and Sociology because there is a degree of crossover with the social sciences. If you are thinking of studying English at university, it is perfectly acceptable to take both English Language and English Literature. English can be combined with a range of other subjects at university.<br/>English provides an excellent foundation for various Higher Education courses including law, medicine, English, linguistics and education. It can be combined with a range of other subjects at university. English offers increasing employability in a range of career areas, especially those that require developed communication skills. Students have gone on to careers in law, health and medicine, commerce and industry, marketing, politics and international relations, general management, as well as leading to more predictable areas like journalism, publishing, the media, education, theatre and public relations.<br/>The student magazine produced by students is part of the enrichment opportunities led by the English Department. Trips include theatre trips to London, Manchester and Stratford-upon-Avon and international trips include a visit to battlefields in France, university taster days, residentials and creative writing workshops. These are all optional but highly recommended. Aspiring Oxford and Cambridge applicants will benefit from our extensive range of activities to support you in making a competitive application including: small group subject tuition, Oxford and Cambridge conferences, visits and contacts with our link staff, access to summer schools, application support and essay competitions, supra-curricular activities and access to free university-level Massive Open Online Courses (MOOC).<br/>What do I do next?<br/>You can apply online via the APPLY NOW button and then add an additional two or three subjects to make up your academic programme. You can also apply for a second, alternative vocational programme of study via a separate application. If after reading this factsheet, you are still undecided about the course most suitable for you, please drop in to one of our Open Evenings, ring Admissions on 01743 260401 or email email@example.com<br/>A Level English Language (Law and Drama & Theatre)<br/>Previous school: Mary Webb School<br/>I came here because it was local to me and I enjoyed the pre-enrolment days which were well organised. English Language is a good A Level to have and it is super interesting to see how language has evolved and changed through time. The teachers are a great help and the resources are brilliant; there are plenty of text books.<br/>Are you an employer?<br/>See how an apprentice can help your business. | Lingua inglese A Level<br/>&#124;Modalità di studio&#124;&#124;Academic A Level&#124;<br/>&#124;Campus&#124;&#124;Campus del ponte inglese&#124;<br/>&#124;Data di inizio&#124;&#124;4 settembre 2023&#124;<br/>&#124;Codice corso&#124;&#124;ENG-AL (2325)&#124;<br/>Un minimo di cinque GCSE al grado 4 o superiore, tra cui lingua inglese e letteratura inglese.<br/>Si prega di notare: È possibile studiare sia letteratura inglese A livello e un livello di lingua inglese perché i corsi sono sufficientemente distinti che non vi è alcuna sovrapposizione o ripetizione di contenuti. Tuttavia, non è possibile studiare un livello di inglese combinato e un livello di letteratura inglese, o un livello di inglese combinato e un livello di lingua inglese.<br/>Cosa comporta il corso?<br/>L'inglese è un argomento eccitante e speriamo che ti piaccia il vivace dibattito e la discussione. Qualunque corso di inglese tu scelga, guadagnerai un sacco di abilità accademiche e lo sviluppo di abilità trasferibili.<br/>Ti verrà insegnato a pensare analiticamente, sintetizzare informazioni e sviluppare abilità di comunicazione che sono un prerequisito per una vasta gamma di percorsi di carriera.<br/>L'importante abilità di imparare a scrivere in modo coerente e critico ti aiuterà nelle tue altre materie ed è inestimabile nell'istruzione superiore.<br/>Il linguaggio è una delle caratteristiche chiave che ci definiscono come esseri umani e, in questo corso, esplorerai come funziona: come impariamo il linguaggio dall'infanzia, come lo usiamo come strumento sociale e come si è evoluto nel tempo. Imparerai le origini dell'inglese, le varie forme che ha assunto nel corso dei secoli, come si è diffuso in tutto il mondo e come potrebbe apparire in futuro.<br/>Studierai anche la ricerca dei teorici in aree del linguaggio come discorso e genere, accenti e dialetti e il linguaggio della tecnologia. Imparerai la grammatica al fine di esplorare i modi in cui gli scrittori usano il linguaggio per comunicare il significato in testi che vanno dai blog al giornalismo del XVII secolo.<br/>L'unità NEA (corso) ti permetterà di scrivere in modo creativo e di intraprendere un'indagine su un aspetto del corso che ti è piaciuto.<br/>Come viene valutato il corso?<br/>80% Esame e 20% Corso. Due compiti di corso e due esami valutati esternamente.<br/>Questo livello A ti fornirà le competenze necessarie per entrare in professioni pratiche come il giornalismo e la scrittura creativa, nonché gradi accademici come studi legali e media. Forma un buon compagno per A Levels in Psicologia e Sociologia perché c'è un certo grado di crossover con le scienze sociali. Se stai pensando di studiare l'inglese all'università, è perfettamente accettabile prendere sia la lingua inglese che la letteratura inglese. L'inglese può essere combinato con una serie di altre materie all'università.<br/>L'inglese fornisce un'eccellente base per vari corsi di istruzione superiore, tra cui legge, medicina, inglese, linguistica e istruzione. Può essere combinato con una serie di altre materie presso l'università. L'inglese offre una maggiore occupabilità in una serie di aree di carriera, in particolare quelle che richiedono competenze di comunicazione sviluppate. Gli studenti hanno proseguito le carriere nel diritto, la salute e la medicina, il commercio e l'industria, il marketing, la politica e le relazioni internazionali, la gestione generale, oltre a condurre a settori più prevedibili come il giornalismo, l'editoria, i media, l'istruzione, il teatro e le relazioni pubbliche.<br/>La rivista studentesca prodotta dagli studenti fa parte delle opportunità di arricchimento guidate dal Dipartimento di inglese. I viaggi includono gite teatrali a Londra, Manchester e Stratford-upon-Avon e viaggi internazionali includono una visita ai campi di battaglia in Francia, giornate di degustazione universitarie, residenziali e laboratori di scrittura creativa. Questi sono tutti facoltativi ma altamente raccomandati. Gli aspiranti candidati di Oxford e Cambridge beneficeranno della nostra vasta gamma di attività per supportarti nella presentazione di una domanda competitiva, tra cui: lezioni in piccoli gruppi, conferenze di Oxford e Cambridge, visite e contatti con il nostro staff di collegamento, accesso alle scuole estive, supporto alle domande e concorsi di saggio, attività supra-curriculari e accesso a corsi online massicci gratuiti a livello universitario (MOOC).<br/>Cosa devo fare dopo?<br/>Puoi applicare online tramite il pulsante APPLICARE ORA e quindi aggiungere ulteriori due o tre materie per comporre il tuo programma accademico. Puoi anche applicare per un secondo programma di studio professionale alternativo tramite una domanda separata. Se dopo aver letto questa scheda, sei ancora indeciso sul corso più adatto a te, ti preghiamo di iscriverti a una delle nostre Serate Aperte, chiamare Ammissioni al numero 01743 260401 o e-mail email@example.com<br/>Un livello di lingua inglese (legge e dramma e teatro)<br/>Scuola precedente: Mary Webb School<br/>Sono venuto qui perché era locale per me e mi sono goduto i giorni di pre-iscrizione che erano ben organizzati. La lingua inglese è un buon A Level da avere ed è super interessante vedere come la lingua si è evoluta e cambiata nel tempo. Gli insegnanti sono di grande aiuto e le risorse sono brillanti; ci sono un sacco di libri di testo.<br/>Sei un datore di lavoro?<br/>Scopri come un apprendista può aiutare il tuo business. |
| In a subproject carried out together with the City of Stockholm within the HazardSupport research project, SMHI has investigated how town planning affects a city’s climate. Scenarios have been produced for Stockholm’s growth up until 2030 and 2050, using summer 2014 as a reference point. These scenarios do not take ongoing climate change into account. Instead, they simply show how the densification and growth of Stockholm can be expected to affect the air temperature.<br/>The main conclusion from the scenarios is that the impact of densification on air temperature is relatively local. No significant effect on the average temperature during the summer is seen at a distance of more than about 2 km, despite extensive densification across large areas. This can be seen in the most central parts of Stockholm, for example, which are already built-up and where no significant reduction in green spaces can therefore be expected. No significant change in air temperature is seen in these areas.<br/>One reason why the densification and expansion of Stockholm has not had any significant impact on air temperature is the relatively rapid air exchange with nearby expanses of water and countryside. Within those areas that are densifying, average summer temperature increases of up to around 1.5°C are being seen. As expected, the biggest temperature increases are observed when natural environments or green areas are built on.<br/>Measures in the local area<br/>One consequence of the locally limited effect of changes in the urban environment is that measures should primarily be focused on direct effects within the local area. Examples of such measures include shady street trees and proximity to green spaces. For the same reason, measures such as green roofs that only indirectly affect the air temperature in the street environment can be expected to have a less significant impact.<br/>A comfort index can be used to summarise the effect of various climate parameters. One example of such an index is the Universal Thermal Climate Index (UTCI). This involves a higher level of ambition in relation to how climate planning is often carried out in today’s planning processes. | In un sottoprogetto realizzato in collaborazione con la città di Stoccolma nell'ambito del progetto di ricerca HazardSupport, SMHI ha studiato come la pianificazione urbana influisce sul clima di una città. Sono stati elaborati scenari per la crescita di Stoccolma fino al 2030 e al 2050, utilizzando l'estate 2014 come punto di riferimento. Questi scenari non tengono conto dei cambiamenti climatici in corso. Invece, mostrano semplicemente come la densificazione e la crescita di Stoccolma possano influenzare la temperatura dell'aria.<br/>La conclusione principale degli scenari è che l'impatto della densificazione sulla temperatura dell'aria è relativamente locale. Nessun effetto significativo sulla temperatura media durante l'estate è visto a una distanza di oltre 2 km, nonostante l'estesa densificazione in grandi aree. Questo si può vedere nelle parti più centrali di Stoccolma, ad esempio, che sono già costruite e dove non ci si può quindi aspettare una riduzione significativa degli spazi verdi.<br/>Uno dei motivi per cui la densificazione e l'espansione di Stoccolma non hanno avuto un impatto significativo sulla temperatura dell'aria è lo scambio d'aria relativamente rapido con le vicine distese d'acqua e la campagna. All'interno di quelle aree che sono densificanti, si vedono aumenti di temperatura estiva media fino a circa 1,5 ° C. Come previsto, i maggiori aumenti di temperatura si osservano quando si costruiscono ambienti naturali o aree verdi.<br/>Misure a livello locale<br/>Una conseguenza dell'effetto locale limitato dei cambiamenti nell'ambiente urbano è che le misure dovrebbero concentrarsi principalmente sugli effetti diretti all'interno dell'area locale. Esempi di tali misure includono alberi di strada ombreggiati e la vicinanza agli spazi verdi. Per lo stesso motivo, misure come i tetti verdi che influenzano solo indirettamente la temperatura dell'aria nell'ambiente stradale possono avere un impatto meno significativo.<br/>Un indice di comfort può essere utilizzato per riassumere l'effetto di vari parametri climatici. Un esempio di tale indice è l'indice universale del clima termico (UTCI). Ciò comporta un livello più elevato di ambizione in relazione al modo in cui la pianificazione climatica viene spesso eseguita nei processi di pianificazione odierni. |
