NOTE: singularity_wrapper should not be needed with the current installation as
all commands have been wrapped.

| original | translation |
|----------|-------------|
| Artificial intelligence (AI), the computerized capability of doing tasks, which until recently was thought to be the exclusive domain of human intelligence, has demonstrated great strides in the past decade. The abilities to play games, provide piloting for an automobile, and respond to spoken language are remarkable successes. How are the challenges and opportunities of medicine different from these challenges and how can we best apply these data-driven techniques to patient care and outcomes? A New England Journal of Medicine paper published in 1980 suggested that more well-defined “specialized” tasks of medical care were more amenable to computer assistance, while the breadth of approach required for defining a problem and narrowing down the problem space was less so, and perhaps, unachievable. On the other hand, one can argue that the modern version of AI, which uses data-driven approaches, will be the most useful in tackling tasks such as outcome prediction that are often difficult for clinicians and patients. The ability today to collect large volumes of data about a single individual (eg, through a wearable device) and the accumulation of large datasets about multiple persons receiving medical care has the potential to apply to the care of individuals. As these techniques of analysis, enumeration, aggregation, and presentation are brought to bear in medicine, the question arises as to their utility and applicability in that domain. Early efforts in decision support were found to be helpful; as the systems proliferated, later experiences have shown difficulties such as alert fatigue and physician burnout becoming more prevalent. Will something similar arise from data-driven predictions? Will empowering patients by equipping them with information gained from data analysis help? Patients, providers, technology, and policymakers each have a role to play in the development and utilization of AI in medicine. Some of the challenges, opportunities, and tradeoffs implicit here are presented as a dialog between a clinician (SJN) and an informatician (QZT).J Med Internet Res 2019;21(11):e16272<br/>Drs Nelson and Zeng-Treitler work together at the Biomedical Informatics Center at George Washington University. In the following we present a hypothetical dialogue which grew out of discussions they had as they considered their differing viewpoints of how artificial intelligence (AI) has developed and where it is going. While Dr Zeng-Treitler’s view of the future of AI is highly optimistic, Dr Nelson's opinion is more cautious. Dr Nelson was a practicing academic internist who became involved in informatics many years ago. He collaborated with Scott Blois on RECONSIDER (an early clinical decision support system) and on the Unified Medical Language System (UMLS) project. He eventually moved to the National Library of Medicine as Head of Medical Subject Headings. While at the National Library of Medicine, he fathered RxNorm, while continuing his work on UMLS and projects involving UMLS. Dr Zeng-Treitler has a background in computer science and obtained her PhD in medical informatics from Columbia University. She has led a number of projects in clinical data mining, natural language processing, and consumer health informatics. During the past few years, her team has been actively investigating the use of AI techniques in clinical research including development of a novel explainable deep learning approach.<br/>Dr Zeng-Treitler (The "Optimist"):<br/>After decades of promises and disappointment, thanks to the seemingly unbounded computing resources and novel, data-driven methods, AI technology has finally arrived. From Jeopardy and Siri to face identification and autonomous vehicles, data-driven approaches have made the leap from laboratory experiments to applications that are transforming our lives outside health care. In some cases, these approaches have come close to passing the Turing Test—a test of a machine’s ability to exhibit supposed human-like intelligence; machines can now perform some complex tasks such as image recognition and authentic game play as well as or better than humans would. Some would argue that the requisite approach is decidedly nonhuman. However, whatever the means to achieving these innovations, such successes have not been followed by analogous successes in health care.<br/>One dramatic example of this disparity of accomplishment is AlphaZero, a computer game engine that mastered chess, Shogi, and Go. Even before the arrival of the current generation of data-driven artifacts, chess engines have been shown to be able to play at a level superior to that of chess champions. Players of Go (a board game that is thought to be much more complex than chess), however, believed that computers were no match for high-level professionals in this game. This belief was shattered first by AlphaGo, which soundly defeated the reigning world champion of Go. Then came AlphaZero. The news is no longer that such approaches can beat the champions of Go, chess, or Shogi. Rather, the remarkable fact is that AlphaZero did not learn from human experiences and that it defeated the best prior chess engines such as Stockfish. AlphaZero triumphed by playing more games against itself than had ever been played by all human players. This is not an approach we could readily duplicate in health care.<br/>Dr Nelson (The "Cautious" One):<br/>Is winning a game, with defined rules and objectives, really the best test of human intelligence? In hindsight, the answer is “No.” For example, sophisticated chess playing programs have existed for nearly 50 years; from such programs, we learned how to organize computing resources to apply simple algorithms in a scalable way. Put differently, we did not learn anything about chess or how humans, even experts, play it. Instead, we learned that a supposed intelligence-requiring task was susceptible to a computational approach. We need to ask where and how such an approach is applicable in health care.<br/>For example, when doing tasks that are generally thought to be human and creative, can the machine recognize when it is out of its depth? Sometimes, humans have the ability to do so. However, if we can define the realm closely enough, I agree that the machines can do wonders. So, how do we define the realm?<br/>In Blois’ seminal paper on Clinical Judgment and Computers , he described the world of a physician’s thought process when seeing a patient, with the diagram shown in . Point A for a physician would be where the patient walks in the door to be seen for the first time. The nature of the complaint, the context in which the complaint occurs, and all of the myriad possibilities are present. As the problem definition moves toward Point B, a computer is better able to manage the information and knowledge necessary for high-quality care. One way in which we can think about defining the realm is that we are moving toward Point B. Some computer scientists have argued that Point A is just about managing facts, but, as Blois observed, it is more about relevance—something that has proven difficult to replicate computationally.<br/>It is indeed important to define the realm for an AI application. Many tasks in health care are much more complex than game play, and we have not witnessed the triumphs of analogous approaches in the biomedical domain as have been achieved in game play. Quite a few studies have been applying the latest deep learning technology (a key AI method) to biomedical datasets [- ]. The specific applications included image processing, natural language processing, and risk prediction. Deep learning, compared with traditional statistical and machine learning methods, has often shown modest improvements rather than breakthroughs [ - ].<br/>Whatever the details of these approaches, they apply nearly unbounded computing resources to very large amounts of data, something that has yet to happen in health care. Therefore, these approaches might prove helpful, but we do not know for sure yet.<br/>For example, a simple question posed by a colleague is beyond our current capabilities: Given a patient who starts out with a feature of metabolic syndrome, which feature of the syndrome will he or she tend to exhibit next? Simplistically, this is exactly the kind of challenge that a data-driven approach should help with, and yet, it is currently “over the horizon” due to the insufficient data that were collected in the past.<br/>Data are a key challenge when applying data-driven approaches to patient care. To begin with, biomedical data are highly complex. There many different types of data including image, text, numerical values, categorical classifications, and DNA sequences, representing tens of thousands of lab tests, procedures, diagnoses, medications, genetic markers, etc. Each data type also has its own characteristics; for example, a laboratory test value may need to be interpreted in the context of age, gender, and current conditions. However, diagnostic codes for different diseases have varying levels of accuracies.<br/>In biomedical data analysis, there is also the paradox of having too much and not enough data at the same time. On one hand, there are a tremendous amount of medical record, social media, and literature data. Efforts like the Million Veterans Project  have also collected a huge amount of DNA data. Using devices for tasks like activity tracking and continuous glucose monitoring generates more data than our current medical record systems can digest. On the other hand, the health record of a patient is an open system with much missing information in contrast with the closed system of a chess or Go game, where all data are available. Patients are observed at irregular intervals (eg, at clinic visits or during hospitalization) and are never subjected to all possible tests or treatments. Sometimes, death is the only definitive outcome.<br/>I agree that data types are multiple and complex. Simple solutions are insufficient, and the proliferation of irrelevant data in a record, not to mention the current cut-and-paste or fill-in-the-template fad, obscures what is important.<br/>One of the major difficulties with medical data is not just that it is not enough, but also that it is theory laden, that is, very few pieces of data are recorded routinely. A lot of data in observations are gathered only when the clinician has thought it is appropriate, that is, when diseases are tested for their absence or presence. If there is no reason to do the test, the test is not performed. Only a few tests are ever performed routinely; a transcribed set of physical observations (as is done in physical examination) is rarely recorded in enough detail (not to mention the failure to observe, which often occurs) to provide sufficient data for a more comprehensive analysis. For that reason alone, studies based on the recorded observations are often incomplete and potentially misleading. However, for predictions, observations not made may be the critical ones. Think about the patient with metabolic syndrome mentioned above. What data are we missing?<br/>Similarly, the results of clinical trials are not a complete picture. Even though participants have been selected, often excluding many individuals because of complicating conditions, the data collected on the participants are designed for testing certain hypotheses, with narrowly defined outcomes. A common criticism is that such trials are so artificial that they are irrelevant.<br/>The lack of integrated and standardized datasets is another issue. Although we can find many large datasets, they are often incomplete and difficult to link to other information. For example, environmental exposure, diet, physical activity, and genetic profile are among the common missing pieces of information when we examine the records about an individual patient. Detailed clinical trial datasets tend to lack long-term follow-up. Privacy issues and monetary incentives are also obstacles in data integration efforts.<br/>Real semantic interoperability to integrate and standardize datasets requires support in both terminology and how that terminology is used. Currently, human intervention is often required to interpret what one system is saying for use in another system. This situation is unfortunate; we can hope that over time, the necessary connections will take place (think of how the United States went from operator assistance on every telephone call to the automatic switching that takes place today). Such a change can only happen when many people see the need for and implement a common standard.<br/>In addition, the notion of “large” in the context of health care data is only relative. Think, instead, of many experiments undertaken by Google; if they desire, the amount of data that can be used to develop and test a model is orders of magnitude greater than that available in health care.<br/>In the domains where data-driven approaches have demonstrated success, there are outcomes that can be judged by human experts or machines themselves. For example, bilingual speakers can tell if natural language translation is working well, and the outcome of board or computer games can be easily determined. This allows easier simulation or annotation of data for machine learning. Such a task is much harder in the biomedical domains; investigation of causes or treatments of diseases in humans involve costly and long-term studies. In some cases, ethical concerns prohibit the experiments; for example, the introduction of potentially harmful genetic mutations into healthy human subjects is out of the question. We lack long-term outcome data for many treatments.<br/>I am not sure that there ever will be such a gold standard without a completely arbitrary definition. Variation between individuals is also a major obstacle. Although we perform studies using multiple subjects to account for biologic variability, our results are only approximate in their relevance to a given individual. For example, assuring genetic diversity in clinical trials is challenging, to say the least. Even the simplest tasks can be staggeringly multifactorial; for example, the information content of genetic testing for warfarin metabolism can be outweighed by whether the patient had lettuce for lunch.<br/>To expand on this observation, suppose you have an automobile that is not working appropriately. Today, you consult the sensors and the computer readout to give you very precise information about what is going wrong. The automobile has a specific design, with specific parameters that can be measured. All of the vehicles of the same year make and model can be assumed to be alike in those important aspects. It is important to realize that every human (with the exception of identical twins) is genetically unique. In that way, people are very different from automobiles or other mechanical devices. To compound the complexity with which the cause of a human problem can be addressed, what the individual experiences throughout their life is unique. Although we have nice abstractions or methods of identifying individuals who share some common characteristics (whether the presence or absence of a disease, the response or lack thereof to a medication, the similar environment, or other considerations), these are only a shorthand notation. With 7 billion persons currently living in this world, the problem appears almost open-ended. Too often in data analysis, we look at diagnostic codes as having a deep meaning. These are accepted without any recognition of the degree of uncertainty of the diagnosis. All our data may be helpful and useful, but we need to continue to view them with a large grain of salt. The fact that Google Translate works as well as it does gives us hope, but as complex as natural language translation is, it is simpler than some clinical tasks.<br/>Despite these challenges, applying data-driven approaches has the potential to transform health care. Today’s health care is labor intensive, from scheduling and triage to diagnosis and treatment. Many tasks currently undertaken by humans can be carried out by intelligent software solutions supported by sufficient data. For instance, improved voice recognition and summarization technology might help reduce the amount of time patients and clinicians spend on paperwork. Improved decision support tools ought to be able to help patients decide about the appropriateness of seeking care. An accurate assessment of short- and long-term risks and benefits will inform treatment selection and lifestyle changes.<br/>To provide another use case, there is evidence that type II diabetes may be reversible, but it is hard to apply this knowledge to an individual patient. Given the patient in front of me, what should I do, or recommend, and with what expectation? Demographics, genomics, comorbidities, psyche, competing risks, and other medications, all play a role. How, in a given person, do I reconcile all the possibilities?<br/>To develop these useful AI tools, we need better data, technology, and policy. To accumulate comprehensive, life-time data, patients must be in control and should be incentivized to share their data for research and care. Insurance, pharmaceutical, and medical institutions change over time. Currently, there are barriers for individuals to be the center of collecting the data on themselves. The barriers are present in data entry, collection, and storage; for example, some personalized health record products are tethered to an institution, while others require extensive transcribing efforts by patients or caregivers. Nevertheless, without patient consent and collaboration, gathering and linking longitudinal environmental, genetic, clinical, and behavioral data are neither feasible nor ethical. The current conditions are a huge barrier to any attempt to use data-driven approaches that have worked outside health care.<br/>Efforts including PatienstLikeMe  and the All of Us Research Project of the National Institutes of Health [ ] are examples of innovative approaches to curate bigger and better datasets. Most patients, however, are not engaged in such efforts. Patients are inherently motivated to improve their own health, but naturally have concerns regarding privacy and often do not see immediate benefits of participating in long-term studies. Appropriate incentives (eg, discounts for routine preventive care) coupled with security and authentication technologies are needed to entice a large and diverse population of patients to gather and share their data. The health care industry today owns parts of patient data and has limited motivation to purchase data from their customers. As the value of data increases, patients will become more valued as a partner.<br/>I agree that patients will need to assume the responsibility of carrying and sharing the information about themselves. However, experience tells us that not everyone is able or willing to do so. It will need cultural and political climate changes to encourage that development.<br/>When we can collect data that are not directly what the philosophers would call “theory-laden,” we may be able to refine our crude methods of patient diagnosis and care. I look forward to that day. If patients are the carrier of those data, it will be easier to obtain and use for analysis.<br/>We also need to design and implement methods specifically for handling very large and “messy” clinical data. For example, we need to understand the context of missing data and errors to get a better picture of ground truth. A lab result may be missed because there is no indication for it, practice preference, an alternative method of assessing, or a failure of data entry. Imagine how much more difficult a chess game will be, if a human player or a chess engine could only observe some squares on the board at irregular time intervals with some error or distortion of the observation.<br/>Further, we do not have an operational definition of “ground truth” in health care; a simple proposal is that one feature of ground truth is that it has predictive value—something that will be valued by clinicians and patients alike.<br/>Google has demonstrated that they can use lots of data to predict likely values for missing data in other areas ; however, it is yet to be determined whether this might work in medicine, but it is probably worth a trial. Irrespective of whether we can use large volumes of data to impute missing values, exploring how to handle the problem of absent observations is crucial, especially whenever we try to apply the results of data-driven approaches to individual patients.<br/>Another thought is that data that are missing, for any reason, are an observation in itself; the fact that the data were not obtained and recorded may be important. Think of the finding that the day and time of a test were more predictive of outcome than the result of the test . We know that the data that are missing will have some predictive value.<br/>On a different note, explanation of the data-driven models is critical to not only their adoption but also their impact . Predicting that a patient will have certain adverse events in the next several days or years is desirable. It may be argued that it is even more important to know the modifiable factors that can reduce risk and enhance outcome. Since deep learning models can be highly nonlinear, we have the opportunity to discover novel and complex patterns.<br/>I agree that explaining the prediction is critical; it is something that separates health care from, say, recognizing whether an image is a dog or a cat. However, I think you meant to say predicting a patient will probably have some adverse outcome. Nothing in life is certain except that it will end. However, we can say “it appears this behavior or finding will likely have an effect on your future” and hopefully be able to express some degree of confidence in that prediction.<br/>Learning how to express the confidence in a prediction is also important. How many folks really understand the statistics behind the predictions that occur today? What are the underlying assumptions behind any probabilistic model? It is more likely that with more frequent use and familiarity with the use of measures derived for AI models will lead to their acceptance.<br/>I agree. These are all steps to be taken in order to optimize the use of big data through AI to improve medical care.<br/>As a parting thought, we need to be cautious about how intrusive data-driven approaches might be in the care process. Although McDonald  demonstrated that performance in care improves with reminders [ ], the later experience has been one of too many reminders, leading to alert fatigue. When caregivers choose to override and ignore helpful information because of overload, have we accomplished anything?<br/>I hope that careful design of systems and consideration of clinical workflow will alleviate the problem of excessive intrusiveness. Although it is tempting to just “let AI do it,” the recent experiences with the Boeing 737 MAX demonstrate that there is danger in doing so. Neither AI nor a pilot alone is the optimal strategy in flying. In health care, involving patients more extensively in their care, together with AI and providers, may ultimately be an approach that works.<br/>Conflicts of Interest<br/>- Blois MS. Clinical Judgment and Computers. N Engl J Med 1980 Jul 24;303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Deep learning for healthcare: review, opportunities and challenges. Brief Bioinform 2018 Nov 27;19(6):1236-1246 [FREE Full text] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. Can machine-learning improve cardiovascular risk prediction using routine clinical data? PLoS ONE 2017 Apr 4;12(4):e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT. Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records. Sci Rep 2016 May 17;6(1):26094 [FREE Full text] [CrossRef] [Medline]<br/>- Quach K. The register. 2019. IBM Watson Health cuts back drug discovery 'artificial intelligence' after lackluster sales URL: https://www.theregister.co.uk/2019/04/18/ibm_watson_health [accessed 2019-10-23]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Scalable and accurate deep learning with electronic health records. NPJ Digit Med 2018 May 8;1(1):18 [FREE Full text] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, et al. Deep Learning in Medical Imaging: General Overview. Korean J Radiol 2017;18(4):570. [CrossRef]<br/>- U.S Department of Veterans Affairs. Million Veteran Program (MVP) URL: https://www.research.va.gov/mvp/ [accessed 2019-10-23]<br/>- Patientslikeme. URL: https://www.patientslikeme.com [accessed 2019-10-23]<br/>- All of Us Research Program. URL: https://allofus.nih.gov [accessed 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. The unreasonable effectiveness of data. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Biases in electronic health record data due to processes within the healthcare system: retrospective observational study. BMJ 2018 Apr 30:k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, Müller H. Causability and explainabilty of artificial intelligence in medicine. WIREs Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Protocol-Based Computer Reminders, the Quality of Care and the Non-Perfectibility of Man. N Engl J Med 1976 Dec 09;295(24):1351-1355. [CrossRef]<br/>&#124;AI: artificial intelligence&#124;<br/>&#124;UMLS: Unified Medical Language System&#124;<br/>Edited by G Eysenbach; submitted 15.09.19; peer-reviewed by A Holzinger; comments to author 14.10.19; revised version received 15.10.19; accepted 20.10.19; published 27.11.19Copyright<br/>©Qing Zeng-Treitler, Stuart J Nelson. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included. | Künstliche Intelligenz (KI), die computergestützte Fähigkeit, Aufgaben zu erledigen, die bis vor kurzem als ausschließliche Domäne der menschlichen Intelligenz galt, hat in den letzten zehn Jahren große Fortschritte gemacht. Die fähigkeiten, spiele zu spielen, für ein auto zu steuern und auf gesprochene sprache zu reagieren, sind bemerkenswerte erfolge. Wie unterscheiden sich die Herausforderungen und Chancen der Medizin von diesen Herausforderungen und wie können wir diese datengesteuerten Techniken am besten auf die Patientenversorgung und die Ergebnisse anwenden? Ein 1980 veröffentlichtes Papier des New England Journal of Medicine deutete darauf hin, dass wohldefiniertere "spezialisierte" Aufgaben der medizinischen Versorgung für die Computerunterstützung zugänglicher waren, während die Breite des Ansatzes, der für die Definition eines Problems und die Verengung des Problemraums erforderlich war, weniger und vielleicht unerreichbar war. Auf der anderen Seite kann man argumentieren, dass die moderne Version der KI, die datengesteuerte Ansätze verwendet, am nützlichsten ist, um Aufgaben wie die Vorhersage von Ergebnissen anzugehen, die für Kliniker und Patienten oft schwierig sind. Die Fähigkeit, heute große Datenmengen über eine einzelne Person zu sammeln (z. B. durch ein tragbares Gerät) und die Anhäufung großer Datensätze über mehrere Personen, die medizinische Versorgung erhalten, hat das Potenzial, sich auf die Betreuung von Personen zu bewerben. Da diese Techniken der Analyse, Aufzählung, Aggregation und Präsentation in der Medizin zum Tragen kommen, stellt sich die Frage nach ihrem Nutzen und ihrer Anwendbarkeit in diesem Bereich. Frühe Bemühungen bei der Entscheidungsunterstützung erwiesen sich als hilfreich; Da sich die Systeme vermehrten, haben spätere Erfahrungen gezeigt, dass Schwierigkeiten wie Alarmmüdigkeit und Arzt-Burnout immer häufiger auftreten. Wird etwas Ähnliches aus datengesteuerten Vorhersagen entstehen? Wird es den Patienten helfen, indem sie sie mit Informationen aus der Datenanalyse ausstatten? Patienten, Anbieter, Technologie und politische Entscheidungsträger spielen jeweils eine Rolle bei der Entwicklung und Nutzung von KI in der Medizin. Einige der hier impliziten Herausforderungen, Chancen und Kompromisse werden als Dialog zwischen einem Kliniker (SJN) und einem Informatiker (QZT) dargestellt. J Med Internet Res 2019;21(11):e16272<br/>Dr. Nelson und Zeng-Treitler arbeiten am Biomedical Informatics Center der George Washington University zusammen. Im Folgenden stellen wir einen hypothetischen Dialog vor, der aus Diskussionen entstand, die sie hatten, als sie ihre unterschiedlichen Sichtweisen darüber betrachteten, wie sich künstliche Intelligenz (KI) entwickelt hat und wohin sie geht. Während Dr. Zeng-Treitlers Sicht auf die Zukunft der KI sehr optimistisch ist, ist Dr. Nelsons Meinung vorsichtiger. Dr. Nelson war ein praktizierender akademischer Internist, der vor vielen Jahren in der Informatik tätig wurde. Er arbeitete mit Scott Blois an RECONSIDER (einem frühen klinischen Entscheidungsunterstützungssystem) und am Projekt Unified Medical Language System (UMLS) zusammen und wechselte schließlich als Leiter der medizinischen Fachüberschriften in die National Library of Medicine. Während an der National Library of Medicine, er gezeugt RxNorm, während seine Arbeit an UMLS und Projekte mit UMLS. Dr Zeng-Treitler hat einen Hintergrund in der Informatik und erhielt ihren PhD in medizinischer Informatik von der Columbia University. Sie hat eine Reihe von Projekten in den Bereichen klinisches Data Mining, Natural Language Processing und Consumer Health Informatics geleitet. In den letzten Jahren hat ihr Team aktiv den Einsatz von KI-Techniken in der klinischen Forschung untersucht, einschließlich der Entwicklung eines neuartigen erklärbaren Deep-Learning-Ansatzes.<br/>Dr. Zeng-Treitler (Der Optimist):<br/>Nach Jahrzehnten der Versprechungen und Enttäuschungen, dank der scheinbar unbegrenzten Rechenressourcen und neuartigen, datengesteuerten Methoden, ist die KI-Technologie endlich angekommen. Von Jeopardy und Siri bis hin zu Identifikations- und autonomen Fahrzeugen haben datengesteuerte Ansätze den Sprung von Laborexperimenten zu Anwendungen geschafft, die unser Leben außerhalb des Gesundheitswesens verändern. In einigen Fällen sind diese Ansätze dem Bestehen des Turing-Tests nahe gekommen - ein Test der Fähigkeit einer Maschine, angebliche menschenähnliche Intelligenz auszustellen; Maschinen können jetzt einige komplexe Aufgaben wie Bilderkennung und authentisches Spiel so gut oder besser ausführen als Menschen. Einige würden argumentieren, dass der erforderliche Ansatz eindeutig nicht menschlich ist. Unabhängig von den Mitteln, um diese Innovationen zu erreichen, wurden solche Erfolge jedoch nicht von analogen Erfolgen in der Gesundheitsversorgung gefolgt.<br/>Ein dramatisches Beispiel für diese Ungleichheit der Leistung ist AlphaZero, eine Computerspiel-Engine, die Schach, Shogi und Go beherrscht. Schon vor der Ankunft der aktuellen Generation von datengesteuerten Artefakten haben Schach-Engines gezeigt, dass sie in der Lage sind, auf einem Niveau zu spielen, das dem von Schachchampions überlegen ist. Spieler von Go (ein Brettspiel, von dem angenommen wird, dass es viel komplexer ist als Schach), glaubten jedoch, dass Computer für hochrangige Profis in diesem Spiel nicht geeignet waren. Dieser Glaube wurde zuerst von AlphaGo erschüttert, das den amtierenden Weltmeister von Go solide besiegte. Dann kam AlphaZero. Die Nachricht ist nicht mehr, dass solche Ansätze die Champions von Go, Schach oder Shogi schlagen können. Vielmehr ist die bemerkenswerte Tatsache, dass AlphaZero nicht aus menschlichen Erfahrungen gelernt hat und dass es die besten vorherigen Schach-Engines wie Stockfish besiegt hat. AlphaZero triumphierte, indem es mehr Spiele gegen sich selbst spielte, als jemals von allen menschlichen Spielern gespielt worden waren. Dies ist kein Ansatz, den wir leicht in der Gesundheitsversorgung duplizieren könnten.<br/>Dr. Nelson (der „Schöne“)<br/>Ist der Gewinn eines Spiels mit definierten Regeln und Zielen wirklich der beste Test für menschliche Intelligenz? Im Nachhinein ist die Antwort "Nein". Zum Beispiel gibt es seit fast 50 Jahren ausgeklügelte Schachspielprogramme; aus solchen Programmen haben wir gelernt, wie man Computerressourcen organisiert, um einfache Algorithmen skalierbar anzuwenden. Anders gesagt, wir haben nichts über Schach gelernt oder wie Menschen, sogar Experten, es spielen. Stattdessen haben wir gelernt, dass eine angebliche Intelligenz erfordernde Aufgabe anfällig für einen rechnerischen Ansatz war. Wir müssen uns fragen, wo und wie ein solcher Ansatz im Gesundheitswesen anwendbar ist.<br/>Wenn man zum Beispiel Aufgaben erledigt, von denen allgemein angenommen wird, dass sie menschlich und kreativ sind, kann die Maschine erkennen, wenn sie außerhalb ihrer Tiefe ist? Manchmal haben Menschen die Fähigkeit, dies zu tun. Wenn wir jedoch den Bereich genau genug definieren können, stimme ich zu, dass die Maschinen Wunder bewirken können. Wie definieren wir den Bereich?<br/>In der bahnbrechenden Arbeit von Blois über klinisches Urteil und Computer beschrieb er die Welt des Gedankenprozesses eines Arztes, wenn er einen Patienten sah, mit dem Diagramm, das in gezeigt ist. Punkt A für einen Arzt wäre, wo der Patient zum ersten Mal in die Tür geht, um gesehen zu werden. Die Art der Beschwerde, der Kontext, in dem die Beschwerde auftritt, und all die unzähligen Möglichkeiten sind vorhanden. Da sich die Problemdefinition in Richtung Punkt B bewegt, ist ein Computer besser in der Lage, die Informationen und das Wissen zu verwalten, die für eine qualitativ hochwertige Pflege erforderlich sind. Einige Informatiker haben argumentiert, dass es bei Punkt A nur darum geht, Fakten zu verwalten, aber, wie Blois beobachtet hat, geht es mehr um Relevanz - etwas, das sich als schwierig erwiesen hat, rechnerisch zu replizieren.<br/>Es ist in der Tat wichtig, den Bereich für eine KI-Anwendung zu definieren. Viele Aufgaben im Gesundheitswesen sind viel komplexer als das Spiel, und wir haben nicht die Triumphe analoger Ansätze im biomedizinischen Bereich erlebt, wie sie im Spiel erreicht wurden. Einige Studien haben die neueste Deep-Learning-Technologie (eine wichtige KI-Methode) auf biomedizinische Datensätze angewendet [- ]. Die spezifischen Anwendungen umfassten Bildverarbeitung, Verarbeitung natürlicher Sprache und Risikovorhersage. Deep Learning hat im Vergleich zu herkömmlichen statistischen und maschinellen Lernmethoden oft eher bescheidene Verbesserungen als Durchbrüche gezeigt.<br/>Was auch immer die Details dieser Ansätze sind, sie wenden nahezu unbegrenzte Rechenressourcen auf sehr große Datenmengen an, was im Gesundheitswesen noch nicht geschehen ist. Daher könnten sich diese Ansätze als hilfreich erweisen, aber wir wissen es noch nicht genau.<br/>Zum Beispiel ist eine einfache Frage, die von einem Kollegen gestellt wird, jenseits unserer gegenwärtigen Fähigkeiten: Wenn ein Patient mit einem Merkmal des metabolischen Syndroms beginnt, welches Merkmal des Syndroms wird er oder sie als nächstes zeigen? Vereinfacht gesagt, ist dies genau die Art von Herausforderung, bei der ein datengetriebener Ansatz helfen sollte, und dennoch ist er derzeit aufgrund der unzureichenden Daten, die in der Vergangenheit gesammelt wurden, "über den Horizont" gerückt.<br/>Daten sind eine zentrale Herausforderung bei der Anwendung datengetriebener Ansätze in der Patientenversorgung. Zunächst einmal sind biomedizinische Daten sehr komplex. Es gibt viele verschiedene Arten von Daten, einschließlich Bild, Text, numerische Werte, kategoriale Klassifikationen und DNA-Sequenzen, die Zehntausende von Labortests, Verfahren, Diagnosen, Medikamente, genetische Marker usw. darstellen. Jeder Datentyp hat auch seine eigenen Eigenschaften. Beispielsweise muss ein Labortestwert möglicherweise im Zusammenhang mit Alter, Geschlecht und aktuellen Bedingungen interpretiert werden. Diagnosecodes für verschiedene Krankheiten weisen jedoch unterschiedliche Genauigkeiten auf.<br/>In der biomedizinischen Datenanalyse gibt es auch das Paradoxon, zu viele und zu wenig Daten gleichzeitig zu haben. Auf der einen Seite gibt es eine enorme Menge an medizinischen Aufzeichnungen, sozialen Medien und Literaturdaten. Bemühungen wie das Million Veterans Project haben auch eine riesige Menge an DNA-Daten gesammelt. Die Verwendung von Geräten für Aufgaben wie Aktivitätsverfolgung und kontinuierliche Glukoseüberwachung generiert mehr Daten, als unsere aktuellen Krankenaktensysteme verdauen können. Auf der anderen Seite ist die Krankenakte eines Patienten ein offenes System mit vielen fehlenden Informationen im Gegensatz zum geschlossenen System eines Schach- oder Go-Spiels, bei dem alle Daten verfügbar sind. Die Patienten werden in unregelmäßigen Abständen (z. B. bei Klinikbesuchen oder während des Krankenhausaufenthalts) beobachtet und werden nie allen möglichen Tests oder Behandlungen unterzogen. Manchmal ist der Tod das einzige endgültige Ergebnis.<br/>Ich stimme zu, dass Datentypen vielfältig und komplex sind. Einfache Lösungen sind unzureichend, und die Verbreitung von irrelevanten Daten in einem Datensatz, ganz zu schweigen von der aktuellen Cut-and-Paste- oder Fill-in-the-Template-Mode, verschleiert, was wichtig ist.<br/>Eine der größten Schwierigkeiten mit medizinischen Daten ist nicht nur, dass es nicht genug ist, sondern auch, dass es theoretisch beladen ist, dh nur sehr wenige Daten werden routinemäßig aufgezeichnet. Viele Daten in Beobachtungen werden nur dann gesammelt, wenn der Arzt es für angemessen gehalten hat, dh wenn Krankheiten auf ihre Abwesenheit oder Anwesenheit getestet werden. Wenn es keinen Grund gibt, den Test durchzuführen, wird der Test nicht durchgeführt. Nur wenige Tests werden jemals routinemäßig durchgeführt; ein transkribierter Satz physikalischer Beobachtungen (wie bei der körperlichen Untersuchung) wird selten so detailliert aufgezeichnet (ganz zu schweigen von der häufig auftretenden Nichtbeobachtung), dass genügend Daten für eine umfassendere Analyse zur Verfügung stehen. Aus diesem Grund sind Studien, die auf den aufgezeichneten Beobachtungen basieren, oft unvollständig und möglicherweise irreführend. Für Vorhersagen können jedoch Beobachtungen, die nicht gemacht werden, die kritischen sein. Denken Sie an den oben genannten Patienten mit metabolischem Syndrom. Welche Daten fehlen uns?<br/>Ebenso sind die Ergebnisse klinischer Studien kein vollständiges Bild. Obwohl die Teilnehmer ausgewählt wurden und oft viele Personen aufgrund komplizierter Bedingungen ausgeschlossen wurden, sind die gesammelten Daten der Teilnehmer für die Prüfung bestimmter Hypothesen mit eng definierten Ergebnissen konzipiert. Eine häufige Kritik ist, dass solche Versuche so künstlich sind, dass sie irrelevant sind.<br/>Der Mangel an integrierten und standardisierten Datensätzen ist ein weiteres Problem. Obwohl wir viele große Datensätze finden können, sind sie oft unvollständig und schwer mit anderen Informationen zu verknüpfen. Zum Beispiel gehören Umweltexposition, Ernährung, körperliche Aktivität und genetisches Profil zu den häufigsten fehlenden Informationen, wenn wir die Aufzeichnungen über einen einzelnen Patienten untersuchen. Datenschutzfragen und monetäre Anreize sind auch Hindernisse bei der Datenintegration.<br/>Echte semantische Interoperabilität, um Datensätze zu integrieren und zu standardisieren, erfordert Unterstützung sowohl in der Terminologie als auch in der Art und Weise, wie diese Terminologie verwendet wird. Derzeit ist oft ein menschliches Eingreifen erforderlich, um zu interpretieren, was ein System für die Verwendung in einem anderen System sagt. Diese Situation ist bedauerlich; wir können hoffen, dass im Laufe der Zeit die notwendigen Verbindungen stattfinden werden (denken Sie daran, wie die Vereinigten Staaten bei jedem Telefonanruf von der Bedienerunterstützung zur automatischen Umschaltung, die heute stattfindet, übergegangen sind). Eine solche Änderung kann nur dann geschehen, wenn viele Menschen die Notwendigkeit einer gemeinsamen Norm erkennen und diese umsetzen.<br/>Darüber hinaus ist der Begriff "groß" im Zusammenhang mit Gesundheitsdaten nur relativ. Denken Sie stattdessen an viele Experimente, die von Google durchgeführt werden; Wenn sie dies wünschen, ist die Menge an Daten, die zur Entwicklung und zum Testen eines Modells verwendet werden können, um Größenordnungen größer als die im Gesundheitswesen verfügbaren.<br/>In den Bereichen, in denen datengetriebene Ansätze Erfolg gezeigt haben, gibt es Ergebnisse, die von menschlichen Experten oder Maschinen selbst beurteilt werden können. Zum Beispiel können zweisprachige Sprecher feststellen, ob die Übersetzung in natürlicher Sprache gut funktioniert, und das Ergebnis von Brett- oder Computerspielen kann leicht bestimmt werden. Dies ermöglicht eine einfachere Simulation oder Kommentierung von Daten für maschinelles Lernen. Eine solche Aufgabe ist in den biomedizinischen Bereichen viel schwieriger; die Untersuchung von Ursachen oder Behandlungen von Krankheiten beim Menschen erfordert kostspielige und langfristige Studien. In einigen Fällen verbieten ethische Bedenken die Experimente. Zum Beispiel ist die Einführung potenziell schädlicher genetischer Mutationen in gesunde menschliche Probanden nicht in Frage. Uns fehlen langfristige Ergebnisdaten für viele Behandlungen.<br/>Ich bin mir nicht sicher, ob es jemals einen solchen Goldstandard ohne eine völlig willkürliche Definition geben wird. Obwohl wir Studien mit mehreren Probanden durchführen, um die biologische Variabilität zu berücksichtigen, sind unsere Ergebnisse nur annähernd in ihrer Relevanz für eine bestimmte Person. Zum Beispiel ist die Sicherstellung der genetischen Vielfalt in klinischen Studien eine Herausforderung, gelinde gesagt. Selbst die einfachsten Aufgaben können erstaunlich multifaktoriell sein; zum Beispiel kann der Informationsgehalt von Gentests für den Warfarinstoffwechsel dadurch aufgewogen werden, ob der Patient Salat zum Mittagessen hatte.<br/>Um diese Beobachtung zu erweitern, nehmen wir an, Sie haben ein Auto, das nicht richtig funktioniert. Heute konsultieren Sie die Sensoren und die Computeranzeige, um Ihnen sehr genaue Informationen darüber zu geben, was schief geht. Das Auto hat ein spezifisches Design, mit spezifischen Parametern, die gemessen werden können. Alle Fahrzeuge des gleichen Jahres machen und Modell kann davon ausgegangen werden, in diesen wichtigen Aspekten gleich zu sein. Es ist wichtig zu erkennen, dass jeder Mensch (mit Ausnahme von eineiigen Zwillingen) genetisch einzigartig ist. Auf diese Weise unterscheiden sich die Menschen sehr von Autos oder anderen mechanischen Geräten. Um die Komplexität zu verstärken, mit der die Ursache eines menschlichen Problems angegangen werden kann, ist das, was der Einzelne während seines gesamten Lebens erlebt, einzigartig. Obwohl wir schöne Abstraktionen oder Methoden zur Identifizierung von Personen haben, die einige gemeinsame Merkmale haben (ob das Vorhandensein oder Fehlen einer Krankheit, die Reaktion oder deren Fehlen auf ein Medikament, die ähnliche Umgebung oder andere Überlegungen), sind dies nur eine Abkürzung Notation. Mit 7 Milliarden Menschen, die derzeit in dieser Welt leben, scheint das Problem fast offen. Zu oft in der Datenanalyse betrachten wir diagnostische Codes als eine tiefe Bedeutung. Diese werden akzeptiert, ohne den Grad der Unsicherheit der Diagnose zu erkennen. Alle unsere Daten können hilfreich und nützlich sein, aber wir müssen sie weiterhin mit einem großen Körnchen Salz betrachten. Die Tatsache, dass Google Translate so gut funktioniert wie es funktioniert, gibt uns Hoffnung, aber so komplex wie die Übersetzung natürlicher Sprache ist, ist es einfacher als einige klinische Aufgaben.<br/>Trotz dieser Herausforderungen hat die Anwendung datengetriebener Ansätze das Potenzial, die Gesundheitsversorgung zu transformieren. Die heutige Gesundheitsversorgung ist arbeitsintensiv, von der Planung und Triage bis hin zur Diagnose und Behandlung. Viele Aufgaben, die derzeit von Menschen übernommen werden, können durch intelligente Softwarelösungen erledigt werden, die durch ausreichende Daten unterstützt werden. Zum Beispiel könnte eine verbesserte Spracherkennungs- und Zusammenfassungstechnologie dazu beitragen, die Zeit zu reduzieren, die Patienten und Kliniker für Papierkram aufwenden. Verbesserte Tools zur Entscheidungsunterstützung sollten Patienten helfen, über die Angemessenheit der Suche nach Pflege zu entscheiden. Eine genaue Bewertung der kurz- und langfristigen Risiken und Vorteile wird die Behandlungsauswahl und Änderungen des Lebensstils beeinflussen.<br/>Um einen weiteren Anwendungsfall zu liefern, gibt es Hinweise darauf, dass Typ-II-Diabetes reversibel sein kann, aber es ist schwierig, dieses Wissen auf einen einzelnen Patienten anzuwenden. Angesichts des Patienten vor mir, was soll ich tun oder empfehlen, und mit welcher Erwartung? Demographie, Genomik, Komorbiditäten, Psyche, konkurrierende Risiken und andere Medikamente spielen eine Rolle. Wie versöhne ich bei einer bestimmten Person alle Möglichkeiten?<br/>Um diese nützlichen KI-Tools zu entwickeln, brauchen wir bessere Daten, Technologien und Richtlinien. Um umfassende, lebenslange Daten zu sammeln, müssen die Patienten die Kontrolle haben und Anreize erhalten, ihre Daten für Forschung und Pflege zu teilen. Versicherungs-, Pharma- und medizinische Einrichtungen ändern sich im Laufe der Zeit. Derzeit gibt es Hindernisse für Einzelpersonen, um das Zentrum der Sammlung der Daten über sich selbst zu sein. Die Barrieren sind bei der Dateneingabe, -sammlung und -speicherung vorhanden; zum Beispiel sind einige personalisierte Gesundheitsdatenprodukte an eine Institution gebunden, während andere umfangreiche Transkriptionsanstrengungen von Patienten oder Pflegekräften erfordern. Ohne die Zustimmung und Zusammenarbeit der Patienten sind die Erfassung und Verknüpfung von Umwelt-, genetischen, klinischen und Verhaltensdaten in Längsrichtung jedoch weder machbar noch ethisch vertretbar. Die aktuellen Bedingungen sind ein großes Hindernis für jeden Versuch, datengesteuerte Ansätze zu verwenden, die außerhalb des Gesundheitswesens funktioniert haben.<br/>Bemühungen wie PatienstLikeMe und das All-of-Us-Forschungsprojekt der National Institutes of Health [ ] sind Beispiele für innovative Ansätze, um größere und bessere Datensätze zu kuratieren. Die meisten Patienten sind jedoch nicht an solchen Bemühungen beteiligt. Die Patienten sind von Natur aus motiviert, ihre eigene Gesundheit zu verbessern, haben aber natürlich Bedenken in Bezug auf die Privatsphäre und sehen oft keine unmittelbaren Vorteile der Teilnahme an Langzeitstudien. Geeignete Anreize (z. B. Rabatte für die routinemäßige Vorsorge) in Verbindung mit Sicherheits- und Authentifizierungstechnologien sind erforderlich, um eine große und vielfältige Patientenpopulation dazu zu verleiten, ihre Daten zu sammeln und zu teilen. Die Gesundheitsbranche besitzt heute Teile von Patientendaten und hat nur eine begrenzte Motivation, Daten von ihren Kunden zu kaufen. Mit zunehmendem Wert der Daten werden die Patienten als Partner mehr geschätzt.<br/>Ich stimme zu, dass die Patienten die Verantwortung für das Tragen und Teilen der Informationen über sich selbst übernehmen müssen. Die Erfahrung sagt uns jedoch, dass nicht jeder dazu in der Lage oder bereit ist. Es wird kulturelle und politische Klimaveränderungen brauchen, um diese Entwicklung zu fördern.<br/>Wenn wir Daten sammeln können, die nicht direkt das sind, was die Philosophen "theoretisch beladen" nennen würden, können wir vielleicht unsere rohen Methoden der Patientendiagnose und -versorgung verfeinern. Ich freue mich auf diesen Tag. Wenn Patienten der Träger dieser Daten sind, wird es einfacher sein, sie zu erhalten und für die Analyse zu verwenden.<br/>Wir müssen auch Methoden entwickeln und implementieren, die speziell für den Umgang mit sehr großen und "unsinnigen" klinischen Daten geeignet sind. Zum Beispiel müssen wir den Kontext fehlender Daten und Fehler verstehen, um ein besseres Bild der Grundwahrheit zu erhalten. Ein Laborergebnis kann verpasst werden, weil es keine Indikation dafür, Praxispräferenz, eine alternative Methode zur Beurteilung oder einen Ausfall der Dateneingabe gibt. Stellen Sie sich vor, wie viel schwieriger ein Schachspiel sein wird, wenn ein menschlicher Spieler oder eine Schachmaschine nur einige Quadrate auf dem Brett in unregelmäßigen Zeitabständen mit einem Fehler oder einer Verzerrung der Beobachtung beobachten könnte.<br/>Darüber hinaus haben wir keine operative Definition von "Grundwahrheit" im Gesundheitswesen; ein einfacher Vorschlag ist, dass ein Merkmal der Grundwahrheit ist, dass sie prädiktiven Wert hat - etwas, das von Klinikern und Patienten gleichermaßen geschätzt wird.<br/>Google hat gezeigt, dass sie viele Daten verwenden können, um wahrscheinliche Werte für fehlende Daten in anderen Bereichen vorherzusagen; Es ist jedoch noch nicht entschieden, ob dies in der Medizin funktionieren könnte, aber es ist wahrscheinlich eine Studie wert. Unabhängig davon, ob wir große Datenmengen verwenden können, um fehlende Werte zu implizieren, ist es entscheidend zu untersuchen, wie mit dem Problem fehlender Beobachtungen umzugehen ist, insbesondere wenn wir versuchen, die Ergebnisse datengetriebener Ansätze auf einzelne Patienten anzuwenden.<br/>Ein anderer Gedanke ist, dass Daten, die aus irgendeinem Grund fehlen, eine Beobachtung an sich sind; die Tatsache, dass die Daten nicht erhalten und aufgezeichnet wurden, kann wichtig sein. Denken Sie an die Feststellung, dass der Tag und die Uhrzeit eines Tests prädiktiver für das Ergebnis waren als das Ergebnis des Tests. Wir wissen, dass die fehlenden Daten einen prädiktiven Wert haben werden.<br/>Eine andere Anmerkung ist, dass die Erklärung der datengesteuerten Modelle nicht nur für ihre Annahme, sondern auch für ihre Auswirkungen von entscheidender Bedeutung ist. Es kann argumentiert werden, dass es noch wichtiger ist, die modifizierbaren Faktoren zu kennen, die das Risiko verringern und das Ergebnis verbessern können. Da Deep-Learning-Modelle sehr nichtlinear sein können, haben wir die Möglichkeit, neue und komplexe Muster zu entdecken.<br/>Ich stimme zu, dass die Erklärung der Vorhersage von entscheidender Bedeutung ist. Es ist etwas, das die Gesundheitsversorgung davon trennt, beispielsweise zu erkennen, ob ein Bild ein Hund oder eine Katze ist. Ich denke jedoch, dass Sie sagen wollten, dass die Vorhersage eines Patienten wahrscheinlich ein negatives Ergebnis haben wird. Nichts im Leben ist sicher, außer dass es enden wird. Wir können jedoch sagen: "Es scheint, dass dieses Verhalten oder diese Feststellung wahrscheinlich einen Einfluss auf Ihre Zukunft haben wird" und hoffentlich in der Lage sein wird, ein gewisses Maß an Vertrauen in diese Vorhersage auszudrücken.<br/>Es ist auch wichtig zu lernen, wie man das Vertrauen in eine Vorhersage zum Ausdruck bringt. Wie viele Leute verstehen die Statistiken hinter den Vorhersagen, die heute auftreten? Was sind die zugrunde liegenden Annahmen hinter einem probabilistischen Modell? Es ist wahrscheinlicher, dass bei häufigerem Gebrauch und Vertrautheit mit dem Einsatz von Maßnahmen, die für KI-Modelle abgeleitet werden, zu ihrer Akzeptanz führen wird.<br/>Ich stimme zu. Dies sind alles Schritte, die unternommen werden müssen, um die Nutzung von Big Data durch KI zu optimieren, um die medizinische Versorgung zu verbessern.<br/>Als Abschiedsgedanke müssen wir vorsichtig sein, wie aufdringlich datengesteuerte Ansätze im Pflegeprozess sein könnten. Obwohl McDonald gezeigt hat, dass sich die Leistung in der Pflege mit Erinnerungen verbessert [ ], war die spätere Erfahrung eine von zu vielen Erinnerungen, die zu alarmierender Müdigkeit führten. Wenn Pflegekräfte sich entscheiden, hilfreiche Informationen wegen Überlastung zu überschreiben und zu ignorieren, haben wir etwas erreicht?<br/>Ich hoffe, dass eine sorgfältige Gestaltung der Systeme und die Berücksichtigung des klinischen Workflows das Problem der übermäßigen Intrusivität lindern werden. Die jüngsten Erfahrungen mit der Boeing 737 MAX zeigen zwar, dass es Gefahr gibt, aber weder KI noch ein Pilot allein ist die optimale Strategie im Fliegen. Im Gesundheitswesen kann die umfassendere Einbeziehung von Patienten in ihre Versorgung zusammen mit KI und Anbietern letztendlich ein Ansatz sein, der funktioniert.<br/>Interessenkonflikte<br/>- Blois MS. Klinische Beurteilung und Computer. N Engl J Med 1980 Jul 24;303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Deep learning for healthcare: review, opportunities and challenges. Brief Bioinform 2018 Nov 27;19(6):1236-1246 [FREE Full text] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. Kann maschinelles Lernen die kardiovaskuläre Risikovorhersage mit routinemäßigen klinischen Daten verbessern? PLoS ONE 2017 Apr 4;12(4):e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT. Tiefer Patient: Eine unbeaufsichtigte Darstellung, um die Zukunft von Patienten aus den elektronischen Gesundheitsakten vorherzusagen. Sci Rep 2016 May 17;6(1):26094 [FREE Full text] [CrossRef] [Medline]<br/>- Quach K. Das Register. 2019. IBM Watson Health schneidet die Entdeckung von Medikamenten "künstliche Intelligenz" nach glanzlosen Verkäufen ab URL: https://www.theregister.co.uk/2019/04/18/ibm_watson_health [Zugriff auf 2019-10-23]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Skalierbares und genaues Deep Learning mit elektronischen Gesundheitsakten. NPJ Digit Med 2018 May 8;1(1):18 [FREE Full text] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, et al. Deep Learning in Medical Imaging: Allgemeiner Überblick. Korean J Radiol 2017;18(4):570. [CrossRef]<br/>- U.S. Department of Veterans Affairs. Million Veteran Program (MVP) URL: https://www.research.va.gov/mvp/ [Zugriff auf 2019-10-23]<br/>- Patientslikeme. URL: https://www.patientslikeme.com [Zugriff 2019-10-23]<br/>- Alle von uns Forschungsprogramm. URL: https://allofus.nih.gov [Zugriff 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. Die unzumutbare Wirksamkeit von Daten. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Biases in elektronischen Gesundheitsdaten aufgrund von Prozessen im Gesundheitswesen: retrospektive Beobachtungsstudie. BMJ 2018 Apr 30:k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, Müller H. Causability and explainability of artificial intelligence in medicine. WIRES Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Protokollbasierte Computererinnerungen, die Qualität der Pflege und die Nicht-Perfektionierbarkeit des Menschen. N Engl J Med 1976 Dec 09;295(24):1351-1355. [CrossRef]<br/>Künstliche Intelligenz (KI)<br/>UMLS: Einheitliches medizinisches Sprachsystem<br/>Herausgegeben von G Eysenbach; eingereicht am 15.09.19; begutachtet von A Holzinger; Kommentar zum Autor 14.10.19; überarbeitete Fassung erhalten am 15.10.19; angenommen am 20.10.19; veröffentlicht am 27.11.19Urheberrecht<br/>©Qing Zeng-Treitler, Stuart J Nelson. Ursprünglich veröffentlicht im Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>Dies ist ein Open-Access-Artikel, der unter den Bedingungen der Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/) vertrieben wird und die uneingeschränkte Nutzung, Verbreitung und Vervielfältigung in jedem Medium erlaubt, vorausgesetzt, das Originalwerk, das zuerst im Journal of Medical Internet Research veröffentlicht wurde, wird ordnungsgemäß zitiert. Die vollständigen bibliographischen Informationen, ein Link zur Originalveröffentlichung auf http://www.jmir.org/, sowie diese Copyright- und Lizenzinformationen müssen enthalten sein. |
| The Story of Selena Quintanilla: A Biography Book for Young Readers (The Story Of: A Biography Series for New Readers) (Paperback)<br/>Most titles are on our shelves or available within 1-5 days.<br/>Discover the life Selena Quintanilla—a story about breaking down barriers in music, for kids ages 6 to 9<br/>Selena Quintanilla was the queen of Tejano music. Before she became a star, Selena was a charismatic young girl who loved singing and performing. She made a lot of sacrifices to become a famous musician, rehearsing her songs and dance moves for hours at a time. Her hard work paid off—she became the first 15-year-old girl to win a Tejano music award and went on to break many records during her career. This Selena biography explores how she went from being a talented girl growing up in Texas to a fashion icon and a world-famous singer.<br/>What sets this Selena book apart:<br/>- Core curriculum—Kids will learn the Who, What, Where, When, Why, and How of Selena’s life, and take a quick quiz to test their knowledge.<br/>- Short chapters—This Selena kids’ book is broken up into brief chapters that make it fun and easy for new readers to discover details about the singer’s life.<br/>- Her lasting legacy—Kids will find out how Selena changed the world of music and why she continues to be a role model for many women and people of color around the globe.<br/>How will Selena’s big spirit and passion for music inspire the child in your life?<br/>About the Author<br/>GLORIA ARJONA teaches Spanish at the California Institute of Technology and is the author of Posadas Unknown Calaveras and ¡Lotería!. She’s also a musician who sings and plays guitar. Learn more at GloriaArjona.com.<br/>“Finally, a Selena book for new readers, one that is told concisely and honestly, and is eminently readable” —Joe Nick Patoski, author of Selena: Como La Flor<br/>“What a wonderful story to inspire girls to follow their dreams. A story that many girls will identify with, especially those from traditional and multicultural families. I liked all the little sidebar lessons throughout the book. Gloria is a very talented teacher.” —Genevieve B. Southgate, director of community programs, Bowers Museum<br/>“Selena Quintanilla’s youthful talent and positive drive are brought to life in Prof. Arjona’s latest book, this one geared to young readers. A highly appealing read highlighting Selena’s flexibility in overcoming obstacles to achieving her dreams and her trailblazing contributions to music and her community. The Callisto Media format of encouraging critical, organized thought via questions, maps, timelines, and a glossary make this an enjoyable learning experience.” —Martin E. Delgado, community library manager<br/>“This is the story of Selena Quintanilla, and what a story it is! In a time where young readers, and young women, need role models more than ever, this book brilliantly depicts the profound humanity, bravery, and talent of a deeply inspiring Latina woman who relentlessly fought for her dream.” —Maite Zubiaurre, UCLA professor | Die Geschichte von Selena Quintanilla: Ein Biografiebuch für junge Leser (Die Geschichte von: Eine Biografieserie für neue Leser) (Taschenbuch)<br/>Die meisten Titel sind in unseren Regalen oder innerhalb von 1-5 Tagen erhältlich.<br/>Entdecken Sie das Leben Selena Quintanilla - eine Geschichte über das Aufbrechen von Barrieren in der Musik für Kinder im Alter von 6 bis 9 Jahren<br/>Selena Quintanilla war die Königin der Tejano-Musik. Bevor sie ein Star wurde, war Selena ein charismatisches junges Mädchen, das es liebte zu singen und aufzutreten. Sie hat viele Opfer gebracht, um eine berühmte Musikerin zu werden, indem sie stundenlang ihre Lieder und Tanzschritte einstudierte. Ihre harte Arbeit zahlte sich aus. Sie wurde das erste 15-jährige Mädchen, das einen Tejano-Musikpreis gewann und brach während ihrer Karriere viele Rekorde. Diese Selena-Biografie untersucht, wie sie von einem talentierten Mädchen, das in Texas aufwuchs, zu einer Modeikone und einer weltberühmten Sängerin wurde.<br/>Was dieses Buch von Selena auszeichnet:<br/>- Kernlehrplan - Kinder lernen das Wer, Was, Wo, Wann, Warum und Wie von Selenas Leben und machen ein schnelles Quiz, um ihr Wissen zu testen.<br/>- Kurze Kapitel - Dieses Kinderbuch von Selena ist in kurze Kapitel unterteilt, die es neuen Lesern leicht machen, Details über das Leben der Sängerin zu erfahren.<br/>- Ihr bleibendes Vermächtnis - Kinder werden herausfinden, wie Selena die Welt der Musik verändert hat und warum sie weiterhin ein Vorbild für viele Frauen und People of Color auf der ganzen Welt ist.<br/>Wie wird Selenas großer Geist und Leidenschaft für Musik das Kind in Ihrem Leben inspirieren?<br/>Über den Autor<br/>GLORIA ARJONA unterrichtet Spanisch am California Institute of Technology und ist die Autorin von Posadas Unknown Calaveras und ¡Lotería!. Sie ist auch eine Musikerin, die singt und Gitarre spielt. Erfahren Sie mehr auf GloriaArjona.com.<br/>"Endlich ein Selena-Buch für neue Leser, das prägnant und ehrlich erzählt wird und eminent lesbar ist" - Joe Nick Patoski, Autor von Selena: Como La Flor<br/>"Was für eine wunderbare Geschichte, um Mädchen zu inspirieren, ihren Träumen zu folgen. Eine Geschichte, mit der sich viele Mädchen identifizieren werden, insbesondere solche aus traditionellen und multikulturellen Familien. Ich mochte all die kleinen Sidebar-Lektionen im ganzen Buch. Gloria ist eine sehr talentierte Lehrerin." - Genevieve B. Southgate, Direktor für Gemeinschaftsprogramme, Bowers Museum<br/>"Selena Quintanillas jugendliches Talent und ihr positiver Antrieb werden in Prof. Arjonas neuestem Buch zum Leben erweckt, das sich an junge Leser richtet. Eine sehr ansprechende Lektüre, die Selenas Flexibilität bei der Überwindung von Hindernissen für die Verwirklichung ihrer Träume und ihre bahnbrechenden Beiträge zur Musik und ihrer Gemeinschaft unterstreicht. Das Callisto Media-Format, das kritisches, organisiertes Denken durch Fragen, Karten, Zeitpläne und ein Glossar fördert, macht dies zu einer unterhaltsamen Lernerfahrung. " - Martin E. Delgado, Community Library Manager<br/>Dies ist die Geschichte von Selena Quintanilla und was für eine Geschichte es ist! In einer Zeit, in der junge Leser und junge Frauen mehr denn je Vorbilder brauchen, zeigt dieses Buch auf brillante Weise die tiefe Menschlichkeit, den Mut und das Talent einer zutiefst inspirierenden Latina-Frau, die unermüdlich für ihren Traum gekämpft hat. Maite Zubiaurre, UCLA-Professorin |
| Here's another reason for men to avoid packing on extra pounds over the holidays: A new study has found that losing weight reduces the risk of an aggressive form of prostate cancer.<br/>After tracking the weight of nearly 70,000 men between 1982 and 1992, researchers from the American Cancer Society and the Duke University Prostate Center found that men who lost more than 11 pounds had a lower risk for aggressive prostate cancer than men whose weight remained the same over a decade.<br/>Previous studies have found that obese men have a higher risk of developing aggressive prostate cancer. This study appears to be the first to indicate that recent weight loss can decrease that risk.<br/>In the study reported this month in Cancer Epidemiology, Biomarkers & Prevention, researchers analyzed the height and weight of the men in 1982 and 1992 and every three years after that until 2003. At that time, more than 5,200 of the men — more than 7 percent — had prostate cancer.<br/>Among those cases, about one in eight had a form of cancer that was aggressive but had not spread to other areas of the body. The study's major finding focused on those aggressive cases, with researchers concluding that those who lost 11 or more pounds were 42 percent less likely to develop that form of prostate cancer than those whose weight remained the same.<br/>"Whether it's exactly 40 percent, we don't know, but they lower their risk when they lose 11-plus pounds. We feel confident, at least in this population, that was real," said lead researcher Dr. Carmen Rodriguez.<br/>More than seven times as many men whose weight remained the same developed aggressive prostate cancer compared to those who lost 11 or more pounds.<br/>"No significant associations" were found regarding the effect of weight gain or loss on the most severe forms of prostate cancer, those that spread throughout the body, the study said.<br/>The number studied was small, the researchers acknowledged, because fewer than 15,000 men lost weight over the time period, and only 1,000 of those developed some form of prostate cancer.<br/>The 69,991 participants were part of a bigger cancer society study of 1.2 million Americans that began in 1982.<br/>Rodriguez said men should avoid putting on extra weight as they get older.<br/>"The main message for men is to not get overweight. If they are overweight, that's another reason to try to lose weight, just to decrease the risk for prostate cancer," said Rodriguez, who works for the Atlanta-based cancer society.<br/>Other than skin cancer, prostate cancer is the most commonly diagnosed cancer for men, and about one in six will get it during his lifetime. It is the second leading cause of cancer death for U.S. men.<br/>The study is considered the first of its kind to examine the role of weight change in the development of prostate cancer, said Dr. Ronald Ennis, director of radiation oncology at St. Luke's-Roosevelt Hospital Center in New York, who was not involved in the study.<br/>"This is one of the best studies" examining the role of weight on prostate cancer, Ennis said. "It does seem to be true that if you are overweight, you are at risk of getting more aggressive forms of prostate cancer and if you lose weight, you can decrease the risk." | Hier ist ein weiterer Grund für Männer, in den Ferien keine zusätzlichen Pfunde zu packen: Eine neue Studie hat herausgefunden, dass das Abnehmen das Risiko einer aggressiven Form von Prostatakrebs reduziert.<br/>Nach der Verfolgung des Gewichts von fast 70.000 Männern zwischen 1982 und 1992 fanden Forscher der American Cancer Society und des Duke University Prostata Center heraus, dass Männer, die mehr als 11 Pfund verloren hatten, ein geringeres Risiko für aggressiven Prostatakrebs hatten als Männer, deren Gewicht über ein Jahrzehnt gleich blieb.<br/>Frühere Studien haben ergeben, dass übergewichtige Männer ein höheres Risiko haben, aggressiven Prostatakrebs zu entwickeln. Diese Studie scheint die erste zu sein, die darauf hindeutet, dass der jüngste Gewichtsverlust dieses Risiko verringern kann.<br/>In der Studie, die diesen Monat in Cancer Epidemiology, Biomarkers & Prevention veröffentlicht wurde, analysierten die Forscher die Größe und das Gewicht der Männer in den Jahren 1982 und 1992 und danach alle drei Jahre bis 2003. Zu dieser Zeit hatten mehr als 5.200 der Männer - mehr als 7 Prozent - Prostatakrebs.<br/>Unter diesen Fällen hatte etwa jeder achte eine Form von Krebs, die aggressiv war, sich aber nicht auf andere Bereiche des Körpers ausgebreitet hatte. Das Hauptergebnis der Studie konzentrierte sich auf diese aggressiven Fälle, wobei die Forscher zu dem Schluss kamen, dass diejenigen, die 11 oder mehr Pfund verloren, 42 Prozent weniger wahrscheinlich waren, diese Form von Prostatakrebs zu entwickeln als diejenigen, deren Gewicht gleich blieb.<br/>"Ob es genau 40 Prozent sind, wissen wir nicht, aber sie senken ihr Risiko, wenn sie über 11 Pfund verlieren. Wir sind zuversichtlich, zumindest in dieser Population, das war real", sagte die leitende Forscherin Dr. Carmen Rodriguez.<br/>Mehr als siebenmal so viele Männer, deren Gewicht gleich blieb, entwickelten aggressiven Prostatakrebs im Vergleich zu denen, die 11 oder mehr Pfund verloren.<br/>"Keine signifikanten Assoziationen" wurden in Bezug auf die Wirkung von Gewichtszunahme oder -verlust auf die schwersten Formen von Prostatakrebs gefunden, die sich im ganzen Körper ausbreiten, sagte die Studie.<br/>Die Zahl, die untersucht wurde, war klein, räumten die Forscher ein, weil weniger als 15.000 Männer im Laufe des Zeitraums an Gewicht verloren und nur 1.000 von ihnen eine Form von Prostatakrebs entwickelten.<br/>Die 69.991 Teilnehmer waren Teil einer größeren Krebsgesellschaft Studie von 1,2 Millionen Amerikanern, die 1982 begann.<br/>Rodriguez sagte, Männer sollten vermeiden, zusätzliches Gewicht zu tragen, wenn sie älter werden.<br/>"Die Hauptbotschaft für Männer ist, nicht übergewichtig zu werden. Wenn sie übergewichtig sind, ist das ein weiterer Grund, um zu versuchen, Gewicht zu verlieren, nur um das Risiko für Prostatakrebs zu verringern", sagte Rodriguez, der für die in Atlanta ansässige Krebsgesellschaft arbeitet.<br/>Anders als Hautkrebs ist Prostatakrebs der am häufigsten diagnostizierte Krebs für Männer, und etwa jeder sechste wird es während seines Lebens bekommen. Es ist die zweithäufigste Ursache für Krebstod für US-Männer.<br/>Die Studie gilt als die erste ihrer Art, um die Rolle der Gewichtsänderung bei der Entwicklung von Prostatakrebs zu untersuchen, sagte Dr. Ronald Ennis, Direktor der Strahlenonkologie am St. Luke's-Roosevelt Hospital Center in New York, der nicht an der Studie beteiligt war.<br/>"Dies ist eine der besten Studien", die die Rolle des Gewichts bei Prostatakrebs untersucht, sagte Ennis. "Es scheint wahr zu sein, dass Sie, wenn Sie übergewichtig sind, ein Risiko haben, aggressivere Formen von Prostatakrebs zu bekommen, und wenn Sie abnehmen, können Sie das Risiko verringern." |
| If you have studied the OSI model with its 7 Layers that describe communication on computer network systems, you should know that the Ethernet standard lies in Layer 1 (Physical) and Layer 2 (Data-Link) of the OSI model.<br/>In this article we will focus on the physical (Layer 1) part of Ethernet, which mainly focuses on the wired physical medium (cabling) that is used to transport Ethernet frames in a network.<br/>Ethernet cables connect devices to computer networks, the “heart” of which is usually an Ethernet switch which has several interface ports for “plugging-in” the cables.<br/>Most of these Ethernet cables feature the standard RJ45 connector for plugging-in to a switch. However, Ethernet communication can be implemented also using Fiber-optic cabling which uses different types of connectors.<br/>Moreover, there are different types of Ethernet cables with varying bandwidths, speeds and types of construction. In this article we will discuss the “copper-made” cables which are the most popular ones in computer networks.<br/>The cables have labels indicating the standard used for manufacturing, ranging from category (cat) 3 to 7.<br/>Ethernet cables consist of several (usually 8) smaller wires (inside the main cable) which are separated in Twisted-pairs. This setup helps in cancelling-out electromagnetic interference between wires, thus allowing signals to travel longer distances inside the wires.<br/>Without the right cable (and of course without the right type of switch), you may experience slower speeds in the network between devices.<br/>Let’s now describe each Category of Ethernet Cables with their characteristics:<br/>&#124;Max Length&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m<br/>(55 m for 10Gbps)<br/>&#124;100 m&#124;&#124;100 m&#124;<br/>&#124;Max Speed&#124;&#124;10 Mbps&#124;&#124;100 Mbps&#124;&#124;1 Gbps&#124;&#124;10 Gbps&#124;&#124;10 Gbps&#124;&#124;>10 Gbps&#124;<br/>&#124;Frequency Bandwidth&#124;&#124;16 MHz&#124;&#124;100 MHz&#124;&#124;100 MHz&#124;&#124;250 MHz&#124;&#124;500 MHz&#124;&#124;600 MHz&#124;<br/>&#124;Shielded / Unshielded&#124;&#124;Unshielded&#124;&#124;Unshielded&#124;&#124;Unshielded&#124;&#124;Shielded or Unshielded&#124;&#124;Shielded&#124;&#124;Shielded&#124;<br/>1) Cat 3<br/>One of the oldest Ethernet cabling standards is category (cat) 3 (TIA/EIA-568-B). These cables allowed 10 Mbps transmission speeds with 16 MHz max bandwidth.<br/>Cat 3 ethernet cables feature unshielded twisted pair (UTP) cabling. With UTP cables, manufacturers twist insulated copper wires together inside a polyethylene jacket. Compared to shielded ethernet cables, UTP cables tend to include more crosstalk.<br/>Network connections commonly featured category 3 ethernet cables until the early 1990s, when category 5 cables replaced cat 3. While some older telephone systems may still use cat 3 cables, they have mostly become obsolete in the networking industry.<br/>2) Cat 5<br/>Cat 5 cables increased the bandwidth of Ethernet connections up to 100 MHz and offered transmission speeds up to 100 Mbps. With Cat 5 ethernet cables, users could access 100BASE-TX ethernet systems, referred to as fast ethernet.<br/>As with the category 3 cables, cat 5 cables still feature crosstalk and interference, due to the UTP design. These cables include four pairs of twisted wires (for a total of 8 wires).<br/>While cat 5 cables primarily provide connections for Ethernet applications, these cables also provide solutions for carrying other data signals, such as video and telephone. In fact, a single cat 5 cable can carry two standard phone lines and a 100BASE-TX connection.<br/>3) Cat 5e<br/>In 2001, the category 5e standard replaced category 5. The letter “e” in the name stands for enhanced.<br/>The cabling still uses unshielded twisted pairs. There are no physical differences between cat 5 and cat 5e cables. However, stricter standards in manufacturing Cat5e cables help minimize crosstalk and allow higher data transmissions than Cat5.<br/>Cat 5e cables also utilize two sets of twisted pairs of wires, resulting in faster speeds. While cat 5e ethernet cable still features 100 MHz bandwidth, these cables allow speeds up to 1000 Mbps (1 Gbps).<br/>While several additional standards have come after cat 5e, these cables remain in production. In fact, due to the lower cost of production and support for gigabit ethernet, cat 5e cables are the most used for network applications throughout the world.<br/>4) Cat 6<br/>Cat 6 ethernet cables helped address issues related to interference and crosstalk. These cables use thinner wires and superior insulation, resulting in a better signal-to-noise ratio.<br/>With these features, cat 6 cables provide a more effective option for adding cable in areas with more electromagnetic interference, such as a crowded server room.<br/>Thanks to the superior design, cat 6 provides improved bandwidth. These cables have a max bandwidth of 250 MHz and max transmission speeds up to 1000 Mbps (1 Gbps) at the 100m range. However, 10Gbps can be achieved in Cat6 in smaller distances (up to 55m).<br/>Some cat 6 cables include shielding while others remain unshielded. With shielding, these cables can provide transmission speeds up to 10 Gbps, but only for short distances as we said above.<br/>5) Cat 6a<br/>Category 6a ethernet cables improve the design of the cat 6 cables. The letter “a” stands for augmented. Unlike cat 6 cables, all cat 6a cables feature shielded cabling for reduced interference.<br/>With the enhancements to the design specifications, cat 6a cables maintain higher transmission speeds and 500 MHz max bandwidth, allowing speeds up to 10000 Mbps (10 Gbps) across longer cables.<br/>While these cables provide faster speeds, the design makes them less flexible. To eliminate crosstalk, these cables feature thicker sheathing, making the cables stiffer and more difficult to work.<br/>6) Cat 7<br/>One of the latest developments is Cat 7 Ethernet cables. Also called class F channel cables, these cables include stricter standards compared to previous categories. The individual wire pairs now include their own shielding, in addition to the outer shielding<br/>With these cables, you get 600 MHz max bandwidth and 10000 Mbps (10 Gbps) transmission speeds. However, by almost completely getting rid of crosstalk, cat 7 ethernet cables offer even greater reliability for 10 Gbps Ethernet connections.<br/>With connections less than 15 meters, cat 7 can support transmission speeds up to 100 Gbps. While the industry has released several new standards since cat 7, these cables are currently the top of the line option for demanding networking applications.<br/>- What is OSPF NSSA (Not So Stubby Area) and How is it Configured?<br/>- Comparison of BOOTP vs DHCP Protocols in Computer Networks<br/>- Pros and Cons of SD-WAN in Networks – Description and Discussion<br/>- Comparison of GNS3 vs EVE-NG vs Packet Tracer for Networks Simulation<br/>- Subnetting vs Supernetting – What’s the Difference? (Explanation Guide) | Wenn Sie das OSI-Modell mit seinen 7 Schichten studiert haben, die die Kommunikation auf Computernetzwerksystemen beschreiben, sollten Sie wissen, dass der Ethernet-Standard in Layer 1 (Physical) und Layer 2 (Data-Link) des OSI-Modells liegt.<br/>In diesem Artikel werden wir uns auf den physischen (Ebene 1) Teil von Ethernet konzentrieren, der sich hauptsächlich auf das kabelgebundene physische Medium (Kabel) konzentriert, das zum Transport von Ethernet-Frames in einem Netzwerk verwendet wird.<br/>Ethernet-Kabel verbinden Geräte mit Computernetzwerken, deren "Herz" in der Regel ein Ethernet-Switch ist, der über mehrere Schnittstellenanschlüsse zum "Einstecken" der Kabel verfügt.<br/>Die meisten dieser Ethernet-Kabel verfügen über den Standard-RJ45-Anschluss zum Einstecken in einen Switch. Die Ethernet-Kommunikation kann jedoch auch über eine Glasfaserverkabelung implementiert werden, die verschiedene Arten von Steckverbindern verwendet.<br/>Darüber hinaus gibt es verschiedene Arten von Ethernet-Kabeln mit unterschiedlichen Bandbreiten, Geschwindigkeiten und Arten der Konstruktion. In diesem Artikel werden wir die "Kupfer" -Kabel diskutieren, die in Computernetzwerken am beliebtesten sind.<br/>Die Kabel haben Etiketten, die den für die Herstellung verwendeten Standard angeben und von Kategorie (Katze) 3 bis 7 reichen.<br/>Ethernet-Kabel bestehen aus mehreren (in der Regel 8) kleineren Drähten (innerhalb des Hauptkabels), die in Twisted-Paare getrennt sind. Dieses Setup hilft bei der Beseitigung elektromagnetischer Störungen zwischen den Drähten, so dass Signale längere Entfernungen innerhalb der Drähte zurücklegen können.<br/>Ohne das richtige Kabel (und natürlich ohne den richtigen Switch) kann es zu langsameren Geschwindigkeiten im Netzwerk zwischen Geräten kommen.<br/>Lassen Sie uns nun jede Kategorie von Ethernet-Kabeln mit ihren Eigenschaften beschreiben:<br/>Maximale Länge: 100 m: 100 m: 100 m: 100 m<br/>(55 m für 10 Gbit/s)<br/>100 m2<br/>Maximale Geschwindigkeit10 Mbps100 Mbps1 Gbps10 Gbps10 Gbps>10 Gbps<br/>- Frequenzbandbreite - 16 MHz - 100 MHz - 250 MHz - 500 MHz - 600 MHz -<br/>Abgeschirmt / Unshielded shielded shielded shielded oder unshielded<br/>1) Katze 3<br/>Einer der ältesten Ethernet-Verkabelungsstandards ist Kategorie (Katze) 3 (TIA/EIA-568-B). Diese Kabel erlaubten 10 Mbps Übertragungsgeschwindigkeiten mit 16 MHz max Bandbreite.<br/>Cat 3 Ethernet-Kabel verfügen über ungeschirmte Twisted-Pair-Kabel (UTP). Mit UTP-Kabeln verdrehen Hersteller isolierte Kupferdrähte in einem Polyethylenmantel. Im Vergleich zu abgeschirmten Ethernet-Kabeln enthalten UTP-Kabel tendenziell mehr Übersprechen.<br/>Netzwerkverbindungen häufig vorgestellten Kategorie 3 Ethernet-Kabel bis Anfang der 1990er Jahre, als Kategorie 5 Kabel ersetzt Katze 3. Während einige ältere Telefonanlagen können immer noch Cat 3 Kabel verwenden, sind sie meist veraltet in der Netzwerkbranche.<br/>2) Katze 5<br/>Cat 5-Kabel erhöhten die Bandbreite der Ethernet-Verbindungen auf bis zu 100 MHz und boten Übertragungsgeschwindigkeiten von bis zu 100 Mbit/s. Mit Cat 5-Ethernet-Kabeln konnten Benutzer auf 100BASE-TX-Ethernet-Systeme zugreifen, die als schnelles Ethernet bezeichnet werden.<br/>Wie bei den Kabeln der Kategorie 3 verfügen Cat-5-Kabel aufgrund des UTP-Designs immer noch über Übersprechen und Interferenzen. Diese Kabel enthalten vier Paare verdrillter Drähte (für insgesamt 8 Drähte).<br/>Während Cat-5-Kabel in erster Linie Verbindungen für Ethernet-Anwendungen bereitstellen, bieten diese Kabel auch Lösungen für die Übertragung anderer Datensignale wie Video und Telefon. In der Tat kann ein einzelnes Cat-5-Kabel zwei Standard-Telefonleitungen und einen 100BASE-TX-Anschluss tragen.<br/>3) Katze 5e<br/>Im Jahr 2001 ersetzte die Kategorie 5e die Kategorie 5. Der Buchstabe "e" im Namen steht für Enhanced.<br/>Die Verkabelung verwendet immer noch ungeschirmte Twisted Pairs. Es gibt keine physischen Unterschiede zwischen Cat 5 und Cat 5e Kabeln. Strengere Standards bei der Herstellung von Cat5e Kabeln helfen jedoch, Übersprechen zu minimieren und höhere Datenübertragungen als Cat5 zu ermöglichen.<br/>Cat 5e-Kabel verwenden auch zwei Sätze verdrehter Kabelpaare, was zu höheren Geschwindigkeiten führt. Während Cat 5e-Ethernet-Kabel immer noch eine Bandbreite von 100 MHz bieten, ermöglichen diese Kabel Geschwindigkeiten von bis zu 1000 Mbit/s (1 Gbit/s).<br/>Während mehrere zusätzliche Standards nach Cat 5e gekommen sind, bleiben diese Kabel in der Produktion. Tatsächlich sind Cat 5e-Kabel aufgrund der geringeren Produktionskosten und der Unterstützung für Gigabit-Ethernet die am häufigsten verwendeten für Netzwerkanwendungen auf der ganzen Welt.<br/>4) Katze 6<br/>Cat 6-Ethernet-Kabel halfen, Probleme im Zusammenhang mit Interferenzen und Übersprechen zu lösen. Diese Kabel verwenden dünnere Drähte und überlegene Isolierung, was zu einem besseren Signal-Rausch-Verhältnis führt.<br/>Mit diesen Funktionen bieten Cat-6-Kabel eine effektivere Option zum Hinzufügen von Kabeln in Bereichen mit stärkerer elektromagnetischer Interferenz, z. B. in einem überfüllten Serverraum.<br/>Dank des überlegenen Designs bietet Cat 6 eine verbesserte Bandbreite. Diese Kabel haben eine maximale Bandbreite von 250 MHz und maximale Übertragungsgeschwindigkeiten von bis zu 1000 Mbit/s (1 Gbit/s) im Bereich von 100 m. In Cat6 können jedoch 10 Gbit/s in kleineren Entfernungen (bis zu 55 m) erreicht werden.<br/>Einige Cat-6-Kabel enthalten eine Abschirmung, während andere ungeschirmt bleiben. Mit einer Abschirmung können diese Kabel Übertragungsgeschwindigkeiten von bis zu 10 Gbit/s bieten, aber nur für kurze Entfernungen, wie oben erwähnt.<br/>5) Katze 6a<br/>Ethernetkabel der Kategorie 6a verbessern das Design der Cat 6-Kabel. Der Buchstabe "a" steht für Augmented. Im Gegensatz zu Cat 6-Kabeln verfügen alle Cat 6a-Kabel über eine abgeschirmte Verkabelung für reduzierte Interferenzen.<br/>Mit den Verbesserungen an den Design-Spezifikationen halten Cat 6a-Kabel höhere Übertragungsgeschwindigkeiten und 500 MHz maximale Bandbreite aufrecht und ermöglichen Geschwindigkeiten von bis zu 10000 Mbit/s (10 Gbit/s) über längere Kabel.<br/>Während diese Kabel schnellere Geschwindigkeiten bieten, macht das Design sie weniger flexibel. Um Übersprechen zu vermeiden, verfügen diese Kabel über eine dickere Ummantelung, wodurch die Kabel steifer und schwieriger zu bearbeiten sind.<br/>6) Katze 7<br/>Eine der neuesten Entwicklungen sind Cat 7-Ethernet-Kabel. Auch als Klasse-F-Kanalkabel bezeichnet, enthalten diese Kabel strengere Standards im Vergleich zu früheren Kategorien. Die einzelnen Drahtpaare verfügen nun neben der äußeren Abschirmung über eine eigene Abschirmung.<br/>Mit diesen Kabeln erhalten Sie 600 MHz maximale Bandbreite und 10000 Mbps (10 Gbps) Übertragungsgeschwindigkeiten. Durch die fast vollständige Beseitigung von Übersprechen bieten Cat 7 Ethernet-Kabel eine noch höhere Zuverlässigkeit für 10 Gbps Ethernet-Verbindungen.<br/>Mit Verbindungen von weniger als 15 Metern unterstützt cat 7 Übertragungsgeschwindigkeiten von bis zu 100 Gbit/s. Während die Industrie seit cat 7 mehrere neue Standards veröffentlicht hat, sind diese Kabel derzeit die erste Wahl für anspruchsvolle Netzwerkanwendungen.<br/>- Was ist OSPF NSSA (Not So Stubby Area) und wie wird es konfiguriert?<br/>- Vergleich von BOOTP- und DHCP-Protokollen in Computernetzwerken<br/>- Vor- und Nachteile von SD-WAN in Netzwerken – Beschreibung und Diskussion<br/>- Vergleich von GNS3 vs EVE-NG vs Packet Tracer für Netzwerksimulation<br/>- Subnetting vs Supernetting – Was ist der Unterschied? (Erläuterung) |
| Views: 4 Author: Site Editor Publish Time: 2022-06-09 Origin: Site<br/>So why should workers wear a portable gas detector and what does it do?<br/>In many industrial environments, workers need to be highly aware of exposure to toxic or combustible gases and vapours or a lack of oxygen. That’s why portable gas detectors and analysers are essential – so they can detect, measure, monitor and react to any gases in the immediate area around them. KELISAIKE SAFETY offers both single- and multi-gas mobile gas monitors that reliably detect a wide range of gases. All of our portable gas detectors and software are designed to make compliance and asset management as intuitive as possible, so you can implement a complete product solution that helps ensure safety at all times.<br/>Portable gas detectors are classed as a type of Personal Protective Equipment (PPE)<br/>They monitor gases in the workers breathing zone by displaying real-time gas levels of a variety of toxic, combustible, flammable gases<br/>They alert the worker of any possible threats which include combustion and oxygen displacement<br/>While portable gas detectors are available with various sensor configurations and features, they are all built with the same purpose - to protect human life! | Aufrufe: 4 Autor: Site Editor Publish Zeit: 2022-06-09 Herkunft: Site<br/>Warum sollten Arbeiter einen tragbaren Gasdetektor tragen und was macht er?<br/>In vielen industriellen Umgebungen müssen Arbeitnehmer sich der Exposition gegenüber giftigen oder brennbaren Gasen und Dämpfen oder einem Sauerstoffmangel bewusst sein. Deshalb sind tragbare Gasdetektoren und -analysatoren unerlässlich – damit sie Gase in ihrer unmittelbaren Umgebung erkennen, messen, überwachen und auf sie reagieren können. KELISAIKE SAFETY bietet sowohl ein- als auch mehrgasige mobile Gasmonitore, die eine Vielzahl von Gasen zuverlässig detektieren. Alle unsere tragbaren Gasdetektoren und Software sind darauf ausgelegt, Compliance und Asset Management so intuitiv wie möglich zu gestalten, sodass Sie eine komplette Produktlösung implementieren können, die jederzeit für Sicherheit sorgt.<br/>Tragbare Gasdetektoren werden als eine Art persönliche Schutzausrüstung (PSA) eingestuft<br/>Sie überwachen Gase in der Atemzone der Arbeiter, indem sie Echtzeit-Gaswerte einer Vielzahl von toxischen, brennbaren und brennbaren Gasen anzeigen.<br/>Sie warnen den Arbeiter vor möglichen Bedrohungen, einschließlich Verbrennung und Sauerstoffverdrängung.<br/>Während tragbare Gasdetektoren mit verschiedenen Sensorkonfigurationen und -funktionen erhältlich sind, sind sie alle mit dem gleichen Zweck gebaut - um menschliches Leben zu schützen! |
