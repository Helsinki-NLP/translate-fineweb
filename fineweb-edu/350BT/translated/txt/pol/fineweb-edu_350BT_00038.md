| original | translation |
|----------|-------------|
| Artificial intelligence (AI), the computerized capability of doing tasks, which until recently was thought to be the exclusive domain of human intelligence, has demonstrated great strides in the past decade. The abilities to play games, provide piloting for an automobile, and respond to spoken language are remarkable successes. How are the challenges and opportunities of medicine different from these challenges and how can we best apply these data-driven techniques to patient care and outcomes? A New England Journal of Medicine paper published in 1980 suggested that more well-defined “specialized” tasks of medical care were more amenable to computer assistance, while the breadth of approach required for defining a problem and narrowing down the problem space was less so, and perhaps, unachievable. On the other hand, one can argue that the modern version of AI, which uses data-driven approaches, will be the most useful in tackling tasks such as outcome prediction that are often difficult for clinicians and patients. The ability today to collect large volumes of data about a single individual (eg, through a wearable device) and the accumulation of large datasets about multiple persons receiving medical care has the potential to apply to the care of individuals. As these techniques of analysis, enumeration, aggregation, and presentation are brought to bear in medicine, the question arises as to their utility and applicability in that domain. Early efforts in decision support were found to be helpful; as the systems proliferated, later experiences have shown difficulties such as alert fatigue and physician burnout becoming more prevalent. Will something similar arise from data-driven predictions? Will empowering patients by equipping them with information gained from data analysis help? Patients, providers, technology, and policymakers each have a role to play in the development and utilization of AI in medicine. Some of the challenges, opportunities, and tradeoffs implicit here are presented as a dialog between a clinician (SJN) and an informatician (QZT).J Med Internet Res 2019;21(11):e16272<br/>Drs Nelson and Zeng-Treitler work together at the Biomedical Informatics Center at George Washington University. In the following we present a hypothetical dialogue which grew out of discussions they had as they considered their differing viewpoints of how artificial intelligence (AI) has developed and where it is going. While Dr Zeng-Treitler’s view of the future of AI is highly optimistic, Dr Nelson's opinion is more cautious. Dr Nelson was a practicing academic internist who became involved in informatics many years ago. He collaborated with Scott Blois on RECONSIDER (an early clinical decision support system) and on the Unified Medical Language System (UMLS) project. He eventually moved to the National Library of Medicine as Head of Medical Subject Headings. While at the National Library of Medicine, he fathered RxNorm, while continuing his work on UMLS and projects involving UMLS. Dr Zeng-Treitler has a background in computer science and obtained her PhD in medical informatics from Columbia University. She has led a number of projects in clinical data mining, natural language processing, and consumer health informatics. During the past few years, her team has been actively investigating the use of AI techniques in clinical research including development of a novel explainable deep learning approach.<br/>Dr Zeng-Treitler (The "Optimist"):<br/>After decades of promises and disappointment, thanks to the seemingly unbounded computing resources and novel, data-driven methods, AI technology has finally arrived. From Jeopardy and Siri to face identification and autonomous vehicles, data-driven approaches have made the leap from laboratory experiments to applications that are transforming our lives outside health care. In some cases, these approaches have come close to passing the Turing Test—a test of a machine’s ability to exhibit supposed human-like intelligence; machines can now perform some complex tasks such as image recognition and authentic game play as well as or better than humans would. Some would argue that the requisite approach is decidedly nonhuman. However, whatever the means to achieving these innovations, such successes have not been followed by analogous successes in health care.<br/>One dramatic example of this disparity of accomplishment is AlphaZero, a computer game engine that mastered chess, Shogi, and Go. Even before the arrival of the current generation of data-driven artifacts, chess engines have been shown to be able to play at a level superior to that of chess champions. Players of Go (a board game that is thought to be much more complex than chess), however, believed that computers were no match for high-level professionals in this game. This belief was shattered first by AlphaGo, which soundly defeated the reigning world champion of Go. Then came AlphaZero. The news is no longer that such approaches can beat the champions of Go, chess, or Shogi. Rather, the remarkable fact is that AlphaZero did not learn from human experiences and that it defeated the best prior chess engines such as Stockfish. AlphaZero triumphed by playing more games against itself than had ever been played by all human players. This is not an approach we could readily duplicate in health care.<br/>Dr Nelson (The "Cautious" One):<br/>Is winning a game, with defined rules and objectives, really the best test of human intelligence? In hindsight, the answer is “No.” For example, sophisticated chess playing programs have existed for nearly 50 years; from such programs, we learned how to organize computing resources to apply simple algorithms in a scalable way. Put differently, we did not learn anything about chess or how humans, even experts, play it. Instead, we learned that a supposed intelligence-requiring task was susceptible to a computational approach. We need to ask where and how such an approach is applicable in health care.<br/>For example, when doing tasks that are generally thought to be human and creative, can the machine recognize when it is out of its depth? Sometimes, humans have the ability to do so. However, if we can define the realm closely enough, I agree that the machines can do wonders. So, how do we define the realm?<br/>In Blois’ seminal paper on Clinical Judgment and Computers , he described the world of a physician’s thought process when seeing a patient, with the diagram shown in . Point A for a physician would be where the patient walks in the door to be seen for the first time. The nature of the complaint, the context in which the complaint occurs, and all of the myriad possibilities are present. As the problem definition moves toward Point B, a computer is better able to manage the information and knowledge necessary for high-quality care. One way in which we can think about defining the realm is that we are moving toward Point B. Some computer scientists have argued that Point A is just about managing facts, but, as Blois observed, it is more about relevance—something that has proven difficult to replicate computationally.<br/>It is indeed important to define the realm for an AI application. Many tasks in health care are much more complex than game play, and we have not witnessed the triumphs of analogous approaches in the biomedical domain as have been achieved in game play. Quite a few studies have been applying the latest deep learning technology (a key AI method) to biomedical datasets [- ]. The specific applications included image processing, natural language processing, and risk prediction. Deep learning, compared with traditional statistical and machine learning methods, has often shown modest improvements rather than breakthroughs [ - ].<br/>Whatever the details of these approaches, they apply nearly unbounded computing resources to very large amounts of data, something that has yet to happen in health care. Therefore, these approaches might prove helpful, but we do not know for sure yet.<br/>For example, a simple question posed by a colleague is beyond our current capabilities: Given a patient who starts out with a feature of metabolic syndrome, which feature of the syndrome will he or she tend to exhibit next? Simplistically, this is exactly the kind of challenge that a data-driven approach should help with, and yet, it is currently “over the horizon” due to the insufficient data that were collected in the past.<br/>Data are a key challenge when applying data-driven approaches to patient care. To begin with, biomedical data are highly complex. There many different types of data including image, text, numerical values, categorical classifications, and DNA sequences, representing tens of thousands of lab tests, procedures, diagnoses, medications, genetic markers, etc. Each data type also has its own characteristics; for example, a laboratory test value may need to be interpreted in the context of age, gender, and current conditions. However, diagnostic codes for different diseases have varying levels of accuracies.<br/>In biomedical data analysis, there is also the paradox of having too much and not enough data at the same time. On one hand, there are a tremendous amount of medical record, social media, and literature data. Efforts like the Million Veterans Project  have also collected a huge amount of DNA data. Using devices for tasks like activity tracking and continuous glucose monitoring generates more data than our current medical record systems can digest. On the other hand, the health record of a patient is an open system with much missing information in contrast with the closed system of a chess or Go game, where all data are available. Patients are observed at irregular intervals (eg, at clinic visits or during hospitalization) and are never subjected to all possible tests or treatments. Sometimes, death is the only definitive outcome.<br/>I agree that data types are multiple and complex. Simple solutions are insufficient, and the proliferation of irrelevant data in a record, not to mention the current cut-and-paste or fill-in-the-template fad, obscures what is important.<br/>One of the major difficulties with medical data is not just that it is not enough, but also that it is theory laden, that is, very few pieces of data are recorded routinely. A lot of data in observations are gathered only when the clinician has thought it is appropriate, that is, when diseases are tested for their absence or presence. If there is no reason to do the test, the test is not performed. Only a few tests are ever performed routinely; a transcribed set of physical observations (as is done in physical examination) is rarely recorded in enough detail (not to mention the failure to observe, which often occurs) to provide sufficient data for a more comprehensive analysis. For that reason alone, studies based on the recorded observations are often incomplete and potentially misleading. However, for predictions, observations not made may be the critical ones. Think about the patient with metabolic syndrome mentioned above. What data are we missing?<br/>Similarly, the results of clinical trials are not a complete picture. Even though participants have been selected, often excluding many individuals because of complicating conditions, the data collected on the participants are designed for testing certain hypotheses, with narrowly defined outcomes. A common criticism is that such trials are so artificial that they are irrelevant.<br/>The lack of integrated and standardized datasets is another issue. Although we can find many large datasets, they are often incomplete and difficult to link to other information. For example, environmental exposure, diet, physical activity, and genetic profile are among the common missing pieces of information when we examine the records about an individual patient. Detailed clinical trial datasets tend to lack long-term follow-up. Privacy issues and monetary incentives are also obstacles in data integration efforts.<br/>Real semantic interoperability to integrate and standardize datasets requires support in both terminology and how that terminology is used. Currently, human intervention is often required to interpret what one system is saying for use in another system. This situation is unfortunate; we can hope that over time, the necessary connections will take place (think of how the United States went from operator assistance on every telephone call to the automatic switching that takes place today). Such a change can only happen when many people see the need for and implement a common standard.<br/>In addition, the notion of “large” in the context of health care data is only relative. Think, instead, of many experiments undertaken by Google; if they desire, the amount of data that can be used to develop and test a model is orders of magnitude greater than that available in health care.<br/>In the domains where data-driven approaches have demonstrated success, there are outcomes that can be judged by human experts or machines themselves. For example, bilingual speakers can tell if natural language translation is working well, and the outcome of board or computer games can be easily determined. This allows easier simulation or annotation of data for machine learning. Such a task is much harder in the biomedical domains; investigation of causes or treatments of diseases in humans involve costly and long-term studies. In some cases, ethical concerns prohibit the experiments; for example, the introduction of potentially harmful genetic mutations into healthy human subjects is out of the question. We lack long-term outcome data for many treatments.<br/>I am not sure that there ever will be such a gold standard without a completely arbitrary definition. Variation between individuals is also a major obstacle. Although we perform studies using multiple subjects to account for biologic variability, our results are only approximate in their relevance to a given individual. For example, assuring genetic diversity in clinical trials is challenging, to say the least. Even the simplest tasks can be staggeringly multifactorial; for example, the information content of genetic testing for warfarin metabolism can be outweighed by whether the patient had lettuce for lunch.<br/>To expand on this observation, suppose you have an automobile that is not working appropriately. Today, you consult the sensors and the computer readout to give you very precise information about what is going wrong. The automobile has a specific design, with specific parameters that can be measured. All of the vehicles of the same year make and model can be assumed to be alike in those important aspects. It is important to realize that every human (with the exception of identical twins) is genetically unique. In that way, people are very different from automobiles or other mechanical devices. To compound the complexity with which the cause of a human problem can be addressed, what the individual experiences throughout their life is unique. Although we have nice abstractions or methods of identifying individuals who share some common characteristics (whether the presence or absence of a disease, the response or lack thereof to a medication, the similar environment, or other considerations), these are only a shorthand notation. With 7 billion persons currently living in this world, the problem appears almost open-ended. Too often in data analysis, we look at diagnostic codes as having a deep meaning. These are accepted without any recognition of the degree of uncertainty of the diagnosis. All our data may be helpful and useful, but we need to continue to view them with a large grain of salt. The fact that Google Translate works as well as it does gives us hope, but as complex as natural language translation is, it is simpler than some clinical tasks.<br/>Despite these challenges, applying data-driven approaches has the potential to transform health care. Today’s health care is labor intensive, from scheduling and triage to diagnosis and treatment. Many tasks currently undertaken by humans can be carried out by intelligent software solutions supported by sufficient data. For instance, improved voice recognition and summarization technology might help reduce the amount of time patients and clinicians spend on paperwork. Improved decision support tools ought to be able to help patients decide about the appropriateness of seeking care. An accurate assessment of short- and long-term risks and benefits will inform treatment selection and lifestyle changes.<br/>To provide another use case, there is evidence that type II diabetes may be reversible, but it is hard to apply this knowledge to an individual patient. Given the patient in front of me, what should I do, or recommend, and with what expectation? Demographics, genomics, comorbidities, psyche, competing risks, and other medications, all play a role. How, in a given person, do I reconcile all the possibilities?<br/>To develop these useful AI tools, we need better data, technology, and policy. To accumulate comprehensive, life-time data, patients must be in control and should be incentivized to share their data for research and care. Insurance, pharmaceutical, and medical institutions change over time. Currently, there are barriers for individuals to be the center of collecting the data on themselves. The barriers are present in data entry, collection, and storage; for example, some personalized health record products are tethered to an institution, while others require extensive transcribing efforts by patients or caregivers. Nevertheless, without patient consent and collaboration, gathering and linking longitudinal environmental, genetic, clinical, and behavioral data are neither feasible nor ethical. The current conditions are a huge barrier to any attempt to use data-driven approaches that have worked outside health care.<br/>Efforts including PatienstLikeMe  and the All of Us Research Project of the National Institutes of Health [ ] are examples of innovative approaches to curate bigger and better datasets. Most patients, however, are not engaged in such efforts. Patients are inherently motivated to improve their own health, but naturally have concerns regarding privacy and often do not see immediate benefits of participating in long-term studies. Appropriate incentives (eg, discounts for routine preventive care) coupled with security and authentication technologies are needed to entice a large and diverse population of patients to gather and share their data. The health care industry today owns parts of patient data and has limited motivation to purchase data from their customers. As the value of data increases, patients will become more valued as a partner.<br/>I agree that patients will need to assume the responsibility of carrying and sharing the information about themselves. However, experience tells us that not everyone is able or willing to do so. It will need cultural and political climate changes to encourage that development.<br/>When we can collect data that are not directly what the philosophers would call “theory-laden,” we may be able to refine our crude methods of patient diagnosis and care. I look forward to that day. If patients are the carrier of those data, it will be easier to obtain and use for analysis.<br/>We also need to design and implement methods specifically for handling very large and “messy” clinical data. For example, we need to understand the context of missing data and errors to get a better picture of ground truth. A lab result may be missed because there is no indication for it, practice preference, an alternative method of assessing, or a failure of data entry. Imagine how much more difficult a chess game will be, if a human player or a chess engine could only observe some squares on the board at irregular time intervals with some error or distortion of the observation.<br/>Further, we do not have an operational definition of “ground truth” in health care; a simple proposal is that one feature of ground truth is that it has predictive value—something that will be valued by clinicians and patients alike.<br/>Google has demonstrated that they can use lots of data to predict likely values for missing data in other areas ; however, it is yet to be determined whether this might work in medicine, but it is probably worth a trial. Irrespective of whether we can use large volumes of data to impute missing values, exploring how to handle the problem of absent observations is crucial, especially whenever we try to apply the results of data-driven approaches to individual patients.<br/>Another thought is that data that are missing, for any reason, are an observation in itself; the fact that the data were not obtained and recorded may be important. Think of the finding that the day and time of a test were more predictive of outcome than the result of the test . We know that the data that are missing will have some predictive value.<br/>On a different note, explanation of the data-driven models is critical to not only their adoption but also their impact . Predicting that a patient will have certain adverse events in the next several days or years is desirable. It may be argued that it is even more important to know the modifiable factors that can reduce risk and enhance outcome. Since deep learning models can be highly nonlinear, we have the opportunity to discover novel and complex patterns.<br/>I agree that explaining the prediction is critical; it is something that separates health care from, say, recognizing whether an image is a dog or a cat. However, I think you meant to say predicting a patient will probably have some adverse outcome. Nothing in life is certain except that it will end. However, we can say “it appears this behavior or finding will likely have an effect on your future” and hopefully be able to express some degree of confidence in that prediction.<br/>Learning how to express the confidence in a prediction is also important. How many folks really understand the statistics behind the predictions that occur today? What are the underlying assumptions behind any probabilistic model? It is more likely that with more frequent use and familiarity with the use of measures derived for AI models will lead to their acceptance.<br/>I agree. These are all steps to be taken in order to optimize the use of big data through AI to improve medical care.<br/>As a parting thought, we need to be cautious about how intrusive data-driven approaches might be in the care process. Although McDonald  demonstrated that performance in care improves with reminders [ ], the later experience has been one of too many reminders, leading to alert fatigue. When caregivers choose to override and ignore helpful information because of overload, have we accomplished anything?<br/>I hope that careful design of systems and consideration of clinical workflow will alleviate the problem of excessive intrusiveness. Although it is tempting to just “let AI do it,” the recent experiences with the Boeing 737 MAX demonstrate that there is danger in doing so. Neither AI nor a pilot alone is the optimal strategy in flying. In health care, involving patients more extensively in their care, together with AI and providers, may ultimately be an approach that works.<br/>Conflicts of Interest<br/>- Blois MS. Clinical Judgment and Computers. N Engl J Med 1980 Jul 24;303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Deep learning for healthcare: review, opportunities and challenges. Brief Bioinform 2018 Nov 27;19(6):1236-1246 [FREE Full text] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. Can machine-learning improve cardiovascular risk prediction using routine clinical data? PLoS ONE 2017 Apr 4;12(4):e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT. Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records. Sci Rep 2016 May 17;6(1):26094 [FREE Full text] [CrossRef] [Medline]<br/>- Quach K. The register. 2019. IBM Watson Health cuts back drug discovery 'artificial intelligence' after lackluster sales URL: https://www.theregister.co.uk/2019/04/18/ibm_watson_health [accessed 2019-10-23]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Scalable and accurate deep learning with electronic health records. NPJ Digit Med 2018 May 8;1(1):18 [FREE Full text] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, et al. Deep Learning in Medical Imaging: General Overview. Korean J Radiol 2017;18(4):570. [CrossRef]<br/>- U.S Department of Veterans Affairs. Million Veteran Program (MVP) URL: https://www.research.va.gov/mvp/ [accessed 2019-10-23]<br/>- Patientslikeme. URL: https://www.patientslikeme.com [accessed 2019-10-23]<br/>- All of Us Research Program. URL: https://allofus.nih.gov [accessed 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. The unreasonable effectiveness of data. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Biases in electronic health record data due to processes within the healthcare system: retrospective observational study. BMJ 2018 Apr 30:k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, Müller H. Causability and explainabilty of artificial intelligence in medicine. WIREs Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Protocol-Based Computer Reminders, the Quality of Care and the Non-Perfectibility of Man. N Engl J Med 1976 Dec 09;295(24):1351-1355. [CrossRef]<br/>&#124;AI: artificial intelligence&#124;<br/>&#124;UMLS: Unified Medical Language System&#124;<br/>Edited by G Eysenbach; submitted 15.09.19; peer-reviewed by A Holzinger; comments to author 14.10.19; revised version received 15.10.19; accepted 20.10.19; published 27.11.19Copyright<br/>©Qing Zeng-Treitler, Stuart J Nelson. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included. | Sztuczna inteligencja (AI), skomputeryzowana zdolność do wykonywania zadań, która do niedawna uważana była za wyłączną dziedzinę ludzkiej inteligencji, wykazała w ostatniej dekadzie wielkie postępy. Umiejętności grania w gry, prowadzenia samochodu i reagowania na język mówiony są niezwykłymi sukcesami. W jaki sposób wyzwania i możliwości medycyny różnią się od tych wyzwań i w jaki sposób możemy najlepiej zastosować te techniki oparte na danych do opieki nad pacjentem i wyników? W artykule opublikowanym w New England Journal of Medicine w 1980 roku zasugerowano, że bardziej dobrze zdefiniowane „specjalizowane” zadania opieki medycznej są bardziej podatne na pomoc komputerową, podczas gdy szerokość podejścia wymagana do zdefiniowania problemu i zawężenia przestrzeni problemowej była mniej taka i być może nieosiągalna. Z drugiej strony można argumentować, że nowoczesna wersja sztucznej inteligencji, która wykorzystuje podejścia oparte na danych, będzie najbardziej przydatna w rozwiązywaniu zadań, takich jak przewidywanie wyników, które są często trudne dla klinicystów i pacjentów. Zdolność do gromadzenia dużych ilości danych o pojedynczej osobie (np. za pośrednictwem urządzenia przenośnego) oraz gromadzenie dużych zbiorów danych o wielu osobach otrzymujących opiekę medyczną ma potencjał zastosowania do opieki nad osobami. Gdy te techniki analizy, wyliczenia, agregacji i prezentacji stają się powszechne w medycynie, powstaje pytanie o ich użyteczność i zastosowanie w tej dziedzinie. Wczesne wysiłki w zakresie wspierania decyzji okazały się pomocne; wraz z rozprzestrzenianiem się systemów, późniejsze doświadczenia wykazały trudności, takie jak alarmowe zmęczenie i wypalenie zawodowe. Czy coś podobnego powstanie z przewidywań opartych na danych? Czy pomocne będzie wzmocnienie pozycji pacjentów poprzez wyposażenie ich w informacje uzyskane z analizy danych? Pacjenci, dostawcy, technologie i decydenci polityczni odgrywają rolę w rozwoju i wykorzystaniu sztucznej inteligencji w medycynie. Niektóre z wyzwań, możliwości i dorozumianych kompromisów są tutaj przedstawione jako dialog między klinicystą (SJN) a informatykiem (QZT). J Med Internet Res 2019;21(11):e16272<br/>Dr Nelson i Zeng-Treitler pracują razem w Centrum Informatyki Biomedycznej na Uniwersytecie George'a Washingtona. W dalszej części przedstawiamy hipotetyczny dialog, który wyrósł z dyskusji, które prowadzili, rozważając różne punkty widzenia na temat tego, jak rozwinęła się sztuczna inteligencja (AI) i dokąd zmierza. Podczas gdy pogląd dr Zeng-Treitlera na przyszłość sztucznej inteligencji jest wysoce optymistyczny, opinia dr Nelsona jest bardziej ostrożna. Dr Nelson był praktykującym internistą akademickim, który wiele lat temu zaangażował się w informatykę. Współpracował ze Scottem Bloisem nad projektem RECONSIDER (wczesny kliniczny system wspomagania decyzji) oraz projektem Unified Medical Language System (UMLS). Ostatecznie przeniósł się do National Library of Medicine na stanowisko szefa działów przedmiotu medycznego. Podczas pobytu w National Library of Medicine, ojcem RxNorm, kontynuował pracę nad UMLS i projektami z udziałem UMLS. Dr Zeng-Treitler ma doświadczenie w informatyce i uzyskał doktorat z informatyki medycznej na Uniwersytecie Columbia. Prowadziła wiele projektów w zakresie eksploracji danych klinicznych, przetwarzania języka naturalnego i informatyki zdrowotnej konsumentów. W ciągu ostatnich kilku lat jej zespół aktywnie badał zastosowanie technik sztucznej inteligencji w badaniach klinicznych, w tym opracowanie nowego podejścia do głębokiego uczenia się.<br/>Dr Zeng-Treitler ("Optymista"):<br/>Po dziesięcioleciach obietnic i rozczarowań, dzięki pozornie nieograniczonym zasobom obliczeniowym i nowatorskim metodom opartym na danych, technologia AI wreszcie przybyła. Od Jeopardy i Siri po identyfikację i autonomiczne pojazdy, podejścia oparte na danych przeszły od eksperymentów laboratoryjnych do zastosowań, które zmieniają nasze życie poza opieką zdrowotną. W niektórych przypadkach podejścia te zbliżyły się do przejścia testu Turinga – testu zdolności maszyny do wykazywania rzekomej inteligencji podobnej do ludzkiej; maszyny mogą teraz wykonywać niektóre złożone zadania, takie jak rozpoznawanie obrazu i autentyczna gra, a także lepiej niż ludzie. Niektórzy twierdzą, że wymagane podejście jest zdecydowanie nieludzkie, ale bez względu na środki do osiągnięcia tych innowacji, takie sukcesy nie poszły w ślad za analogicznymi sukcesami w opiece zdrowotnej.<br/>Dramatycznym przykładem tej nierówności osiągnięć jest AlphaZero, silnik gier komputerowych, który opanował szachy, Shogi i Go. Jeszcze przed pojawieniem się obecnej generacji artefaktów napędzanych danymi, wykazano, że silniki szachowe są w stanie grać na wyższym poziomie niż mistrzowie szachowi. Gracze z Go (gra planszowa, która jest uważana za znacznie bardziej złożoną niż szachy), uważali jednak, że komputery nie pasują do profesjonalistów na wysokim poziomie w tej grze. Ta wiara została zniszczona najpierw przez AlphaGo, który mocno pokonał panującego mistrza świata Go. Następnie przyszedł AlphaZero. Wiadomość jest już, że takie podejścia mogą pokonać mistrzów Go, szachy, lub Shogi. Niezwykłym faktem jest to, że AlphaZero nie uczył się na ludzkich doświadczeniach i że pokonał najlepsze wcześniejsze silniki szachowe, takie jak Stockfish. AlphaZero triumfował, grając więcej gier przeciwko sobie niż kiedykolwiek grał przez wszystkich ludzkich graczy. Nie jest to podejście, które można łatwo powielić w opiece zdrowotnej.<br/>Dr Nelson („Ostrożny”):<br/>Czy wygrana gry, z określonymi zasadami i celami, jest naprawdę najlepszym testem ludzkiej inteligencji? Patrząc wstecz, odpowiedź brzmi: "Nie". Na przykład wyrafinowane programy do gry w szachy istnieją od prawie 50 lat; z takich programów nauczyliśmy się organizować zasoby obliczeniowe w celu zastosowania prostych algorytmów w skalowalny sposób. Inaczej mówiąc, nie nauczyliśmy się niczego o szachach ani o tym, jak ludzie, nawet eksperci, w nie grają. Zamiast tego dowiedzieliśmy się, że domniemane zadanie wymagające inteligencji jest podatne na podejście obliczeniowe. Musimy zapytać, gdzie i w jaki sposób takie podejście ma zastosowanie w opiece zdrowotnej.<br/>Na przykład podczas wykonywania zadań, które są ogólnie uważane za ludzkie i kreatywne, maszyna może rozpoznać, kiedy jest poza swoją głębią? Czasami ludzie mają możliwość tego zrobić. Jeśli jednak możemy zdefiniować królestwo wystarczająco dokładnie, zgadzam się, że maszyny mogą czynić cuda. Jak więc zdefiniować królestwo?<br/>W głównej pracy Bloisa na temat osądu klinicznego i komputerów , opisał świat procesu myślenia lekarza podczas oglądania pacjenta, z diagramem pokazanym w . Punkt A dla lekarza byłby miejscem, w którym pacjent wchodzi do drzwi, aby być widzianym po raz pierwszy. Charakter skargi, kontekst, w którym występuje skarga, i wszystkie niezliczone możliwości są obecne. W miarę jak definicja problemu przesuwa się w kierunku punktu B, komputer jest w stanie lepiej zarządzać informacjami i wiedzą niezbędnymi do wysokiej jakości opieki. Jednym ze sposobów, w jaki możemy myśleć o zdefiniowaniu sfery, jest to, że idziemy w kierunku punktu B. Niektórzy informatycy twierdzą, że punkt A dotyczy tylko zarządzania faktami, ale, jak zauważył Blois, chodzi bardziej o znaczenie - coś, co okazało się trudne do powtórzenia obliczeniowo.<br/>Rzeczywiście ważne jest zdefiniowanie sfery aplikacji AI. Wiele zadań w opiece zdrowotnej jest znacznie bardziej złożonych niż gra, a my nie byliśmy świadkami triumfów analogicznych podejść w dziedzinie biomedycznej, które zostały osiągnięte w grze. W kilku badaniach zastosowano najnowszą technologię głębokiego uczenia się (kluczową metodę sztucznej inteligencji) do zbiorów danych biomedycznych [- ]. Specyficzne zastosowania obejmowały przetwarzanie obrazu, przetwarzanie języka naturalnego i przewidywanie ryzyka. Głębokie uczenie się, w porównaniu z tradycyjnymi metodami statystycznymi i uczenia maszynowego, często wykazywało skromne ulepszenia, a nie przełomy [ - ].<br/>Niezależnie od szczegółów tych podejść, stosują one prawie nieograniczone zasoby obliczeniowe do bardzo dużych ilości danych, coś, co jeszcze się nie wydarzyło w opiece zdrowotnej. Dlatego te podejścia mogą okazać się pomocne, ale nie jesteśmy jeszcze pewni.<br/>Na przykład, proste pytanie zadane przez kolegę jest poza naszymi obecnymi możliwościami: Biorąc pod uwagę pacjenta, który zaczyna z cechą zespołu metabolicznego, która cecha zespołu będzie miała tendencję do dalszego wykazywania? Prościej mówiąc, jest to dokładnie takie wyzwanie, z jakim powinno pomóc podejście oparte na danych, a mimo to jest ono obecnie „za horyzontem” ze względu na niewystarczające dane, które zostały zebrane w przeszłości.<br/>Dane są kluczowym wyzwaniem przy stosowaniu podejść opartych na danych w opiece nad pacjentami. Na początek, dane biomedyczne są bardzo złożone. Istnieje wiele różnych typów danych, w tym obraz, tekst, wartości liczbowe, klasyfikacje kategoryczne i sekwencje DNA, reprezentujące dziesiątki tysięcy testów laboratoryjnych, procedur, diagnoz, leków, markerów genetycznych itp. Każdy typ danych ma również swoją własną charakterystykę; na przykład wartość testu laboratoryjnego może wymagać interpretacji w kontekście wieku, płci i aktualnych warunków. Jednak kody diagnostyczne dla różnych chorób mają różne poziomy dokładności.<br/>W analizie danych biomedycznych istnieje również paradoks posiadania za dużo i za mało danych w tym samym czasie. Z jednej strony istnieje ogromna ilość dokumentacji medycznej, mediów społecznościowych i danych z literatury. Wysiłki takie jak Million Veterans Project również zgromadziły ogromną ilość danych DNA. Korzystanie z urządzeń do zadań takich jak śledzenie aktywności i ciągłe monitorowanie glukozy generuje więcej danych niż nasze obecne systemy dokumentacji medycznej mogą trawić. Z drugiej strony, dokumentacja zdrowotna pacjenta jest systemem otwartym z wieloma brakującymi informacjami, w przeciwieństwie do zamkniętego systemu gry w szachy lub Go, gdzie wszystkie dane są dostępne. Pacjenci są obserwowani w nieregularnych odstępach czasu (np. podczas wizyt w klinice lub podczas hospitalizacji) i nigdy nie są poddawani wszelkim możliwym testom lub leczeniu. Czasami śmierć jest jedynym ostatecznym wynikiem.<br/>Zgadzam się, że typy danych są wielorakie i złożone. Proste rozwiązania są niewystarczające, a rozprzestrzenianie się nieistotnych danych w rekordzie, nie wspominając już o obecnej fadzie cięcia i wklejania lub wypełniania w szablonie, zaciemnia to, co ważne.<br/>Jedną z głównych trudności z danymi medycznymi jest nie tylko to, że nie wystarczają, ale także to, że są one obciążone teorią, czyli bardzo niewiele danych jest rutynowo rejestrowanych. Dużo danych w obserwacjach zbiera się tylko wtedy, gdy klinicysta uznał to za stosowne, to znaczy, gdy choroby są testowane na ich nieobecność lub obecność. Jeśli nie ma powodu, aby wykonać test, test nie jest wykonywany. Tylko kilka testów jest wykonywanych rutynowo; transkrybowany zbiór obserwacji fizycznych (jak robi się to w badaniu fizycznym) jest rzadko rejestrowany wystarczająco szczegółowo (nie wspominając o nieobserwacji, która często występuje), aby dostarczyć wystarczających danych do bardziej kompleksowej analizy. Z tego samego powodu badania oparte na zarejestrowanych obserwacjach są często niekompletne i potencjalnie wprowadzające w błąd. Jednak w przypadku przewidywań nieprzeprowadzone obserwacje mogą być krytyczne. Pomyśl o pacjencie z wyżej wymienionym zespołem metabolicznym. Jakich danych nam brakuje?<br/>Podobnie wyniki badań klinicznych nie są kompletnym obrazem. Mimo że uczestnicy zostali wybrani, często wykluczając wiele osób ze względu na skomplikowane warunki, dane zebrane od uczestników są przeznaczone do testowania pewnych hipotez, z wąsko zdefiniowanymi wynikami. Powszechną krytyką jest to, że takie próby są tak sztuczne, że są nieistotne.<br/>Innym problemem jest brak zintegrowanych i znormalizowanych zbiorów danych. Chociaż możemy znaleźć wiele dużych zbiorów danych, często są one niekompletne i trudne do powiązania z innymi informacjami. Na przykład narażenie na środowisko, dieta, aktywność fizyczna i profil genetyczny są jednymi z powszechnych brakujących informacji, gdy badamy zapisy dotyczące indywidualnego pacjenta. Szczegółowe zestawy danych z badań klinicznych mają tendencję do braku długoterminowej obserwacji. Kwestie prywatności i zachęty pieniężne są również przeszkodami w wysiłkach na rzecz integracji danych.<br/>Prawdziwa interoperacyjność semantyczna do integracji i standaryzacji zbiorów danych wymaga wsparcia zarówno w terminologii, jak i w sposobie jej wykorzystania. Obecnie często wymagana jest interwencja człowieka, aby zinterpretować to, co jeden system mówi do użycia w innym systemie. Sytuacja ta jest niefortunna; możemy mieć nadzieję, że z czasem nastąpią niezbędne połączenia (pomyślmy o tym, jak Stany Zjednoczone przeszły od pomocy operatora przy każdym rozmowie telefonicznej do automatycznego przełączania, które ma miejsce dzisiaj). Taka zmiana może nastąpić tylko wtedy, gdy wiele osób dostrzega potrzebę i wdraża wspólne standardy.<br/>Ponadto pojęcie „dużych” w kontekście danych dotyczących opieki zdrowotnej jest jedynie względne. Zamiast tego pomyśl o wielu eksperymentach przeprowadzonych przez Google; jeśli chcą, ilość danych, które można wykorzystać do opracowania i przetestowania modelu, jest o wiele większa niż ta dostępna w opiece zdrowotnej.<br/>W dziedzinach, w których podejścia oparte na danych wykazały sukces, istnieją wyniki, które mogą być oceniane przez ekspertów ludzkich lub samych maszyn. Na przykład dwujęzyczne osoby mogą stwierdzić, czy tłumaczenie języka naturalnego działa dobrze, a wynik gier planszowych lub komputerowych można łatwo określić. Umożliwia to łatwiejszą symulację lub adnotację danych do uczenia maszynowego. Takie zadanie jest znacznie trudniejsze w dziedzinach biomedycznych; badanie przyczyn lub leczenia chorób u ludzi wymaga kosztownych i długoterminowych badań. W niektórych przypadkach obawy etyczne zabraniają eksperymentów; na przykład wprowadzenie potencjalnie szkodliwych mutacji genetycznych u zdrowych osób ludzkich nie jest kwestią. Brakuje nam długoterminowych danych o wynikach wielu terapii.<br/>Nie jestem pewien, czy kiedykolwiek będzie taki standard złota bez całkowicie arbitralnej definicji. Różnice między jednostkami są również główną przeszkodą. Chociaż przeprowadzamy badania z wykorzystaniem wielu podmiotów, aby uwzględnić zmienność biologiczną, nasze wyniki są tylko przybliżone pod względem ich znaczenia dla danej osoby. Na przykład zapewnienie różnorodności genetycznej w badaniach klinicznych jest wyzwaniem. Nawet najprostsze zadania mogą być zaskakująco wieloczynnikowe; na przykład zawartość informacji z testów genetycznych na metabolizm warfaryny może być przeważona przez to, czy pacjent miał sałatę na obiad.<br/>Aby rozwinąć tę obserwację, przypuśćmy, że masz samochód, który nie działa prawidłowo. Dziś konsultujesz się z czujnikami i odczytem komputera, aby uzyskać bardzo dokładne informacje o tym, co się dzieje. Samochód ma specyficzną konstrukcję, ze specyficznymi parametrami, które można zmierzyć. Wszystkie pojazdy tego samego roku marki i modelu można założyć, że są podobne w tych ważnych aspektach. Ważne jest, aby uświadomić sobie, że każdy człowiek (z wyjątkiem jednojajowych bliźniąt) jest genetycznie wyjątkowy. W ten sposób ludzie bardzo różnią się od samochodów lub innych urządzeń mechanicznych. Łączenie złożoności, z jaką można rozwiązać przyczynę ludzkiego problemu, to, co jednostka doświadcza przez całe życie, jest wyjątkowe. Chociaż mamy ładne abstrakcje lub metody identyfikacji osób, które dzielą pewne wspólne cechy (czy to obecność lub brak choroby, odpowiedź lub jej brak na lek, podobne środowisko lub inne względy), są to tylko notatki skrócone. Z 7 miliardów ludzi żyjących obecnie na tym świecie, problem wydaje się niemal otwarta. Zbyt często w analizie danych, patrzymy na kody diagnostyczne jako mają głęboki sens. Są one akceptowane bez uznania stopnia niepewności diagnozy. Wszystkie nasze dane mogą być pomocne i przydatne, ale musimy nadal patrzeć na nie z dużym ziarenkiem soli. Fakt, że Tłumacz Google działa tak dobrze, jak działa, daje nam nadzieję, ale tak skomplikowane jak tłumaczenie języka naturalnego, jest prostsze niż niektóre zadania kliniczne.<br/>Pomimo tych wyzwań, zastosowanie podejścia opartego na danych ma potencjał do przekształcenia opieki zdrowotnej. Dzisiejsza opieka zdrowotna jest intensywna, od planowania i sortowania po diagnozę i leczenie. Wiele zadań podejmowanych obecnie przez ludzi może być realizowanych za pomocą inteligentnych rozwiązań programowych wspieranych przez wystarczającą ilość danych. Na przykład ulepszona technologia rozpoznawania głosu i podsumowywania może pomóc zmniejszyć ilość czasu spędzanego przez pacjentów i klinicystów na papierkowej pracy. Ulepszone narzędzia wspomagające podejmowanie decyzji powinny być w stanie pomóc pacjentom w podjęciu decyzji o stosowności poszukiwania opieki. Dokładna ocena krótko- i długoterminowych zagrożeń i korzyści poinformuje o wyborze leczenia i zmianach stylu życia.<br/>Aby przedstawić inny przypadek użycia, istnieją dowody na to, że cukrzyca typu II może być odwracalna, ale trudno jest zastosować tę wiedzę do indywidualnego pacjenta. Biorąc pod uwagę pacjenta przede mną, co powinienem zrobić lub polecić i z jakim oczekiwaniem? Demografia, genomika, choroby współistniejące, psychika, konkurencyjne ryzyko i inne leki – wszystko to odgrywa rolę. Jak w danej osobie pogodzić wszystkie możliwości?<br/>Aby opracować te przydatne narzędzia sztucznej inteligencji, potrzebujemy lepszych danych, technologii i polityki. Aby gromadzić kompleksowe dane przez całe życie, pacjenci muszą mieć kontrolę i powinni być zachęcani do udostępniania swoich danych do badań i opieki. Instytucje ubezpieczeniowe, farmaceutyczne i medyczne zmieniają się z biegiem czasu. Obecnie istnieją bariery dla osób fizycznych, aby być centrum gromadzenia danych o sobie. Bariery są obecne w wprowadzaniu danych, gromadzeniu i przechowywaniu; na przykład niektóre spersonalizowane produkty z dokumentacji zdrowotnej są przywiązane do instytucji, podczas gdy inne wymagają dużych wysiłków transkrypcyjnych przez pacjentów lub opiekunów. Niemniej jednak, bez zgody pacjenta i współpracy, gromadzenie i łączenie wzdłużnych danych środowiskowych, genetycznych, klinicznych i behawioralnych nie jest ani wykonalne, ani etyczne. Obecne warunki stanowią ogromną barierę dla wszelkich prób wykorzystania podejść opartych na danych, które działały poza opieką zdrowotną.<br/>Wysiłki, w tym PatienstLikeMe i All of Us Research Project Narodowego Instytutu Zdrowia [ ] są przykładami innowacyjnych podejść do kuracji większych i lepszych zbiorów danych. Większość pacjentów nie angażuje się jednak w takie wysiłki. Pacjenci są z natury zmotywowani do poprawy własnego zdrowia, ale naturalnie mają obawy dotyczące prywatności i często nie widzą natychmiastowych korzyści z udziału w badaniach długoterminowych. Potrzebne są odpowiednie zachęty (np. zniżki na rutynową opiekę profilaktyczną) w połączeniu z technologiami bezpieczeństwa i uwierzytelniania, aby zachęcić dużą i zróżnicowaną populację pacjentów do gromadzenia i udostępniania swoich danych. Dzisiejsza branża opieki zdrowotnej jest właścicielem części danych pacjentów i ma ograniczoną motywację do zakupu danych od swoich klientów. Wraz ze wzrostem wartości danych pacjenci stają się coraz bardziej cenieni jako partnerzy.<br/>Zgadzam się, że pacjenci będą musieli wziąć na siebie odpowiedzialność za przenoszenie i dzielenie się informacjami o sobie. Jednak doświadczenie mówi nam, że nie każdy jest w stanie lub chce to zrobić. Potrzebne będą zmiany klimatu kulturowego i politycznego, aby zachęcić do takiego rozwoju.<br/>Kiedy będziemy mogli zebrać dane, które nie są bezpośrednio tym, co filozofowie nazwaliby "teorią obciążoną", możemy być w stanie udoskonalić nasze surowe metody diagnostyki i opieki nad pacjentem. Czekam na ten dzień. Jeśli pacjenci są nosicielami tych danych, łatwiej będzie je uzyskać i wykorzystać do analizy.<br/>Musimy również zaprojektować i wdrożyć metody specjalnie do obsługi bardzo dużych i "nieczystych" danych klinicznych. Na przykład musimy zrozumieć kontekst brakujących danych i błędów, aby uzyskać lepszy obraz prawdy. Wynik laboratoryjny może być pominięty, ponieważ nie ma na to wskazań, preferencji praktyki, alternatywnej metody oceny lub niepowodzenia w wprowadzaniu danych. Wyobraź sobie, jak trudniej byłoby grać w szachy, gdyby człowiek lub silnik szachowy mógł obserwować tylko niektóre kwadraty na planszy w nieregularnych odstępach czasu z pewnym błędem lub zniekształceniem obserwacji.<br/>Co więcej, nie mamy operacyjnej definicji „prawdy gruntowej” w opiece zdrowotnej; prostą propozycją jest to, że jedną z cech prawdy gruntowej jest to, że ma ona wartość predykcyjną – coś, co będzie cenione zarówno przez klinicystów, jak i pacjentów.<br/>Google zademonstrowało, że może wykorzystać wiele danych do przewidywania prawdopodobnych wartości brakujących danych w innych obszarach; jednak jeszcze nie ustalono, czy może to zadziałać w medycynie, ale prawdopodobnie warto to przetestować. Niezależnie od tego, czy możemy wykorzystać duże ilości danych do przypisywania brakujących wartości, kluczowe jest zbadanie, jak radzić sobie z problemem nieobecności obserwacji, zwłaszcza gdy próbujemy zastosować wyniki podejścia opartego na danych do poszczególnych pacjentów.<br/>Inną myślą jest to, że brakujące dane, z jakiegokolwiek powodu, są obserwacją samą w sobie; fakt, że dane nie zostały uzyskane i zarejestrowane, może być ważny. Pomyśl o odkryciu, że dzień i godzina testu były bardziej przewidywalne niż wynik testu. Wiemy, że brakujące dane będą miały pewną wartość predykcyjną.<br/>Z drugiej strony, wyjaśnienie modeli opartych na danych ma kluczowe znaczenie nie tylko dla ich przyjęcia, ale także dla ich wpływu. Pożądane jest przewidywanie, że pacjent będzie miał pewne zdarzenia niepożądane w ciągu najbliższych kilku dni lub lat. Można argumentować, że jeszcze ważniejsze jest poznanie modyfikowalnych czynników, które mogą zmniejszyć ryzyko i poprawić wyniki. Ponieważ modele głębokiego uczenia się mogą być wysoce nieliniowe, mamy możliwość odkrywania nowych i złożonych wzorców.<br/>Zgadzam się, że wyjaśnienie przewidywania jest krytyczne; jest to coś, co oddziela opiekę zdrowotną od, powiedzmy, rozpoznawania, czy obraz jest psem czy kotem. Jednak myślę, że miałeś na myśli przewidywanie pacjenta prawdopodobnie będzie miało jakiś niekorzystny wynik. Nic w życiu nie jest pewne, z wyjątkiem tego, że się skończy. Możemy jednak powiedzieć, że "wydaje się, że to zachowanie lub odkrycie prawdopodobnie wpłynie na twoją przyszłość" i miejmy nadzieję, że będziemy w stanie wyrazić pewien stopień zaufania do tej prognozy.<br/>Ważne jest również nauczenie się wyrażania zaufania do przewidywania. Ile osób naprawdę rozumie statystyki za przewidywaniami, które występują dzisiaj? Jakie są podstawowe założenia za każdym modelem prawdopodobieństwa? Bardziej prawdopodobne jest, że przy częstszym stosowaniu i znajomości stosowania środków pochodnych dla modeli AI doprowadzą do ich akceptacji.<br/>Zgadzam się. Są to wszystkie kroki, które należy podjąć, aby zoptymalizować wykorzystanie dużych zbiorów danych poprzez sztuczną inteligencję w celu poprawy opieki medycznej.<br/>Jako myśl rozstania, musimy być ostrożni o tym, jak inwazyjne podejścia oparte na danych mogą być w procesie opieki. Chociaż McDonald wykazał, że wydajność w opiece poprawia się dzięki przypomnieniom [ ], późniejsze doświadczenie było jednym z zbyt wielu przypomnień, prowadzących do alarmującego zmęczenia. Kiedy opiekunowie decydują się na nadpisanie i ignorowanie przydatnych informacji z powodu przeciążenia, czy coś osiągnęliśmy?<br/>Mam nadzieję, że staranne projektowanie systemów i rozważanie klinicznego przepływu pracy złagodzi problem nadmiernej natrętności. Chociaż kuszące jest po prostu „niech AI to zrobi”, ostatnie doświadczenia z Boeingiem 737 MAX pokazują, że jest w tym niebezpieczeństwo. Ani AI, ani sam pilot nie jest optymalną strategią w locie. W opiece zdrowotnej, angażowanie pacjentów w szerszym zakresie w ich opiekę, wraz ze sztuczną inteligencją i dostawcami, może ostatecznie być podejściem, które działa.<br/>Konflikt interesów<br/>- Blois MS. Wyrok kliniczny i komputery. N Engl J Med 1980 Jul 24;303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Głębokie uczenie się dla opieki zdrowotnej: przegląd, możliwości i wyzwania. Brief Bioinform 2018 Listopad 27;19(6):1236-1246 [DARMOWY Pełny tekst] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. Czy uczenie maszynowe może poprawić przewidywanie ryzyka sercowo-naczyniowego za pomocą rutynowych danych klinicznych? PLoS ONE 2017 Apr 4;12(4):e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT. Głęboki Pacjent: Nienadzorowana reprezentacja przewidzieć przyszłość pacjentów z elektronicznych zapisów zdrowotnych. Sci Rep 2016 maja 17;6(1):26094 [DARMOWY Pełny tekst] [CrossRef] [Medline]<br/>- Quach K. Rejestr. 2019. IBM Watson Health cofa odkrycie leku 'sztuczna inteligencja' po lackluster URL sprzedaży: https://www.theregister.co.uk/2019/04/18/ibm_watson_health [dostęp 2019-10-23]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Skalowane i dokładne głębokie uczenie się z elektronicznych zapisów zdrowia. NPJ Digit Med 2018 May 8;1(1):18 [DARMOWY Pełny tekst] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, i in. Głębokie uczenie się w obrazowaniu medycznym: Ogólny przegląd. Koreański J Radiol 2017;18(4):570. [CrossRef]<br/>- Departament Spraw Weteranów Stanów Zjednoczonych. Milionowy program weteranów (MVP) URL: https://www.research.va.gov/mvp/ [dostęp 2019-10-23]<br/>- Patientslikeme. URL: https://www.patientslikeme.com [dostęp 2019-10-23]<br/>- All of Us Research Program. URL: https://allofus.nih.gov [dostęp 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. Nieuzasadniona skuteczność danych. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Uprzedzenia w elektronicznych danych dotyczących zdrowia wynikające z procesów w systemie opieki zdrowotnej: retrospektywne badanie obserwacyjne. BMJ 2018 Apr 30:k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, Müller H. Przyczynowość i objaśnialność sztucznej inteligencji w medycynie. WIREs Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Protokół oparty przypomnienia komputerowe, jakość opieki i nie-doskonałości człowieka. N Engl J Med 1976 grudzień 09;295(24):1351-1355. [CrossRef]<br/>&#124;AI: sztuczna inteligencja.<br/>&#124;UMLS: Ujednolicony System Językowy Medyczny&#124;<br/>Edytowane przez G Eysenbach; zgłoszone 15.09.19; recenzowane przez A Holzinger; komentarze do autora 14.10.19; zmieniona wersja otrzymana 15.10.19; zaakceptowane 20.10.19; opublikowane 27.11.19Copyright<br/>© Qing Zeng-Treitler, Stuart J Nelson. Pierwotnie opublikowany w Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>Jest to artykuł o otwartym dostępie rozpowszechniany na warunkach licencji Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), która zezwala na nieograniczone wykorzystanie, dystrybucję i reprodukcję na dowolnym nośniku, pod warunkiem że oryginalna praca, po raz pierwszy opublikowana w Journal of Medical Internet Research, jest odpowiednio cytowana. Pełna informacja bibliograficzna, link do oryginalnej publikacji na http://www.jmir.org/, a także te informacje o prawach autorskich i licencji muszą być zawarte. |
| The Story of Selena Quintanilla: A Biography Book for Young Readers (The Story Of: A Biography Series for New Readers) (Paperback)<br/>Most titles are on our shelves or available within 1-5 days.<br/>Discover the life Selena Quintanilla—a story about breaking down barriers in music, for kids ages 6 to 9<br/>Selena Quintanilla was the queen of Tejano music. Before she became a star, Selena was a charismatic young girl who loved singing and performing. She made a lot of sacrifices to become a famous musician, rehearsing her songs and dance moves for hours at a time. Her hard work paid off—she became the first 15-year-old girl to win a Tejano music award and went on to break many records during her career. This Selena biography explores how she went from being a talented girl growing up in Texas to a fashion icon and a world-famous singer.<br/>What sets this Selena book apart:<br/>- Core curriculum—Kids will learn the Who, What, Where, When, Why, and How of Selena’s life, and take a quick quiz to test their knowledge.<br/>- Short chapters—This Selena kids’ book is broken up into brief chapters that make it fun and easy for new readers to discover details about the singer’s life.<br/>- Her lasting legacy—Kids will find out how Selena changed the world of music and why she continues to be a role model for many women and people of color around the globe.<br/>How will Selena’s big spirit and passion for music inspire the child in your life?<br/>About the Author<br/>GLORIA ARJONA teaches Spanish at the California Institute of Technology and is the author of Posadas Unknown Calaveras and ¡Lotería!. She’s also a musician who sings and plays guitar. Learn more at GloriaArjona.com.<br/>“Finally, a Selena book for new readers, one that is told concisely and honestly, and is eminently readable” —Joe Nick Patoski, author of Selena: Como La Flor<br/>“What a wonderful story to inspire girls to follow their dreams. A story that many girls will identify with, especially those from traditional and multicultural families. I liked all the little sidebar lessons throughout the book. Gloria is a very talented teacher.” —Genevieve B. Southgate, director of community programs, Bowers Museum<br/>“Selena Quintanilla’s youthful talent and positive drive are brought to life in Prof. Arjona’s latest book, this one geared to young readers. A highly appealing read highlighting Selena’s flexibility in overcoming obstacles to achieving her dreams and her trailblazing contributions to music and her community. The Callisto Media format of encouraging critical, organized thought via questions, maps, timelines, and a glossary make this an enjoyable learning experience.” —Martin E. Delgado, community library manager<br/>“This is the story of Selena Quintanilla, and what a story it is! In a time where young readers, and young women, need role models more than ever, this book brilliantly depicts the profound humanity, bravery, and talent of a deeply inspiring Latina woman who relentlessly fought for her dream.” —Maite Zubiaurre, UCLA professor | Historia Seleny Quintanilli: książka biograficzna dla młodych czytelników (The Story Of: A Biography Series for New Readers)<br/>Większość tytułów jest na naszych półkach lub dostępna w ciągu 1-5 dni.<br/>Odkryj życie Selena Quintanilla - opowieść o przełamywaniu barier w muzyce dla dzieci w wieku od 6 do 9 lat<br/>Selena Quintanilla była królową muzyki Tejano. Zanim stała się gwiazdą, Selena była charyzmatyczną młodą dziewczyną, która uwielbiała śpiewać i występować. Wiele poświęciła, aby zostać sławną muzyką, godzinami ćwicząc swoje piosenki i ruchy taneczne. Jej ciężka praca się opłaciła - stała się pierwszą 15-letnią dziewczyną, która zdobyła nagrodę muzyczną Tejano i pobiła wiele rekordów w swojej karierze. Ta biografia Seleny bada, jak przeszła od utalentowanej dziewczyny dorastającej w Teksasie do ikony mody i światowej sławy piosenkarki.<br/>Co wyróżnia tę książkę Selena:<br/>- Podstawowy program nauczania - Dzieci nauczą się, kto, co, gdzie, kiedy, dlaczego i jak z życia Seleny i podejmą szybki quiz, aby sprawdzić swoją wiedzę.<br/>Krótki rozdział - Ta książka dla dzieci Seleny jest podzielona na krótkie rozdziały, które sprawiają, że zabawa i łatwe dla nowych czytelników, aby dowiedzieć się szczegółów o życiu piosenkarki.<br/>- Jej trwałe dziedzictwo - Dzieci dowiedzą się, jak Selena zmieniła świat muzyki i dlaczego nadal jest wzorem do naśladowania dla wielu kobiet i kolorowych ludzi na całym świecie.<br/>Jak wielki duch i pasja Seleny do muzyki zainspirują dziecko w twoim życiu?<br/>O autorze<br/>GLORIA ARJONA uczy hiszpańskiego w California Institute of Technology i jest autorką Posadas Unknown Calaveras i ¡Loteria!. Jest również muzykiem, który śpiewa i gra na gitarze. Dowiedz się więcej na GloriaArjona.com.<br/>"Wreszcie, książka Seleny dla nowych czytelników, taka, która jest opowiedziana zwięźle i uczciwie, i jest wyjątkowo czytelna" - Joe Nick Patoski, autor Seleny: Como La Flor<br/>"Co za wspaniała historia, aby zainspirować dziewczyny do podążania za swoimi marzeniami. Historia, z którą wiele dziewcząt utożsamia się, zwłaszcza tych z tradycyjnych i wielokulturowych rodzin. Podobały mi się wszystkie małe lekcje na pasku bocznym w całej książce. Gloria jest bardzo utalentowanym nauczycielem.” – Genevieve B. Southgate, dyrektor programów społecznych w Bowers Museum<br/>Młody talent i pozytywny nastrój Seleny Quintanilli ożywiają się w najnowszej książce prof. Arjony, skierowanej do młodych czytelników. Bardzo atrakcyjna lektura podkreśla elastyczność Seleny w pokonywaniu przeszkód w realizacji jej marzeń i jej pionierskiego wkładu w muzykę i jej społeczność. Format Callisto Media zachęcający do krytycznego, zorganizowanego myślenia za pomocą pytań, map, osi czasu i słownika sprawia, że jest to przyjemne doświadczenie w nauce.” – Martin E. Delgado, menedżer biblioteki społecznościowej<br/>To jest historia Seleny Quintanilli i co to za historia! W czasach, gdy młodzi czytelnicy i młode kobiety bardziej niż kiedykolwiek potrzebują wzorców do naśladowania, książka ta błyskotliwie przedstawia głębokie człowieczeństwo, odwagę i talent głęboko inspirującej latynoskiej kobiety, która nieustannie walczyła o swoje marzenie. —Maite Zubiaurre, profesor UCLA |
| Here's another reason for men to avoid packing on extra pounds over the holidays: A new study has found that losing weight reduces the risk of an aggressive form of prostate cancer.<br/>After tracking the weight of nearly 70,000 men between 1982 and 1992, researchers from the American Cancer Society and the Duke University Prostate Center found that men who lost more than 11 pounds had a lower risk for aggressive prostate cancer than men whose weight remained the same over a decade.<br/>Previous studies have found that obese men have a higher risk of developing aggressive prostate cancer. This study appears to be the first to indicate that recent weight loss can decrease that risk.<br/>In the study reported this month in Cancer Epidemiology, Biomarkers & Prevention, researchers analyzed the height and weight of the men in 1982 and 1992 and every three years after that until 2003. At that time, more than 5,200 of the men — more than 7 percent — had prostate cancer.<br/>Among those cases, about one in eight had a form of cancer that was aggressive but had not spread to other areas of the body. The study's major finding focused on those aggressive cases, with researchers concluding that those who lost 11 or more pounds were 42 percent less likely to develop that form of prostate cancer than those whose weight remained the same.<br/>"Whether it's exactly 40 percent, we don't know, but they lower their risk when they lose 11-plus pounds. We feel confident, at least in this population, that was real," said lead researcher Dr. Carmen Rodriguez.<br/>More than seven times as many men whose weight remained the same developed aggressive prostate cancer compared to those who lost 11 or more pounds.<br/>"No significant associations" were found regarding the effect of weight gain or loss on the most severe forms of prostate cancer, those that spread throughout the body, the study said.<br/>The number studied was small, the researchers acknowledged, because fewer than 15,000 men lost weight over the time period, and only 1,000 of those developed some form of prostate cancer.<br/>The 69,991 participants were part of a bigger cancer society study of 1.2 million Americans that began in 1982.<br/>Rodriguez said men should avoid putting on extra weight as they get older.<br/>"The main message for men is to not get overweight. If they are overweight, that's another reason to try to lose weight, just to decrease the risk for prostate cancer," said Rodriguez, who works for the Atlanta-based cancer society.<br/>Other than skin cancer, prostate cancer is the most commonly diagnosed cancer for men, and about one in six will get it during his lifetime. It is the second leading cause of cancer death for U.S. men.<br/>The study is considered the first of its kind to examine the role of weight change in the development of prostate cancer, said Dr. Ronald Ennis, director of radiation oncology at St. Luke's-Roosevelt Hospital Center in New York, who was not involved in the study.<br/>"This is one of the best studies" examining the role of weight on prostate cancer, Ennis said. "It does seem to be true that if you are overweight, you are at risk of getting more aggressive forms of prostate cancer and if you lose weight, you can decrease the risk." | Oto kolejny powód, dla którego mężczyźni powinni unikać pakowania nadmiaru kilogramów podczas wakacji: nowe badanie wykazało, że utrata wagi zmniejsza ryzyko agresywnej formy raka prostaty.<br/>Po prześledzeniu wagi prawie 70 000 mężczyzn w latach 1982-1992, naukowcy z American Cancer Society i Duke University Prostate Center odkryli, że mężczyźni, którzy stracili więcej niż 11 funtów, mieli mniejsze ryzyko agresywnego raka prostaty niż mężczyźni, których waga pozostawała taka sama przez dekadę.<br/>Wcześniejsze badania wykazały, że otyli mężczyźni mają większe ryzyko rozwoju agresywnego raka prostaty. Badanie to wydaje się być pierwszym, który wskazuje, że ostatnia utrata masy ciała może zmniejszyć to ryzyko.<br/>W badaniu zgłoszonym w tym miesiącu w Cancer Epidemiology, Biomarkers & Prevention, naukowcy analizowali wzrost i wagę mężczyzn w 1982 i 1992 roku, a następnie co trzy lata do 2003 roku. W tym czasie ponad 5200 mężczyzn - ponad 7% - miało raka prostaty.<br/>Wśród tych przypadków około jeden na osiem miał formę raka, która była agresywna, ale nie rozprzestrzeniła się na inne obszary ciała. Główne odkrycie badania koncentrowało się na tych agresywnych przypadkach, a naukowcy doszli do wniosku, że ci, którzy stracili 11 lub więcej kilogramów, byli o 42% mniej narażeni na rozwój tej formy raka prostaty niż ci, których waga pozostała taka sama.<br/>"Czy to dokładnie 40 procent, nie wiemy, ale obniżają ryzyko, gdy tracą 11 plus funtów. Czujemy się pewni, przynajmniej w tej populacji, że było to prawdziwe" - powiedział główny badacz dr Carmen Rodriguez.<br/>Ponad siedem razy więcej mężczyzn, których waga pozostała taka sama, rozwinęło agresywnego raka prostaty w porównaniu do tych, którzy stracili 11 lub więcej funtów.<br/>"Nie znaleziono znaczących skojarzeń" dotyczących wpływu przyrostu masy ciała lub utraty masy ciała na najcięższe formy raka prostaty, te, które rozprzestrzeniają się w całym organizmie.<br/>Naukowcy przyznali, że liczba badanych była niewielka, ponieważ mniej niż 15 000 mężczyzn straciło na wadze w czasie, a tylko 1000 z nich rozwinęło jakąś formę raka prostaty.<br/>69 991 uczestników było częścią większego badania społeczeństwa onkologicznego z udziałem 1,2 miliona Amerykanów, które rozpoczęło się w 1982 roku.<br/>Rodriguez powiedział, że mężczyźni powinni unikać przybierania na wadze w miarę starzenia się.<br/>"Głównym przesłaniem dla mężczyzn jest nie nadwaga. Jeśli mają nadwagę, jest to kolejny powód, aby spróbować schudnąć, aby zmniejszyć ryzyko raka prostaty" - powiedział Rodriguez, który pracuje dla Atlanta Cancer Society.<br/>Poza rakiem skóry, rak prostaty jest najczęściej zdiagnozowanym rakiem u mężczyzn, a około jeden na sześć zachoruje na niego w ciągu swojego życia. Jest to druga wiodąca przyczyna zgonów z powodu raka u mężczyzn w USA.<br/>Badanie jest uważane za pierwsze w swoim rodzaju, aby zbadać rolę zmiany masy ciała w rozwoju raka prostaty, powiedział dr Ronald Ennis, dyrektor onkologii promieniowania w St Luke's-Roosevelt Hospital Center w Nowym Jorku, który nie był zaangażowany w badanie.<br/>"Jest to jedno z najlepszych badań" badających rolę wagi w raku prostaty, powiedział Ennis. "Wydaje się, że to prawda, że jeśli masz nadwagę, jesteś narażony na bardziej agresywne formy raka prostaty, a jeśli schudniesz, możesz zmniejszyć ryzyko." |
| If you have studied the OSI model with its 7 Layers that describe communication on computer network systems, you should know that the Ethernet standard lies in Layer 1 (Physical) and Layer 2 (Data-Link) of the OSI model.<br/>In this article we will focus on the physical (Layer 1) part of Ethernet, which mainly focuses on the wired physical medium (cabling) that is used to transport Ethernet frames in a network.<br/>Ethernet cables connect devices to computer networks, the “heart” of which is usually an Ethernet switch which has several interface ports for “plugging-in” the cables.<br/>Most of these Ethernet cables feature the standard RJ45 connector for plugging-in to a switch. However, Ethernet communication can be implemented also using Fiber-optic cabling which uses different types of connectors.<br/>Moreover, there are different types of Ethernet cables with varying bandwidths, speeds and types of construction. In this article we will discuss the “copper-made” cables which are the most popular ones in computer networks.<br/>The cables have labels indicating the standard used for manufacturing, ranging from category (cat) 3 to 7.<br/>Ethernet cables consist of several (usually 8) smaller wires (inside the main cable) which are separated in Twisted-pairs. This setup helps in cancelling-out electromagnetic interference between wires, thus allowing signals to travel longer distances inside the wires.<br/>Without the right cable (and of course without the right type of switch), you may experience slower speeds in the network between devices.<br/>Let’s now describe each Category of Ethernet Cables with their characteristics:<br/>&#124;Max Length&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m<br/>(55 m for 10Gbps)<br/>&#124;100 m&#124;&#124;100 m&#124;<br/>&#124;Max Speed&#124;&#124;10 Mbps&#124;&#124;100 Mbps&#124;&#124;1 Gbps&#124;&#124;10 Gbps&#124;&#124;10 Gbps&#124;&#124;>10 Gbps&#124;<br/>&#124;Frequency Bandwidth&#124;&#124;16 MHz&#124;&#124;100 MHz&#124;&#124;100 MHz&#124;&#124;250 MHz&#124;&#124;500 MHz&#124;&#124;600 MHz&#124;<br/>&#124;Shielded / Unshielded&#124;&#124;Unshielded&#124;&#124;Unshielded&#124;&#124;Unshielded&#124;&#124;Shielded or Unshielded&#124;&#124;Shielded&#124;&#124;Shielded&#124;<br/>1) Cat 3<br/>One of the oldest Ethernet cabling standards is category (cat) 3 (TIA/EIA-568-B). These cables allowed 10 Mbps transmission speeds with 16 MHz max bandwidth.<br/>Cat 3 ethernet cables feature unshielded twisted pair (UTP) cabling. With UTP cables, manufacturers twist insulated copper wires together inside a polyethylene jacket. Compared to shielded ethernet cables, UTP cables tend to include more crosstalk.<br/>Network connections commonly featured category 3 ethernet cables until the early 1990s, when category 5 cables replaced cat 3. While some older telephone systems may still use cat 3 cables, they have mostly become obsolete in the networking industry.<br/>2) Cat 5<br/>Cat 5 cables increased the bandwidth of Ethernet connections up to 100 MHz and offered transmission speeds up to 100 Mbps. With Cat 5 ethernet cables, users could access 100BASE-TX ethernet systems, referred to as fast ethernet.<br/>As with the category 3 cables, cat 5 cables still feature crosstalk and interference, due to the UTP design. These cables include four pairs of twisted wires (for a total of 8 wires).<br/>While cat 5 cables primarily provide connections for Ethernet applications, these cables also provide solutions for carrying other data signals, such as video and telephone. In fact, a single cat 5 cable can carry two standard phone lines and a 100BASE-TX connection.<br/>3) Cat 5e<br/>In 2001, the category 5e standard replaced category 5. The letter “e” in the name stands for enhanced.<br/>The cabling still uses unshielded twisted pairs. There are no physical differences between cat 5 and cat 5e cables. However, stricter standards in manufacturing Cat5e cables help minimize crosstalk and allow higher data transmissions than Cat5.<br/>Cat 5e cables also utilize two sets of twisted pairs of wires, resulting in faster speeds. While cat 5e ethernet cable still features 100 MHz bandwidth, these cables allow speeds up to 1000 Mbps (1 Gbps).<br/>While several additional standards have come after cat 5e, these cables remain in production. In fact, due to the lower cost of production and support for gigabit ethernet, cat 5e cables are the most used for network applications throughout the world.<br/>4) Cat 6<br/>Cat 6 ethernet cables helped address issues related to interference and crosstalk. These cables use thinner wires and superior insulation, resulting in a better signal-to-noise ratio.<br/>With these features, cat 6 cables provide a more effective option for adding cable in areas with more electromagnetic interference, such as a crowded server room.<br/>Thanks to the superior design, cat 6 provides improved bandwidth. These cables have a max bandwidth of 250 MHz and max transmission speeds up to 1000 Mbps (1 Gbps) at the 100m range. However, 10Gbps can be achieved in Cat6 in smaller distances (up to 55m).<br/>Some cat 6 cables include shielding while others remain unshielded. With shielding, these cables can provide transmission speeds up to 10 Gbps, but only for short distances as we said above.<br/>5) Cat 6a<br/>Category 6a ethernet cables improve the design of the cat 6 cables. The letter “a” stands for augmented. Unlike cat 6 cables, all cat 6a cables feature shielded cabling for reduced interference.<br/>With the enhancements to the design specifications, cat 6a cables maintain higher transmission speeds and 500 MHz max bandwidth, allowing speeds up to 10000 Mbps (10 Gbps) across longer cables.<br/>While these cables provide faster speeds, the design makes them less flexible. To eliminate crosstalk, these cables feature thicker sheathing, making the cables stiffer and more difficult to work.<br/>6) Cat 7<br/>One of the latest developments is Cat 7 Ethernet cables. Also called class F channel cables, these cables include stricter standards compared to previous categories. The individual wire pairs now include their own shielding, in addition to the outer shielding<br/>With these cables, you get 600 MHz max bandwidth and 10000 Mbps (10 Gbps) transmission speeds. However, by almost completely getting rid of crosstalk, cat 7 ethernet cables offer even greater reliability for 10 Gbps Ethernet connections.<br/>With connections less than 15 meters, cat 7 can support transmission speeds up to 100 Gbps. While the industry has released several new standards since cat 7, these cables are currently the top of the line option for demanding networking applications.<br/>- What is OSPF NSSA (Not So Stubby Area) and How is it Configured?<br/>- Comparison of BOOTP vs DHCP Protocols in Computer Networks<br/>- Pros and Cons of SD-WAN in Networks – Description and Discussion<br/>- Comparison of GNS3 vs EVE-NG vs Packet Tracer for Networks Simulation<br/>- Subnetting vs Supernetting – What’s the Difference? (Explanation Guide) | Jeśli studiowałeś model OSI z jego 7 warstwami, które opisują komunikację w systemach sieci komputerowych, powinieneś wiedzieć, że standard Ethernet znajduje się w warstwie 1 (fizycznej) i warstwie 2 (Data-Link) modelu OSI.<br/>W tym artykule skupimy się na fizycznej (warstwa 1) części Ethernetu, która skupia się głównie na przewodowym medium fizycznym (kablowaniu) wykorzystywanym do transportu ramek Ethernetu w sieci.<br/>Kable Ethernet łączą urządzenia z sieciami komputerowymi, których "sercem" jest zwykle przełącznik Ethernet, który ma kilka portów interfejsu do "podłączania" kabli.<br/>Większość z tych kabli Ethernet posiada standardowe złącze RJ45 do podłączenia do przełącznika. Jednak komunikacja Ethernet może być również realizowana za pomocą okablowania światłowodowego, które wykorzystuje różne typy złączy.<br/>Ponadto istnieją różne typy kabli Ethernet o różnych przepustowościach, prędkościach i rodzajach konstrukcji. W tym artykule omówimy kable "miedziane", które są najbardziej popularne w sieciach komputerowych.<br/>Kable mają etykiety wskazujące standard stosowany do produkcji, począwszy od kategorii (cat) 3 do 7.<br/>Kable Ethernet składają się z kilku (zwykle 8) mniejszych przewodów (wewnątrz kabla głównego), które są oddzielone w parach skręconych. Ta konfiguracja pomaga w anulowaniu zakłóceń elektromagnetycznych między przewodami, umożliwiając w ten sposób sygnałom przemieszczanie się na większe odległości wewnątrz przewodów.<br/>Bez odpowiedniego kabla (i oczywiście bez odpowiedniego typu przełącznika) możesz odczuwać wolniejsze prędkości w sieci między urządzeniami.<br/>Opiszmy teraz każdą kategorię kabli Ethernet z ich cechami:<br/>&#124;Maks. długość&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m<br/>(55 m dla 10Gbps)<br/>&#124;100 m&#124;&#124;100 m&#124;<br/>&#124;Max Speed&#124;&#124;10 Mbps&#124;&#124;100 Mbps&#124;&#124;1 Gbps&#124;&#124;10 Gbps&#124;&#124;10 Gbps&#124;&#124;>10 Gbps&#124;<br/>Szerokość pasma częstotliwości: 16 MHz: 100 MHz: 250 MHz: 500 MHz: 600 MHz:<br/>&#124;Osłonięta/Unshielded&#124;&#124;Unshielded&#124;Unshielded&#124;Unshielded&#124;Unshielded&#124;Unshielded&#124;Unshielded&#124;Unshielded&#124;Unshielded&#124;Unshielded&#124;Unshielded&#124;Unshielded&#124;<br/>1) Kot 3<br/>Jednym z najstarszych standardów okablowania Ethernet jest kategoria (cat) 3 (TIA/EIA-568-B). Te kable pozwalały na prędkość transmisji 10 Mbps przy maksymalnej przepustowości 16 MHz.<br/>Kable ethernetowe Cat 3 wyposażone są w nieekranowane kable skręcone (UTP). Dzięki kablom UTP producenci skręcają izolowane druty miedziane wewnątrz płaszcza polietylenowego. W porównaniu z ekranowanymi kablami ethernetowymi kable UTP mają tendencję do zawierania większej liczby rozmów krzyżowych.<br/>Połączenia sieciowe były powszechnie wyposażone w kable ethernetowe kategorii 3 aż do początku lat 90., kiedy to kable kategorii 5 zastąpiły kat. 3. Podczas gdy niektóre starsze systemy telefoniczne mogą nadal używać kabli kat. 3, w większości stały się przestarzałe w branży sieciowej.<br/>2) Kot 5<br/>Kable Cat 5 zwiększyły przepustowość połączeń Ethernet do 100 MHz i zaoferowały szybkość transmisji do 100 Mb/s. Dzięki kablom Cat 5 użytkownicy mogli uzyskać dostęp do systemów ethernetowych 100BASE-TX, zwanych szybkimi sieciami ethernetowymi.<br/>Podobnie jak w przypadku kabli kategorii 3, kable kategorii 5 nadal mają rozmów krzyżowych i zakłóceń, ze względu na konstrukcję UTP. Te kable zawierają cztery pary skręconych przewodów (w sumie 8 przewodów).<br/>Podczas gdy kable Cat 5 zapewniają przede wszystkim połączenia dla aplikacji Ethernet, kable te zapewniają również rozwiązania do przenoszenia innych sygnałów danych, takich jak wideo i telefon. W rzeczywistości pojedynczy kabel Cat 5 może przenosić dwie standardowe linie telefoniczne i połączenie 100BASE-TX.<br/>3) Kot 5e<br/>W 2001 r. norma kategorii 5e zastąpiła kategorię 5. Litera "e" w nazwie oznacza wzmocnioną.<br/>Okablowanie nadal wykorzystuje nieekranowane pary skręcone. Nie ma fizycznych różnic między kablami Cat 5 i Cat 5e. Jednak surowsze standardy w produkcji kabli Cat5e pomagają zminimalizować przeplatanie i pozwalają na wyższą transmisję danych niż Cat5.<br/>Kable Cat 5e wykorzystują również dwa zestawy skręconych par przewodów, co skutkuje szybszymi prędkościami. Podczas gdy kabel Cat 5e ethernet nadal ma przepustowość 100 MHz, kable te pozwalają na prędkość do 1000 Mbps (1 Gbps).<br/>Podczas gdy kilka dodatkowych standardów pojawiło się po kat. 5e, kable te pozostają w produkcji. W rzeczywistości, ze względu na niższe koszty produkcji i wsparcie dla gigabitowego ethernetu, kable kat. 5e są najczęściej używane do zastosowań sieciowych na całym świecie.<br/>4) Kot 6<br/>Kable ethernetowe Cat 6 pomogły rozwiązać problemy związane z zakłóceniami i crosstalk. Te kable wykorzystują cieńsze przewody i doskonałą izolację, co skutkuje lepszym stosunkiem sygnału do szumu.<br/>Dzięki tym funkcjom kable Cat 6 zapewniają bardziej skuteczną opcję dodawania kabli w miejscach o większej interferencji elektromagnetycznej, takich jak zatłoczona sala serwerowa.<br/>Dzięki doskonałej konstrukcji, Cat 6 zapewnia lepszą przepustowość. Te kable mają maksymalną przepustowość 250 MHz i maksymalną prędkość transmisji do 1000 Mbps (1 Gbps) w zakresie 100m. Jednak 10Gbps można osiągnąć w Cat6 na mniejszych odległościach (do 55m).<br/>Niektóre kable Cat 6 obejmują ekranowanie, podczas gdy inne pozostają niezasłonięte. Dzięki ekranowaniu kable te mogą zapewnić prędkość transmisji do 10 Gbps, ale tylko na krótkie odległości, jak powiedzieliśmy powyżej.<br/>5) Kot 6a<br/>Kable ethernetowe kategorii 6a poprawiają konstrukcję kabli kat. 6. Litera "a" oznacza rozszerzone. W przeciwieństwie do kabli kat. 6a, wszystkie kable kat. 6a mają ekranowane okablowanie dla zmniejszenia zakłóceń.<br/>Dzięki ulepszeniom specyfikacji projektowych, kable Cat 6a utrzymują wyższą prędkość transmisji i maksymalną przepustowość 500 MHz, umożliwiając prędkość do 10000 Mbps (10 Gbps) na dłuższych kablach.<br/>Podczas gdy te kable zapewniają większe prędkości, konstrukcja sprawia, że są mniej elastyczne. Aby wyeliminować przeplatanie, te kable mają grubszą powłokę, dzięki czemu kable są sztywniejsze i trudniejsze w obsłudze.<br/>6) Kot 7<br/>Jednym z najnowszych osiągnięć są kable Cat 7 Ethernet. Zwane również kablami kanałowymi klasy F, kable te zawierają bardziej rygorystyczne standardy w porównaniu z poprzednimi kategoriami. Poszczególne pary drutów zawierają teraz własne ekranowanie, oprócz zewnętrznego ekranowania<br/>Dzięki tym kablom uzyskasz maksymalną przepustowość 600 MHz i szybkość transmisji 10000 Mbps (10 Gbps). Jednak dzięki niemal całkowitemu pozbyciu się rozmów krzyżowych, kable ethernetowe Cat 7 oferują jeszcze większą niezawodność dla połączeń Ethernet 10 Gbps.<br/>Przy połączeniach mniejszych niż 15 metrów, kat. 7 może obsługiwać prędkość transmisji do 100 Gb/s. Podczas gdy branża wydała kilka nowych standardów od kat. 7, kable te są obecnie na szczycie opcji linii dla wymagających aplikacji sieciowych.<br/>- Co to jest OSPF NSSA (Nie tak Stubby Area) i jak jest skonfigurowany?<br/>- Porównanie protokołów BOOTP i DHCP w sieciach komputerowych<br/>- Plusy i minusy SD-WAN w sieciach – opis i dyskusja<br/>- Porównanie GNS3 vs EVE-NG vs Packet Tracer dla symulacji sieci<br/>- Subnetting vs Supernetting – Jaka jest różnica? (Przewodnik wyjaśniający) |
| Views: 4 Author: Site Editor Publish Time: 2022-06-09 Origin: Site<br/>So why should workers wear a portable gas detector and what does it do?<br/>In many industrial environments, workers need to be highly aware of exposure to toxic or combustible gases and vapours or a lack of oxygen. That’s why portable gas detectors and analysers are essential – so they can detect, measure, monitor and react to any gases in the immediate area around them. KELISAIKE SAFETY offers both single- and multi-gas mobile gas monitors that reliably detect a wide range of gases. All of our portable gas detectors and software are designed to make compliance and asset management as intuitive as possible, so you can implement a complete product solution that helps ensure safety at all times.<br/>Portable gas detectors are classed as a type of Personal Protective Equipment (PPE)<br/>They monitor gases in the workers breathing zone by displaying real-time gas levels of a variety of toxic, combustible, flammable gases<br/>They alert the worker of any possible threats which include combustion and oxygen displacement<br/>While portable gas detectors are available with various sensor configurations and features, they are all built with the same purpose - to protect human life! | Wyświetleń: 4 Autor: Edytor witryny Czas publikacji: 2022-06-09 Pochodzenie: Strona<br/>Dlaczego więc pracownicy powinni nosić przenośny detektor gazu i co to robi?<br/>W wielu środowiskach przemysłowych pracownicy muszą być bardzo świadomi narażenia na toksyczne lub palne gazy i opary lub brak tlenu. Dlatego przenośne detektory i analizatory gazów są niezbędne – mogą wykrywać, mierzyć, monitorować i reagować na wszelkie gazy w bezpośrednim sąsiedztwie. KELISAIKE SAFETY oferuje zarówno jedno-, jak i wielogazowe mobilne monitory gazowe, które niezawodnie wykrywają szeroki zakres gazów. Wszystkie nasze przenośne detektory gazu i oprogramowanie są zaprojektowane tak, aby zapewnić jak najbardziej intuicyjną zgodność i zarządzanie zasobami, dzięki czemu możesz wdrożyć kompletne rozwiązanie produktowe, które pomaga zapewnić bezpieczeństwo przez cały czas.<br/>Przenośne detektory gazu są klasyfikowane jako rodzaj osobistego wyposażenia ochronnego (PPE).<br/>Monitorują gazy w strefie oddychania pracowników, wyświetlając w czasie rzeczywistym poziomy gazów różnych toksycznych, palnych, łatwopalnych gazów<br/>Ostrzegają pracownika o wszelkich możliwych zagrożeniach, które obejmują spalanie i przemieszczanie tlenu.<br/>Podczas gdy przenośne detektory gazu są dostępne z różnymi konfiguracjami i funkcjami czujników, wszystkie są zbudowane w tym samym celu - aby chronić ludzkie życie! |
| Salvador Dalí Biography<br/>The prints of Salvador Dalí are rooted in a rich past. In actuality, Dalí’s prints have a history that dates back to his early years of art school. The young Dalí was taught the fine art of engraving and etching by his mentor. Dalí gained a respect for the technical details of printmaking, a respect he would maintain throughout the rest of his life. The connection between Dalí and graphic prints is in fact intricate and protracted. In his lifetime, Dalí produced just around 1,700 graphic prints. A large number of them are hand-signed, limited-edition editions. Some are regarded as some of the best prints created in the 20th century.<br/>Dalí had the ability to experiment with a wide range of subjects through his print work, including etchings, engravings, mixed media, lithographs, and photo-litho. Dalí would produce beautiful suites or single prints. These suites frequently feature a book motif, with the prints acting as the artwork. Among the literary works Dal illustrated were Alice in Wonderland, Hamlet, and The Old Man and the Sea. Other times, similar suites would focus on different subjects, such as flowers (FlorDal), science fiction (Conquest of the Cosmos), or fine print production (Currier and Ives). Dal also produced single prints that showcased his flawless printmaking skills. Prints by Dalí that are among his best include Flower Man, Symphony Bicyclette, Dream Passage, and The Studio of Dalí.<br/>Although it might be speculated that Dalí produced many more prints than the “approved” ones we attribute to him today, Dal’s first prints appeared in the 1920s. His superb craftsmanship is seen in works like Head of a Young Girl and Immaculate Conception. The graphic piece Les Chants de Maldoror is among Dal’s best-known creations. The stories that separate the suites are a perfect match for the pre-surrealistic aspects of the book. A complete set of this suite is now in high demand. The majority of these early works were etchings and engravings; as Dalí’s printing skills improved, he expanded the range of his mediums and themes.<br/>The 1960s are often referred to as the “Golden Age” of Dalí’s prints. In fact, Dalí produced some of his most creative pieces during this decade. For an edition of The Divine Comedy, he finished one hundred wood block prints. This suite is regarded as a work of genius, and Dalí produced magnificent graphics to complement Virgil’s poetry. A fruitful collaboration with the American publishers Phyllis and Sidney Lucas also began throughout this decade. The Lucas’ and Dalí’s combined efforts would result in some of the most enduring Dal paintings ever. Prints like The Drawers of Memory, Fantastic Voyage, The Lucky Number of Salvador Daíi, The Studio of Dalí, and Departure of The Fishermen are examples of the prints that resulted from their collaboration. For Dalí, these were undoubtedly successful years. Over the course of this decade, Dal finished hundreds of photographs. His output was extraordinarily high. However, some of his best graphic creations remained to be seen.<br/>Dal returned to his melting clocks painting, his most well-known creation, in the 1970s. Some people believe that Dalí’s 1975 lithograph Changes In Great Masterpieces is his best creation overall. The collection consists of six images, five of which are Dalí’s interpretations of paintings by Rembrandt, Vermeer, Raphael, and Velasquez. The Persistence of Memory, Dalí’s own masterwork, is reinterpreted in the sixth picture.<br/>Together with his American publishers, Phyllis and Sidney Lucas, Mozart created this suite. Dalí updates his original piece by including a fourth melting clock. The broken clock creeps through the midst of the scene. The fourth clock, according to some, represents the fourth dimension, or time. Some people think that when Dal revised The Persistence of Memory, some 40 years after the original, he was considering his own transience and legacy and paying homage to the Dal of old.<br/>Changes in Great Masterpieces was only one of Dalí’s outstanding creations during the 1970s. In the suites Moses and Monotheism, Imagination and Objects of the Future, and Alchemy of The Philosophers, he produced some magnificent artwork. His two four-piece “puzzles,” The Rejuvenation of Time and The Puzzle of Life, are his largest lithographs. Ten Recipes of Immortality, a collection of three dimensional “pop-up” prints, is an example of how he expanded the scope of his graphic works into the third dimension. Although the 1960s may have been Dalí’s most productive decade, the 1970s appear to have been his most inventive and creative years as he explored new concepts and pushed himself even farther.<br/>In 1982, Dalí’s final prints were released. Dalí’s health had already started to deteriorate by this point, and his output had significantly decreased. However, Dalí was still able to create some excellent graphic prints despite his advanced age. Portrait of Autumn, which is bathed in gorgeous yellows, greens, and reds, is a glorification of the god Dionysus. Collectors of Dalí’s work see Chevalier Surealiste as a must-have piece, and it pays homage to one of Dalí’s heroes, Velasquez. Crucifixion is a superb example of Dalí’s artistry and a testament to his interest in Roman Catholicism.<br/>Dalí spent his entire life working as a printmaker. When evaluating his legacy, one must take into account the graphic arts creations he developed. Some of Dalí’s most artistic icons and imagery, as well as some of his best uses of his imagination, can be seen in these prints. | Salvador Dalí<br/>Wydruki Salvadora Dalego są zakorzenione w bogatej przeszłości. W rzeczywistości wydruki Dalego mają historię, która sięga wczesnych lat szkoły artystycznej. Młody Dalí został nauczony sztuki grawerowania i trawienia przez swojego mentora. Dalí zyskał szacunek dla szczegółów technicznych grafiki, szacunek, który zachowałby przez resztę życia. Związek między Dalí a grafikami jest w rzeczywistości skomplikowany i długotrwały. Za życia Dalí wyprodukował zaledwie około 1700 wydruków graficznych. Duża liczba z nich to ręcznie podpisane, limitowane edycje. Niektóre z nich są uważane za jedne z najlepszych wydruków stworzonych w XX wieku.<br/>Dalí miał możliwość eksperymentowania z szeroką gamą przedmiotów poprzez swoje prace drukarskie, w tym trawienie, grawerowanie, media mieszane, litografie i foto-litho. Dalí produkował piękne apartamenty lub pojedyncze wydruki. Wśród ilustrowanych dzieł literackich Dal znalazły się Alicja w Krainie Czarów, Hamlet i Stary człowiek i morze. Innym razem podobne apartamenty skupiały się na różnych tematach, takich jak kwiaty (FlorDal), science fiction (Conquest of the Cosmos) lub produkcja drobnego druku (Currier i Ives). Dal produkował również pojedyncze wydruki, które pokazywały jego doskonałe umiejętności grafiki. Wśród jego najlepszych dzieł znalazły się m.in. Flower Man, Symphony Bicyclette, Dream Passage oraz The Studio of Dalí.<br/>Chociaż można spekulować, że Dalí wyprodukował o wiele więcej odcisków niż "zatwierdzone" te, które przypisujemy mu dzisiaj, pierwsze odciski Dal pojawiły się w 1920 roku. Jego doskonałe rzemiosło jest widoczne w pracach takich jak Głowa młodej dziewczyny i Niepokalanego Poczęcia. Grafika Les Chants de Maldoror jest jedną z najbardziej znanych kreacji Dal. Historie, które oddzielają apartamenty, idealnie pasują do przed-surrealistycznych aspektów książki. Kompletny zestaw tego pakietu jest teraz bardzo poszukiwany. Większość z tych wczesnych prac były trawienie i grawerowanie; w miarę poprawy umiejętności drukarskich Dalí, poszerzył zakres swoich mediów i tematów.<br/>Lata sześćdziesiąte są często określane jako „złoty wiek” druków Dalego. W rzeczywistości Dalí wyprodukował jedne z jego najbardziej kreatywnych utworów w tej dekadzie. Dla wydania The Divine Comedy ukończył sto druków z bloków drewna. Ta suita jest uważana za dzieło geniuszu, a Dalí wyprodukował wspaniałą grafikę uzupełniającą poezję Virgila. W tym dziesięcioleciu rozpoczęła się również owocna współpraca z amerykańskimi wydawcami Phyllis i Sidney Lucas. Wspólne wysiłki Lucasa i Dalego doprowadziłyby do powstania jednych z najbardziej trwałych obrazów Dal w historii. Wydruki takie jak Szuflady pamięci, Fantastyczna podróż, Szczęśliwy numer Salvadora Daíi, Studio Dalego i Odjazd Rybaków są przykładami wydruków, które powstały w wyniku ich współpracy. Dla Dalego były to niewątpliwie udane lata. W ciągu tej dekady Dal ukończył setki zdjęć. Jego produkcja była niezwykle wysoka. Jednak niektóre z jego najlepszych twórczości graficznych pozostały do zobaczenia.<br/>Dal powrócił do malarstwa zegarów topnienia, jego najbardziej znanego dzieła, w latach 70. Niektórzy uważają, że litografia Dalí'ego z 1975 r. Zmiany w wielkich arcydziełach jest jego najlepszym dziełem. Kolekcja składa się z sześciu obrazów, z których pięć to interpretacje obrazów Rembrandta, Vermeera, Raphaela i Velasqueza. Wytrwałość pamięci, własne arcydzieło Dalego, jest reinterpretowane w szóstym obrazie.<br/>Wraz ze swoimi amerykańskimi wydawcami, Phyllis i Sidney Lucas, Mozart stworzył ten pakiet. Dalí aktualizuje swój oryginalny utwór, włączając czwarty topliwy zegar. Zepsuty zegar przesuwa się przez środek sceny. Czwarty zegar, według niektórych, reprezentuje czwarty wymiar, czyli czas. Niektórzy uważają, że kiedy Dal rewizji Trwałość pamięci, około 40 lat po oryginału, rozważał swoją własną przejściowość i dziedzictwo i oddać hołd dla Dal dawnych.<br/>Zmiany w wielkich arcydziełach były tylko jednym z wybitnych dzieł Dalego w latach 70. XX wieku. W suitach Mojżesz i Monoteizm, Wyobraźnia i Przedmioty Przyszłości oraz Alchemia Filozofów stworzył wspaniałe dzieła sztuki. Dwie jego czteroczęściowe „puzzle”, Odmłodzenie czasu i Puzzle życia, to jego największe litografie. Dziesięć Przepisów Nieśmiertelności, zbiór trójwymiarowych wydruków "pop-up", jest przykładem tego, jak rozszerzył zakres swoich prac graficznych do trzeciego wymiaru. Chociaż lata sześćdziesiąte mogły być najbardziej produktywną dekadą Dalego, lata siedemdziesiąte wydają się być jego najbardziej wynalazczymi i twórczymi latami, gdy badał nowe koncepcje i popychał się jeszcze dalej.<br/>W 1982 roku ukazały się ostatnie wydruki Dalego. W tym momencie stan zdrowia Dalego już zaczął się pogarszać, a jego produkcja znacznie spadła. Jednak Dalí nadal był w stanie stworzyć doskonałe wydruki graficzne pomimo jego zaawansowanego wieku. Portret jesieni, który jest kąpany w przepięknych żółtych, zielonych i czerwonych kolorach, jest gloryfikacją boga Dionizosa. Kolekcjonerzy dzieł Dalego widzą Chevalier Surealiste jako obowiązkowy kawałek i oddaje hołd jednemu z bohaterów Dalego, Velasquezowi. Ukrzyżowanie jest doskonałym przykładem sztuki Dalego i świadectwem jego zainteresowania katolicyzmem.<br/>Dalí spędził całe życie pracując jako grafik. Oceniając jego dziedzictwo, należy wziąć pod uwagę twórczość grafiki, którą opracował. Niektóre z najbardziej artystycznych ikon i obrazów Dalego, a także niektóre z jego najlepszych zastosowań jego wyobraźni, można zobaczyć na tych wydrukach. |
| English Language A Level<br/>&#124;Mode of study&#124;&#124;Academic A Level&#124;<br/>&#124;Campus&#124;&#124;English Bridge Campus&#124;<br/>&#124;Start date&#124;&#124;4 September 2023&#124;<br/>&#124;Course code&#124;&#124;ENG-AL (2325)&#124;<br/>A minimum of five GCSEs at grade 4 or above, including English Language and English Literature.<br/>Please note: You can study both English A level Literature and A level English Language because the courses are sufficiently distinct that there is no overlap or repetition of content. However, you cannot study A Level English Combined and A Level English Literature, or A Level English Combined and A Level English Language.<br/>What does the course involve?<br/>English is an exciting subject and we hope you’ll enjoy the lively debate and discussion. Whichever English course you choose, you’ll gain a great deal of academic prowess and the development of transferable skills.<br/>You will be taught to think analytically, synthesise information, and develop communication skills that are a prerequisite for a wide range of career paths.<br/>The important skill of learning to write coherently and critically will aid you in your other subjects and is invaluable in higher education.<br/>Language is one of the key features that define us as human beings and, on this course, you will explore how it works: how we learn language from infancy, how we use it as a social tool, and how it has evolved over time. You will learn about the origins of English, the various forms it has taken over the centuries, how it has spread across the globe and what it might look like in the future.<br/>You will also study the research of theorists in areas of language such as speech and gender, accents and dialects, and the language of technology. You will learn about grammar in order to explore the ways writers use language to communicate meaning in texts ranging from blogs to 17th-century journalism.<br/>The NEA (coursework) unit will allow you to write creatively and to undertake an investigation into an aspect of the course you have enjoyed.<br/>How is the course assessed?<br/>80% Exam and 20% Coursework. Two coursework tasks and two externally-assessed exams.<br/>This A Level will equip you with the necessary skills to go into practical professions such as journalism and creative writing as well as academic degrees such as law and media studies. It forms a good companion to A Levels in Psychology and Sociology because there is a degree of crossover with the social sciences. If you are thinking of studying English at university, it is perfectly acceptable to take both English Language and English Literature. English can be combined with a range of other subjects at university.<br/>English provides an excellent foundation for various Higher Education courses including law, medicine, English, linguistics and education. It can be combined with a range of other subjects at university. English offers increasing employability in a range of career areas, especially those that require developed communication skills. Students have gone on to careers in law, health and medicine, commerce and industry, marketing, politics and international relations, general management, as well as leading to more predictable areas like journalism, publishing, the media, education, theatre and public relations.<br/>The student magazine produced by students is part of the enrichment opportunities led by the English Department. Trips include theatre trips to London, Manchester and Stratford-upon-Avon and international trips include a visit to battlefields in France, university taster days, residentials and creative writing workshops. These are all optional but highly recommended. Aspiring Oxford and Cambridge applicants will benefit from our extensive range of activities to support you in making a competitive application including: small group subject tuition, Oxford and Cambridge conferences, visits and contacts with our link staff, access to summer schools, application support and essay competitions, supra-curricular activities and access to free university-level Massive Open Online Courses (MOOC).<br/>What do I do next?<br/>You can apply online via the APPLY NOW button and then add an additional two or three subjects to make up your academic programme. You can also apply for a second, alternative vocational programme of study via a separate application. If after reading this factsheet, you are still undecided about the course most suitable for you, please drop in to one of our Open Evenings, ring Admissions on 01743 260401 or email email@example.com<br/>A Level English Language (Law and Drama & Theatre)<br/>Previous school: Mary Webb School<br/>I came here because it was local to me and I enjoyed the pre-enrolment days which were well organised. English Language is a good A Level to have and it is super interesting to see how language has evolved and changed through time. The teachers are a great help and the resources are brilliant; there are plenty of text books.<br/>Are you an employer?<br/>See how an apprentice can help your business. | Język angielski Poziom<br/>&#124;Moda studiów&#124;&#124;Akademiczny poziom&#124;<br/>&#124;Campus&#124;&#124;English Bridge Campus&#124;<br/>&#124;Data rozpoczęcia&#124;&#124;4 września 2023 r.&#124;<br/>&#124;Kod kursu&#124;&#124;ENG-AL (2325)&#124;<br/>Co najmniej pięć GCSEs w klasie 4 lub wyższej, w tym języka angielskiego i literatury angielskiej.<br/>Uwaga: Możesz studiować zarówno literaturę angielską na poziomie A, jak i język angielski na poziomie A, ponieważ kursy są wystarczająco odrębne, aby nie było nakładania się lub powtarzania treści. Jednak nie można uczyć się języka angielskiego na poziomie połączonym z literaturą angielską na poziomie lub języka angielskiego na poziomie połączonym z językiem angielskim na poziomie.<br/>Co obejmuje kurs?<br/>Angielski jest ekscytującym tematem i mamy nadzieję, że spodoba Ci się tętniąca życiem debata i dyskusja. Niezależnie od tego, jaki kurs języka angielskiego wybierzesz, zyskasz wiele umiejętności akademickich i rozwój umiejętności zbywalnych.<br/>Zostaniesz nauczony myśleć analitycznie, syntetyzować informacje i rozwijać umiejętności komunikacyjne, które są warunkiem wstępnym dla szerokiej gamy ścieżek kariery.<br/>Ważna umiejętność uczenia się pisania spójnie i krytycznie pomoże Ci w innych przedmiotach i jest bezcenna w szkolnictwie wyższym.<br/>Język jest jedną z kluczowych cech, które definiują nas jako ludzi i na tym kursie zbadasz, jak to działa: jak uczymy się języka od niemowlęctwa, jak używamy go jako narzędzia społecznego i jak ewoluowało z biegiem czasu. Dowiesz się o pochodzeniu języka angielskiego, różnych formach, które przybrał na przestrzeni wieków, jak rozprzestrzenił się na całym świecie i jak może wyglądać w przyszłości.<br/>Będziesz również studiować badania teoretyków w dziedzinach języka, takich jak mowa i płeć, akcenty i dialekty oraz język technologii. Dowiesz się o gramatyce, aby zbadać sposoby, w jakie pisarze używają języka do komunikowania znaczenia w tekstach, począwszy od blogów po 17-wieczne dziennikarstwo.<br/>Jednostka NEA (coursework) pozwoli Ci twórczo pisać i przeprowadzić dochodzenie w aspekcie kursu, który Ci się podobał.<br/>Jak ocenia się kurs?<br/>80% egzaminu i 20% zajęć. Dwa zadania zajęć i dwa egzaminy oceniane zewnętrznie.<br/>Ten poziom A wyposaży Cię w niezbędne umiejętności, aby przejść do praktycznych zawodów, takich jak dziennikarstwo i pisanie kreatywne, a także stopni akademickich, takich jak prawo i studia medialne. Stanowi dobry towarzysz do poziomów w psychologii i socjologii, ponieważ istnieje stopień krzyżowania z naukami społecznymi. Jeśli myślisz o studiowaniu języka angielskiego na uniwersytecie, doskonale do przyjęcia jest przyjęcie zarówno języka angielskiego, jak i literatury angielskiej. Angielski można łączyć z wieloma innymi przedmiotami na uniwersytecie.<br/>Angielski stanowi doskonałą podstawę dla różnych kursów szkolnictwa wyższego, w tym prawa, medycyny, języka angielskiego, lingwistyki i edukacji. Może być łączony z szeregiem innych przedmiotów na uniwersytecie. Angielski oferuje zwiększenie szans na zatrudnienie w wielu dziedzinach kariery, zwłaszcza tych, które wymagają rozwiniętych umiejętności komunikacyjnych. Studenci kontynuowali karierę w prawie, zdrowiu i medycynie, handlu i przemyśle, marketingu, polityce i stosunkach międzynarodowych, zarządzaniu ogólnym, a także prowadząc do bardziej przewidywalnych obszarów, takich jak dziennikarstwo, wydawnictwo, media, edukacja, teatr i public relations.<br/>Magazyn studencki produkowany przez studentów jest częścią możliwości wzbogacania prowadzonych przez Wydział Angielski. Wycieczki obejmują wycieczki teatralne do Londynu, Manchesteru i Stratford-upon-Avon, a wycieczki międzynarodowe obejmują wizytę na polach bitew we Francji, dni degustacyjne na uniwersytetach, mieszkania i warsztaty kreatywnego pisania. Wszystkie są opcjonalne, ale wysoce zalecane. Aspirujący kandydaci z Oksfordu i Cambridge skorzystają z naszej szerokiej gamy działań, które pomogą Ci w przygotowaniu konkurencyjnej aplikacji, w tym: lekcje dla małych grup, konferencje Oxford i Cambridge, wizyty i kontakty z naszym personelem linkowym, dostęp do szkół letnich, wsparcie aplikacji i konkursy esejów, zajęcia ponadlekcyjne oraz dostęp do bezpłatnych uniwersyteckich masowych otwartych kursów online (MOOC).<br/>Co mam teraz zrobić?<br/>Możesz ubiegać się online za pomocą przycisku APLIKUJ TERAZ, a następnie dodać dodatkowe dwa lub trzy przedmioty do swojego programu akademickiego. Możesz również ubiegać się o drugi, alternatywny program studiów zawodowych za pośrednictwem oddzielnej aplikacji. Jeśli po przeczytaniu tego arkusza informacyjnego nadal nie jesteś zdecydowany na temat kursu najbardziej odpowiedniego dla Ciebie, wpadnij na jeden z naszych otwartych wieczorów, zadzwoń Przyjęcia na 01743 260401 lub e-mail@example.com<br/>Język angielski na poziomie (prawo i dramat i teatr)<br/>Poprzednia szkoła: Mary Webb School<br/>Przyjechałem tu, ponieważ było to dla mnie lokalne i cieszyłem się dniami przed rejestracją, które były dobrze zorganizowane. Język angielski jest dobrym poziomem i jest bardzo interesujące, aby zobaczyć, jak język ewoluował i zmieniał się w czasie. Nauczyciele są wielką pomocą, a zasoby są genialne; istnieje wiele podręczników.<br/>Czy jesteś pracodawcą?<br/>Zobacz, jak praktykant może pomóc Twojej firmie. |
| In a subproject carried out together with the City of Stockholm within the HazardSupport research project, SMHI has investigated how town planning affects a city’s climate. Scenarios have been produced for Stockholm’s growth up until 2030 and 2050, using summer 2014 as a reference point. These scenarios do not take ongoing climate change into account. Instead, they simply show how the densification and growth of Stockholm can be expected to affect the air temperature.<br/>The main conclusion from the scenarios is that the impact of densification on air temperature is relatively local. No significant effect on the average temperature during the summer is seen at a distance of more than about 2 km, despite extensive densification across large areas. This can be seen in the most central parts of Stockholm, for example, which are already built-up and where no significant reduction in green spaces can therefore be expected. No significant change in air temperature is seen in these areas.<br/>One reason why the densification and expansion of Stockholm has not had any significant impact on air temperature is the relatively rapid air exchange with nearby expanses of water and countryside. Within those areas that are densifying, average summer temperature increases of up to around 1.5°C are being seen. As expected, the biggest temperature increases are observed when natural environments or green areas are built on.<br/>Measures in the local area<br/>One consequence of the locally limited effect of changes in the urban environment is that measures should primarily be focused on direct effects within the local area. Examples of such measures include shady street trees and proximity to green spaces. For the same reason, measures such as green roofs that only indirectly affect the air temperature in the street environment can be expected to have a less significant impact.<br/>A comfort index can be used to summarise the effect of various climate parameters. One example of such an index is the Universal Thermal Climate Index (UTCI). This involves a higher level of ambition in relation to how climate planning is often carried out in today’s planning processes. | W ramach podprojektu realizowanego wspólnie z miastem Sztokholm w ramach projektu badawczego HazardSupport, SMHI zbadał wpływ planowania miejskiego na klimat miasta. Opracowano scenariusze dotyczące wzrostu gospodarczego w Sztokholmie do 2030 i 2050 r., wykorzystując lato 2014 jako punkt odniesienia. Scenariusze te nie uwzględniają trwających zmian klimatu. Zamiast tego po prostu pokazują, w jaki sposób gęstość i wzrost Sztokholmu mogą mieć wpływ na temperaturę powietrza.<br/>Głównym wnioskiem ze scenariuszy jest to, że wpływ zagęszczenia na temperaturę powietrza jest stosunkowo lokalny. Nie ma znaczącego wpływu na średnią temperaturę w okresie letnim z odległości większej niż około 2 km, pomimo rozległego zagęszczenia na dużych obszarach. Można to zaobserwować na przykład w najbardziej centralnych częściach Sztokholmu, które są już zabudowane i w których nie można oczekiwać znacznego zmniejszenia obszarów zielonych.<br/>Jednym z powodów, dla których zagęszczenie i ekspansja Sztokholmu nie miały znaczącego wpływu na temperaturę powietrza, jest stosunkowo szybka wymiana powietrza z pobliskimi obszarami wodnymi i wiejskimi. W tych obszarach, które są gęstsze, obserwuje się wzrost średniej temperatury letniej o około 1,5 ° C. Zgodnie z oczekiwaniami, największy wzrost temperatury obserwuje się, gdy budowane są środowiska naturalne lub tereny zielone.<br/>Środki na obszarze lokalnym<br/>Jedną z konsekwencji miejscowo ograniczonego wpływu zmian w środowisku miejskim jest to, że środki powinny koncentrować się przede wszystkim na bezpośrednich skutkach w obrębie obszaru lokalnego. Przykładami takich środków są zacienione drzewa uliczne i bliskość terenów zielonych. Z tego samego powodu można oczekiwać, że środki, takie jak zielone dachy, które tylko pośrednio wpływają na temperaturę powietrza w środowisku ulicznym, będą miały mniej znaczący wpływ.<br/>Wskaźnik komfortu może być stosowany do podsumowania wpływu różnych parametrów klimatycznych. Przykładem takiego wskaźnika jest Universal Thermal Climate Index (UTCI). Wiąże się to z wyższym poziomem ambicji w odniesieniu do tego, w jaki sposób planowanie klimatyczne jest często realizowane w dzisiejszych procesach planowania. |
