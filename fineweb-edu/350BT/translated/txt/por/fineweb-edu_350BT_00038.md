| original | translation |
|----------|-------------|
| Artificial intelligence (AI), the computerized capability of doing tasks, which until recently was thought to be the exclusive domain of human intelligence, has demonstrated great strides in the past decade. The abilities to play games, provide piloting for an automobile, and respond to spoken language are remarkable successes. How are the challenges and opportunities of medicine different from these challenges and how can we best apply these data-driven techniques to patient care and outcomes? A New England Journal of Medicine paper published in 1980 suggested that more well-defined “specialized” tasks of medical care were more amenable to computer assistance, while the breadth of approach required for defining a problem and narrowing down the problem space was less so, and perhaps, unachievable. On the other hand, one can argue that the modern version of AI, which uses data-driven approaches, will be the most useful in tackling tasks such as outcome prediction that are often difficult for clinicians and patients. The ability today to collect large volumes of data about a single individual (eg, through a wearable device) and the accumulation of large datasets about multiple persons receiving medical care has the potential to apply to the care of individuals. As these techniques of analysis, enumeration, aggregation, and presentation are brought to bear in medicine, the question arises as to their utility and applicability in that domain. Early efforts in decision support were found to be helpful; as the systems proliferated, later experiences have shown difficulties such as alert fatigue and physician burnout becoming more prevalent. Will something similar arise from data-driven predictions? Will empowering patients by equipping them with information gained from data analysis help? Patients, providers, technology, and policymakers each have a role to play in the development and utilization of AI in medicine. Some of the challenges, opportunities, and tradeoffs implicit here are presented as a dialog between a clinician (SJN) and an informatician (QZT).J Med Internet Res 2019;21(11):e16272<br/>Drs Nelson and Zeng-Treitler work together at the Biomedical Informatics Center at George Washington University. In the following we present a hypothetical dialogue which grew out of discussions they had as they considered their differing viewpoints of how artificial intelligence (AI) has developed and where it is going. While Dr Zeng-Treitler’s view of the future of AI is highly optimistic, Dr Nelson's opinion is more cautious. Dr Nelson was a practicing academic internist who became involved in informatics many years ago. He collaborated with Scott Blois on RECONSIDER (an early clinical decision support system) and on the Unified Medical Language System (UMLS) project. He eventually moved to the National Library of Medicine as Head of Medical Subject Headings. While at the National Library of Medicine, he fathered RxNorm, while continuing his work on UMLS and projects involving UMLS. Dr Zeng-Treitler has a background in computer science and obtained her PhD in medical informatics from Columbia University. She has led a number of projects in clinical data mining, natural language processing, and consumer health informatics. During the past few years, her team has been actively investigating the use of AI techniques in clinical research including development of a novel explainable deep learning approach.<br/>Dr Zeng-Treitler (The "Optimist"):<br/>After decades of promises and disappointment, thanks to the seemingly unbounded computing resources and novel, data-driven methods, AI technology has finally arrived. From Jeopardy and Siri to face identification and autonomous vehicles, data-driven approaches have made the leap from laboratory experiments to applications that are transforming our lives outside health care. In some cases, these approaches have come close to passing the Turing Test—a test of a machine’s ability to exhibit supposed human-like intelligence; machines can now perform some complex tasks such as image recognition and authentic game play as well as or better than humans would. Some would argue that the requisite approach is decidedly nonhuman. However, whatever the means to achieving these innovations, such successes have not been followed by analogous successes in health care.<br/>One dramatic example of this disparity of accomplishment is AlphaZero, a computer game engine that mastered chess, Shogi, and Go. Even before the arrival of the current generation of data-driven artifacts, chess engines have been shown to be able to play at a level superior to that of chess champions. Players of Go (a board game that is thought to be much more complex than chess), however, believed that computers were no match for high-level professionals in this game. This belief was shattered first by AlphaGo, which soundly defeated the reigning world champion of Go. Then came AlphaZero. The news is no longer that such approaches can beat the champions of Go, chess, or Shogi. Rather, the remarkable fact is that AlphaZero did not learn from human experiences and that it defeated the best prior chess engines such as Stockfish. AlphaZero triumphed by playing more games against itself than had ever been played by all human players. This is not an approach we could readily duplicate in health care.<br/>Dr Nelson (The "Cautious" One):<br/>Is winning a game, with defined rules and objectives, really the best test of human intelligence? In hindsight, the answer is “No.” For example, sophisticated chess playing programs have existed for nearly 50 years; from such programs, we learned how to organize computing resources to apply simple algorithms in a scalable way. Put differently, we did not learn anything about chess or how humans, even experts, play it. Instead, we learned that a supposed intelligence-requiring task was susceptible to a computational approach. We need to ask where and how such an approach is applicable in health care.<br/>For example, when doing tasks that are generally thought to be human and creative, can the machine recognize when it is out of its depth? Sometimes, humans have the ability to do so. However, if we can define the realm closely enough, I agree that the machines can do wonders. So, how do we define the realm?<br/>In Blois’ seminal paper on Clinical Judgment and Computers , he described the world of a physician’s thought process when seeing a patient, with the diagram shown in . Point A for a physician would be where the patient walks in the door to be seen for the first time. The nature of the complaint, the context in which the complaint occurs, and all of the myriad possibilities are present. As the problem definition moves toward Point B, a computer is better able to manage the information and knowledge necessary for high-quality care. One way in which we can think about defining the realm is that we are moving toward Point B. Some computer scientists have argued that Point A is just about managing facts, but, as Blois observed, it is more about relevance—something that has proven difficult to replicate computationally.<br/>It is indeed important to define the realm for an AI application. Many tasks in health care are much more complex than game play, and we have not witnessed the triumphs of analogous approaches in the biomedical domain as have been achieved in game play. Quite a few studies have been applying the latest deep learning technology (a key AI method) to biomedical datasets [- ]. The specific applications included image processing, natural language processing, and risk prediction. Deep learning, compared with traditional statistical and machine learning methods, has often shown modest improvements rather than breakthroughs [ - ].<br/>Whatever the details of these approaches, they apply nearly unbounded computing resources to very large amounts of data, something that has yet to happen in health care. Therefore, these approaches might prove helpful, but we do not know for sure yet.<br/>For example, a simple question posed by a colleague is beyond our current capabilities: Given a patient who starts out with a feature of metabolic syndrome, which feature of the syndrome will he or she tend to exhibit next? Simplistically, this is exactly the kind of challenge that a data-driven approach should help with, and yet, it is currently “over the horizon” due to the insufficient data that were collected in the past.<br/>Data are a key challenge when applying data-driven approaches to patient care. To begin with, biomedical data are highly complex. There many different types of data including image, text, numerical values, categorical classifications, and DNA sequences, representing tens of thousands of lab tests, procedures, diagnoses, medications, genetic markers, etc. Each data type also has its own characteristics; for example, a laboratory test value may need to be interpreted in the context of age, gender, and current conditions. However, diagnostic codes for different diseases have varying levels of accuracies.<br/>In biomedical data analysis, there is also the paradox of having too much and not enough data at the same time. On one hand, there are a tremendous amount of medical record, social media, and literature data. Efforts like the Million Veterans Project  have also collected a huge amount of DNA data. Using devices for tasks like activity tracking and continuous glucose monitoring generates more data than our current medical record systems can digest. On the other hand, the health record of a patient is an open system with much missing information in contrast with the closed system of a chess or Go game, where all data are available. Patients are observed at irregular intervals (eg, at clinic visits or during hospitalization) and are never subjected to all possible tests or treatments. Sometimes, death is the only definitive outcome.<br/>I agree that data types are multiple and complex. Simple solutions are insufficient, and the proliferation of irrelevant data in a record, not to mention the current cut-and-paste or fill-in-the-template fad, obscures what is important.<br/>One of the major difficulties with medical data is not just that it is not enough, but also that it is theory laden, that is, very few pieces of data are recorded routinely. A lot of data in observations are gathered only when the clinician has thought it is appropriate, that is, when diseases are tested for their absence or presence. If there is no reason to do the test, the test is not performed. Only a few tests are ever performed routinely; a transcribed set of physical observations (as is done in physical examination) is rarely recorded in enough detail (not to mention the failure to observe, which often occurs) to provide sufficient data for a more comprehensive analysis. For that reason alone, studies based on the recorded observations are often incomplete and potentially misleading. However, for predictions, observations not made may be the critical ones. Think about the patient with metabolic syndrome mentioned above. What data are we missing?<br/>Similarly, the results of clinical trials are not a complete picture. Even though participants have been selected, often excluding many individuals because of complicating conditions, the data collected on the participants are designed for testing certain hypotheses, with narrowly defined outcomes. A common criticism is that such trials are so artificial that they are irrelevant.<br/>The lack of integrated and standardized datasets is another issue. Although we can find many large datasets, they are often incomplete and difficult to link to other information. For example, environmental exposure, diet, physical activity, and genetic profile are among the common missing pieces of information when we examine the records about an individual patient. Detailed clinical trial datasets tend to lack long-term follow-up. Privacy issues and monetary incentives are also obstacles in data integration efforts.<br/>Real semantic interoperability to integrate and standardize datasets requires support in both terminology and how that terminology is used. Currently, human intervention is often required to interpret what one system is saying for use in another system. This situation is unfortunate; we can hope that over time, the necessary connections will take place (think of how the United States went from operator assistance on every telephone call to the automatic switching that takes place today). Such a change can only happen when many people see the need for and implement a common standard.<br/>In addition, the notion of “large” in the context of health care data is only relative. Think, instead, of many experiments undertaken by Google; if they desire, the amount of data that can be used to develop and test a model is orders of magnitude greater than that available in health care.<br/>In the domains where data-driven approaches have demonstrated success, there are outcomes that can be judged by human experts or machines themselves. For example, bilingual speakers can tell if natural language translation is working well, and the outcome of board or computer games can be easily determined. This allows easier simulation or annotation of data for machine learning. Such a task is much harder in the biomedical domains; investigation of causes or treatments of diseases in humans involve costly and long-term studies. In some cases, ethical concerns prohibit the experiments; for example, the introduction of potentially harmful genetic mutations into healthy human subjects is out of the question. We lack long-term outcome data for many treatments.<br/>I am not sure that there ever will be such a gold standard without a completely arbitrary definition. Variation between individuals is also a major obstacle. Although we perform studies using multiple subjects to account for biologic variability, our results are only approximate in their relevance to a given individual. For example, assuring genetic diversity in clinical trials is challenging, to say the least. Even the simplest tasks can be staggeringly multifactorial; for example, the information content of genetic testing for warfarin metabolism can be outweighed by whether the patient had lettuce for lunch.<br/>To expand on this observation, suppose you have an automobile that is not working appropriately. Today, you consult the sensors and the computer readout to give you very precise information about what is going wrong. The automobile has a specific design, with specific parameters that can be measured. All of the vehicles of the same year make and model can be assumed to be alike in those important aspects. It is important to realize that every human (with the exception of identical twins) is genetically unique. In that way, people are very different from automobiles or other mechanical devices. To compound the complexity with which the cause of a human problem can be addressed, what the individual experiences throughout their life is unique. Although we have nice abstractions or methods of identifying individuals who share some common characteristics (whether the presence or absence of a disease, the response or lack thereof to a medication, the similar environment, or other considerations), these are only a shorthand notation. With 7 billion persons currently living in this world, the problem appears almost open-ended. Too often in data analysis, we look at diagnostic codes as having a deep meaning. These are accepted without any recognition of the degree of uncertainty of the diagnosis. All our data may be helpful and useful, but we need to continue to view them with a large grain of salt. The fact that Google Translate works as well as it does gives us hope, but as complex as natural language translation is, it is simpler than some clinical tasks.<br/>Despite these challenges, applying data-driven approaches has the potential to transform health care. Today’s health care is labor intensive, from scheduling and triage to diagnosis and treatment. Many tasks currently undertaken by humans can be carried out by intelligent software solutions supported by sufficient data. For instance, improved voice recognition and summarization technology might help reduce the amount of time patients and clinicians spend on paperwork. Improved decision support tools ought to be able to help patients decide about the appropriateness of seeking care. An accurate assessment of short- and long-term risks and benefits will inform treatment selection and lifestyle changes.<br/>To provide another use case, there is evidence that type II diabetes may be reversible, but it is hard to apply this knowledge to an individual patient. Given the patient in front of me, what should I do, or recommend, and with what expectation? Demographics, genomics, comorbidities, psyche, competing risks, and other medications, all play a role. How, in a given person, do I reconcile all the possibilities?<br/>To develop these useful AI tools, we need better data, technology, and policy. To accumulate comprehensive, life-time data, patients must be in control and should be incentivized to share their data for research and care. Insurance, pharmaceutical, and medical institutions change over time. Currently, there are barriers for individuals to be the center of collecting the data on themselves. The barriers are present in data entry, collection, and storage; for example, some personalized health record products are tethered to an institution, while others require extensive transcribing efforts by patients or caregivers. Nevertheless, without patient consent and collaboration, gathering and linking longitudinal environmental, genetic, clinical, and behavioral data are neither feasible nor ethical. The current conditions are a huge barrier to any attempt to use data-driven approaches that have worked outside health care.<br/>Efforts including PatienstLikeMe  and the All of Us Research Project of the National Institutes of Health [ ] are examples of innovative approaches to curate bigger and better datasets. Most patients, however, are not engaged in such efforts. Patients are inherently motivated to improve their own health, but naturally have concerns regarding privacy and often do not see immediate benefits of participating in long-term studies. Appropriate incentives (eg, discounts for routine preventive care) coupled with security and authentication technologies are needed to entice a large and diverse population of patients to gather and share their data. The health care industry today owns parts of patient data and has limited motivation to purchase data from their customers. As the value of data increases, patients will become more valued as a partner.<br/>I agree that patients will need to assume the responsibility of carrying and sharing the information about themselves. However, experience tells us that not everyone is able or willing to do so. It will need cultural and political climate changes to encourage that development.<br/>When we can collect data that are not directly what the philosophers would call “theory-laden,” we may be able to refine our crude methods of patient diagnosis and care. I look forward to that day. If patients are the carrier of those data, it will be easier to obtain and use for analysis.<br/>We also need to design and implement methods specifically for handling very large and “messy” clinical data. For example, we need to understand the context of missing data and errors to get a better picture of ground truth. A lab result may be missed because there is no indication for it, practice preference, an alternative method of assessing, or a failure of data entry. Imagine how much more difficult a chess game will be, if a human player or a chess engine could only observe some squares on the board at irregular time intervals with some error or distortion of the observation.<br/>Further, we do not have an operational definition of “ground truth” in health care; a simple proposal is that one feature of ground truth is that it has predictive value—something that will be valued by clinicians and patients alike.<br/>Google has demonstrated that they can use lots of data to predict likely values for missing data in other areas ; however, it is yet to be determined whether this might work in medicine, but it is probably worth a trial. Irrespective of whether we can use large volumes of data to impute missing values, exploring how to handle the problem of absent observations is crucial, especially whenever we try to apply the results of data-driven approaches to individual patients.<br/>Another thought is that data that are missing, for any reason, are an observation in itself; the fact that the data were not obtained and recorded may be important. Think of the finding that the day and time of a test were more predictive of outcome than the result of the test . We know that the data that are missing will have some predictive value.<br/>On a different note, explanation of the data-driven models is critical to not only their adoption but also their impact . Predicting that a patient will have certain adverse events in the next several days or years is desirable. It may be argued that it is even more important to know the modifiable factors that can reduce risk and enhance outcome. Since deep learning models can be highly nonlinear, we have the opportunity to discover novel and complex patterns.<br/>I agree that explaining the prediction is critical; it is something that separates health care from, say, recognizing whether an image is a dog or a cat. However, I think you meant to say predicting a patient will probably have some adverse outcome. Nothing in life is certain except that it will end. However, we can say “it appears this behavior or finding will likely have an effect on your future” and hopefully be able to express some degree of confidence in that prediction.<br/>Learning how to express the confidence in a prediction is also important. How many folks really understand the statistics behind the predictions that occur today? What are the underlying assumptions behind any probabilistic model? It is more likely that with more frequent use and familiarity with the use of measures derived for AI models will lead to their acceptance.<br/>I agree. These are all steps to be taken in order to optimize the use of big data through AI to improve medical care.<br/>As a parting thought, we need to be cautious about how intrusive data-driven approaches might be in the care process. Although McDonald  demonstrated that performance in care improves with reminders [ ], the later experience has been one of too many reminders, leading to alert fatigue. When caregivers choose to override and ignore helpful information because of overload, have we accomplished anything?<br/>I hope that careful design of systems and consideration of clinical workflow will alleviate the problem of excessive intrusiveness. Although it is tempting to just “let AI do it,” the recent experiences with the Boeing 737 MAX demonstrate that there is danger in doing so. Neither AI nor a pilot alone is the optimal strategy in flying. In health care, involving patients more extensively in their care, together with AI and providers, may ultimately be an approach that works.<br/>Conflicts of Interest<br/>- Blois MS. Clinical Judgment and Computers. N Engl J Med 1980 Jul 24;303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Deep learning for healthcare: review, opportunities and challenges. Brief Bioinform 2018 Nov 27;19(6):1236-1246 [FREE Full text] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. Can machine-learning improve cardiovascular risk prediction using routine clinical data? PLoS ONE 2017 Apr 4;12(4):e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT. Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records. Sci Rep 2016 May 17;6(1):26094 [FREE Full text] [CrossRef] [Medline]<br/>- Quach K. The register. 2019. IBM Watson Health cuts back drug discovery 'artificial intelligence' after lackluster sales URL: https://www.theregister.co.uk/2019/04/18/ibm_watson_health [accessed 2019-10-23]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Scalable and accurate deep learning with electronic health records. NPJ Digit Med 2018 May 8;1(1):18 [FREE Full text] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, et al. Deep Learning in Medical Imaging: General Overview. Korean J Radiol 2017;18(4):570. [CrossRef]<br/>- U.S Department of Veterans Affairs. Million Veteran Program (MVP) URL: https://www.research.va.gov/mvp/ [accessed 2019-10-23]<br/>- Patientslikeme. URL: https://www.patientslikeme.com [accessed 2019-10-23]<br/>- All of Us Research Program. URL: https://allofus.nih.gov [accessed 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. The unreasonable effectiveness of data. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Biases in electronic health record data due to processes within the healthcare system: retrospective observational study. BMJ 2018 Apr 30:k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, Müller H. Causability and explainabilty of artificial intelligence in medicine. WIREs Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Protocol-Based Computer Reminders, the Quality of Care and the Non-Perfectibility of Man. N Engl J Med 1976 Dec 09;295(24):1351-1355. [CrossRef]<br/>&#124;AI: artificial intelligence&#124;<br/>&#124;UMLS: Unified Medical Language System&#124;<br/>Edited by G Eysenbach; submitted 15.09.19; peer-reviewed by A Holzinger; comments to author 14.10.19; revised version received 15.10.19; accepted 20.10.19; published 27.11.19Copyright<br/>©Qing Zeng-Treitler, Stuart J Nelson. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included. | A inteligência artificial (IA), a capacidade computadorizada de fazer tarefas, que até recentemente se pensava ser o domínio exclusivo da inteligência humana, demonstrou grandes avanços na última década. As habilidades para jogar jogos, fornecer pilotagem para um automóvel e responder à linguagem falada são sucessos notáveis. Como os desafios e as oportunidades da medicina são diferentes desses desafios e como podemos aplicar melhor essas técnicas baseadas em dados ao atendimento e aos resultados dos pacientes? Um artigo do New England Journal of Medicine publicado em 1980 sugeriu que tarefas "especializadas" mais bem definidas de cuidados médicos eram mais suscetíveis à assistência computacional, enquanto a amplitude de abordagem necessária para definir um problema e estreitar o espaço do problema era menos, e talvez, inatingível. Por outro lado, pode-se argumentar que a versão moderna da IA, que usa abordagens baseadas em dados, será a mais útil para lidar com tarefas como a previsão de resultados, que muitas vezes são difíceis para médicos e pacientes. Hoje, a capacidade de coletar grandes volumes de dados sobre um único indivíduo (por exemplo, através de um dispositivo wearable) e o acúmulo de grandes conjuntos de dados sobre várias pessoas que recebem cuidados médicos tem o potencial de se aplicar ao cuidado de indivíduos. À medida que essas técnicas de análise, enumeração, agregação e apresentação são trazidas à prática na medicina, surge a questão de sua utilidade e aplicabilidade nesse domínio. Os primeiros esforços no apoio à decisão foram considerados úteis; à medida que os sistemas proliferaram, experiências posteriores mostraram dificuldades como a fadiga de alerta e o esgotamento do médico se tornando mais prevalente. Será que algo semelhante surgirá de previsões baseadas em dados? Será que capacitar os pacientes, equipando-os com informações obtidas a partir da análise de dados, ajudará? Pacientes, provedores, tecnologia e formuladores de políticas têm um papel a desempenhar no desenvolvimento e utilização da IA na medicina. Alguns dos desafios, oportunidades e tradeoffs implícitos aqui são apresentados como um diálogo entre um clínico (SJN) e um informático (QZT). J Med Internet Res 2019;21(11):e16272<br/>Drs Nelson e Zeng-Treitler trabalham juntos no Centro de Informática Biomédica da Universidade George Washington. A seguir apresentamos um diálogo hipotético que surgiu das discussões que tiveram ao considerar seus diferentes pontos de vista sobre como a inteligência artificial (IA) se desenvolveu e para onde está indo. Enquanto a visão do Dr. Zeng-Treitler sobre o futuro da IA é altamente otimista, a opinião do Dr. Nelson é mais cautelosa. O Dr. Nelson era um internista acadêmico que se envolveu em informática há muitos anos. Ele colaborou com Scott Blois no RECONSIDER (um sistema de apoio à decisão clínica precoce) e no projeto do Sistema Único de Linguagem Médica (UMLS). Ele eventualmente se mudou para a Biblioteca Nacional de Medicina como Chefe de Cabeçalhos de Assuntos Médicos. Enquanto na Biblioteca Nacional de Medicina, ele gerou RxNorm, enquanto continuava seu trabalho em UMLS e projetos envolvendo UMLS. Dr. Zeng-Treitler tem formação em ciência da computação e obteve seu PhD em informática médica da Universidade de Columbia. Ela liderou uma série de projetos em mineração de dados clínicos, processamento de linguagem natural e informática de saúde do consumidor. Nos últimos anos, sua equipe tem investigado ativamente o uso de técnicas de IA em pesquisas clínicas, incluindo o desenvolvimento de uma nova abordagem de aprendizado profundo explicável.<br/>Dr. Zeng-Treitler (O Otimista):<br/>Depois de décadas de promessas e decepções, graças aos recursos de computação aparentemente ilimitados e aos novos métodos orientados a dados, a tecnologia de IA finalmente chegou. De Jeopardy e Siri para enfrentar a identificação e veículos autônomos, abordagens baseadas em dados fizeram o salto de experimentos de laboratório para aplicações que estão transformando nossas vidas fora dos cuidados de saúde. Em alguns casos, essas abordagens chegaram perto de passar no Teste de Turing – um teste da capacidade de uma máquina de exibir suposta inteligência humana; as máquinas agora podem realizar algumas tarefas complexas, como reconhecimento de imagem e jogo autêntico, bem como ou melhor do que os humanos. Alguns argumentariam que a abordagem necessária é decididamente não-humana, mas, quaisquer que sejam os meios para alcançar essas inovações, tais sucessos não foram seguidos por sucessos análogos na assistência à saúde.<br/>Um exemplo dramático dessa disparidade de realização é AlphaZero, um motor de jogo de computador que dominou o xadrez, Shogi e Go. Mesmo antes da chegada da atual geração de artefatos baseados em dados, os motores de xadrez mostraram ser capazes de jogar em um nível superior ao dos campeões de xadrez. Jogadores de Go (um jogo de tabuleiro que é pensado para ser muito mais complexo do que o xadrez), no entanto, acreditava que os computadores não eram páreo para profissionais de alto nível neste jogo. Essa crença foi quebrada primeiro pelo AlphaGo, que derrotou o atual campeão mundial de Go. Depois veio o AlphaZero. A notícia é que tais abordagens não podem mais vencer os campeões de Go, xadrez ou Shogi. Em vez disso, o fato notável é que AlphaZero não aprendeu com as experiências humanas e derrotou os melhores motores de xadrez anteriores, como Stockfish. AlphaZero triunfou jogando mais jogos contra si mesmo do que nunca tinha sido jogado por todos os jogadores humanos. Esta não é uma abordagem que poderíamos facilmente duplicar nos cuidados de saúde.<br/>Dr. Nelson (O Cauteloso):<br/>Ganhar um jogo, com regras e objetivos definidos, é realmente o melhor teste de inteligência humana? Em retrospectiva, a resposta é "Não". Por exemplo, sofisticados programas de xadrez existem há quase 50 anos; a partir desses programas, aprendemos a organizar recursos de computação para aplicar algoritmos simples de forma escalável. Dito de outra forma, não aprendemos nada sobre xadrez ou como os humanos, até mesmo especialistas, o jogam. Em vez disso, aprendemos que uma suposta tarefa que requer inteligência era suscetível a uma abordagem computacional. Precisamos perguntar onde e como essa abordagem é aplicável nos cuidados de saúde.<br/>Por exemplo, ao fazer tarefas que geralmente se pensa serem humanas e criativas, a máquina pode reconhecer quando está fora de sua profundidade? Às vezes, os humanos têm a capacidade de fazê-lo. No entanto, se pudermos definir o reino de perto o suficiente, concordo que as máquinas podem fazer maravilhas. Então, como podemos definir o reino?<br/>No artigo seminal de Blois sobre Julgamento Clínico e Computadores , ele descreveu o mundo do processo de pensamento de um médico ao ver um paciente, com o diagrama mostrado em . O ponto A para um médico seria onde o paciente entra pela porta para ser visto pela primeira vez. A natureza da queixa, o contexto em que a queixa ocorre e todas as inúmeras possibilidades estão presentes. À medida que a definição de problema se move em direção ao ponto B, um computador é mais capaz de gerenciar as informações e os conhecimentos necessários para cuidados de alta qualidade. Uma maneira pela qual podemos pensar em definir o reino é que estamos nos movendo em direção ao Ponto B. Alguns cientistas da computação argumentaram que o Ponto A é apenas sobre o gerenciamento de fatos, mas, como Blois observou, é mais sobre relevância – algo que provou ser difícil de replicar computacionalmente.<br/>De fato, é importante definir o âmbito de uma aplicação de IA. Muitas tarefas em cuidados de saúde são muito mais complexas do que o jogo, e não testemunhamos os triunfos de abordagens análogas no domínio biomédico como foram alcançadas no jogo. Alguns estudos têm aplicado a mais recente tecnologia de deep learning (um método chave de IA) a conjuntos de dados biomédicos [- ]. As aplicações específicas incluíram processamento de imagens, processamento de linguagem natural e previsão de risco. O aprendizado profundo, em comparação com os métodos tradicionais de aprendizado estatístico e de máquina, muitas vezes mostrou melhorias modestas em vez de avanços.<br/>Quaisquer que sejam os detalhes dessas abordagens, elas aplicam recursos de computação quase ilimitados a grandes quantidades de dados, algo que ainda não aconteceu nos cuidados de saúde. Portanto, essas abordagens podem ser úteis, mas ainda não sabemos ao certo.<br/>Por exemplo, uma pergunta simples feita por um colega está além de nossas capacidades atuais: Dado um paciente que começa com uma característica da síndrome metabólica, qual característica da síndrome ele ou ela tenderá a exibir em seguida? Simplisticamente, este é exatamente o tipo de desafio com o qual uma abordagem baseada em dados deve ajudar, e ainda assim, atualmente está "sobre o horizonte" devido aos dados insuficientes que foram coletados no passado.<br/>Os dados são um desafio fundamental na aplicação de abordagens orientadas por dados para o atendimento ao paciente. Para começar, os dados biomédicos são altamente complexos. Existem muitos tipos diferentes de dados, incluindo imagem, texto, valores numéricos, classificações categóricas e sequências de DNA, representando dezenas de milhares de testes de laboratório, procedimentos, diagnósticos, medicamentos, marcadores genéticos, etc. Cada tipo de dados também tem suas próprias características; por exemplo, um valor de teste laboratorial pode precisar ser interpretado no contexto de idade, sexo e condições atuais. No entanto, os códigos de diagnóstico para diferentes doenças têm diferentes níveis de precisão.<br/>Na análise de dados biomédicos, há também o paradoxo de ter dados demais e não suficientes ao mesmo tempo. Por um lado, há uma enorme quantidade de registros médicos, mídias sociais e dados da literatura. Esforços como o Projeto Million Veterans também coletaram uma enorme quantidade de dados de DNA. Usando dispositivos para tarefas como rastreamento de atividade e monitoramento contínuo de glicose gera mais dados do que nossos atuais sistemas de registros médicos podem digerir. Por outro lado, o registro de saúde de um paciente é um sistema aberto com muita informação em falta em contraste com o sistema fechado de um jogo de xadrez ou Go, onde todos os dados estão disponíveis. Os pacientes são observados em intervalos irregulares (por exemplo, em visitas clínicas ou durante a hospitalização) e nunca são submetidos a todos os testes ou tratamentos possíveis. Às vezes, a morte é o único resultado definitivo.<br/>Concordo que os tipos de dados são múltiplos e complexos. Soluções simples são insuficientes, e a proliferação de dados irrelevantes em um registro, para não mencionar a atual moda de cortar e colar ou preencher o modelo, obscurece o que é importante.<br/>Uma das principais dificuldades com os dados médicos não é apenas que não é suficiente, mas também que é uma teoria carregada, ou seja, muito poucas peças de dados são registradas rotineiramente. Muitos dados em observações são coletados apenas quando o clínico achou apropriado, ou seja, quando as doenças são testadas quanto à sua ausência ou presença. Se não houver motivo para fazer o teste, o teste não é realizado. Apenas alguns testes são realizados rotineiramente; um conjunto transcrito de observações físicas (como é feito no exame físico) raramente é gravado com detalhes suficientes (para não mencionar a incapacidade de observar, que muitas vezes ocorre) para fornecer dados suficientes para uma análise mais abrangente. Por essa razão, os estudos baseados nas observações registradas são muitas vezes incompletos e potencialmente enganosos. No entanto, para as previsões, as observações não feitas podem ser as críticas. Pense no paciente com síndrome metabólica mencionada acima. Que dados estamos perdendo?<br/>Da mesma forma, os resultados dos ensaios clínicos não são um quadro completo. Mesmo que os participantes tenham sido selecionados, muitas vezes excluindo muitos indivíduos por causa de condições complicadas, os dados coletados sobre os participantes são projetados para testar certas hipóteses, com resultados estritamente definidos. Uma crítica comum é que tais julgamentos são tão artificiais que são irrelevantes.<br/>A falta de conjuntos de dados integrados e padronizados é outro problema. Embora possamos encontrar muitos grandes conjuntos de dados, eles são muitas vezes incompletos e difíceis de vincular a outras informações. Por exemplo, a exposição ambiental, a dieta, a atividade física e o perfil genético estão entre as informações ausentes comuns quando examinamos os registros sobre um paciente individual. Conjuntos de dados detalhados de ensaios clínicos tendem a faltar acompanhamento a longo prazo. As questões de privacidade e os incentivos monetários também são obstáculos nos esforços de integração de dados.<br/>A interoperabilidade semântica real para integrar e padronizar conjuntos de dados requer suporte tanto na terminologia quanto na forma como essa terminologia é usada. Atualmente, a intervenção humana é frequentemente necessária para interpretar o que um sistema está dizendo para uso em outro sistema. Esta situação é lamentável; podemos esperar que, ao longo do tempo, as conexões necessárias aconteçam (pense em como os Estados Unidos passaram da assistência ao operador em cada chamada telefônica para a comutação automática que ocorre hoje). Essa mudança só pode acontecer quando muitas pessoas percebem a necessidade e implementam um padrão comum.<br/>Além disso, a noção de "grande" no contexto dos dados de saúde é apenas relativa. Pense, em vez disso, em muitos experimentos realizados pelo Google; se desejarem, a quantidade de dados que podem ser usados para desenvolver e testar um modelo é de ordens de magnitude maior do que a disponível nos cuidados de saúde.<br/>Nos domínios em que as abordagens baseadas em dados demonstraram sucesso, há resultados que podem ser julgados por especialistas humanos ou pelas próprias máquinas. Por exemplo, falantes bilíngues podem dizer se a tradução de linguagem natural está funcionando bem, e o resultado de jogos de tabuleiro ou de computador pode ser facilmente determinado. Isso permite uma simulação ou anotação mais fácil de dados para aprendizado de máquina. Tal tarefa é muito mais difícil nos domínios biomédicos; a investigação de causas ou tratamentos de doenças em seres humanos envolve estudos caros e de longo prazo. Em alguns casos, as preocupações éticas proíbem os experimentos; por exemplo, a introdução de mutações genéticas potencialmente prejudiciais em indivíduos humanos saudáveis está fora de questão.<br/>Não tenho a certeza de que alguma vez haverá um padrão-ouro sem uma definição completamente arbitrária. A variação entre indivíduos também é um grande obstáculo. Embora realizemos estudos usando múltiplos sujeitos para explicar a variabilidade biológica, nossos resultados são apenas aproximados em sua relevância para um determinado indivíduo. Por exemplo, garantir a diversidade genética em ensaios clínicos é desafiador, para dizer o mínimo. Mesmo as tarefas mais simples podem ser surpreendentemente multifatoriais; por exemplo, o conteúdo de informações dos testes genéticos para o metabolismo da varfarina pode ser superado pelo fato de o paciente ter alface para o almoço.<br/>Para expandir essa observação, suponha que você tenha um automóvel que não esteja funcionando adequadamente. Hoje, você consulta os sensores e a leitura do computador para lhe dar informações muito precisas sobre o que está acontecendo de errado. O automóvel tem um design específico, com parâmetros específicos que podem ser medidos. Todos os veículos da mesma marca e modelo do ano podem ser assumidos como iguais nesses aspectos importantes. É importante perceber que cada ser humano (com exceção de gêmeos idênticos) é geneticamente único. Dessa forma, as pessoas são muito diferentes de automóveis ou outros dispositivos mecânicos. Para agravar a complexidade com que a causa de um problema humano pode ser abordada, o que o indivíduo experimenta ao longo de sua vida é único. Embora tenhamos boas abstrações ou métodos para identificar indivíduos que compartilham algumas características comuns (seja a presença ou ausência de uma doença, a resposta ou falta dela a um medicamento, o ambiente semelhante ou outras considerações), estas são apenas uma notação abreviada. Com 7 bilhões de pessoas vivendo atualmente neste mundo, o problema parece quase aberto. Muitas vezes na análise de dados, olhamos para os códigos de diagnóstico como tendo um significado profundo. Estes são aceitos sem qualquer reconhecimento do grau de incerteza do diagnóstico. Todos os nossos dados podem ser úteis e úteis, mas precisamos continuar a vê-los com um grande grão de sal. O fato de que o Google Translate funciona tão bem quanto nos dá esperança, mas por mais complexa que seja a tradução em linguagem natural, é mais simples do que algumas tarefas clínicas.<br/>Apesar desses desafios, a aplicação de abordagens baseadas em dados tem o potencial de transformar a assistência à saúde. A assistência à saúde de hoje é intensiva em mão-de-obra, desde o agendamento e triagem até o diagnóstico e tratamento. Muitas tarefas atualmente realizadas por seres humanos podem ser realizadas por soluções de software inteligentes apoiadas por dados suficientes. Por exemplo, o reconhecimento de voz melhorado e a tecnologia de resumo podem ajudar a reduzir a quantidade de tempo que os pacientes e os médicos gastam na papelada. Ferramentas de apoio à decisão melhoradas devem ser capazes de ajudar os pacientes a decidir sobre a adequação de procurar cuidados. Uma avaliação precisa dos riscos e benefícios de curto e longo prazo informará a seleção do tratamento e as mudanças no estilo de vida.<br/>Para fornecer outro caso de uso, há evidências de que o diabetes tipo II pode ser reversível, mas é difícil aplicar esse conhecimento a um paciente individual. Dado o paciente na minha frente, o que devo fazer, ou recomendar, e com que expectativa? Demografia, genômica, comorbidades, psique, riscos concorrentes e outros medicamentos, todos desempenham um papel. Como, em uma determinada pessoa, eu reconcilio todas as possibilidades?<br/>Para desenvolver essas ferramentas úteis de IA, precisamos de melhores dados, tecnologia e políticas. Para acumular dados abrangentes e duradouros, os pacientes devem estar no controle e devem ser incentivados a compartilhar seus dados para pesquisa e cuidados. As instituições de seguros, farmacêuticas e médicas mudam ao longo do tempo. Atualmente, existem barreiras para que os indivíduos sejam o centro de coleta de dados sobre si mesmos. As barreiras estão presentes na entrada, coleta e armazenamento de dados; por exemplo, alguns produtos de registros de saúde personalizados são amarrados a uma instituição, enquanto outros exigem extensos esforços de transcrição por pacientes ou cuidadores. No entanto, sem o consentimento e a colaboração do paciente, coletar e vincular dados ambientais, genéticos, clínicos e comportamentais longitudinais não é viável nem ético. As condições atuais são uma enorme barreira para qualquer tentativa de usar abordagens baseadas em dados que tenham funcionado fora dos cuidados de saúde.<br/>Esforços, incluindo PatienstLikeMe e o Projeto de Pesquisa All of Us dos Institutos Nacionais de Saúde [ ] são exemplos de abordagens inovadoras para curar conjuntos de dados maiores e melhores. A maioria dos pacientes, no entanto, não está envolvida em tais esforços. Os pacientes são inerentemente motivados a melhorar sua própria saúde, mas naturalmente têm preocupações com relação à privacidade e muitas vezes não vêem benefícios imediatos de participar de estudos de longo prazo. Incentivos apropriados (por exemplo, descontos para cuidados preventivos de rotina) juntamente com tecnologias de segurança e autenticação são necessários para atrair uma grande e diversificada população de pacientes para coletar e compartilhar seus dados. A indústria de cuidados de saúde hoje possui partes dos dados dos pacientes e tem motivação limitada para comprar dados de seus clientes. À medida que o valor dos dados aumenta, os pacientes se tornarão mais valorizados como parceiros.<br/>Concordo que os pacientes terão que assumir a responsabilidade de carregar e compartilhar as informações sobre si mesmos. No entanto, a experiência nos diz que nem todos são capazes ou dispostos a fazê-lo. Precisará de mudanças climáticas culturais e políticas para incentivar esse desenvolvimento.<br/>Quando pudermos coletar dados que não são diretamente o que os filósofos chamariam de "carregados de teoria", poderemos ser capazes de refinar nossos métodos grosseiros de diagnóstico e atendimento ao paciente. Se os pacientes forem os portadores desses dados, será mais fácil obtê-los e utilizá-los para análise.<br/>Também precisamos projetar e implementar métodos especificamente para lidar com dados clínicos muito grandes e "desastrosos". Por exemplo, precisamos entender o contexto de dados ausentes e erros para obter uma melhor imagem da verdade no terreno. Um resultado de laboratório pode ser perdido porque não há indicação para ele, preferência de prática, um método alternativo de avaliação ou uma falha na entrada de dados. Imagine como um jogo de xadrez será muito mais difícil, se um jogador humano ou uma máquina de xadrez só pudesse observar algumas quadras no tabuleiro em intervalos de tempo irregulares com algum erro ou distorção da observação.<br/>Além disso, não temos uma definição operacional de "verdade fundamental" nos cuidados de saúde; uma proposta simples é que uma característica da verdade fundamental é que ela tem valor preditivo - algo que será valorizado por médicos e pacientes.<br/>O Google demonstrou que pode usar muitos dados para prever valores prováveis para dados em falta em outras áreas; no entanto, ainda não está determinado se isso pode funcionar em medicina, mas provavelmente vale a pena um teste. Independentemente de podermos usar grandes volumes de dados para imputar valores ausentes, explorar como lidar com o problema das observações ausentes é crucial, especialmente quando tentamos aplicar os resultados de abordagens baseadas em dados a pacientes individuais.<br/>Outro pensamento é que os dados que faltam, por qualquer motivo, são uma observação em si; o fato de que os dados não foram obtidos e registrados pode ser importante. Pense na constatação de que o dia e a hora de um teste foram mais preditivos do resultado do que o resultado do teste . Sabemos que os dados que faltam terão algum valor preditivo.<br/>Em uma nota diferente, a explicação dos modelos orientados por dados é fundamental não apenas para sua adoção, mas também para seu impacto . Prever que um paciente terá certos eventos adversos nos próximos dias ou anos é desejável. Pode-se argumentar que é ainda mais importante conhecer os fatores modificáveis que podem reduzir o risco e melhorar o resultado. Uma vez que os modelos de aprendizagem profunda podem ser altamente não lineares, temos a oportunidade de descobrir padrões novos e complexos.<br/>Concordo que explicar a previsão é fundamental; é algo que separa os cuidados de saúde de, digamos, reconhecer se uma imagem é um cão ou um gato. No entanto, acho que você quis dizer que prever um paciente provavelmente terá algum resultado adverso. Nada na vida é certo, exceto que ele vai acabar. No entanto, podemos dizer "parece que este comportamento ou descoberta provavelmente terá um efeito sobre o seu futuro" e esperamos ser capazes de expressar algum grau de confiança nessa previsão.<br/>Aprender a expressar a confiança em uma previsão também é importante. Quantas pessoas realmente entendem as estatísticas por trás das previsões que ocorrem hoje? Quais são as suposições subjacentes por trás de qualquer modelo probabilístico? É mais provável que com o uso mais frequente e a familiaridade com o uso de medidas derivadas para modelos de IA levem à sua aceitação.<br/>Concordo. Estas são todas as medidas a serem tomadas a fim de otimizar o uso de big data através da IA para melhorar os cuidados médicos.<br/>Como um pensamento de despedida, precisamos ser cautelosos sobre como as abordagens baseadas em dados podem ser intrusivas no processo de atendimento. Embora o McDonald tenha demonstrado que o desempenho no cuidado melhora com lembretes, a experiência posterior tem sido um dos muitos lembretes, levando à fadiga de alerta. Quando os cuidadores optam por ignorar e ignorar informações úteis por causa da sobrecarga, realizamos alguma coisa?<br/>Espero que o projeto cuidadoso de sistemas e a consideração do fluxo de trabalho clínico aliviem o problema da intrusão excessiva. Embora seja tentador apenas "deixar a IA fazer isso", as experiências recentes com o Boeing 737 MAX demonstram que há perigo em fazê-lo. Nem a IA nem um piloto sozinho é a estratégia ideal em vôo. Nos cuidados de saúde, envolver os pacientes mais extensivamente em seus cuidados, juntamente com a IA e os provedores, pode ser uma abordagem que funcione.<br/>Conflitos de interesse<br/>- Blois MS. Julgamento Clínico e Computadores. N Engl J Med 1980 Jul 24;303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Deep learning for healthcare: review, opportunities and challenges. Breve Bioinform 2018 Nov 27;19(6):1236-1246 [Texto completo GRÁTIS] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. O aprendizado de máquina pode melhorar a previsão do risco cardiovascular usando dados clínicos de rotina? PLoS ONE 2017 Apr 4;12(4):e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT. Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records. Sci Rep 2016 May 17;6(1):26094 [Texto completo LIVRE] [CrossRef] [Medline]<br/>- Quach K. O registro. 2019. IBM Watson Health reduz a descoberta de medicamentos 'inteligência artificial' após URL de vendas sem brilho: https://www.theregister.co.uk/2019/04/18/ibm_watson_health [acessado 2019-10-23]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Aprendizagem profunda escalável e precisa com registros eletrônicos de saúde. NPJ Digit Med 2018 Maio 8;1(1):18 [Texto completo LIVRE] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, et al. Deep Learning in Medical Imaging: General Overview. Coreano J Radiol 2017;18(4):570. [CrossRef]<br/>- U.S. Department of Veterans Affairs. Million Veteran Program (MVP) URL: https://www.research.va.gov/mvp/ [acesso 2019-10-23]<br/>- Patientslikeme. URL: https://www.patientslikeme.com [acesso 2019-10-23]<br/>- Programa de Pesquisa All of Us. URL: https://allofus.nih.gov [acessado 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. A eficácia irracional dos dados. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Viés em dados de registros eletrônicos de saúde devido a processos dentro do sistema de saúde: estudo observacional retrospectivo. BMJ 2018 Apr 30:k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, Müller H. Causabilidade e explicabilidade da inteligência artificial em medicina. WIRES Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Lembranças de computador baseadas em protocolo, a qualidade dos cuidados e a não-perfeição do homem. N Engl J Med 1976 Dec 09;295(24):1351-1355. [CrossRef]<br/>&#124;AI: inteligência artificial&#124;<br/>&#124;UMLS: Sistema de Linguagem Médica Unificado&#124;<br/>Editado por G Eysenbach; submetido 15.09.19; revisado por A Holzinger; comentários ao autor 14.10.19; versão revisada recebida 15.10.19; aceito 20.10.19; publicado 27.11.19Copyright<br/>©Qing Zeng-Treitler, Stuart J Nelson. Originalmente publicado no Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>Este é um artigo de acesso aberto distribuído sob os termos da Licença de Atribuição Creative Commons (https://creativecommons.org/licenses/by/4.0/), que permite o uso, distribuição e reprodução sem restrições em qualquer meio, desde que o trabalho original, publicado pela primeira vez no Journal of Medical Internet Research, seja devidamente citado. A informação bibliográfica completa, um link para a publicação original em http://www.jmir.org/, bem como esta informação sobre direitos autorais e licença devem ser incluídos. |
| The Story of Selena Quintanilla: A Biography Book for Young Readers (The Story Of: A Biography Series for New Readers) (Paperback)<br/>Most titles are on our shelves or available within 1-5 days.<br/>Discover the life Selena Quintanilla—a story about breaking down barriers in music, for kids ages 6 to 9<br/>Selena Quintanilla was the queen of Tejano music. Before she became a star, Selena was a charismatic young girl who loved singing and performing. She made a lot of sacrifices to become a famous musician, rehearsing her songs and dance moves for hours at a time. Her hard work paid off—she became the first 15-year-old girl to win a Tejano music award and went on to break many records during her career. This Selena biography explores how she went from being a talented girl growing up in Texas to a fashion icon and a world-famous singer.<br/>What sets this Selena book apart:<br/>- Core curriculum—Kids will learn the Who, What, Where, When, Why, and How of Selena’s life, and take a quick quiz to test their knowledge.<br/>- Short chapters—This Selena kids’ book is broken up into brief chapters that make it fun and easy for new readers to discover details about the singer’s life.<br/>- Her lasting legacy—Kids will find out how Selena changed the world of music and why she continues to be a role model for many women and people of color around the globe.<br/>How will Selena’s big spirit and passion for music inspire the child in your life?<br/>About the Author<br/>GLORIA ARJONA teaches Spanish at the California Institute of Technology and is the author of Posadas Unknown Calaveras and ¡Lotería!. She’s also a musician who sings and plays guitar. Learn more at GloriaArjona.com.<br/>“Finally, a Selena book for new readers, one that is told concisely and honestly, and is eminently readable” —Joe Nick Patoski, author of Selena: Como La Flor<br/>“What a wonderful story to inspire girls to follow their dreams. A story that many girls will identify with, especially those from traditional and multicultural families. I liked all the little sidebar lessons throughout the book. Gloria is a very talented teacher.” —Genevieve B. Southgate, director of community programs, Bowers Museum<br/>“Selena Quintanilla’s youthful talent and positive drive are brought to life in Prof. Arjona’s latest book, this one geared to young readers. A highly appealing read highlighting Selena’s flexibility in overcoming obstacles to achieving her dreams and her trailblazing contributions to music and her community. The Callisto Media format of encouraging critical, organized thought via questions, maps, timelines, and a glossary make this an enjoyable learning experience.” —Martin E. Delgado, community library manager<br/>“This is the story of Selena Quintanilla, and what a story it is! In a time where young readers, and young women, need role models more than ever, this book brilliantly depicts the profound humanity, bravery, and talent of a deeply inspiring Latina woman who relentlessly fought for her dream.” —Maite Zubiaurre, UCLA professor | A História de Selena Quintanilla: Um Livro de Biografia para Jovens Leitores (The Story Of: Uma Série de Biografia para Novos Leitores) (Paperback)<br/>A maioria dos títulos está nas nossas prateleiras ou disponível dentro de 1-5 dias.<br/>Descubra a vida de Selena Quintanilla – uma história sobre quebrar barreiras na música, para crianças de 6 a 9 anos<br/>Selena Quintanilla era a rainha da música Tejano. Antes de se tornar uma estrela, Selena era uma jovem carismática que adorava cantar e se apresentar. Ela fez muitos sacrifícios para se tornar uma músico famosa, ensaiando suas músicas e danças por horas de cada vez. Seu trabalho duro valeu a pena – ela se tornou a primeira garota de 15 anos a ganhar um prêmio de música Tejano e passou a quebrar muitos recordes durante sua carreira. Esta biografia de Selena explora como ela passou de ser uma menina talentosa crescendo no Texas para um ícone da moda e uma cantora mundialmente famosa.<br/>O que distingue este livro de Selena:<br/>- Currículo básico - As crianças aprenderão o Quem, o quê, onde, quando, por que e como da vida de Selena, e farão um teste rápido para testar seus conhecimentos.<br/>Capítulos curtos - Este livro infantil de Selena é dividido em capítulos curtos que tornam divertido e fácil para os novos leitores descobrirem detalhes sobre a vida da cantora.<br/>Seu legado duradouro – as crianças vão descobrir como Selena mudou o mundo da música e por que ela continua a ser um modelo para muitas mulheres e pessoas de cor em todo o mundo.<br/>Como o grande espírito e paixão de Selena pela música vai inspirar a criança em sua vida?<br/>Sobre o autor<br/>GLORIA ARJONA ensina espanhol no Instituto de Tecnologia da Califórnia e é autora de Posadas Unknown Calaveras e ¡Lotería!. Ela também é uma músico que canta e toca guitarra. Saiba mais em GloriaArjona.com.<br/>“Finalmente, um livro de Selena para novos leitores, que é conciso e honesto, e é eminentemente legível” – Joe Nick Patoski, autor de Selena: Como La Flor<br/>"Que história maravilhosa para inspirar as meninas a seguir seus sonhos. Uma história com a qual muitas meninas se identificarão, especialmente aquelas de famílias tradicionais e multiculturais. Eu gostei de todas as pequenas lições da barra lateral ao longo do livro. Gloria é uma professora muito talentosa.” — Genevieve B. Southgate, diretora de programas comunitários, Bowers Museum<br/>“O talento jovem e o impulso positivo de Selena Quintanilla são trazidos à vida no último livro do Prof. Arjona, este voltado para jovens leitores. Uma leitura muito atraente destacando a flexibilidade de Selena na superação de obstáculos para alcançar seus sonhos e suas contribuições pioneiras para a música e sua comunidade. O formato Callisto Media de incentivar o pensamento crítico e organizado através de perguntas, mapas, cronogramas e um glossário torna esta uma experiência de aprendizagem agradável." — Martin E. Delgado, gerente da biblioteca da comunidade<br/>“Esta é a história de Selena Quintanilla, e que história é! Numa época em que jovens leitores e jovens mulheres precisam mais do que nunca de modelos a seguir, este livro retrata brilhantemente a profunda humanidade, bravura e talento de uma mulher latina profundamente inspiradora que lutou incansavelmente por seu sonho. —Maite Zubiaurre, professor da UCLA |
| Here's another reason for men to avoid packing on extra pounds over the holidays: A new study has found that losing weight reduces the risk of an aggressive form of prostate cancer.<br/>After tracking the weight of nearly 70,000 men between 1982 and 1992, researchers from the American Cancer Society and the Duke University Prostate Center found that men who lost more than 11 pounds had a lower risk for aggressive prostate cancer than men whose weight remained the same over a decade.<br/>Previous studies have found that obese men have a higher risk of developing aggressive prostate cancer. This study appears to be the first to indicate that recent weight loss can decrease that risk.<br/>In the study reported this month in Cancer Epidemiology, Biomarkers & Prevention, researchers analyzed the height and weight of the men in 1982 and 1992 and every three years after that until 2003. At that time, more than 5,200 of the men — more than 7 percent — had prostate cancer.<br/>Among those cases, about one in eight had a form of cancer that was aggressive but had not spread to other areas of the body. The study's major finding focused on those aggressive cases, with researchers concluding that those who lost 11 or more pounds were 42 percent less likely to develop that form of prostate cancer than those whose weight remained the same.<br/>"Whether it's exactly 40 percent, we don't know, but they lower their risk when they lose 11-plus pounds. We feel confident, at least in this population, that was real," said lead researcher Dr. Carmen Rodriguez.<br/>More than seven times as many men whose weight remained the same developed aggressive prostate cancer compared to those who lost 11 or more pounds.<br/>"No significant associations" were found regarding the effect of weight gain or loss on the most severe forms of prostate cancer, those that spread throughout the body, the study said.<br/>The number studied was small, the researchers acknowledged, because fewer than 15,000 men lost weight over the time period, and only 1,000 of those developed some form of prostate cancer.<br/>The 69,991 participants were part of a bigger cancer society study of 1.2 million Americans that began in 1982.<br/>Rodriguez said men should avoid putting on extra weight as they get older.<br/>"The main message for men is to not get overweight. If they are overweight, that's another reason to try to lose weight, just to decrease the risk for prostate cancer," said Rodriguez, who works for the Atlanta-based cancer society.<br/>Other than skin cancer, prostate cancer is the most commonly diagnosed cancer for men, and about one in six will get it during his lifetime. It is the second leading cause of cancer death for U.S. men.<br/>The study is considered the first of its kind to examine the role of weight change in the development of prostate cancer, said Dr. Ronald Ennis, director of radiation oncology at St. Luke's-Roosevelt Hospital Center in New York, who was not involved in the study.<br/>"This is one of the best studies" examining the role of weight on prostate cancer, Ennis said. "It does seem to be true that if you are overweight, you are at risk of getting more aggressive forms of prostate cancer and if you lose weight, you can decrease the risk." | Aqui está outra razão para os homens evitarem empacotar libras extras durante as férias: Um novo estudo descobriu que perder peso reduz o risco de uma forma agressiva de câncer de próstata.<br/>Depois de rastrear o peso de quase 70.000 homens entre 1982 e 1992, pesquisadores da American Cancer Society e do Duke University Prostate Center descobriram que os homens que perderam mais de 11 quilos tinham um risco menor de câncer de próstata agressivo do que os homens cujo peso permaneceu o mesmo ao longo de uma década.<br/>Estudos anteriores descobriram que os homens obesos têm um risco maior de desenvolver câncer de próstata agressivo. Este estudo parece ser o primeiro a indicar que a perda de peso recente pode diminuir esse risco.<br/>No estudo publicado este mês na Cancer Epidemiology, Biomarkers & Prevention, os pesquisadores analisaram a altura e o peso dos homens em 1982 e 1992 e a cada três anos depois disso até 2003. Naquela época, mais de 5.200 dos homens - mais de 7% - tinham câncer de próstata.<br/>Entre esses casos, cerca de um em cada oito tinha uma forma de câncer que era agressiva, mas não se espalhou para outras áreas do corpo. A principal descoberta do estudo se concentrou nesses casos agressivos, com os pesquisadores concluindo que aqueles que perderam 11 ou mais quilos tinham 42% menos chances de desenvolver essa forma de câncer de próstata do que aqueles cujo peso permaneceu o mesmo.<br/>"Se é exatamente 40 por cento, não sabemos, mas eles reduzem seu risco quando perdem mais de 11 quilos. Nos sentimos confiantes, pelo menos nesta população, isso foi real", disse a pesquisadora principal, a Dra. Carmen Rodriguez.<br/>Mais de sete vezes mais homens cujo peso permaneceu o mesmo desenvolveram câncer de próstata agressivo em comparação com aqueles que perderam 11 ou mais quilos.<br/>“Não foram encontradas associações significativas” com relação ao efeito do ganho ou perda de peso nas formas mais graves de câncer de próstata, aquelas que se espalham por todo o corpo, disse o estudo.<br/>O número estudado foi pequeno, reconheceram os pesquisadores, porque menos de 15.000 homens perderam peso durante o período de tempo, e apenas 1.000 desses desenvolveram alguma forma de câncer de próstata.<br/>Os 69.991 participantes fizeram parte de um estudo maior da sociedade do câncer de 1,2 milhão de americanos que começou em 1982.<br/>Rodriguez disse que os homens devem evitar aumentar de peso à medida que envelhecem.<br/>"A principal mensagem para os homens é não ficarem acima do peso. Se eles estão acima do peso, essa é outra razão para tentar perder peso, apenas para diminuir o risco de câncer de próstata", disse Rodriguez, que trabalha para a sociedade de câncer com sede em Atlanta.<br/>Além do câncer de pele, o câncer de próstata é o câncer mais comumente diagnosticado para os homens, e cerca de um em cada seis vai pegá-lo durante sua vida. É a segunda principal causa de morte por câncer para os homens dos EUA.<br/>O estudo é considerado o primeiro de seu tipo a examinar o papel da mudança de peso no desenvolvimento do câncer de próstata, disse o Dr. Ronald Ennis, diretor de oncologia de radiação no St. Luke's-Roosevelt Hospital Center, em Nova York, que não esteve envolvido no estudo.<br/>"Este é um dos melhores estudos" examinando o papel do peso no câncer de próstata, disse Ennis. “Parece ser verdade que se você está acima do peso, você está em risco de obter formas mais agressivas de câncer de próstata e se você perder peso, você pode diminuir o risco.” |
| If you have studied the OSI model with its 7 Layers that describe communication on computer network systems, you should know that the Ethernet standard lies in Layer 1 (Physical) and Layer 2 (Data-Link) of the OSI model.<br/>In this article we will focus on the physical (Layer 1) part of Ethernet, which mainly focuses on the wired physical medium (cabling) that is used to transport Ethernet frames in a network.<br/>Ethernet cables connect devices to computer networks, the “heart” of which is usually an Ethernet switch which has several interface ports for “plugging-in” the cables.<br/>Most of these Ethernet cables feature the standard RJ45 connector for plugging-in to a switch. However, Ethernet communication can be implemented also using Fiber-optic cabling which uses different types of connectors.<br/>Moreover, there are different types of Ethernet cables with varying bandwidths, speeds and types of construction. In this article we will discuss the “copper-made” cables which are the most popular ones in computer networks.<br/>The cables have labels indicating the standard used for manufacturing, ranging from category (cat) 3 to 7.<br/>Ethernet cables consist of several (usually 8) smaller wires (inside the main cable) which are separated in Twisted-pairs. This setup helps in cancelling-out electromagnetic interference between wires, thus allowing signals to travel longer distances inside the wires.<br/>Without the right cable (and of course without the right type of switch), you may experience slower speeds in the network between devices.<br/>Let’s now describe each Category of Ethernet Cables with their characteristics:<br/>&#124;Max Length&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m<br/>(55 m for 10Gbps)<br/>&#124;100 m&#124;&#124;100 m&#124;<br/>&#124;Max Speed&#124;&#124;10 Mbps&#124;&#124;100 Mbps&#124;&#124;1 Gbps&#124;&#124;10 Gbps&#124;&#124;10 Gbps&#124;&#124;>10 Gbps&#124;<br/>&#124;Frequency Bandwidth&#124;&#124;16 MHz&#124;&#124;100 MHz&#124;&#124;100 MHz&#124;&#124;250 MHz&#124;&#124;500 MHz&#124;&#124;600 MHz&#124;<br/>&#124;Shielded / Unshielded&#124;&#124;Unshielded&#124;&#124;Unshielded&#124;&#124;Unshielded&#124;&#124;Shielded or Unshielded&#124;&#124;Shielded&#124;&#124;Shielded&#124;<br/>1) Cat 3<br/>One of the oldest Ethernet cabling standards is category (cat) 3 (TIA/EIA-568-B). These cables allowed 10 Mbps transmission speeds with 16 MHz max bandwidth.<br/>Cat 3 ethernet cables feature unshielded twisted pair (UTP) cabling. With UTP cables, manufacturers twist insulated copper wires together inside a polyethylene jacket. Compared to shielded ethernet cables, UTP cables tend to include more crosstalk.<br/>Network connections commonly featured category 3 ethernet cables until the early 1990s, when category 5 cables replaced cat 3. While some older telephone systems may still use cat 3 cables, they have mostly become obsolete in the networking industry.<br/>2) Cat 5<br/>Cat 5 cables increased the bandwidth of Ethernet connections up to 100 MHz and offered transmission speeds up to 100 Mbps. With Cat 5 ethernet cables, users could access 100BASE-TX ethernet systems, referred to as fast ethernet.<br/>As with the category 3 cables, cat 5 cables still feature crosstalk and interference, due to the UTP design. These cables include four pairs of twisted wires (for a total of 8 wires).<br/>While cat 5 cables primarily provide connections for Ethernet applications, these cables also provide solutions for carrying other data signals, such as video and telephone. In fact, a single cat 5 cable can carry two standard phone lines and a 100BASE-TX connection.<br/>3) Cat 5e<br/>In 2001, the category 5e standard replaced category 5. The letter “e” in the name stands for enhanced.<br/>The cabling still uses unshielded twisted pairs. There are no physical differences between cat 5 and cat 5e cables. However, stricter standards in manufacturing Cat5e cables help minimize crosstalk and allow higher data transmissions than Cat5.<br/>Cat 5e cables also utilize two sets of twisted pairs of wires, resulting in faster speeds. While cat 5e ethernet cable still features 100 MHz bandwidth, these cables allow speeds up to 1000 Mbps (1 Gbps).<br/>While several additional standards have come after cat 5e, these cables remain in production. In fact, due to the lower cost of production and support for gigabit ethernet, cat 5e cables are the most used for network applications throughout the world.<br/>4) Cat 6<br/>Cat 6 ethernet cables helped address issues related to interference and crosstalk. These cables use thinner wires and superior insulation, resulting in a better signal-to-noise ratio.<br/>With these features, cat 6 cables provide a more effective option for adding cable in areas with more electromagnetic interference, such as a crowded server room.<br/>Thanks to the superior design, cat 6 provides improved bandwidth. These cables have a max bandwidth of 250 MHz and max transmission speeds up to 1000 Mbps (1 Gbps) at the 100m range. However, 10Gbps can be achieved in Cat6 in smaller distances (up to 55m).<br/>Some cat 6 cables include shielding while others remain unshielded. With shielding, these cables can provide transmission speeds up to 10 Gbps, but only for short distances as we said above.<br/>5) Cat 6a<br/>Category 6a ethernet cables improve the design of the cat 6 cables. The letter “a” stands for augmented. Unlike cat 6 cables, all cat 6a cables feature shielded cabling for reduced interference.<br/>With the enhancements to the design specifications, cat 6a cables maintain higher transmission speeds and 500 MHz max bandwidth, allowing speeds up to 10000 Mbps (10 Gbps) across longer cables.<br/>While these cables provide faster speeds, the design makes them less flexible. To eliminate crosstalk, these cables feature thicker sheathing, making the cables stiffer and more difficult to work.<br/>6) Cat 7<br/>One of the latest developments is Cat 7 Ethernet cables. Also called class F channel cables, these cables include stricter standards compared to previous categories. The individual wire pairs now include their own shielding, in addition to the outer shielding<br/>With these cables, you get 600 MHz max bandwidth and 10000 Mbps (10 Gbps) transmission speeds. However, by almost completely getting rid of crosstalk, cat 7 ethernet cables offer even greater reliability for 10 Gbps Ethernet connections.<br/>With connections less than 15 meters, cat 7 can support transmission speeds up to 100 Gbps. While the industry has released several new standards since cat 7, these cables are currently the top of the line option for demanding networking applications.<br/>- What is OSPF NSSA (Not So Stubby Area) and How is it Configured?<br/>- Comparison of BOOTP vs DHCP Protocols in Computer Networks<br/>- Pros and Cons of SD-WAN in Networks – Description and Discussion<br/>- Comparison of GNS3 vs EVE-NG vs Packet Tracer for Networks Simulation<br/>- Subnetting vs Supernetting – What’s the Difference? (Explanation Guide) | Se você estudou o modelo OSI com suas 7 camadas que descrevem a comunicação em sistemas de rede de computadores, você deve saber que o padrão Ethernet está na camada 1 (física) e na camada 2 (data-link) do modelo OSI.<br/>Neste artigo, vamos nos concentrar na parte física (camada 1) da Ethernet, que se concentra principalmente no meio físico com fio (cablagem) que é usado para transportar quadros Ethernet em uma rede.<br/>Os cabos Ethernet conectam dispositivos a redes de computadores, cujo "coração" é geralmente um switch Ethernet que tem várias portas de interface para "conectar" os cabos.<br/>A maioria desses cabos Ethernet possui o conector RJ45 padrão para conectar-se a um switch. No entanto, a comunicação Ethernet também pode ser implementada usando cabeamento de fibra óptica que usa diferentes tipos de conectores.<br/>Além disso, existem diferentes tipos de cabos Ethernet com diferentes larguras de banda, velocidades e tipos de construção. Neste artigo vamos discutir os cabos "de cobre", que são os mais populares em redes de computadores.<br/>Os cabos têm etiquetas que indicam o padrão usado para a fabricação, variando da categoria (cat) 3 a 7.<br/>Os cabos Ethernet consistem em vários (geralmente 8) fios menores (dentro do cabo principal) que são separados em pares torcidos. Esta configuração ajuda a cancelar a interferência eletromagnética entre os fios, permitindo assim que os sinais viajem distâncias mais longas dentro dos fios.<br/>Sem o cabo certo (e, claro, sem o tipo certo de switch), você pode experimentar velocidades mais lentas na rede entre dispositivos.<br/>Vamos agora descrever cada categoria de cabos Ethernet com suas características:<br/>الالارالرارارالراراررانارانارانارانراران<br/>(55 m para 10Gbps)<br/>&#124;100 m&#124;100 m&#124;<br/>Velocidade Máxima Velocidade Máxima Velocidade Máxima Velocidade 10 Mbps Velocidade 100 Mbps Velocidade 1 Gbps Velocidade Máxima Velocidade 10 Mbps Velocidade 10 Gbps Velocidade 10 Gbps Velocidade 10 Gbps Velocidade 10 Gbps Velocidade Mbps Velocidade 10 Gbps Velocidade<br/>Largura de Banda de Frequência&#124;16 MHz&#124;100 MHz&#124;100 MHz&#124;250 MHz&#124;500 MHz&#124;600 MHz<br/>&#124;Shielded / Unshielded&#124;Shielded&#124;Shielded&#124;Shielded&#124;Shielded ou Unshielded&#124;Shielded&#124;Shielded<br/>1) Cat 3<br/>Um dos mais antigos padrões de cabeamento Ethernet é a categoria (cat) 3 (TIA/EIA-568-B). Esses cabos permitiram velocidades de transmissão de 10 Mbps com largura de banda máxima de 16 MHz.<br/>Os cabos Ethernet Cat 3 apresentam cabeamento de par trançado (UTP) não blindado. Com os cabos UTP, os fabricantes torcem os fios de cobre isolados juntos dentro de uma jaqueta de polietileno. Em comparação com os cabos Ethernet blindados, os cabos UTP tendem a incluir mais interferência.<br/>As conexões de rede geralmente apresentavam cabos Ethernet de categoria 3 até o início da década de 1990, quando os cabos de categoria 5 substituíram os cabos Cat 3. Embora alguns sistemas telefônicos mais antigos ainda possam usar cabos Cat 3, eles se tornaram obsoletos na indústria de redes.<br/>2) Cat 5<br/>Os cabos Cat 5 aumentaram a largura de banda das conexões Ethernet até 100 MHz e ofereceram velocidades de transmissão de até 100 Mbps. Com os cabos Ethernet Cat 5, os usuários podem acessar sistemas Ethernet 100BASE-TX, conhecidos como Ethernet rápida.<br/>Tal como acontece com os cabos da categoria 3, os cabos cat 5 ainda apresentam interferência e interferência, devido ao design UTP. Estes cabos incluem quatro pares de fios torcidos (para um total de 8 fios).<br/>Embora os cabos cat 5 forneçam principalmente conexões para aplicações Ethernet, esses cabos também fornecem soluções para transportar outros sinais de dados, como vídeo e telefone. Na verdade, um único cabo Cat 5 pode transportar duas linhas telefônicas padrão e uma conexão 100BASE-TX.<br/>3) Cat 5e<br/>Em 2001, a norma de categoria 5e substituiu a categoria 5. A letra "e" no nome significa melhorada.<br/>O cabeamento ainda usa pares torcidos não blindados. Não há diferenças físicas entre os cabos cat 5 e cat 5e. No entanto, padrões mais rigorosos na fabricação de cabos Cat5e ajudam a minimizar a interferência e permitem transmissões de dados mais altas do que o Cat5.<br/>Os cabos Cat 5e também utilizam dois conjuntos de pares de fios torcidos, resultando em velocidades mais rápidas. Enquanto o cabo Ethernet cat 5e ainda possui largura de banda de 100 MHz, esses cabos permitem velocidades de até 1000 Mbps (1 Gbps).<br/>Embora vários padrões adicionais tenham vindo após o cat 5e, esses cabos permanecem em produção. Na verdade, devido ao menor custo de produção e suporte para gigabit Ethernet, os cabos cat 5e são os mais usados para aplicações de rede em todo o mundo.<br/>4) Gato 6<br/>Os cabos Ethernet Cat 6 ajudaram a resolver problemas relacionados a interferências e interferências. Esses cabos usam fios mais finos e isolamento superior, resultando em uma melhor relação sinal-ruído.<br/>Com esses recursos, os cabos Cat 6 fornecem uma opção mais eficaz para adicionar cabos em áreas com mais interferência eletromagnética, como uma sala de servidores lotada.<br/>Graças ao design superior, o cat 6 oferece largura de banda melhorada. Estes cabos têm uma largura de banda máxima de 250 MHz e velocidades de transmissão máximas de até 1000 Mbps (1 Gbps) na faixa de 100m. No entanto, 10Gbps podem ser alcançados no Cat6 em distâncias menores (até 55m).<br/>Alguns cabos Cat 6 incluem blindagem, enquanto outros permanecem desprotegidos. Com blindagem, esses cabos podem fornecer velocidades de transmissão de até 10 Gbps, mas apenas para curtas distâncias, como dissemos acima.<br/>5) Cat 6a<br/>Os cabos Ethernet da categoria 6a melhoram o design dos cabos Cat 6. A letra "a" significa aumentado. Ao contrário dos cabos Cat 6, todos os cabos Cat 6a apresentam cabos blindados para reduzir as interferências.<br/>Com os aprimoramentos às especificações de design, os cabos cat 6a mantêm velocidades de transmissão mais altas e largura de banda máxima de 500 MHz, permitindo velocidades de até 10000 Mbps (10 Gbps) em cabos mais longos.<br/>Embora esses cabos forneçam velocidades mais rápidas, o design os torna menos flexíveis. Para eliminar a interferência, esses cabos apresentam um revestimento mais espesso, tornando os cabos mais rígidos e mais difíceis de trabalhar.<br/>6) Gato 7<br/>Um dos mais recentes desenvolvimentos são os cabos Ethernet Cat 7. Também chamados de cabos de canal classe F, esses cabos incluem padrões mais rigorosos em comparação com as categorias anteriores. Os pares de fios individuais agora incluem sua própria blindagem, além da blindagem externa<br/>Com esses cabos, você obtém largura de banda máxima de 600 MHz e velocidades de transmissão de 10000 Mbps (10 Gbps). No entanto, ao se livrar quase completamente da interferência, os cabos Ethernet cat 7 oferecem ainda maior confiabilidade para conexões Ethernet de 10 Gbps.<br/>Com conexões inferiores a 15 metros, o cat 7 pode suportar velocidades de transmissão de até 100 Gbps. Embora a indústria tenha lançado vários novos padrões desde o cat 7, esses cabos são atualmente a opção de ponta para aplicações de rede exigentes.<br/>- O que é o OSPF NSSA (Área Não Tão Estupida) e como ele é configurado?<br/>- Comparação de protocolos BOOTP vs DHCP em redes de computadores<br/>- Prós e contras da SD-WAN em redes – Descrição e discussão<br/>- Comparação de GNS3 vs EVE-NG vs Packet Tracer para simulação de redes<br/>- Subnetting vs Supernetting – Qual é a diferença? (Guia de explicação) |
| Views: 4 Author: Site Editor Publish Time: 2022-06-09 Origin: Site<br/>So why should workers wear a portable gas detector and what does it do?<br/>In many industrial environments, workers need to be highly aware of exposure to toxic or combustible gases and vapours or a lack of oxygen. That’s why portable gas detectors and analysers are essential – so they can detect, measure, monitor and react to any gases in the immediate area around them. KELISAIKE SAFETY offers both single- and multi-gas mobile gas monitors that reliably detect a wide range of gases. All of our portable gas detectors and software are designed to make compliance and asset management as intuitive as possible, so you can implement a complete product solution that helps ensure safety at all times.<br/>Portable gas detectors are classed as a type of Personal Protective Equipment (PPE)<br/>They monitor gases in the workers breathing zone by displaying real-time gas levels of a variety of toxic, combustible, flammable gases<br/>They alert the worker of any possible threats which include combustion and oxygen displacement<br/>While portable gas detectors are available with various sensor configurations and features, they are all built with the same purpose - to protect human life! | Visualizações: 4 Autor: Editor do Site Tempo de publicação: 2022-06-09 Origem: Site<br/>Então, por que os trabalhadores devem usar um detector de gás portátil e o que ele faz?<br/>Em muitos ambientes industriais, os trabalhadores precisam estar altamente conscientes da exposição a gases e vapores tóxicos ou combustíveis ou da falta de oxigênio. É por isso que os detectores e analisadores de gás portáteis são essenciais – para que possam detectar, medir, monitorar e reagir a quaisquer gases na área imediata ao seu redor. A KELISAIKE SAFETY oferece monitores de gás móveis monogás e multigás que detectam de forma confiável uma ampla gama de gases. Todos os nossos detectores de gás portáteis e software são projetados para tornar a conformidade e o gerenciamento de ativos o mais intuitivo possível, para que você possa implementar uma solução de produto completa que ajude a garantir a segurança em todos os momentos.<br/>Os detectores de gás portáteis são classificados como um tipo de equipamento de proteção individual (EPI).<br/>Eles monitoram os gases na zona de respiração dos trabalhadores, exibindo em tempo real os níveis de gás de uma variedade de gases tóxicos, combustíveis e inflamáveis.<br/>Eles alertam o trabalhador de possíveis ameaças que incluem combustão e deslocamento de oxigênio<br/>Embora os detectores de gás portáteis estejam disponíveis com várias configurações e recursos de sensores, todos eles são construídos com o mesmo propósito - para proteger a vida humana! |
| Salvador Dalí Biography<br/>The prints of Salvador Dalí are rooted in a rich past. In actuality, Dalí’s prints have a history that dates back to his early years of art school. The young Dalí was taught the fine art of engraving and etching by his mentor. Dalí gained a respect for the technical details of printmaking, a respect he would maintain throughout the rest of his life. The connection between Dalí and graphic prints is in fact intricate and protracted. In his lifetime, Dalí produced just around 1,700 graphic prints. A large number of them are hand-signed, limited-edition editions. Some are regarded as some of the best prints created in the 20th century.<br/>Dalí had the ability to experiment with a wide range of subjects through his print work, including etchings, engravings, mixed media, lithographs, and photo-litho. Dalí would produce beautiful suites or single prints. These suites frequently feature a book motif, with the prints acting as the artwork. Among the literary works Dal illustrated were Alice in Wonderland, Hamlet, and The Old Man and the Sea. Other times, similar suites would focus on different subjects, such as flowers (FlorDal), science fiction (Conquest of the Cosmos), or fine print production (Currier and Ives). Dal also produced single prints that showcased his flawless printmaking skills. Prints by Dalí that are among his best include Flower Man, Symphony Bicyclette, Dream Passage, and The Studio of Dalí.<br/>Although it might be speculated that Dalí produced many more prints than the “approved” ones we attribute to him today, Dal’s first prints appeared in the 1920s. His superb craftsmanship is seen in works like Head of a Young Girl and Immaculate Conception. The graphic piece Les Chants de Maldoror is among Dal’s best-known creations. The stories that separate the suites are a perfect match for the pre-surrealistic aspects of the book. A complete set of this suite is now in high demand. The majority of these early works were etchings and engravings; as Dalí’s printing skills improved, he expanded the range of his mediums and themes.<br/>The 1960s are often referred to as the “Golden Age” of Dalí’s prints. In fact, Dalí produced some of his most creative pieces during this decade. For an edition of The Divine Comedy, he finished one hundred wood block prints. This suite is regarded as a work of genius, and Dalí produced magnificent graphics to complement Virgil’s poetry. A fruitful collaboration with the American publishers Phyllis and Sidney Lucas also began throughout this decade. The Lucas’ and Dalí’s combined efforts would result in some of the most enduring Dal paintings ever. Prints like The Drawers of Memory, Fantastic Voyage, The Lucky Number of Salvador Daíi, The Studio of Dalí, and Departure of The Fishermen are examples of the prints that resulted from their collaboration. For Dalí, these were undoubtedly successful years. Over the course of this decade, Dal finished hundreds of photographs. His output was extraordinarily high. However, some of his best graphic creations remained to be seen.<br/>Dal returned to his melting clocks painting, his most well-known creation, in the 1970s. Some people believe that Dalí’s 1975 lithograph Changes In Great Masterpieces is his best creation overall. The collection consists of six images, five of which are Dalí’s interpretations of paintings by Rembrandt, Vermeer, Raphael, and Velasquez. The Persistence of Memory, Dalí’s own masterwork, is reinterpreted in the sixth picture.<br/>Together with his American publishers, Phyllis and Sidney Lucas, Mozart created this suite. Dalí updates his original piece by including a fourth melting clock. The broken clock creeps through the midst of the scene. The fourth clock, according to some, represents the fourth dimension, or time. Some people think that when Dal revised The Persistence of Memory, some 40 years after the original, he was considering his own transience and legacy and paying homage to the Dal of old.<br/>Changes in Great Masterpieces was only one of Dalí’s outstanding creations during the 1970s. In the suites Moses and Monotheism, Imagination and Objects of the Future, and Alchemy of The Philosophers, he produced some magnificent artwork. His two four-piece “puzzles,” The Rejuvenation of Time and The Puzzle of Life, are his largest lithographs. Ten Recipes of Immortality, a collection of three dimensional “pop-up” prints, is an example of how he expanded the scope of his graphic works into the third dimension. Although the 1960s may have been Dalí’s most productive decade, the 1970s appear to have been his most inventive and creative years as he explored new concepts and pushed himself even farther.<br/>In 1982, Dalí’s final prints were released. Dalí’s health had already started to deteriorate by this point, and his output had significantly decreased. However, Dalí was still able to create some excellent graphic prints despite his advanced age. Portrait of Autumn, which is bathed in gorgeous yellows, greens, and reds, is a glorification of the god Dionysus. Collectors of Dalí’s work see Chevalier Surealiste as a must-have piece, and it pays homage to one of Dalí’s heroes, Velasquez. Crucifixion is a superb example of Dalí’s artistry and a testament to his interest in Roman Catholicism.<br/>Dalí spent his entire life working as a printmaker. When evaluating his legacy, one must take into account the graphic arts creations he developed. Some of Dalí’s most artistic icons and imagery, as well as some of his best uses of his imagination, can be seen in these prints. | Biografia de Salvador Dalí<br/>As impressões de Salvador Dalí estão enraizadas em um passado rico. Na verdade, as impressões de Dalí têm uma história que remonta aos seus primeiros anos de escola de arte. O jovem Dalí foi ensinado a bela arte de gravar e gravar por seu mentor. Dalí ganhou um respeito pelos detalhes técnicos da gravura, um respeito que ele manteria pelo resto de sua vida. A conexão entre Dalí e estampas gráficas é de fato intrincada e prolongada. Em sua vida, Dalí produziu apenas cerca de 1.700 impressões gráficas. Um grande número delas são edições de edição limitada assinadas à mão. Algumas são consideradas como algumas das melhores impressões criadas no século 20.<br/>Dalí teve a capacidade de experimentar uma ampla gama de assuntos através de seu trabalho de impressão, incluindo gravuras, gravuras, mídia mista, litografias e foto-litografia. Dalí produziria belas suítes ou impressões individuais. Essas suítes frequentemente apresentam um motivo de livro, com as gravuras atuando como a obra de arte. Entre as obras literárias Dal ilustradas estavam Alice no País das Maravilhas, Hamlet e O Velho e o Mar. Outras vezes, suítes semelhantes se concentravam em diferentes assuntos, como flores (FlorDal), ficção científica (Conquest of the Cosmos) ou produção de impressão fina (Currier e Ives). Dal também produziu impressões únicas que mostraram suas habilidades de gravura impecável. As gravuras de Dalí que estão entre as suas melhores incluem Flower Man, Symphony Bicyclette, Dream Passage e The Studio of Dalí.<br/>Embora possa ser especulado que Dalí produziu muito mais impressões do que as "aprovadas" que lhe atribuímos hoje, as primeiras impressões de Dal apareceram na década de 1920. Sua soberba habilidade é vista em obras como Cabeça de uma Jovem e Imaculada Conceição. A peça gráfica Les Chants de Maldoror está entre as criações mais conhecidas de Dal. As histórias que separam as suítes são uma combinação perfeita para os aspectos pré-surrealistas do livro. Um conjunto completo desta suíte está agora em alta demanda. A maioria dessas obras iniciais eram gravuras e gravuras; à medida que as habilidades de impressão de Dalí melhoravam, ele expandiu a gama de seus meios e temas.<br/>A década de 1960 é muitas vezes referida como a "Idade de Ouro" das impressões de Dalí. De fato, Dalí produziu algumas de suas peças mais criativas durante esta década. Para uma edição de A Divina Comédia, ele terminou cem impressões de blocos de madeira. Esta suíte é considerada uma obra de gênio, e Dalí produziu magníficos gráficos para complementar a poesia de Virgil. Uma colaboração frutífera com as editoras americanas Phyllis e Sidney Lucas também começou ao longo desta década. Os esforços combinados de Lucas e Dalí resultariam em algumas das pinturas Dal mais duradouras de todos os tempos. Estampas como As Gavetas da Memória, Viagem Fantástica, O Número Sortudo de Salvador Daii, O Estúdio de Dalí e A Partida dos Pescadores são exemplos das estampas que resultaram de sua colaboração. Para Dalí, estes foram, sem dúvida, anos de sucesso. Ao longo desta década, Dal terminou centenas de fotografias. Sua produção foi extraordinariamente alta. No entanto, algumas de suas melhores criações gráficas permaneceram para ser vistas.<br/>Dal voltou à sua pintura de relógios de derretimento, sua criação mais conhecida, na década de 1970. Algumas pessoas acreditam que a litografia de 1975 de Dalí Mudanças em Grandes Obras-primas é sua melhor criação em geral. A coleção é composta por seis imagens, cinco das quais são interpretações de Dalí de pinturas de Rembrandt, Vermeer, Rafael e Velasquez. A Persistência da Memória, obra-prima de Dalí, é reinterpretada no sexto quadro.<br/>Junto com suas editoras americanas, Phyllis e Sidney Lucas, Mozart criou esta suíte. Dalí atualiza sua peça original, incluindo um quarto relógio de fusão. O relógio quebrado rasteja pelo meio da cena. O quarto relógio, de acordo com alguns, representa a quarta dimensão, ou tempo. Algumas pessoas pensam que quando Dal revisou The Persistence of Memory, cerca de 40 anos depois do original, ele estava considerando sua própria transitoriedade e legado e prestando homenagem ao antigo Dal.<br/>Mudanças em Grandes Obras-primas foi apenas uma das criações notáveis de Dalí durante a década de 1970. Nas suítes Moisés e Monoteísmo, Imaginação e Objetos do Futuro e Alquimia dos Filósofos, ele produziu algumas obras de arte magníficas. Seus dois "quebra-cabeças" de quatro peças, O Rejuvenescimento do Tempo e O Quebra-cabeça da Vida, são suas maiores litografias. Dez receitas da imortalidade, uma coleção de impressões pop-up tridimensionais, é um exemplo de como ele expandiu o escopo de suas obras gráficas para a terceira dimensão. Embora a década de 1960 possa ter sido a década mais produtiva de Dalí, a década de 1970 parece ter sido seus anos mais inventivos e criativos à medida que ele explorava novos conceitos e se empurrava ainda mais longe.<br/>Em 1982, as últimas impressões de Dalí foram lançadas. A saúde de Dalí já havia começado a se deteriorar neste ponto, e sua produção havia diminuído significativamente. No entanto, Dalí ainda era capaz de criar algumas impressões gráficas excelentes, apesar de sua idade avançada. Retrato do Outono, que é banhado em lindos amarelos, verdes e vermelhos, é uma glorificação do deus Dionísio. Os colecionadores da obra de Dalí veem Chevalier Surealiste como uma peça imperdível, e presta homenagem a um dos heróis de Dalí, Velasquez. A crucificação é um excelente exemplo da arte de Dalí e um testemunho de seu interesse no catolicismo romano.<br/>Dalí passou toda a sua vida trabalhando como gravurista. Ao avaliar seu legado, deve-se levar em conta as criações de artes gráficas que ele desenvolveu. Alguns dos ícones e imagens mais artísticos de Dalí, bem como alguns de seus melhores usos de sua imaginação, podem ser vistos nessas impressões. |
| English Language A Level<br/>&#124;Mode of study&#124;&#124;Academic A Level&#124;<br/>&#124;Campus&#124;&#124;English Bridge Campus&#124;<br/>&#124;Start date&#124;&#124;4 September 2023&#124;<br/>&#124;Course code&#124;&#124;ENG-AL (2325)&#124;<br/>A minimum of five GCSEs at grade 4 or above, including English Language and English Literature.<br/>Please note: You can study both English A level Literature and A level English Language because the courses are sufficiently distinct that there is no overlap or repetition of content. However, you cannot study A Level English Combined and A Level English Literature, or A Level English Combined and A Level English Language.<br/>What does the course involve?<br/>English is an exciting subject and we hope you’ll enjoy the lively debate and discussion. Whichever English course you choose, you’ll gain a great deal of academic prowess and the development of transferable skills.<br/>You will be taught to think analytically, synthesise information, and develop communication skills that are a prerequisite for a wide range of career paths.<br/>The important skill of learning to write coherently and critically will aid you in your other subjects and is invaluable in higher education.<br/>Language is one of the key features that define us as human beings and, on this course, you will explore how it works: how we learn language from infancy, how we use it as a social tool, and how it has evolved over time. You will learn about the origins of English, the various forms it has taken over the centuries, how it has spread across the globe and what it might look like in the future.<br/>You will also study the research of theorists in areas of language such as speech and gender, accents and dialects, and the language of technology. You will learn about grammar in order to explore the ways writers use language to communicate meaning in texts ranging from blogs to 17th-century journalism.<br/>The NEA (coursework) unit will allow you to write creatively and to undertake an investigation into an aspect of the course you have enjoyed.<br/>How is the course assessed?<br/>80% Exam and 20% Coursework. Two coursework tasks and two externally-assessed exams.<br/>This A Level will equip you with the necessary skills to go into practical professions such as journalism and creative writing as well as academic degrees such as law and media studies. It forms a good companion to A Levels in Psychology and Sociology because there is a degree of crossover with the social sciences. If you are thinking of studying English at university, it is perfectly acceptable to take both English Language and English Literature. English can be combined with a range of other subjects at university.<br/>English provides an excellent foundation for various Higher Education courses including law, medicine, English, linguistics and education. It can be combined with a range of other subjects at university. English offers increasing employability in a range of career areas, especially those that require developed communication skills. Students have gone on to careers in law, health and medicine, commerce and industry, marketing, politics and international relations, general management, as well as leading to more predictable areas like journalism, publishing, the media, education, theatre and public relations.<br/>The student magazine produced by students is part of the enrichment opportunities led by the English Department. Trips include theatre trips to London, Manchester and Stratford-upon-Avon and international trips include a visit to battlefields in France, university taster days, residentials and creative writing workshops. These are all optional but highly recommended. Aspiring Oxford and Cambridge applicants will benefit from our extensive range of activities to support you in making a competitive application including: small group subject tuition, Oxford and Cambridge conferences, visits and contacts with our link staff, access to summer schools, application support and essay competitions, supra-curricular activities and access to free university-level Massive Open Online Courses (MOOC).<br/>What do I do next?<br/>You can apply online via the APPLY NOW button and then add an additional two or three subjects to make up your academic programme. You can also apply for a second, alternative vocational programme of study via a separate application. If after reading this factsheet, you are still undecided about the course most suitable for you, please drop in to one of our Open Evenings, ring Admissions on 01743 260401 or email email@example.com<br/>A Level English Language (Law and Drama & Theatre)<br/>Previous school: Mary Webb School<br/>I came here because it was local to me and I enjoyed the pre-enrolment days which were well organised. English Language is a good A Level to have and it is super interesting to see how language has evolved and changed through time. The teachers are a great help and the resources are brilliant; there are plenty of text books.<br/>Are you an employer?<br/>See how an apprentice can help your business. | Língua Inglesa Um Nível<br/>&#124;Modo de estudo&#124;Academic A Level&#124;<br/>&#124;Campus &#124;English Bridge Campus &#124;<br/>&#124;Data de início&#124;4 Setembro 2023&#124;<br/>&#124;Course code&#124;ENG-AL (2325)&#124;<br/>Um mínimo de cinco GCSEs no 4o ano ou acima, incluindo Língua Inglesa e Literatura Inglesa.<br/>Por favor, note: Você pode estudar Inglês Literatura de nível A e Inglês de nível A porque os cursos são suficientemente distintos para que não haja sobreposição ou repetição de conteúdo. No entanto, você não pode estudar um Nível de Inglês Combinado e um Nível de Literatura Inglesa, ou um Nível de Inglês Combinado e um Nível de Língua Inglesa.<br/>O que o curso envolve?<br/>Inglês é um assunto emocionante e esperamos que você goste do animado debate e discussão. Seja qual for o curso de inglês que você escolher, você ganhará uma grande quantidade de proezas acadêmicas e o desenvolvimento de habilidades transferíveis.<br/>Você será ensinado a pensar analiticamente, sintetizar informações e desenvolver habilidades de comunicação que são um pré-requisito para uma ampla gama de carreiras.<br/>A importante habilidade de aprender a escrever de forma coerente e crítica irá ajudá-lo em seus outros assuntos e é inestimável no ensino superior.<br/>A linguagem é uma das principais características que nos definem como seres humanos e, neste curso, você explorará como ela funciona: como aprendemos a linguagem desde a infância, como a usamos como uma ferramenta social e como ela evoluiu ao longo do tempo. Você aprenderá sobre as origens do inglês, as várias formas que assumiu ao longo dos séculos, como se espalhou pelo mundo e como pode ser no futuro.<br/>Você também estudará a pesquisa de teóricos em áreas de linguagem, como fala e gênero, acentos e dialetos e a linguagem da tecnologia. Você aprenderá sobre gramática, a fim de explorar as maneiras como os escritores usam a linguagem para comunicar significado em textos que vão desde blogs até jornalismo do século 17.<br/>A unidade NEA (curso) permitirá que você escreva de forma criativa e realize uma investigação sobre um aspecto do curso que você gostou.<br/>Como é avaliado o curso?<br/>80% Exame e 20% Curso. Duas tarefas de curso e dois exames avaliados externamente.<br/>Este A Level irá equipá-lo com as habilidades necessárias para entrar em profissões práticas, como jornalismo e escrita criativa, bem como graus acadêmicos, como estudos de direito e mídia. Forma um bom companheiro para A Levels in Psychology and Sociology porque há um grau de cruzamento com as ciências sociais. Se você está pensando em estudar inglês na universidade, é perfeitamente aceitável ter tanto a língua inglesa quanto a literatura inglesa. O inglês pode ser combinado com uma variedade de outras disciplinas na universidade.<br/>O inglês fornece uma excelente base para vários cursos de ensino superior, incluindo direito, medicina, inglês, lingüística e educação. Ele pode ser combinado com uma variedade de outros assuntos na universidade. Inglês oferece crescente empregabilidade em uma variedade de áreas de carreira, especialmente aqueles que exigem habilidades de comunicação desenvolvidas. Os alunos passaram a carreiras em direito, saúde e medicina, comércio e indústria, marketing, política e relações internacionais, gestão geral, bem como levando a áreas mais previsíveis, como jornalismo, publicação, mídia, educação, teatro e relações públicas.<br/>A revista estudantil produzida pelos alunos faz parte das oportunidades de enriquecimento lideradas pelo Departamento de Inglês. As viagens incluem viagens teatrais para Londres, Manchester e Stratford-upon-Avon e viagens internacionais incluem uma visita a campos de batalha na França, dias de degustação universitária, residenciais e oficinas de escrita criativa. Estes são todos opcionais, mas altamente recomendados. Os candidatos aspirantes a Oxford e Cambridge se beneficiarão de nossa ampla gama de atividades para apoiá-lo na realização de uma aplicação competitiva, incluindo: aulas em pequenos grupos, conferências de Oxford e Cambridge, visitas e contatos com nossa equipe de link, acesso a escolas de verão, suporte a aplicativos e competições de redação, atividades supra-curriculares e acesso a cursos online abertos maciços (MOOC) de nível universitário gratuito.<br/>O que eu faço a seguir?<br/>Você pode se inscrever on-line através do botão APLICAR AGORA e, em seguida, adicionar dois ou três assuntos adicionais para compor seu programa acadêmico. Você também pode se inscrever para um segundo programa de estudo vocacional alternativo através de uma aplicação separada. Se depois de ler esta ficha, você ainda está indeciso sobre o curso mais adequado para você, por favor, entre em uma das nossas noites abertas, ligue para Admissões em 01743 260401 ou e-mail email@example.com<br/>Um Nível de Língua Inglesa (Lei e Drama e Teatro)<br/>Escola anterior: Mary Webb School<br/>Eu vim aqui porque era local para mim e eu gostei dos dias de pré-inscrição que foram bem organizados. Inglês é um bom A Level para ter e é super interessante ver como o idioma evoluiu e mudou ao longo do tempo. Os professores são uma grande ajuda e os recursos são brilhantes; há muitos livros de texto.<br/>Você é um empregador?<br/>Veja como um aprendiz pode ajudar o seu negócio. |
| In a subproject carried out together with the City of Stockholm within the HazardSupport research project, SMHI has investigated how town planning affects a city’s climate. Scenarios have been produced for Stockholm’s growth up until 2030 and 2050, using summer 2014 as a reference point. These scenarios do not take ongoing climate change into account. Instead, they simply show how the densification and growth of Stockholm can be expected to affect the air temperature.<br/>The main conclusion from the scenarios is that the impact of densification on air temperature is relatively local. No significant effect on the average temperature during the summer is seen at a distance of more than about 2 km, despite extensive densification across large areas. This can be seen in the most central parts of Stockholm, for example, which are already built-up and where no significant reduction in green spaces can therefore be expected. No significant change in air temperature is seen in these areas.<br/>One reason why the densification and expansion of Stockholm has not had any significant impact on air temperature is the relatively rapid air exchange with nearby expanses of water and countryside. Within those areas that are densifying, average summer temperature increases of up to around 1.5°C are being seen. As expected, the biggest temperature increases are observed when natural environments or green areas are built on.<br/>Measures in the local area<br/>One consequence of the locally limited effect of changes in the urban environment is that measures should primarily be focused on direct effects within the local area. Examples of such measures include shady street trees and proximity to green spaces. For the same reason, measures such as green roofs that only indirectly affect the air temperature in the street environment can be expected to have a less significant impact.<br/>A comfort index can be used to summarise the effect of various climate parameters. One example of such an index is the Universal Thermal Climate Index (UTCI). This involves a higher level of ambition in relation to how climate planning is often carried out in today’s planning processes. | Em um subprojeto realizado em conjunto com a cidade de Estocolmo no âmbito do projeto de pesquisa HazardSupport, o SMHI investigou como o planejamento urbano afeta o clima de uma cidade. Foram produzidos cenários para o crescimento de Estocolmo até 2030 e 2050, utilizando o verão de 2014 como ponto de referência. Estes cenários não têm em conta as alterações climáticas em curso. Em vez disso, eles simplesmente mostram como a densificação e o crescimento de Estocolmo podem afetar a temperatura do ar.<br/>A principal conclusão dos cenários é que o impacto da densificação na temperatura do ar é relativamente local. Nenhum efeito significativo sobre a temperatura média durante o verão é visto a uma distância de mais de cerca de 2 km, apesar da extensa densificação em grandes áreas. Isto pode ser visto nas partes mais centrais de Estocolmo, por exemplo, que já estão construídas e onde, portanto, não se pode esperar uma redução significativa nos espaços verdes. Não se observa nenhuma mudança significativa na temperatura do ar nessas áreas.<br/>Uma razão pela qual a densificação e expansão de Estocolmo não teve nenhum impacto significativo na temperatura do ar é a troca de ar relativamente rápida com extensões próximas de água e campo. Dentro das áreas que estão densificando, aumentos médios de temperatura de verão de até cerca de 1,5 ° C estão sendo vistos. Como esperado, os maiores aumentos de temperatura são observados quando ambientes naturais ou áreas verdes são construídas sobre.<br/>Medidas na área local<br/>Uma consequência do efeito localmente limitado das mudanças no ambiente urbano é que as medidas devem ser focadas principalmente em efeitos diretos dentro da área local. Exemplos de tais medidas incluem árvores de rua sombreadas e proximidade com espaços verdes. Pela mesma razão, medidas como telhados verdes que afetam apenas indiretamente a temperatura do ar no ambiente da rua podem ter um impacto menos significativo.<br/>Um índice de conforto pode ser usado para resumir o efeito de vários parâmetros climáticos. Um exemplo de tal índice é o Índice Universal de Clima Térmico (UTCI). Isso envolve um maior nível de ambição em relação à forma como o planejamento climático é frequentemente realizado nos processos de planejamento de hoje. |
