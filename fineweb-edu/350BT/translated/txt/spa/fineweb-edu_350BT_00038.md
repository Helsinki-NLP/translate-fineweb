| original | translation |
|----------|-------------|
| Artificial intelligence (AI), the computerized capability of doing tasks, which until recently was thought to be the exclusive domain of human intelligence, has demonstrated great strides in the past decade. The abilities to play games, provide piloting for an automobile, and respond to spoken language are remarkable successes. How are the challenges and opportunities of medicine different from these challenges and how can we best apply these data-driven techniques to patient care and outcomes? A New England Journal of Medicine paper published in 1980 suggested that more well-defined “specialized” tasks of medical care were more amenable to computer assistance, while the breadth of approach required for defining a problem and narrowing down the problem space was less so, and perhaps, unachievable. On the other hand, one can argue that the modern version of AI, which uses data-driven approaches, will be the most useful in tackling tasks such as outcome prediction that are often difficult for clinicians and patients. The ability today to collect large volumes of data about a single individual (eg, through a wearable device) and the accumulation of large datasets about multiple persons receiving medical care has the potential to apply to the care of individuals. As these techniques of analysis, enumeration, aggregation, and presentation are brought to bear in medicine, the question arises as to their utility and applicability in that domain. Early efforts in decision support were found to be helpful; as the systems proliferated, later experiences have shown difficulties such as alert fatigue and physician burnout becoming more prevalent. Will something similar arise from data-driven predictions? Will empowering patients by equipping them with information gained from data analysis help? Patients, providers, technology, and policymakers each have a role to play in the development and utilization of AI in medicine. Some of the challenges, opportunities, and tradeoffs implicit here are presented as a dialog between a clinician (SJN) and an informatician (QZT).J Med Internet Res 2019;21(11):e16272<br/>Drs Nelson and Zeng-Treitler work together at the Biomedical Informatics Center at George Washington University. In the following we present a hypothetical dialogue which grew out of discussions they had as they considered their differing viewpoints of how artificial intelligence (AI) has developed and where it is going. While Dr Zeng-Treitler’s view of the future of AI is highly optimistic, Dr Nelson's opinion is more cautious. Dr Nelson was a practicing academic internist who became involved in informatics many years ago. He collaborated with Scott Blois on RECONSIDER (an early clinical decision support system) and on the Unified Medical Language System (UMLS) project. He eventually moved to the National Library of Medicine as Head of Medical Subject Headings. While at the National Library of Medicine, he fathered RxNorm, while continuing his work on UMLS and projects involving UMLS. Dr Zeng-Treitler has a background in computer science and obtained her PhD in medical informatics from Columbia University. She has led a number of projects in clinical data mining, natural language processing, and consumer health informatics. During the past few years, her team has been actively investigating the use of AI techniques in clinical research including development of a novel explainable deep learning approach.<br/>Dr Zeng-Treitler (The "Optimist"):<br/>After decades of promises and disappointment, thanks to the seemingly unbounded computing resources and novel, data-driven methods, AI technology has finally arrived. From Jeopardy and Siri to face identification and autonomous vehicles, data-driven approaches have made the leap from laboratory experiments to applications that are transforming our lives outside health care. In some cases, these approaches have come close to passing the Turing Test—a test of a machine’s ability to exhibit supposed human-like intelligence; machines can now perform some complex tasks such as image recognition and authentic game play as well as or better than humans would. Some would argue that the requisite approach is decidedly nonhuman. However, whatever the means to achieving these innovations, such successes have not been followed by analogous successes in health care.<br/>One dramatic example of this disparity of accomplishment is AlphaZero, a computer game engine that mastered chess, Shogi, and Go. Even before the arrival of the current generation of data-driven artifacts, chess engines have been shown to be able to play at a level superior to that of chess champions. Players of Go (a board game that is thought to be much more complex than chess), however, believed that computers were no match for high-level professionals in this game. This belief was shattered first by AlphaGo, which soundly defeated the reigning world champion of Go. Then came AlphaZero. The news is no longer that such approaches can beat the champions of Go, chess, or Shogi. Rather, the remarkable fact is that AlphaZero did not learn from human experiences and that it defeated the best prior chess engines such as Stockfish. AlphaZero triumphed by playing more games against itself than had ever been played by all human players. This is not an approach we could readily duplicate in health care.<br/>Dr Nelson (The "Cautious" One):<br/>Is winning a game, with defined rules and objectives, really the best test of human intelligence? In hindsight, the answer is “No.” For example, sophisticated chess playing programs have existed for nearly 50 years; from such programs, we learned how to organize computing resources to apply simple algorithms in a scalable way. Put differently, we did not learn anything about chess or how humans, even experts, play it. Instead, we learned that a supposed intelligence-requiring task was susceptible to a computational approach. We need to ask where and how such an approach is applicable in health care.<br/>For example, when doing tasks that are generally thought to be human and creative, can the machine recognize when it is out of its depth? Sometimes, humans have the ability to do so. However, if we can define the realm closely enough, I agree that the machines can do wonders. So, how do we define the realm?<br/>In Blois’ seminal paper on Clinical Judgment and Computers , he described the world of a physician’s thought process when seeing a patient, with the diagram shown in . Point A for a physician would be where the patient walks in the door to be seen for the first time. The nature of the complaint, the context in which the complaint occurs, and all of the myriad possibilities are present. As the problem definition moves toward Point B, a computer is better able to manage the information and knowledge necessary for high-quality care. One way in which we can think about defining the realm is that we are moving toward Point B. Some computer scientists have argued that Point A is just about managing facts, but, as Blois observed, it is more about relevance—something that has proven difficult to replicate computationally.<br/>It is indeed important to define the realm for an AI application. Many tasks in health care are much more complex than game play, and we have not witnessed the triumphs of analogous approaches in the biomedical domain as have been achieved in game play. Quite a few studies have been applying the latest deep learning technology (a key AI method) to biomedical datasets [- ]. The specific applications included image processing, natural language processing, and risk prediction. Deep learning, compared with traditional statistical and machine learning methods, has often shown modest improvements rather than breakthroughs [ - ].<br/>Whatever the details of these approaches, they apply nearly unbounded computing resources to very large amounts of data, something that has yet to happen in health care. Therefore, these approaches might prove helpful, but we do not know for sure yet.<br/>For example, a simple question posed by a colleague is beyond our current capabilities: Given a patient who starts out with a feature of metabolic syndrome, which feature of the syndrome will he or she tend to exhibit next? Simplistically, this is exactly the kind of challenge that a data-driven approach should help with, and yet, it is currently “over the horizon” due to the insufficient data that were collected in the past.<br/>Data are a key challenge when applying data-driven approaches to patient care. To begin with, biomedical data are highly complex. There many different types of data including image, text, numerical values, categorical classifications, and DNA sequences, representing tens of thousands of lab tests, procedures, diagnoses, medications, genetic markers, etc. Each data type also has its own characteristics; for example, a laboratory test value may need to be interpreted in the context of age, gender, and current conditions. However, diagnostic codes for different diseases have varying levels of accuracies.<br/>In biomedical data analysis, there is also the paradox of having too much and not enough data at the same time. On one hand, there are a tremendous amount of medical record, social media, and literature data. Efforts like the Million Veterans Project  have also collected a huge amount of DNA data. Using devices for tasks like activity tracking and continuous glucose monitoring generates more data than our current medical record systems can digest. On the other hand, the health record of a patient is an open system with much missing information in contrast with the closed system of a chess or Go game, where all data are available. Patients are observed at irregular intervals (eg, at clinic visits or during hospitalization) and are never subjected to all possible tests or treatments. Sometimes, death is the only definitive outcome.<br/>I agree that data types are multiple and complex. Simple solutions are insufficient, and the proliferation of irrelevant data in a record, not to mention the current cut-and-paste or fill-in-the-template fad, obscures what is important.<br/>One of the major difficulties with medical data is not just that it is not enough, but also that it is theory laden, that is, very few pieces of data are recorded routinely. A lot of data in observations are gathered only when the clinician has thought it is appropriate, that is, when diseases are tested for their absence or presence. If there is no reason to do the test, the test is not performed. Only a few tests are ever performed routinely; a transcribed set of physical observations (as is done in physical examination) is rarely recorded in enough detail (not to mention the failure to observe, which often occurs) to provide sufficient data for a more comprehensive analysis. For that reason alone, studies based on the recorded observations are often incomplete and potentially misleading. However, for predictions, observations not made may be the critical ones. Think about the patient with metabolic syndrome mentioned above. What data are we missing?<br/>Similarly, the results of clinical trials are not a complete picture. Even though participants have been selected, often excluding many individuals because of complicating conditions, the data collected on the participants are designed for testing certain hypotheses, with narrowly defined outcomes. A common criticism is that such trials are so artificial that they are irrelevant.<br/>The lack of integrated and standardized datasets is another issue. Although we can find many large datasets, they are often incomplete and difficult to link to other information. For example, environmental exposure, diet, physical activity, and genetic profile are among the common missing pieces of information when we examine the records about an individual patient. Detailed clinical trial datasets tend to lack long-term follow-up. Privacy issues and monetary incentives are also obstacles in data integration efforts.<br/>Real semantic interoperability to integrate and standardize datasets requires support in both terminology and how that terminology is used. Currently, human intervention is often required to interpret what one system is saying for use in another system. This situation is unfortunate; we can hope that over time, the necessary connections will take place (think of how the United States went from operator assistance on every telephone call to the automatic switching that takes place today). Such a change can only happen when many people see the need for and implement a common standard.<br/>In addition, the notion of “large” in the context of health care data is only relative. Think, instead, of many experiments undertaken by Google; if they desire, the amount of data that can be used to develop and test a model is orders of magnitude greater than that available in health care.<br/>In the domains where data-driven approaches have demonstrated success, there are outcomes that can be judged by human experts or machines themselves. For example, bilingual speakers can tell if natural language translation is working well, and the outcome of board or computer games can be easily determined. This allows easier simulation or annotation of data for machine learning. Such a task is much harder in the biomedical domains; investigation of causes or treatments of diseases in humans involve costly and long-term studies. In some cases, ethical concerns prohibit the experiments; for example, the introduction of potentially harmful genetic mutations into healthy human subjects is out of the question. We lack long-term outcome data for many treatments.<br/>I am not sure that there ever will be such a gold standard without a completely arbitrary definition. Variation between individuals is also a major obstacle. Although we perform studies using multiple subjects to account for biologic variability, our results are only approximate in their relevance to a given individual. For example, assuring genetic diversity in clinical trials is challenging, to say the least. Even the simplest tasks can be staggeringly multifactorial; for example, the information content of genetic testing for warfarin metabolism can be outweighed by whether the patient had lettuce for lunch.<br/>To expand on this observation, suppose you have an automobile that is not working appropriately. Today, you consult the sensors and the computer readout to give you very precise information about what is going wrong. The automobile has a specific design, with specific parameters that can be measured. All of the vehicles of the same year make and model can be assumed to be alike in those important aspects. It is important to realize that every human (with the exception of identical twins) is genetically unique. In that way, people are very different from automobiles or other mechanical devices. To compound the complexity with which the cause of a human problem can be addressed, what the individual experiences throughout their life is unique. Although we have nice abstractions or methods of identifying individuals who share some common characteristics (whether the presence or absence of a disease, the response or lack thereof to a medication, the similar environment, or other considerations), these are only a shorthand notation. With 7 billion persons currently living in this world, the problem appears almost open-ended. Too often in data analysis, we look at diagnostic codes as having a deep meaning. These are accepted without any recognition of the degree of uncertainty of the diagnosis. All our data may be helpful and useful, but we need to continue to view them with a large grain of salt. The fact that Google Translate works as well as it does gives us hope, but as complex as natural language translation is, it is simpler than some clinical tasks.<br/>Despite these challenges, applying data-driven approaches has the potential to transform health care. Today’s health care is labor intensive, from scheduling and triage to diagnosis and treatment. Many tasks currently undertaken by humans can be carried out by intelligent software solutions supported by sufficient data. For instance, improved voice recognition and summarization technology might help reduce the amount of time patients and clinicians spend on paperwork. Improved decision support tools ought to be able to help patients decide about the appropriateness of seeking care. An accurate assessment of short- and long-term risks and benefits will inform treatment selection and lifestyle changes.<br/>To provide another use case, there is evidence that type II diabetes may be reversible, but it is hard to apply this knowledge to an individual patient. Given the patient in front of me, what should I do, or recommend, and with what expectation? Demographics, genomics, comorbidities, psyche, competing risks, and other medications, all play a role. How, in a given person, do I reconcile all the possibilities?<br/>To develop these useful AI tools, we need better data, technology, and policy. To accumulate comprehensive, life-time data, patients must be in control and should be incentivized to share their data for research and care. Insurance, pharmaceutical, and medical institutions change over time. Currently, there are barriers for individuals to be the center of collecting the data on themselves. The barriers are present in data entry, collection, and storage; for example, some personalized health record products are tethered to an institution, while others require extensive transcribing efforts by patients or caregivers. Nevertheless, without patient consent and collaboration, gathering and linking longitudinal environmental, genetic, clinical, and behavioral data are neither feasible nor ethical. The current conditions are a huge barrier to any attempt to use data-driven approaches that have worked outside health care.<br/>Efforts including PatienstLikeMe  and the All of Us Research Project of the National Institutes of Health [ ] are examples of innovative approaches to curate bigger and better datasets. Most patients, however, are not engaged in such efforts. Patients are inherently motivated to improve their own health, but naturally have concerns regarding privacy and often do not see immediate benefits of participating in long-term studies. Appropriate incentives (eg, discounts for routine preventive care) coupled with security and authentication technologies are needed to entice a large and diverse population of patients to gather and share their data. The health care industry today owns parts of patient data and has limited motivation to purchase data from their customers. As the value of data increases, patients will become more valued as a partner.<br/>I agree that patients will need to assume the responsibility of carrying and sharing the information about themselves. However, experience tells us that not everyone is able or willing to do so. It will need cultural and political climate changes to encourage that development.<br/>When we can collect data that are not directly what the philosophers would call “theory-laden,” we may be able to refine our crude methods of patient diagnosis and care. I look forward to that day. If patients are the carrier of those data, it will be easier to obtain and use for analysis.<br/>We also need to design and implement methods specifically for handling very large and “messy” clinical data. For example, we need to understand the context of missing data and errors to get a better picture of ground truth. A lab result may be missed because there is no indication for it, practice preference, an alternative method of assessing, or a failure of data entry. Imagine how much more difficult a chess game will be, if a human player or a chess engine could only observe some squares on the board at irregular time intervals with some error or distortion of the observation.<br/>Further, we do not have an operational definition of “ground truth” in health care; a simple proposal is that one feature of ground truth is that it has predictive value—something that will be valued by clinicians and patients alike.<br/>Google has demonstrated that they can use lots of data to predict likely values for missing data in other areas ; however, it is yet to be determined whether this might work in medicine, but it is probably worth a trial. Irrespective of whether we can use large volumes of data to impute missing values, exploring how to handle the problem of absent observations is crucial, especially whenever we try to apply the results of data-driven approaches to individual patients.<br/>Another thought is that data that are missing, for any reason, are an observation in itself; the fact that the data were not obtained and recorded may be important. Think of the finding that the day and time of a test were more predictive of outcome than the result of the test . We know that the data that are missing will have some predictive value.<br/>On a different note, explanation of the data-driven models is critical to not only their adoption but also their impact . Predicting that a patient will have certain adverse events in the next several days or years is desirable. It may be argued that it is even more important to know the modifiable factors that can reduce risk and enhance outcome. Since deep learning models can be highly nonlinear, we have the opportunity to discover novel and complex patterns.<br/>I agree that explaining the prediction is critical; it is something that separates health care from, say, recognizing whether an image is a dog or a cat. However, I think you meant to say predicting a patient will probably have some adverse outcome. Nothing in life is certain except that it will end. However, we can say “it appears this behavior or finding will likely have an effect on your future” and hopefully be able to express some degree of confidence in that prediction.<br/>Learning how to express the confidence in a prediction is also important. How many folks really understand the statistics behind the predictions that occur today? What are the underlying assumptions behind any probabilistic model? It is more likely that with more frequent use and familiarity with the use of measures derived for AI models will lead to their acceptance.<br/>I agree. These are all steps to be taken in order to optimize the use of big data through AI to improve medical care.<br/>As a parting thought, we need to be cautious about how intrusive data-driven approaches might be in the care process. Although McDonald  demonstrated that performance in care improves with reminders [ ], the later experience has been one of too many reminders, leading to alert fatigue. When caregivers choose to override and ignore helpful information because of overload, have we accomplished anything?<br/>I hope that careful design of systems and consideration of clinical workflow will alleviate the problem of excessive intrusiveness. Although it is tempting to just “let AI do it,” the recent experiences with the Boeing 737 MAX demonstrate that there is danger in doing so. Neither AI nor a pilot alone is the optimal strategy in flying. In health care, involving patients more extensively in their care, together with AI and providers, may ultimately be an approach that works.<br/>Conflicts of Interest<br/>- Blois MS. Clinical Judgment and Computers. N Engl J Med 1980 Jul 24;303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Deep learning for healthcare: review, opportunities and challenges. Brief Bioinform 2018 Nov 27;19(6):1236-1246 [FREE Full text] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. Can machine-learning improve cardiovascular risk prediction using routine clinical data? PLoS ONE 2017 Apr 4;12(4):e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT. Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records. Sci Rep 2016 May 17;6(1):26094 [FREE Full text] [CrossRef] [Medline]<br/>- Quach K. The register. 2019. IBM Watson Health cuts back drug discovery 'artificial intelligence' after lackluster sales URL: https://www.theregister.co.uk/2019/04/18/ibm_watson_health [accessed 2019-10-23]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Scalable and accurate deep learning with electronic health records. NPJ Digit Med 2018 May 8;1(1):18 [FREE Full text] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, et al. Deep Learning in Medical Imaging: General Overview. Korean J Radiol 2017;18(4):570. [CrossRef]<br/>- U.S Department of Veterans Affairs. Million Veteran Program (MVP) URL: https://www.research.va.gov/mvp/ [accessed 2019-10-23]<br/>- Patientslikeme. URL: https://www.patientslikeme.com [accessed 2019-10-23]<br/>- All of Us Research Program. URL: https://allofus.nih.gov [accessed 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. The unreasonable effectiveness of data. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Biases in electronic health record data due to processes within the healthcare system: retrospective observational study. BMJ 2018 Apr 30:k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, Müller H. Causability and explainabilty of artificial intelligence in medicine. WIREs Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Protocol-Based Computer Reminders, the Quality of Care and the Non-Perfectibility of Man. N Engl J Med 1976 Dec 09;295(24):1351-1355. [CrossRef]<br/>&#124;AI: artificial intelligence&#124;<br/>&#124;UMLS: Unified Medical Language System&#124;<br/>Edited by G Eysenbach; submitted 15.09.19; peer-reviewed by A Holzinger; comments to author 14.10.19; revised version received 15.10.19; accepted 20.10.19; published 27.11.19Copyright<br/>©Qing Zeng-Treitler, Stuart J Nelson. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included. | La inteligencia artificial (IA), la capacidad computarizada de hacer tareas, que hasta hace poco se pensaba que era el dominio exclusivo de la inteligencia humana, ha demostrado grandes avances en la última década. Las habilidades para jugar juegos, proporcionar pilotaje para un automóvil y responder al lenguaje hablado son éxitos notables. ¿En qué se diferencian los desafíos y oportunidades de la medicina de estos desafíos y cómo podemos aplicar mejor estas técnicas basadas en datos para la atención y los resultados del paciente? Un artículo de New England Journal of Medicine publicado en 1980 sugirió que las tareas "especializadas" más bien definidas de atención médica eran más susceptibles a la asistencia informática, mientras que la amplitud de enfoque requerida para definir un problema y reducir el espacio del problema era menos factible, y tal vez, inalcanzable. Por otro lado, se puede argumentar que la versión moderna de la IA, que utiliza enfoques basados en datos, será la más útil para abordar tareas como la predicción de resultados que a menudo son difíciles para los médicos y los pacientes. La capacidad actual de recopilar grandes volúmenes de datos sobre un solo individuo (por ejemplo, a través de un dispositivo portátil) y la acumulación de grandes conjuntos de datos sobre múltiples personas que reciben atención médica tiene el potencial de aplicarse al cuidado de los individuos. A medida que estas técnicas de análisis, enumeración, agregación y presentación se aplican en medicina, surge la pregunta sobre su utilidad y aplicabilidad en ese dominio. Se encontró que los primeros esfuerzos en el apoyo a la decisión eran útiles; a medida que los sistemas proliferaban, las experiencias posteriores han mostrado dificultades como la fatiga de alerta y el agotamiento del médico cada vez más prevalente. ¿Surgirá algo similar de las predicciones basadas en datos? ¿Ayudará capacitar a los pacientes equipándolos con la información obtenida del análisis de datos? Los pacientes, los proveedores, la tecnología y los responsables políticos tienen un papel que desempeñar en el desarrollo y la utilización de la IA en la medicina. Algunos de los desafíos, oportunidades y compensaciones implícitas aquí se presentan como un diálogo entre un clínico (SJN) y un informático (QZT). J Med Internet Res 2019;21(11):e16272<br/>Los doctores Nelson y Zeng-Treitler trabajan juntos en el Centro de Informática Biomédica de la Universidad George Washington. A continuación presentamos un diálogo hipotético que surgió de las discusiones que tuvieron al considerar sus diferentes puntos de vista sobre cómo se ha desarrollado la inteligencia artificial (IA) y hacia dónde va. Si bien la visión del Dr. Zeng-Treitler sobre el futuro de la IA es muy optimista, la opinión del Dr. Nelson es más cautelosa. El Dr. Nelson era un internista académico practicante que se involucró en informática hace muchos años. Colaboró con Scott Blois en RECONSIDER (un sistema temprano de apoyo a la decisión clínica) y en el proyecto del Sistema Unificado de Lenguaje Médico (UMLS), y finalmente se mudó a la Biblioteca Nacional de Medicina como Jefe de Temas Médicos. Mientras estaba en la Biblioteca Nacional de Medicina, fue padre de RxNorm, mientras continuaba su trabajo en UMLS y proyectos relacionados con UMLS. El Dr. Zeng-Treitler tiene experiencia en ciencias de la computación y obtuvo su doctorado en informática médica de la Universidad de Columbia. Ha liderado una serie de proyectos en minería de datos clínicos, procesamiento de lenguaje natural e informática de salud del consumidor. Durante los últimos años, su equipo ha estado investigando activamente el uso de técnicas de IA en la investigación clínica, incluido el desarrollo de un nuevo enfoque de aprendizaje profundo explicable.<br/>Dr. Zeng-Treitler (El "Optimista")<br/>Después de décadas de promesas y decepciones, gracias a los recursos informáticos aparentemente ilimitados y los métodos novedosos basados en datos, la tecnología de IA finalmente ha llegado. Desde Jeopardy y Siri hasta vehículos de identificación y autónomos, los enfoques basados en datos han dado el salto de los experimentos de laboratorio a las aplicaciones que están transformando nuestras vidas fuera de la atención médica. En algunos casos, estos enfoques se han acercado a pasar la prueba de Turing, una prueba de la capacidad de una máquina para exhibir una supuesta inteligencia similar a la humana; las máquinas ahora pueden realizar algunas tareas complejas como el reconocimiento de imágenes y el juego auténtico, así como o mejor que los humanos. Algunos argumentarían que el enfoque requerido es decididamente no humano, sin embargo, cualesquiera que sean los medios para lograr estas innovaciones, tales éxitos no han sido seguidos por éxitos análogos en la atención de la salud.<br/>Un ejemplo dramático de esta disparidad de logros es AlphaZero, un motor de juego de computadora que dominó el ajedrez, Shogi y Go. Incluso antes de la llegada de la generación actual de artefactos basados en datos, se ha demostrado que los motores de ajedrez pueden jugar a un nivel superior al de los campeones de ajedrez. Los jugadores de Go (un juego de mesa que se cree que es mucho más complejo que el ajedrez), sin embargo, creían que las computadoras no eran rival para los profesionales de alto nivel en este juego. Esta creencia fue destrozada primero por AlphaGo, que derrotó profundamente al campeón mundial reinante de Go. Luego vino AlphaZero. La noticia ya no es que tales enfoques puedan vencer a los campeones de Go, ajedrez o Shogi. Más bien, el hecho notable es que AlphaZero no aprendió de las experiencias humanas y que derrotó a los mejores motores de ajedrez anteriores como Stockfish. AlphaZero triunfó jugando más juegos contra sí mismo que nunca habían jugado todos los jugadores humanos. Este no es un enfoque que podríamos duplicar fácilmente en el cuidado de la salud.<br/>El Dr. Nelson (El "Precavido")<br/>¿Es ganar un juego, con reglas y objetivos definidos, realmente la mejor prueba de la inteligencia humana? En retrospectiva, la respuesta es "No". Por ejemplo, los sofisticados programas de ajedrez han existido durante casi 50 años; a partir de tales programas, aprendimos a organizar los recursos informáticos para aplicar algoritmos simples de una manera escalable. Dicho de otra manera, no aprendimos nada sobre el ajedrez o cómo los humanos, incluso los expertos, lo juegan. En cambio, aprendimos que una supuesta tarea que requería inteligencia era susceptible a un enfoque computacional. Necesitamos preguntarnos dónde y cómo es aplicable tal enfoque en la atención médica.<br/>Por ejemplo, cuando se realizan tareas que generalmente se consideran humanas y creativas, ¿puede la máquina reconocer cuándo está fuera de su profundidad? A veces, los humanos tienen la capacidad de hacerlo. Sin embargo, si podemos definir el reino lo suficientemente cerca, estoy de acuerdo en que las máquinas pueden hacer maravillas. Entonces, ¿cómo definimos el reino?<br/>En el artículo seminal de Blois sobre Juicio Clínico y Computadoras, describió el mundo del proceso de pensamiento de un médico al ver a un paciente, con el diagrama que se muestra en . El punto A para un médico sería donde el paciente entra por la puerta para ser visto por primera vez. La naturaleza de la queja, el contexto en el que ocurre la queja y todas las innumerables posibilidades están presentes. A medida que la definición del problema se mueve hacia el punto B, una computadora puede administrar mejor la información y el conocimiento necesarios para una atención de alta calidad. Una forma en que podemos pensar en definir el reino es que nos estamos moviendo hacia el Punto B. Algunos científicos informáticos han argumentado que el Punto A se trata solo de administrar los hechos, pero, como observó Blois, se trata más de relevancia, algo que ha demostrado ser difícil de replicar computacionalmente.<br/>De hecho, es importante definir el ámbito de una aplicación de IA. Muchas tareas en el cuidado de la salud son mucho más complejas que el juego, y no hemos sido testigos de los triunfos de enfoques análogos en el dominio biomédico como se han logrado en el juego. Bastantes estudios han estado aplicando la última tecnología de aprendizaje profundo (un método clave de IA) a conjuntos de datos biomédicos [- ]. Las aplicaciones específicas incluyeron procesamiento de imágenes, procesamiento de lenguaje natural y predicción de riesgos. El aprendizaje profundo, en comparación con los métodos estadísticos y de aprendizaje automático tradicionales, a menudo ha mostrado mejoras modestas en lugar de avances.<br/>Cualesquiera que sean los detalles de estos enfoques, aplican recursos informáticos casi ilimitados a cantidades muy grandes de datos, algo que aún no ha sucedido en la atención médica. Por lo tanto, estos enfoques pueden resultar útiles, pero aún no lo sabemos con certeza.<br/>Por ejemplo, una simple pregunta planteada por un colega está más allá de nuestras capacidades actuales: Dado un paciente que comienza con una característica del síndrome metabólico, ¿qué característica del síndrome tenderá a exhibir a continuación? Simplistamente, este es exactamente el tipo de desafío con el que un enfoque basado en datos debería ayudar, y sin embargo, actualmente está "en el horizonte" debido a los datos insuficientes que se recopilaron en el pasado.<br/>Los datos son un desafío clave al aplicar enfoques basados en datos para la atención al paciente. Para empezar, los datos biomédicos son muy complejos. Hay muchos tipos diferentes de datos, incluyendo imágenes, texto, valores numéricos, clasificaciones categóricas y secuencias de ADN, que representan decenas de miles de pruebas de laboratorio, procedimientos, diagnósticos, medicamentos, marcadores genéticos, etc. Cada tipo de datos también tiene sus propias características; por ejemplo, un valor de prueba de laboratorio puede necesitar ser interpretado en el contexto de la edad, el género y las condiciones actuales. Sin embargo, los códigos de diagnóstico para diferentes enfermedades tienen diferentes niveles de precisión.<br/>En el análisis de datos biomédicos, también existe la paradoja de tener demasiados y no suficientes datos al mismo tiempo. Por un lado, hay una enorme cantidad de registros médicos, redes sociales y datos de literatura. Esfuerzos como el Million Veterans Project también han recopilado una gran cantidad de datos de ADN. El uso de dispositivos para tareas como el seguimiento de actividades y el monitoreo continuo de glucosa genera más datos de los que nuestros sistemas de registros médicos actuales pueden digerir. Por otro lado, el registro de salud de un paciente es un sistema abierto con mucha información faltante en contraste con el sistema cerrado de un juego de ajedrez o Go, donde todos los datos están disponibles. Los pacientes son observados a intervalos irregulares (por ejemplo, en visitas clínicas o durante la hospitalización) y nunca son sometidos a todas las pruebas o tratamientos posibles. A veces, la muerte es el único resultado definitivo.<br/>Estoy de acuerdo en que los tipos de datos son múltiples y complejos. Las soluciones simples son insuficientes, y la proliferación de datos irrelevantes en un registro, sin mencionar la moda actual de cortar y pegar o rellenar la plantilla, oscurece lo que es importante.<br/>Una de las principales dificultades con los datos médicos no es solo que no es suficiente, sino también que está cargado de teoría, es decir, que se registran muy pocos datos de forma rutinaria. Una gran cantidad de datos en las observaciones se recogen sólo cuando el médico ha pensado que es apropiado, es decir, cuando las enfermedades se prueban para su ausencia o presencia. Si no hay ninguna razón para hacer la prueba, la prueba no se realiza. Solo unas pocas pruebas se realizan de forma rutinaria; un conjunto transcrito de observaciones físicas (como se hace en el examen físico) rara vez se registra con suficiente detalle (sin mencionar la falta de observación, que a menudo ocurre) para proporcionar datos suficientes para un análisis más completo. Por esa sola razón, los estudios basados en las observaciones registradas a menudo son incompletos y potencialmente engañosos. Sin embargo, para las predicciones, las observaciones no realizadas pueden ser las críticas. Piense en el paciente con síndrome metabólico mencionado anteriormente. ¿Qué datos nos faltan?<br/>Del mismo modo, los resultados de los ensayos clínicos no son una imagen completa. A pesar de que los participantes han sido seleccionados, a menudo excluyendo a muchos individuos debido a condiciones complicadas, los datos recopilados sobre los participantes están diseñados para probar ciertas hipótesis, con resultados estrechamente definidos. Una crítica común es que tales juicios son tan artificiales que son irrelevantes.<br/>La falta de conjuntos de datos integrados y estandarizados es otro problema. Aunque podemos encontrar muchos conjuntos de datos grandes, a menudo son incompletos y difíciles de vincular a otra información. Por ejemplo, la exposición ambiental, la dieta, la actividad física y el perfil genético son algunas de las piezas de información comunes que faltan cuando examinamos los registros sobre un paciente individual.Los conjuntos de datos detallados de ensayos clínicos tienden a carecer de seguimiento a largo plazo. Los problemas de privacidad y los incentivos monetarios también son obstáculos en los esfuerzos de integración de datos.<br/>La interoperabilidad semántica real para integrar y estandarizar conjuntos de datos requiere soporte tanto en terminología como en cómo se usa esa terminología. Actualmente, a menudo se requiere la intervención humana para interpretar lo que un sistema está diciendo para su uso en otro sistema. Esta situación es desafortunada; podemos esperar que con el tiempo, se lleven a cabo las conexiones necesarias (piense en cómo los Estados Unidos pasaron de la asistencia del operador en cada llamada telefónica a la conmutación automática que tiene lugar hoy). Tal cambio solo puede ocurrir cuando muchas personas ven la necesidad de implementar un estándar común.<br/>Además, la noción de "grande" en el contexto de los datos de atención médica es solo relativa. Piense, en cambio, en muchos experimentos realizados por Google; si lo desean, la cantidad de datos que se pueden usar para desarrollar y probar un modelo es de órdenes de magnitud mayor que la disponible en la atención médica.<br/>En los dominios donde los enfoques basados en datos han demostrado éxito, hay resultados que pueden ser juzgados por expertos humanos o por las propias máquinas. Por ejemplo, los hablantes bilingues pueden saber si la traducción del lenguaje natural está funcionando bien, y el resultado de los juegos de mesa o de computadora se puede determinar fácilmente, lo que permite una simulación o anotación más fácil de los datos para el aprendizaje automático. Tal tarea es mucho más difícil en los dominios biomédicos; la investigación de causas o tratamientos de enfermedades en humanos implica estudios costosos y a largo plazo. En algunos casos, las preocupaciones éticas prohíben los experimentos; por ejemplo, la introducción de mutaciones genéticas potencialmente dañinas en sujetos humanos sanos está fuera de discusión. Carecemos de datos de resultados a largo plazo para muchos tratamientos.<br/>No estoy seguro de que alguna vez haya un patrón oro sin una definición completamente arbitraria. La variación entre individuos también es un obstáculo importante. Aunque realizamos estudios utilizando múltiples sujetos para tener en cuenta la variabilidad biológica, nuestros resultados son solo aproximados en su relevancia para un individuo dado. Por ejemplo, asegurar la diversidad genética en los ensayos clínicos es un desafío, por decir lo menos. Incluso las tareas más simples pueden ser asombrosamente multifactoriales; por ejemplo, el contenido de información de las pruebas genéticas para el metabolismo de la warfarina puede ser superado por si el paciente tenía lechuga para el almuerzo.<br/>Para ampliar esta observación, suponga que tiene un automóvil que no funciona correctamente. Hoy en día, consulte los sensores y la lectura de la computadora para brindarle información muy precisa sobre lo que está sucediendo. El automóvil tiene un diseño específico, con parámetros específicos que se pueden medir. Todos los vehículos del mismo año hacen y modelo se puede suponer que son iguales en esos aspectos importantes. Es importante darse cuenta de que cada ser humano (con la excepción de los gemelos idénticos) es genéticamente único. De esa manera, las personas son muy diferentes de los automóviles u otros dispositivos mecánicos. Para agravar la complejidad con la que se puede abordar la causa de un problema humano, lo que el individuo experimenta a lo largo de su vida es único. Aunque tenemos buenas abstracciones o métodos para identificar individuos que comparten algunas características comunes (ya sea la presencia o ausencia de una enfermedad, la respuesta o falta de ella a un medicamento, el entorno similar u otras consideraciones), estas son solo una notación abreviada. Con 7 mil millones de personas viviendo actualmente en este mundo, el problema parece casi abierto. Demasiado a menudo en el análisis de datos, consideramos que los códigos de diagnóstico tienen un significado profundo. Estos son aceptados sin ningún reconocimiento del grado de incertidumbre del diagnóstico. Todos nuestros datos pueden ser útiles y útiles, pero tenemos que seguir viéndolos con un gran grano de sal. El hecho de que Google Translate funcione tan bien como lo hace nos da esperanza, pero tan compleja como la traducción del lenguaje natural es, es más simple que algunas tareas clínicas.<br/>A pesar de estos desafíos, la aplicación de enfoques basados en datos tiene el potencial de transformar la atención médica. La atención médica actual requiere mucha mano de obra, desde la programación y el triaje hasta el diagnóstico y el tratamiento. Muchas de las tareas que actualmente realizan los seres humanos pueden llevarse a cabo mediante soluciones de software inteligentes respaldadas por datos suficientes. Por ejemplo, la tecnología mejorada de reconocimiento de voz y resumen podría ayudar a reducir la cantidad de tiempo que los pacientes y los médicos pasan en el papeleo. Una evaluación precisa de los riesgos y beneficios a corto y largo plazo informará la selección del tratamiento y los cambios en el estilo de vida.<br/>Para proporcionar otro caso de uso, hay evidencia de que la diabetes tipo II puede ser reversible, pero es difícil aplicar este conocimiento a un paciente individual. Dado el paciente frente a mí, ¿qué debo hacer, o recomendar, y con qué expectativa? La demografía, la genómica, las comorbilidades, la psique, los riesgos en competencia y otros medicamentos juegan un papel importante. ¿Cómo, en una persona determinada, reconcilio todas las posibilidades?<br/>Para desarrollar estas útiles herramientas de IA, necesitamos mejores datos, tecnología y políticas. Para acumular datos completos de por vida, los pacientes deben tener el control y deben ser incentivados a compartir sus datos para la investigación y la atención. Las instituciones de seguros, farmacéuticas y médicas cambian con el tiempo. Actualmente, existen barreras para que las personas sean el centro de recopilación de datos sobre sí mismas. Las barreras están presentes en la entrada, recopilación y almacenamiento de datos; por ejemplo, algunos productos de registros de salud personalizados están atados a una institución, mientras que otros requieren amplios esfuerzos de transcripción por parte de pacientes o cuidadores. Sin embargo, sin el consentimiento y la colaboración del paciente, recopilar y vincular datos longitudinales ambientales, genéticos, clínicos y de comportamiento no es factible ni ético. Las condiciones actuales son una gran barrera para cualquier intento de utilizar enfoques basados en datos que han funcionado fuera de la atención médica.<br/>Los esfuerzos que incluyen PatienstLikeMe y el Proyecto de Investigación All of Us de los Institutos Nacionales de Salud [ ] son ejemplos de enfoques innovadores para seleccionar conjuntos de datos más grandes y mejores. Los pacientes están motivados inherentemente para mejorar su propia salud, pero naturalmente tienen preocupaciones con respecto a la privacidad y, a menudo, no ven beneficios inmediatos de participar en estudios a largo plazo. Se necesitan incentivos apropiados (por ejemplo, descuentos para la atención preventiva de rutina) junto con tecnologías de seguridad y autenticación para atraer a una población grande y diversa de pacientes a recopilar y compartir sus datos. La industria del cuidado de la salud hoy en día posee partes de los datos de los pacientes y tiene una motivación limitada para comprar datos de sus clientes. A medida que aumenta el valor de los datos, los pacientes se volverán más valorados como socios.<br/>Estoy de acuerdo en que los pacientes tendrán que asumir la responsabilidad de llevar y compartir la información sobre sí mismos. Sin embargo, la experiencia nos dice que no todos pueden o quieren hacerlo. Necesitará cambios climáticos culturales y políticos para fomentar ese desarrollo.<br/>Cuando podamos recopilar datos que no sean directamente lo que los filósofos llamarían "cargados de teoría", podremos refinar nuestros crudos métodos de diagnóstico y cuidado del paciente. Si los pacientes son los portadores de esos datos, será más fácil de obtener y usar para el análisis.<br/>También necesitamos diseñar e implementar métodos específicamente para manejar datos clínicos muy grandes y "desordenados". Por ejemplo, necesitamos comprender el contexto de los datos faltantes y los errores para obtener una mejor imagen de la verdad básica. Se puede perder un resultado de laboratorio porque no hay indicación para ello, preferencia de práctica, un método alternativo de evaluación o un fallo en la entrada de datos. Imagínese cuánto más difícil será un juego de ajedrez, si un jugador humano o un motor de ajedrez sólo pudiera observar algunas casillas en el tablero a intervalos de tiempo irregulares con algún error o distorsión de la observación.<br/>Además, no tenemos una definición operativa de "verdad fundamental" en la atención de la salud; una simple propuesta es que una característica de la verdad fundamental es que tiene un valor predictivo, algo que será valorado tanto por los médicos como por los pacientes.<br/>Google ha demostrado que puede usar muchos datos para predecir los valores probables de los datos faltantes en otras áreas; sin embargo, aún no se ha determinado si esto podría funcionar en medicina, pero probablemente valga la pena una prueba. Independientemente de si podemos usar grandes volúmenes de datos para imputar valores faltantes, explorar cómo manejar el problema de las observaciones ausentes es crucial, especialmente cuando tratamos de aplicar los resultados de los enfoques basados en datos a pacientes individuales.<br/>Otro pensamiento es que los datos que faltan, por cualquier razón, son una observación en sí misma; el hecho de que los datos no se obtuvieron y registraron puede ser importante. Piense en el hallazgo de que el día y la hora de una prueba fueron más predictivos del resultado que el resultado de la prueba. Sabemos que los datos que faltan tendrán algún valor predictivo.<br/>En una nota diferente, la explicación de los modelos basados en datos es fundamental no solo para su adopción sino también para su impacto. Predecir que un paciente tendrá ciertos eventos adversos en los próximos días o años es deseable. Se puede argumentar que es aún más importante conocer los factores modificables que pueden reducir el riesgo y mejorar los resultados. Dado que los modelos de aprendizaje profundo pueden ser altamente no lineales, tenemos la oportunidad de descubrir patrones novedosos y complejos.<br/>Estoy de acuerdo en que explicar la predicción es fundamental; es algo que separa la atención médica de, por ejemplo, reconocer si una imagen es un perro o un gato. Sin embargo, creo que querías decir que predecir un paciente probablemente tendrá algún resultado adverso. Nada en la vida es seguro excepto que terminará. Sin embargo, podemos decir "parece que este comportamiento o hallazgo probablemente tendrá un efecto en su futuro" y esperamos poder expresar cierto grado de confianza en esa predicción.<br/>Aprender a expresar la confianza en una predicción también es importante. ¿Cuántas personas realmente entienden las estadísticas detrás de las predicciones que ocurren hoy? ¿Cuáles son las suposiciones subyacentes detrás de cualquier modelo probabilístico? Es más probable que con un uso más frecuente y familiaridad con el uso de medidas derivadas de modelos de IA conduzcan a su aceptación.<br/>Estoy de acuerdo. Estos son todos los pasos a seguir para optimizar el uso de big data a través de IA para mejorar la atención médica.<br/>Como pensamiento de despedida, debemos ser cautelosos sobre cuán intrusivos podrían ser los enfoques basados en datos en el proceso de atención. Aunque McDonald demostró que el rendimiento en la atención mejora con recordatorios, la experiencia posterior ha sido uno de demasiados recordatorios, lo que lleva a la fatiga de alerta. Cuando los cuidadores optan por anular e ignorar la información útil debido a la sobrecarga, ¿hemos logrado algo?<br/>Espero que el diseño cuidadoso de los sistemas y la consideración del flujo de trabajo clínico alivie el problema de la intrusión excesiva. Aunque es tentador simplemente "dejar que AI lo haga", las experiencias recientes con el Boeing 737 MAX demuestran que hay peligro al hacerlo. Ni la IA ni un piloto por sí solos son la estrategia óptima para volar. En el cuidado de la salud, involucrar a los pacientes más ampliamente en su cuidado, junto con la IA y los proveedores, puede ser en última instancia un enfoque que funcione.<br/>Conflictos de intereses<br/>- Blois MS. Juicio clínico y computadoras. N Engl J Med 1980 Jul 24;303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Aprendizaje profundo para la atención médica: revisión, oportunidades y desafíos. Breve Bioinform 2018 Nov 27;19 (6): 1236-1246 [Texto completo GRATUITO] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. ¿Puede el aprendizaje automático mejorar la predicción del riesgo cardiovascular utilizando datos clínicos de rutina? PLoS ONE 2017 Apr 4; 12 (4): e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT paciente profundo: una representación no supervisada para predecir el futuro de los pacientes de los registros electrónicos de salud. Sci Rep 2016 17 de mayo; 6 (1): 26094 [texto completo gratuito] [CrossRef] [Medline]<br/>- Quach K. The register. 2019. IBM Watson Health reduce la 'inteligencia artificial' del descubrimiento de fármacos después de la deslucida URL de ventas: https://www.theregister.co.uk/2019/04/18/ibm-watson-health [consultado el 2019-10-23]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Aprendizaje profundo escalable y preciso con registros electrónicos de salud. NPJ Digit Med 2018 8 de mayo; 1 (1): 18 [texto completo gratuito] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, et al. Aprendizaje profundo en imágenes médicas: Descripción general. Korean J Radiol 2017; 18 (4): 570. [CrossRef]<br/>- U.S. Department of Veterans Affairs. Million Veteran Program (MVP) URL: https://www.research.va.gov/mvp/ [consultado el 2019-10-23]<br/>- Patientslikeme. URL: https://www.patientslikeme.com [consultado 2019-10-23]<br/>- Programa de Investigación All of Us. URL: https://allofus.nih.gov [consultado 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. La efectividad irrazonable de los datos. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Sesgos en los datos electrónicos de registros de salud debido a procesos dentro del sistema de salud: estudio observacional retrospectivo. BMJ 2018 Apr 30: k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, Moller H. Causabilidad y explicabilidad de la inteligencia artificial en medicina. WIREs Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Recordatorios informáticos basados en protocolos, la calidad de la atención y la no perfeccionidad del hombre. N Engl J Med 1976 Dec 09;295(24):1351-1355. [CrossRef]<br/>AI: inteligencia artificial<br/>UMLS: Sistema Unificado de Lenguaje Médico<br/>Editado por G Eysenbach; presentado el 15.09.19; revisado por pares por A Holzinger; comentarios al autor 14.10.19; versión revisada recibida el 15.10.19; aceptado el 20.10.19; publicado el 27.11.19Derechos de autor<br/>Qing Zeng-Treitler, Stuart J Nelson. Publicado originalmente en el Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>Este es un artículo de acceso abierto distribuido bajo los términos de la Licencia de Atribución de Creative Commons (https://creativecommons.org/licenses/by/4.0/), que permite el uso, distribución y reproducción sin restricciones en cualquier medio, siempre que el trabajo original, publicado por primera vez en el Journal of Medical Internet Research, se cite correctamente. Se debe incluir la información bibliográfica completa, un enlace a la publicación original en http://www.jmir.org/, así como esta información de derechos de autor y licencia. |
| The Story of Selena Quintanilla: A Biography Book for Young Readers (The Story Of: A Biography Series for New Readers) (Paperback)<br/>Most titles are on our shelves or available within 1-5 days.<br/>Discover the life Selena Quintanilla—a story about breaking down barriers in music, for kids ages 6 to 9<br/>Selena Quintanilla was the queen of Tejano music. Before she became a star, Selena was a charismatic young girl who loved singing and performing. She made a lot of sacrifices to become a famous musician, rehearsing her songs and dance moves for hours at a time. Her hard work paid off—she became the first 15-year-old girl to win a Tejano music award and went on to break many records during her career. This Selena biography explores how she went from being a talented girl growing up in Texas to a fashion icon and a world-famous singer.<br/>What sets this Selena book apart:<br/>- Core curriculum—Kids will learn the Who, What, Where, When, Why, and How of Selena’s life, and take a quick quiz to test their knowledge.<br/>- Short chapters—This Selena kids’ book is broken up into brief chapters that make it fun and easy for new readers to discover details about the singer’s life.<br/>- Her lasting legacy—Kids will find out how Selena changed the world of music and why she continues to be a role model for many women and people of color around the globe.<br/>How will Selena’s big spirit and passion for music inspire the child in your life?<br/>About the Author<br/>GLORIA ARJONA teaches Spanish at the California Institute of Technology and is the author of Posadas Unknown Calaveras and ¡Lotería!. She’s also a musician who sings and plays guitar. Learn more at GloriaArjona.com.<br/>“Finally, a Selena book for new readers, one that is told concisely and honestly, and is eminently readable” —Joe Nick Patoski, author of Selena: Como La Flor<br/>“What a wonderful story to inspire girls to follow their dreams. A story that many girls will identify with, especially those from traditional and multicultural families. I liked all the little sidebar lessons throughout the book. Gloria is a very talented teacher.” —Genevieve B. Southgate, director of community programs, Bowers Museum<br/>“Selena Quintanilla’s youthful talent and positive drive are brought to life in Prof. Arjona’s latest book, this one geared to young readers. A highly appealing read highlighting Selena’s flexibility in overcoming obstacles to achieving her dreams and her trailblazing contributions to music and her community. The Callisto Media format of encouraging critical, organized thought via questions, maps, timelines, and a glossary make this an enjoyable learning experience.” —Martin E. Delgado, community library manager<br/>“This is the story of Selena Quintanilla, and what a story it is! In a time where young readers, and young women, need role models more than ever, this book brilliantly depicts the profound humanity, bravery, and talent of a deeply inspiring Latina woman who relentlessly fought for her dream.” —Maite Zubiaurre, UCLA professor | La Historia de Selena Quintanilla: Un Libro de Biografía para Jóvenes Lectores (La Historia de: Una Serie de Biografía para Nuevos Lectores)<br/>La mayoría de los títulos están en nuestros estantes o disponibles dentro de 1-5 días.<br/>Descubre la vida de Selena Quintanilla, una historia sobre cómo romper barreras en la música para niños de 6 a 9 años<br/>Selena Quintanilla era la reina de la música tejana. Antes de convertirse en estrella, Selena era una joven carismática a la que le encantaba cantar y actuar. Hizo muchos sacrificios para convertirse en una músico famosa, ensayando sus canciones y movimientos de baile durante horas a la vez. Su arduo trabajo valió la pena: se convirtió en la primera niña de 15 años en ganar un premio de música tejana y rompió muchos récords durante su carrera. Esta biografía de Selena explora cómo pasó de ser una chica talentosa que creció en Texas a un ícono de la moda y una cantante de fama mundial.<br/>Lo que distingue a este libro de Selena:<br/>Currículo básico: los niños aprenderán el quién, qué, dónde, cuándo, por qué y cómo de la vida de Selena, y tomarán un cuestionario rápido para probar sus conocimientos.<br/>- Capítulos cortos: este libro para niños de Selena se divide en capítulos breves que hacen que sea divertido y fácil para los nuevos lectores descubrir detalles sobre la vida del cantante.<br/>Su legado perdurable: los niños descubrirán cómo Selena cambió el mundo de la música y por qué sigue siendo un modelo a seguir para muchas mujeres y personas de color en todo el mundo.<br/>¿Cómo inspirará el gran espíritu y la pasión de Selena por la música al niño en tu vida?<br/>Sobre el autor<br/>GLORIA ARJONA enseña español en el Instituto Tecnológico de California y es autora de Posadas Unknown Calaveras y ¡Lotería!. También es una músico que canta y toca la guitarra. Aprende más en GloriaArjona.com.<br/>"Finalmente, un libro de Selena para nuevos lectores, uno que se cuenta de manera concisa y honesta, y es eminentemente legible" - Joe Nick Patoski, autor de Selena: Como La Flor<br/>"Qué historia tan maravillosa para inspirar a las niñas a seguir sus sueños. Una historia con la que muchas niñas se identificarán, especialmente las de familias tradicionales y multiculturales. Me gustaron todas las pequeñas lecciones de barra lateral a lo largo del libro. Gloria es una maestra muy talentosa." -Genevieve B. Southgate, director de programas comunitarios, Bowers Museum<br/>“El talento juvenil y el impulso positivo de Selena Quintanilla cobran vida en el último libro del profesor Arjona, este dirigido a lectores jóvenes. Una lectura muy atractiva que destaca la flexibilidad de Selena para superar los obstáculos para lograr sus sueños y sus contribuciones pioneras a la música y su comunidad. El formato Callisto Media de fomentar el pensamiento crítico y organizado a través de preguntas, mapas, líneas de tiempo y un glosario hacen de esta una experiencia de aprendizaje agradable ". - Martin E. Delgado, administrador de la biblioteca comunitaria<br/>“Esta es la historia de Selena Quintanilla, ¡y qué historia es! En un momento en que los lectores jóvenes, y las mujeres jóvenes, necesitan modelos a seguir más que nunca, este libro describe brillantemente la profunda humanidad, valentía y talento de una mujer latina profundamente inspiradora que luchó sin descanso por su sueño. Maite Zubiaurre, profesora de UCLA |
| Here's another reason for men to avoid packing on extra pounds over the holidays: A new study has found that losing weight reduces the risk of an aggressive form of prostate cancer.<br/>After tracking the weight of nearly 70,000 men between 1982 and 1992, researchers from the American Cancer Society and the Duke University Prostate Center found that men who lost more than 11 pounds had a lower risk for aggressive prostate cancer than men whose weight remained the same over a decade.<br/>Previous studies have found that obese men have a higher risk of developing aggressive prostate cancer. This study appears to be the first to indicate that recent weight loss can decrease that risk.<br/>In the study reported this month in Cancer Epidemiology, Biomarkers & Prevention, researchers analyzed the height and weight of the men in 1982 and 1992 and every three years after that until 2003. At that time, more than 5,200 of the men — more than 7 percent — had prostate cancer.<br/>Among those cases, about one in eight had a form of cancer that was aggressive but had not spread to other areas of the body. The study's major finding focused on those aggressive cases, with researchers concluding that those who lost 11 or more pounds were 42 percent less likely to develop that form of prostate cancer than those whose weight remained the same.<br/>"Whether it's exactly 40 percent, we don't know, but they lower their risk when they lose 11-plus pounds. We feel confident, at least in this population, that was real," said lead researcher Dr. Carmen Rodriguez.<br/>More than seven times as many men whose weight remained the same developed aggressive prostate cancer compared to those who lost 11 or more pounds.<br/>"No significant associations" were found regarding the effect of weight gain or loss on the most severe forms of prostate cancer, those that spread throughout the body, the study said.<br/>The number studied was small, the researchers acknowledged, because fewer than 15,000 men lost weight over the time period, and only 1,000 of those developed some form of prostate cancer.<br/>The 69,991 participants were part of a bigger cancer society study of 1.2 million Americans that began in 1982.<br/>Rodriguez said men should avoid putting on extra weight as they get older.<br/>"The main message for men is to not get overweight. If they are overweight, that's another reason to try to lose weight, just to decrease the risk for prostate cancer," said Rodriguez, who works for the Atlanta-based cancer society.<br/>Other than skin cancer, prostate cancer is the most commonly diagnosed cancer for men, and about one in six will get it during his lifetime. It is the second leading cause of cancer death for U.S. men.<br/>The study is considered the first of its kind to examine the role of weight change in the development of prostate cancer, said Dr. Ronald Ennis, director of radiation oncology at St. Luke's-Roosevelt Hospital Center in New York, who was not involved in the study.<br/>"This is one of the best studies" examining the role of weight on prostate cancer, Ennis said. "It does seem to be true that if you are overweight, you are at risk of getting more aggressive forms of prostate cancer and if you lose weight, you can decrease the risk." | Aquí hay otra razón para que los hombres eviten acumular kilos de más durante las vacaciones: un nuevo estudio ha encontrado que perder peso reduce el riesgo de una forma agresiva de cáncer de próstata.<br/>Después de rastrear el peso de casi 70,000 hombres entre 1982 y 1992, los investigadores de la Sociedad Americana del Cáncer y el Centro de la Próstata de la Universidad de Duke encontraron que los hombres que perdieron más de 11 libras tenían un menor riesgo de cáncer de próstata agresivo que los hombres cuyo peso permaneció igual durante una década.<br/>Estudios anteriores han encontrado que los hombres obesos tienen un mayor riesgo de desarrollar cáncer de próstata agresivo. Este estudio parece ser el primero en indicar que la pérdida de peso reciente puede disminuir ese riesgo.<br/>En el estudio publicado este mes en Cancer Epidemiology, Biomarkers & Prevention, los investigadores analizaron la altura y el peso de los hombres en 1982 y 1992 y cada tres años hasta 2003. En ese momento, más de 5.200 de los hombres, más del 7 por ciento, tenían cáncer de próstata.<br/>Entre esos casos, aproximadamente uno de cada ocho tenía una forma de cáncer que era agresiva pero no se había diseminado a otras áreas del cuerpo. El hallazgo principal del estudio se centró en esos casos agresivos, y los investigadores concluyeron que aquellos que perdieron 11 libras o más tenían un 42 por ciento menos de probabilidades de desarrollar esa forma de cáncer de próstata que aquellos cuyo peso seguía siendo el mismo.<br/>"No sabemos si es exactamente el 40 por ciento, pero reducen su riesgo cuando pierden más de 11 libras. Nos sentimos seguros de que, al menos en esta población, eso fue real", dijo la investigadora principal, la Dra. Carmen Rodríguez.<br/>Más de siete veces más hombres cuyo peso seguía siendo el mismo desarrollaron cáncer de próstata agresivo en comparación con aquellos que perdieron 11 libras o más.<br/>No se encontraron "asociaciones significativas" con respecto al efecto del aumento o la pérdida de peso en las formas más graves de cáncer de próstata, las que se diseminaron por todo el cuerpo, según el estudio.<br/>El número estudiado fue pequeño, reconocieron los investigadores, porque menos de 15,000 hombres perdieron peso durante el período de tiempo, y solo 1,000 de ellos desarrollaron algún tipo de cáncer de próstata.<br/>Los 69,991 participantes fueron parte de un estudio más grande de la sociedad del cáncer de 1,2 millones de estadounidenses que comenzó en 1982.<br/>Rodríguez dijo que los hombres deben evitar aumentar de peso a medida que envejecen.<br/>"El mensaje principal para los hombres es no tener sobrepeso, si tienen sobrepeso, esa es otra razón para tratar de perder peso, solo para disminuir el riesgo de cáncer de próstata", dijo Rodríguez, quien trabaja para la sociedad del cáncer con sede en Atlanta.<br/>Además del cáncer de piel, el cáncer de próstata es el cáncer más comúnmente diagnosticado para los hombres, y aproximadamente uno de cada seis lo contraerá durante su vida. Es la segunda causa principal de muerte por cáncer para los hombres de los Estados Unidos.<br/>El estudio se considera el primero de su tipo en examinar el papel del cambio de peso en el desarrollo del cáncer de próstata, dijo el Dr. Ronald Ennis, director de oncología de radiación en el Centro Hospitalario St. Luke-Roosevelt en Nueva York, que no participó en el estudio.<br/>"Este es uno de los mejores estudios" que examinan el papel del peso en el cáncer de próstata, dijo Ennis. "Parece ser cierto que si tiene sobrepeso, corre el riesgo de contraer formas más agresivas de cáncer de próstata y si pierde peso, puede disminuir el riesgo". |
| If you have studied the OSI model with its 7 Layers that describe communication on computer network systems, you should know that the Ethernet standard lies in Layer 1 (Physical) and Layer 2 (Data-Link) of the OSI model.<br/>In this article we will focus on the physical (Layer 1) part of Ethernet, which mainly focuses on the wired physical medium (cabling) that is used to transport Ethernet frames in a network.<br/>Ethernet cables connect devices to computer networks, the “heart” of which is usually an Ethernet switch which has several interface ports for “plugging-in” the cables.<br/>Most of these Ethernet cables feature the standard RJ45 connector for plugging-in to a switch. However, Ethernet communication can be implemented also using Fiber-optic cabling which uses different types of connectors.<br/>Moreover, there are different types of Ethernet cables with varying bandwidths, speeds and types of construction. In this article we will discuss the “copper-made” cables which are the most popular ones in computer networks.<br/>The cables have labels indicating the standard used for manufacturing, ranging from category (cat) 3 to 7.<br/>Ethernet cables consist of several (usually 8) smaller wires (inside the main cable) which are separated in Twisted-pairs. This setup helps in cancelling-out electromagnetic interference between wires, thus allowing signals to travel longer distances inside the wires.<br/>Without the right cable (and of course without the right type of switch), you may experience slower speeds in the network between devices.<br/>Let’s now describe each Category of Ethernet Cables with their characteristics:<br/>&#124;Max Length&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m<br/>(55 m for 10Gbps)<br/>&#124;100 m&#124;&#124;100 m&#124;<br/>&#124;Max Speed&#124;&#124;10 Mbps&#124;&#124;100 Mbps&#124;&#124;1 Gbps&#124;&#124;10 Gbps&#124;&#124;10 Gbps&#124;&#124;>10 Gbps&#124;<br/>&#124;Frequency Bandwidth&#124;&#124;16 MHz&#124;&#124;100 MHz&#124;&#124;100 MHz&#124;&#124;250 MHz&#124;&#124;500 MHz&#124;&#124;600 MHz&#124;<br/>&#124;Shielded / Unshielded&#124;&#124;Unshielded&#124;&#124;Unshielded&#124;&#124;Unshielded&#124;&#124;Shielded or Unshielded&#124;&#124;Shielded&#124;&#124;Shielded&#124;<br/>1) Cat 3<br/>One of the oldest Ethernet cabling standards is category (cat) 3 (TIA/EIA-568-B). These cables allowed 10 Mbps transmission speeds with 16 MHz max bandwidth.<br/>Cat 3 ethernet cables feature unshielded twisted pair (UTP) cabling. With UTP cables, manufacturers twist insulated copper wires together inside a polyethylene jacket. Compared to shielded ethernet cables, UTP cables tend to include more crosstalk.<br/>Network connections commonly featured category 3 ethernet cables until the early 1990s, when category 5 cables replaced cat 3. While some older telephone systems may still use cat 3 cables, they have mostly become obsolete in the networking industry.<br/>2) Cat 5<br/>Cat 5 cables increased the bandwidth of Ethernet connections up to 100 MHz and offered transmission speeds up to 100 Mbps. With Cat 5 ethernet cables, users could access 100BASE-TX ethernet systems, referred to as fast ethernet.<br/>As with the category 3 cables, cat 5 cables still feature crosstalk and interference, due to the UTP design. These cables include four pairs of twisted wires (for a total of 8 wires).<br/>While cat 5 cables primarily provide connections for Ethernet applications, these cables also provide solutions for carrying other data signals, such as video and telephone. In fact, a single cat 5 cable can carry two standard phone lines and a 100BASE-TX connection.<br/>3) Cat 5e<br/>In 2001, the category 5e standard replaced category 5. The letter “e” in the name stands for enhanced.<br/>The cabling still uses unshielded twisted pairs. There are no physical differences between cat 5 and cat 5e cables. However, stricter standards in manufacturing Cat5e cables help minimize crosstalk and allow higher data transmissions than Cat5.<br/>Cat 5e cables also utilize two sets of twisted pairs of wires, resulting in faster speeds. While cat 5e ethernet cable still features 100 MHz bandwidth, these cables allow speeds up to 1000 Mbps (1 Gbps).<br/>While several additional standards have come after cat 5e, these cables remain in production. In fact, due to the lower cost of production and support for gigabit ethernet, cat 5e cables are the most used for network applications throughout the world.<br/>4) Cat 6<br/>Cat 6 ethernet cables helped address issues related to interference and crosstalk. These cables use thinner wires and superior insulation, resulting in a better signal-to-noise ratio.<br/>With these features, cat 6 cables provide a more effective option for adding cable in areas with more electromagnetic interference, such as a crowded server room.<br/>Thanks to the superior design, cat 6 provides improved bandwidth. These cables have a max bandwidth of 250 MHz and max transmission speeds up to 1000 Mbps (1 Gbps) at the 100m range. However, 10Gbps can be achieved in Cat6 in smaller distances (up to 55m).<br/>Some cat 6 cables include shielding while others remain unshielded. With shielding, these cables can provide transmission speeds up to 10 Gbps, but only for short distances as we said above.<br/>5) Cat 6a<br/>Category 6a ethernet cables improve the design of the cat 6 cables. The letter “a” stands for augmented. Unlike cat 6 cables, all cat 6a cables feature shielded cabling for reduced interference.<br/>With the enhancements to the design specifications, cat 6a cables maintain higher transmission speeds and 500 MHz max bandwidth, allowing speeds up to 10000 Mbps (10 Gbps) across longer cables.<br/>While these cables provide faster speeds, the design makes them less flexible. To eliminate crosstalk, these cables feature thicker sheathing, making the cables stiffer and more difficult to work.<br/>6) Cat 7<br/>One of the latest developments is Cat 7 Ethernet cables. Also called class F channel cables, these cables include stricter standards compared to previous categories. The individual wire pairs now include their own shielding, in addition to the outer shielding<br/>With these cables, you get 600 MHz max bandwidth and 10000 Mbps (10 Gbps) transmission speeds. However, by almost completely getting rid of crosstalk, cat 7 ethernet cables offer even greater reliability for 10 Gbps Ethernet connections.<br/>With connections less than 15 meters, cat 7 can support transmission speeds up to 100 Gbps. While the industry has released several new standards since cat 7, these cables are currently the top of the line option for demanding networking applications.<br/>- What is OSPF NSSA (Not So Stubby Area) and How is it Configured?<br/>- Comparison of BOOTP vs DHCP Protocols in Computer Networks<br/>- Pros and Cons of SD-WAN in Networks – Description and Discussion<br/>- Comparison of GNS3 vs EVE-NG vs Packet Tracer for Networks Simulation<br/>- Subnetting vs Supernetting – What’s the Difference? (Explanation Guide) | Si ha estudiado el modelo OSI con sus 7 capas que describen la comunicación en sistemas de red informática, debe saber que el estándar Ethernet se encuentra en la capa 1 (física) y la capa 2 (enlace de datos) del modelo OSI.<br/>En este artículo nos centraremos en la parte física (Capa 1) de Ethernet, que se centra principalmente en el medio físico cableado (cableado) que se utiliza para transportar tramas Ethernet en una red.<br/>Los cables Ethernet conectan dispositivos a redes informáticas, cuyo "corazón" suele ser un conmutador Ethernet que tiene varios puertos de interfaz para "conectar" los cables.<br/>La mayoría de estos cables Ethernet cuentan con el conector estándar RJ45 para enchufar a un switch. Sin embargo, la comunicación Ethernet también se puede implementar utilizando cableado de fibra óptica que utiliza diferentes tipos de conectores.<br/>Además, hay diferentes tipos de cables Ethernet con diferentes anchos de banda, velocidades y tipos de construcción. En este artículo discutiremos los cables "hechos de cobre" que son los más populares en las redes informáticas.<br/>Los cables tienen etiquetas que indican el estándar utilizado para la fabricación, que van desde la categoría (cat) 3 a 7.<br/>Los cables Ethernet consisten en varios cables (generalmente 8) más pequeños (dentro del cable principal) que están separados en pares trenzados. Esta configuración ayuda a cancelar la interferencia electromagnética entre los cables, permitiendo así que las señales viajen distancias más largas dentro de los cables.<br/>Sin el cable adecuado (y, por supuesto, sin el tipo correcto de interruptor), puede experimentar velocidades más lentas en la red entre dispositivos.<br/>Ahora describamos cada categoría de cables Ethernet con sus características:<br/>Longitud máxima 100 m 100 m 100 m 100 m 100 m<br/>(55 m por 10Gbps)<br/>100 m<br/>Velocidad máxima: 10 Mbps: 100 Mbps: 1 Gbps: 10 Gbps: 10 Gbps: 10 Gbps<br/>Ancho de banda de frecuencia 16 MHz 100 MHz 100 MHz 250 MHz 500 MHz 600 MHz<br/>?Shielded / Unshielded? Unshielded? Unshielded? Unshielded? Unshielded?<br/>1) Gato 3<br/>Uno de los estándares de cableado Ethernet más antiguos es la categoría 3 (TIA/EIA-568-B). Estos cables permitían velocidades de transmisión de 10 Mbps con un ancho de banda máximo de 16 MHz.<br/>Los cables Ethernet Cat 3 cuentan con cableado de par trenzado (UTP) sin blindaje. Con los cables UTP, los fabricantes tuercen los cables de cobre aislados juntos dentro de una camisa de polietileno. En comparación con los cables Ethernet blindados, los cables UTP tienden a incluir más diafonía.<br/>Las conexiones de red comúnmente presentaban cables Ethernet de categoría 3 hasta principios de la década de 1990, cuando los cables de categoría 5 reemplazaron al cat 3. Mientras que algunos sistemas telefónicos más antiguos aún pueden usar cables cat 3, en su mayoría se han vuelto obsoletos en la industria de las redes.<br/>2) Cat 5<br/>Los cables Cat 5 aumentaron el ancho de banda de las conexiones Ethernet hasta 100 MHz y ofrecían velocidades de transmisión de hasta 100 Mbps. Con los cables Ethernet Cat 5, los usuarios podían acceder a los sistemas Ethernet 100BASE-TX, conocidos como ethernet rápido.<br/>Al igual que con los cables de categoría 3, los cables cat 5 todavía cuentan con diafonía e interferencia, debido al diseño UTP. Estos cables incluyen cuatro pares de cables trenzados (para un total de 8 cables).<br/>Mientras que los cables cat 5 proporcionan principalmente conexiones para aplicaciones Ethernet, estos cables también proporcionan soluciones para transportar otras señales de datos, como video y teléfono. De hecho, un solo cable cat 5 puede llevar dos líneas telefónicas estándar y una conexión 100BASE-TX.<br/>3) Cat 5e<br/>En 2001, el estándar de categoría 5e reemplazó a la categoría 5. La letra "e" en el nombre significa mejorado.<br/>El cableado todavía utiliza pares trenzados sin blindaje. No hay diferencias físicas entre los cables cat 5 y cat 5e. Sin embargo, los estándares más estrictos en la fabricación de cables Cat5e ayudan a minimizar la diafonía y permiten transmisiones de datos más altas que Cat5.<br/>Los cables Cat 5e también utilizan dos conjuntos de pares de cables trenzados, lo que resulta en velocidades más rápidas. Mientras que el cable Ethernet cat 5e todavía cuenta con un ancho de banda de 100 MHz, estos cables permiten velocidades de hasta 1000 Mbps (1 Gbps).<br/>Si bien varios estándares adicionales han llegado después del cat 5e, estos cables permanecen en producción. De hecho, debido al menor costo de producción y soporte para gigabit ethernet, los cables cat 5e son los más utilizados para aplicaciones de red en todo el mundo.<br/>4) Gato 6<br/>Los cables Ethernet Cat 6 ayudaron a resolver los problemas relacionados con la interferencia y la diafonía. Estos cables utilizan cables más delgados y un aislamiento superior, lo que resulta en una mejor relación señal-ruido.<br/>Con estas características, los cables cat 6 proporcionan una opción más efectiva para agregar cables en áreas con más interferencia electromagnética, como una sala de servidores abarrotada.<br/>Gracias al diseño superior, cat 6 proporciona un ancho de banda mejorado. Estos cables tienen un ancho de banda máximo de 250 MHz y velocidades de transmisión máximas de hasta 1000 Mbps (1 Gbps) en el rango de 100 m. Sin embargo, se pueden lograr 10 Gbps en Cat6 en distancias más pequeñas (hasta 55 m).<br/>Algunos cables cat 6 incluyen blindaje mientras que otros permanecen sin blindaje. Con blindaje, estos cables pueden proporcionar velocidades de transmisión de hasta 10 Gbps, pero solo para distancias cortas como dijimos anteriormente.<br/>5) Gato 6a<br/>Los cables Ethernet de categoría 6a mejoran el diseño de los cables cat 6. La letra "a" significa aumentado. A diferencia de los cables cat 6, todos los cables cat 6a cuentan con cableado blindado para reducir la interferencia.<br/>Con las mejoras en las especificaciones de diseño, los cables cat 6a mantienen velocidades de transmisión más altas y un ancho de banda máximo de 500 MHz, lo que permite velocidades de hasta 10000 Mbps (10 Gbps) en cables más largos.<br/>Si bien estos cables proporcionan velocidades más rápidas, el diseño los hace menos flexibles. Para eliminar la diafonía, estos cables cuentan con un revestimiento más grueso, lo que hace que los cables sean más rígidos y más difíciles de trabajar.<br/>6) Gato 7<br/>Uno de los últimos desarrollos son los cables Ethernet Cat 7. También llamados cables de canal de clase F, estos cables incluyen estándares más estrictos en comparación con las categorías anteriores. Los pares de cables individuales ahora incluyen su propio blindaje, además del blindaje exterior.<br/>Con estos cables, se obtiene un ancho de banda máximo de 600 MHz y velocidades de transmisión de 10000 Mbps (10 Gbps). Sin embargo, al deshacerse casi por completo de la diafonía, los cables Ethernet cat 7 ofrecen una confiabilidad aún mayor para conexiones Ethernet de 10 Gbps.<br/>Con conexiones de menos de 15 metros, el cat 7 puede soportar velocidades de transmisión de hasta 100 Gbps. Si bien la industria ha lanzado varios estándares nuevos desde el cat 7, estos cables son actualmente la opción de primera línea para aplicaciones de red exigentes.<br/>¿Qué es OSPF NSSA (Not So Stubby Área) y cómo se configura?<br/>- Comparación de los protocolos BOOTP vs DHCP en redes informáticas<br/>Pros y contras de SD-WAN en redes: descripción y discusión<br/>- Comparación de GNS3 vs EVE-NG vs Packet Tracer para Simulación de Redes<br/>- Subnetting vs Supernetting – ¿Cuál es la diferencia? (Guía de explicación) |
| Views: 4 Author: Site Editor Publish Time: 2022-06-09 Origin: Site<br/>So why should workers wear a portable gas detector and what does it do?<br/>In many industrial environments, workers need to be highly aware of exposure to toxic or combustible gases and vapours or a lack of oxygen. That’s why portable gas detectors and analysers are essential – so they can detect, measure, monitor and react to any gases in the immediate area around them. KELISAIKE SAFETY offers both single- and multi-gas mobile gas monitors that reliably detect a wide range of gases. All of our portable gas detectors and software are designed to make compliance and asset management as intuitive as possible, so you can implement a complete product solution that helps ensure safety at all times.<br/>Portable gas detectors are classed as a type of Personal Protective Equipment (PPE)<br/>They monitor gases in the workers breathing zone by displaying real-time gas levels of a variety of toxic, combustible, flammable gases<br/>They alert the worker of any possible threats which include combustion and oxygen displacement<br/>While portable gas detectors are available with various sensor configurations and features, they are all built with the same purpose - to protect human life! | Vistas: 4 Autor: Editor del sitio Hora de publicación: 2022-06-09 Origen: Sitio<br/>Entonces, ¿por qué los trabajadores deben usar un detector de gas portátil y qué hace?<br/>En muchos entornos industriales, los trabajadores deben ser muy conscientes de la exposición a gases y vapores tóxicos o combustibles o la falta de oxígeno. Es por eso que los detectores y analizadores de gas portátiles son esenciales, para que puedan detectar, medir, monitorear y reaccionar a cualquier gas en el área inmediata a su alrededor. KELISAIKE SAFETY ofrece monitores de gas móviles de gas único y multigas que detectan de manera confiable una amplia gama de gases. Todos nuestros detectores de gas portátiles y software están diseñados para hacer que el cumplimiento y la gestión de activos sean lo más intuitivos posible, para que pueda implementar una solución de producto completa que ayude a garantizar la seguridad en todo momento.<br/>Los detectores de gas portátiles se clasifican como un tipo de equipo de protección personal (PPE)<br/>Supervisan los gases en la zona de respiración de los trabajadores al mostrar los niveles de gases en tiempo real de una variedad de gases tóxicos, combustibles e inflamables.<br/>Alertan al trabajador de cualquier posible amenaza que incluya la combustión y el desplazamiento de oxígeno.<br/>Mientras que los detectores de gas portátiles están disponibles con varias configuraciones y características de sensores, ¡todos están construidos con el mismo propósito: proteger la vida humana! |
| Salvador Dalí Biography<br/>The prints of Salvador Dalí are rooted in a rich past. In actuality, Dalí’s prints have a history that dates back to his early years of art school. The young Dalí was taught the fine art of engraving and etching by his mentor. Dalí gained a respect for the technical details of printmaking, a respect he would maintain throughout the rest of his life. The connection between Dalí and graphic prints is in fact intricate and protracted. In his lifetime, Dalí produced just around 1,700 graphic prints. A large number of them are hand-signed, limited-edition editions. Some are regarded as some of the best prints created in the 20th century.<br/>Dalí had the ability to experiment with a wide range of subjects through his print work, including etchings, engravings, mixed media, lithographs, and photo-litho. Dalí would produce beautiful suites or single prints. These suites frequently feature a book motif, with the prints acting as the artwork. Among the literary works Dal illustrated were Alice in Wonderland, Hamlet, and The Old Man and the Sea. Other times, similar suites would focus on different subjects, such as flowers (FlorDal), science fiction (Conquest of the Cosmos), or fine print production (Currier and Ives). Dal also produced single prints that showcased his flawless printmaking skills. Prints by Dalí that are among his best include Flower Man, Symphony Bicyclette, Dream Passage, and The Studio of Dalí.<br/>Although it might be speculated that Dalí produced many more prints than the “approved” ones we attribute to him today, Dal’s first prints appeared in the 1920s. His superb craftsmanship is seen in works like Head of a Young Girl and Immaculate Conception. The graphic piece Les Chants de Maldoror is among Dal’s best-known creations. The stories that separate the suites are a perfect match for the pre-surrealistic aspects of the book. A complete set of this suite is now in high demand. The majority of these early works were etchings and engravings; as Dalí’s printing skills improved, he expanded the range of his mediums and themes.<br/>The 1960s are often referred to as the “Golden Age” of Dalí’s prints. In fact, Dalí produced some of his most creative pieces during this decade. For an edition of The Divine Comedy, he finished one hundred wood block prints. This suite is regarded as a work of genius, and Dalí produced magnificent graphics to complement Virgil’s poetry. A fruitful collaboration with the American publishers Phyllis and Sidney Lucas also began throughout this decade. The Lucas’ and Dalí’s combined efforts would result in some of the most enduring Dal paintings ever. Prints like The Drawers of Memory, Fantastic Voyage, The Lucky Number of Salvador Daíi, The Studio of Dalí, and Departure of The Fishermen are examples of the prints that resulted from their collaboration. For Dalí, these were undoubtedly successful years. Over the course of this decade, Dal finished hundreds of photographs. His output was extraordinarily high. However, some of his best graphic creations remained to be seen.<br/>Dal returned to his melting clocks painting, his most well-known creation, in the 1970s. Some people believe that Dalí’s 1975 lithograph Changes In Great Masterpieces is his best creation overall. The collection consists of six images, five of which are Dalí’s interpretations of paintings by Rembrandt, Vermeer, Raphael, and Velasquez. The Persistence of Memory, Dalí’s own masterwork, is reinterpreted in the sixth picture.<br/>Together with his American publishers, Phyllis and Sidney Lucas, Mozart created this suite. Dalí updates his original piece by including a fourth melting clock. The broken clock creeps through the midst of the scene. The fourth clock, according to some, represents the fourth dimension, or time. Some people think that when Dal revised The Persistence of Memory, some 40 years after the original, he was considering his own transience and legacy and paying homage to the Dal of old.<br/>Changes in Great Masterpieces was only one of Dalí’s outstanding creations during the 1970s. In the suites Moses and Monotheism, Imagination and Objects of the Future, and Alchemy of The Philosophers, he produced some magnificent artwork. His two four-piece “puzzles,” The Rejuvenation of Time and The Puzzle of Life, are his largest lithographs. Ten Recipes of Immortality, a collection of three dimensional “pop-up” prints, is an example of how he expanded the scope of his graphic works into the third dimension. Although the 1960s may have been Dalí’s most productive decade, the 1970s appear to have been his most inventive and creative years as he explored new concepts and pushed himself even farther.<br/>In 1982, Dalí’s final prints were released. Dalí’s health had already started to deteriorate by this point, and his output had significantly decreased. However, Dalí was still able to create some excellent graphic prints despite his advanced age. Portrait of Autumn, which is bathed in gorgeous yellows, greens, and reds, is a glorification of the god Dionysus. Collectors of Dalí’s work see Chevalier Surealiste as a must-have piece, and it pays homage to one of Dalí’s heroes, Velasquez. Crucifixion is a superb example of Dalí’s artistry and a testament to his interest in Roman Catholicism.<br/>Dalí spent his entire life working as a printmaker. When evaluating his legacy, one must take into account the graphic arts creations he developed. Some of Dalí’s most artistic icons and imagery, as well as some of his best uses of his imagination, can be seen in these prints. | Biografía de Salvador Dalí<br/>Los grabados de Salvador Dalí tienen sus raíces en un pasado rico. En realidad, los grabados de Dalí tienen una historia que se remonta a sus primeros años en la escuela de arte. Su mentor le enseñó el arte del grabado y el grabado. Dalí se ganó un respeto por los detalles técnicos del grabado, un respeto que mantendría durante el resto de su vida. La conexión entre Dalí y las impresiones gráficas es de hecho intrincada y prolongada. En su vida, Dalí produjo alrededor de 1.700 grabados gráficos. Un gran número de ellos son ediciones firmadas a mano, de edición limitada. Algunos son considerados como algunos de los mejores grabados creados en el siglo XX.<br/>Dalí tenía la capacidad de experimentar con una amplia gama de temas a través de su trabajo de impresión, incluyendo grabados, grabados, medios mixtos, litografías y fotolitos. Dalí produciría hermosas suites o impresiones individuales. Entre las obras literarias que Dal ilustró se encontraban Alicia en el país de las maravillas, Hamlet y El viejo y el mar. Otras veces, suites similares se enfocaban en diferentes temas, como flores (FlorDal), ciencia ficción (Conquista del Cosmos) o producción de letra pequeña (Currier e Ives). Dal también produjo impresiones individuales que mostraban sus impecables habilidades de grabado. Los grabados de Dalí que se encuentran entre sus mejores incluyen Flower Man, Symphony Bicyclette, Dream Passage y The Studio of Dalí.<br/>Aunque se podría especular que Dalí produjo muchas más impresiones que las "aprobadas" que le atribuimos hoy en día, las primeras impresiones de Dal aparecieron en la década de 1920. Su excelente artesanía se ve en obras como Cabeza de una joven e Inmaculada Concepción. La pieza gráfica Les Chants de Maldoror es una de las creaciones más conocidas de Dal. Las historias que separan las suites son perfectas para los aspectos pre-surrealistas del libro. Un conjunto completo de esta suite está ahora en gran demanda. La mayoría de estos trabajos tempranos eran aguafuertes y grabados; ya que las habilidades de impresión de Dalí mejoraron, amplió la variedad de sus medios y temas.<br/>La década de 1960 se refiere a menudo como la "Edad de Oro" de las impresiones de Dalí. De hecho, Dalí produjo algunas de sus piezas más creativas durante esta década. Para una edición de La Divina Comedia, terminó cien impresiones de bloques de madera. Esta suite es considerada como una obra de genio, y Dalí produjo magníficos gráficos para complementar la poesía de Virgil. Una fructífera colaboración con las editoriales estadounidenses Phyllis y Sidney Lucas también comenzó a lo largo de esta década. Los esfuerzos combinados de Lucas y Dalí darían como resultado algunas de las pinturas Dal más duraderas de la historia. Grabados como The Drawers of Memory, Fantastic Voyage, The Lucky Number of Salvador Daii, The Studio of Dalí y Departure of The Fishermen son ejemplos de los grabados que resultaron de su colaboración. Para Dalí, estos fueron sin duda años exitosos. A lo largo de esta década, Dal terminó cientos de fotografías. Su producción fue extraordinariamente alta. Sin embargo, algunas de sus mejores creaciones gráficas aún estaban por verse.<br/>Dal regresó a su pintura de los relojes derretidos, su creación más conocida, en la década de 1970. Algunas personas creen que la litografía de 1975 de Dalí Changes In Great Masterpieces es su mejor creación en general. La colección consta de seis imágenes, cinco de las cuales son interpretaciones de Dalí de pinturas de Rembrandt, Vermeer, Rafael y Velásquez. La persistencia de la memoria, la obra maestra de Dalí, se reinterpreta en la sexta imagen.<br/>Junto con sus editores estadounidenses, Phyllis y Sidney Lucas, Mozart creó esta suite. Dalí actualiza su pieza original incluyendo un cuarto reloj de fusión. El reloj roto se arrastra por el medio de la escena. El cuarto reloj, según algunos, representa la cuarta dimensión, o tiempo. Algunas personas piensan que cuando Dal revisó La persistencia de la memoria, unos 40 años después del original, estaba considerando su propia fugacidad y legado y rindiendo homenaje al Dal de antaño.<br/>Cambios en las grandes obras maestras fue solo una de las creaciones destacadas de Dalí durante la década de 1970. En las suites Moses and Monotheism, Imagination and Objects of the Future y Alchemy of The Philosophers, produjo algunas magníficas obras de arte. Sus dos "rompecabezas" de cuatro piezas, El rejuvenecimiento del tiempo y El rompecabezas de la vida, son sus litografías más grandes. Diez Recetas de la Inmortalidad, una colección de tres dimensiones "pop-up" impresiones, es un ejemplo de cómo amplió el alcance de sus obras gráficas en la tercera dimensión. Aunque la década de 1960 puede haber sido la década más productiva de Dalí, la década de 1970 parece haber sido sus años más inventivos y creativos, ya que exploró nuevos conceptos y se empujó aún más lejos.<br/>En 1982, se publicaron las impresiones finales de Dalí. La salud de Dalí ya había comenzado a deteriorarse en este punto, y su producción había disminuido significativamente. Sin embargo, Dalí todavía era capaz de crear algunas impresiones gráficas excelentes a pesar de su avanzada edad. Retrato del otoño, bañado en hermosos amarillos, verdes y rojos, es una glorificación del dios Dionisio. Los coleccionistas de la obra de Dalí ven a Chevalier Surealiste como una pieza imprescindible, y rinde homenaje a uno de los héroes de Dalí, Velásquez. La crucifixión es un magnífico ejemplo del arte de Dalí y un testimonio de su interés por el catolicismo romano.<br/>Dalí pasó toda su vida trabajando como grabador. Al evaluar su legado, hay que tener en cuenta las creaciones de artes gráficas que desarrolló. Algunos de los iconos e imágenes más artísticos de Dalí, así como algunos de sus mejores usos de su imaginación, se pueden ver en estas impresiones. |
| English Language A Level<br/>&#124;Mode of study&#124;&#124;Academic A Level&#124;<br/>&#124;Campus&#124;&#124;English Bridge Campus&#124;<br/>&#124;Start date&#124;&#124;4 September 2023&#124;<br/>&#124;Course code&#124;&#124;ENG-AL (2325)&#124;<br/>A minimum of five GCSEs at grade 4 or above, including English Language and English Literature.<br/>Please note: You can study both English A level Literature and A level English Language because the courses are sufficiently distinct that there is no overlap or repetition of content. However, you cannot study A Level English Combined and A Level English Literature, or A Level English Combined and A Level English Language.<br/>What does the course involve?<br/>English is an exciting subject and we hope you’ll enjoy the lively debate and discussion. Whichever English course you choose, you’ll gain a great deal of academic prowess and the development of transferable skills.<br/>You will be taught to think analytically, synthesise information, and develop communication skills that are a prerequisite for a wide range of career paths.<br/>The important skill of learning to write coherently and critically will aid you in your other subjects and is invaluable in higher education.<br/>Language is one of the key features that define us as human beings and, on this course, you will explore how it works: how we learn language from infancy, how we use it as a social tool, and how it has evolved over time. You will learn about the origins of English, the various forms it has taken over the centuries, how it has spread across the globe and what it might look like in the future.<br/>You will also study the research of theorists in areas of language such as speech and gender, accents and dialects, and the language of technology. You will learn about grammar in order to explore the ways writers use language to communicate meaning in texts ranging from blogs to 17th-century journalism.<br/>The NEA (coursework) unit will allow you to write creatively and to undertake an investigation into an aspect of the course you have enjoyed.<br/>How is the course assessed?<br/>80% Exam and 20% Coursework. Two coursework tasks and two externally-assessed exams.<br/>This A Level will equip you with the necessary skills to go into practical professions such as journalism and creative writing as well as academic degrees such as law and media studies. It forms a good companion to A Levels in Psychology and Sociology because there is a degree of crossover with the social sciences. If you are thinking of studying English at university, it is perfectly acceptable to take both English Language and English Literature. English can be combined with a range of other subjects at university.<br/>English provides an excellent foundation for various Higher Education courses including law, medicine, English, linguistics and education. It can be combined with a range of other subjects at university. English offers increasing employability in a range of career areas, especially those that require developed communication skills. Students have gone on to careers in law, health and medicine, commerce and industry, marketing, politics and international relations, general management, as well as leading to more predictable areas like journalism, publishing, the media, education, theatre and public relations.<br/>The student magazine produced by students is part of the enrichment opportunities led by the English Department. Trips include theatre trips to London, Manchester and Stratford-upon-Avon and international trips include a visit to battlefields in France, university taster days, residentials and creative writing workshops. These are all optional but highly recommended. Aspiring Oxford and Cambridge applicants will benefit from our extensive range of activities to support you in making a competitive application including: small group subject tuition, Oxford and Cambridge conferences, visits and contacts with our link staff, access to summer schools, application support and essay competitions, supra-curricular activities and access to free university-level Massive Open Online Courses (MOOC).<br/>What do I do next?<br/>You can apply online via the APPLY NOW button and then add an additional two or three subjects to make up your academic programme. You can also apply for a second, alternative vocational programme of study via a separate application. If after reading this factsheet, you are still undecided about the course most suitable for you, please drop in to one of our Open Evenings, ring Admissions on 01743 260401 or email email@example.com<br/>A Level English Language (Law and Drama & Theatre)<br/>Previous school: Mary Webb School<br/>I came here because it was local to me and I enjoyed the pre-enrolment days which were well organised. English Language is a good A Level to have and it is super interesting to see how language has evolved and changed through time. The teachers are a great help and the resources are brilliant; there are plenty of text books.<br/>Are you an employer?<br/>See how an apprentice can help your business. | Idioma Inglés A Nivel<br/>Modo de estudio Nivel académico A<br/>Campus del Puente Inglés<br/>Fecha de inicio: 4 de septiembre de 2023<br/>Código del curso ENG-AL (2325)<br/>Un mínimo de cinco GCSEs en el grado 4 o superior, incluido el idioma inglés y la literatura inglesa.<br/>Tenga en cuenta: puede estudiar literatura de nivel A de inglés y un idioma inglés de nivel A porque los cursos son lo suficientemente distintos como para que no haya superposición o repetición de contenido. Sin embargo, no puede estudiar un nivel combinado de inglés y un nivel de literatura en inglés, o un nivel combinado de inglés y un nivel de idioma inglés.<br/>¿Qué implica el curso?<br/>El inglés es un tema emocionante y esperamos que disfrutes del animado debate y discusión. Cualquiera que sea el curso de inglés que elijas, obtendrás una gran destreza académica y el desarrollo de habilidades transferibles.<br/>Se le enseñará a pensar analíticamente, sintetizar información y desarrollar habilidades de comunicación que son un requisito previo para una amplia gama de carreras profesionales.<br/>La importante habilidad de aprender a escribir de manera coherente y crítica le ayudará en sus otras materias y es invaluable en la educación superior.<br/>El lenguaje es una de las características clave que nos definen como seres humanos y, en este curso, explorará cómo funciona: cómo aprendemos el lenguaje desde la infancia, cómo lo usamos como una herramienta social y cómo ha evolucionado con el tiempo. Aprenderá sobre los orígenes del inglés, las diversas formas que ha tomado a lo largo de los siglos, cómo se ha extendido por todo el mundo y cómo podría verse en el futuro.<br/>También estudiará la investigación de teóricos en áreas del lenguaje como el habla y el género, acentos y dialectos, y el lenguaje de la tecnología. Aprenderá sobre gramática para explorar las formas en que los escritores usan el lenguaje para comunicar el significado en textos que van desde blogs hasta periodismo del siglo XVII.<br/>La unidad NEA (cursos) le permitirá escribir creativamente y llevar a cabo una investigación sobre un aspecto del curso que ha disfrutado.<br/>¿Cómo se evalúa el curso?<br/>80% de examen y 20% de trabajo de curso. Dos tareas de trabajo de curso y dos exámenes evaluados externamente.<br/>Este A Level lo equipará con las habilidades necesarias para dedicarse a profesiones prácticas como el periodismo y la escritura creativa, así como títulos académicos como estudios de derecho y medios. Forma un buen compañero para A Levels en Psicología y Sociología porque hay un grado de cruce con las ciencias sociales. Si está pensando en estudiar inglés en la universidad, es perfectamente aceptable tomar tanto el idioma inglés como la literatura inglesa. El inglés se puede combinar con una variedad de otras materias en la universidad.<br/>Inglés proporciona una excelente base para varios cursos de educación superior, incluyendo derecho, medicina, Inglés, linguística y educación. Se puede combinar con una variedad de otras materias en la universidad. El inglés ofrece una mayor empleabilidad en una variedad de áreas profesionales, especialmente aquellas que requieren habilidades de comunicación desarrolladas. Los estudiantes han seguido carreras en derecho, salud y medicina, comercio e industria, marketing, política y relaciones internacionales, gestión general, así como áreas más predecibles como periodismo, publicaciones, medios de comunicación, educación, teatro y relaciones públicas.<br/>La revista estudiantil producida por los estudiantes es parte de las oportunidades de enriquecimiento dirigidas por el Departamento de Inglés. Los viajes incluyen viajes de teatro a Londres, Manchester y Stratford-upon-Avon y viajes internacionales incluyen una visita a los campos de batalla en Francia, días de catas universitarias, residencias y talleres de escritura creativa. Los aspirantes a postulantes a Oxford y Cambridge se beneficiarán de nuestra amplia gama de actividades para ayudarlo a realizar una solicitud competitiva que incluye: matrícula de asignaturas en grupos pequeños, conferencias de Oxford y Cambridge, visitas y contactos con nuestro personal de enlace, acceso a escuelas de verano, concursos de soporte de solicitudes y ensayos, actividades supracurriculares y acceso a cursos en línea masivos abiertos (MOOC) gratuitos a nivel universitario.<br/>¿Qué hago ahora?<br/>Puede solicitar en línea a través del botón SOLICITAR AHORA y luego agregar dos o tres asignaturas adicionales para formar su programa académico. También puede solicitar un segundo programa de estudio vocacional alternativo a través de una solicitud separada. Si después de leer esta hoja informativa, aún no está decidido sobre el curso más adecuado para usted, visite una de nuestras noches abiertas, llame Admisiones al 01743 260401 o envíe un correo electrónico a example.com<br/>Un nivel de inglés (ley, drama y teatro)<br/>Escuela anterior: Escuela Mary Webb<br/>Vine aquí porque era local para mí y disfruté de los días de preinscripción que estaban bien organizados. El idioma inglés es un buen nivel A para tener y es muy interesante ver cómo el idioma ha evolucionado y cambiado a través del tiempo. Los profesores son una gran ayuda y los recursos son brillantes; hay un montón de libros de texto.<br/>¿Es usted un empleador?<br/>Vea cómo un aprendiz puede ayudar a su negocio. |
| In a subproject carried out together with the City of Stockholm within the HazardSupport research project, SMHI has investigated how town planning affects a city’s climate. Scenarios have been produced for Stockholm’s growth up until 2030 and 2050, using summer 2014 as a reference point. These scenarios do not take ongoing climate change into account. Instead, they simply show how the densification and growth of Stockholm can be expected to affect the air temperature.<br/>The main conclusion from the scenarios is that the impact of densification on air temperature is relatively local. No significant effect on the average temperature during the summer is seen at a distance of more than about 2 km, despite extensive densification across large areas. This can be seen in the most central parts of Stockholm, for example, which are already built-up and where no significant reduction in green spaces can therefore be expected. No significant change in air temperature is seen in these areas.<br/>One reason why the densification and expansion of Stockholm has not had any significant impact on air temperature is the relatively rapid air exchange with nearby expanses of water and countryside. Within those areas that are densifying, average summer temperature increases of up to around 1.5°C are being seen. As expected, the biggest temperature increases are observed when natural environments or green areas are built on.<br/>Measures in the local area<br/>One consequence of the locally limited effect of changes in the urban environment is that measures should primarily be focused on direct effects within the local area. Examples of such measures include shady street trees and proximity to green spaces. For the same reason, measures such as green roofs that only indirectly affect the air temperature in the street environment can be expected to have a less significant impact.<br/>A comfort index can be used to summarise the effect of various climate parameters. One example of such an index is the Universal Thermal Climate Index (UTCI). This involves a higher level of ambition in relation to how climate planning is often carried out in today’s planning processes. | En un subproyecto llevado a cabo junto con la Ciudad de Estocolmo dentro del proyecto de investigación HazardSupport, SMHI ha investigado cómo la planificación urbana afecta el clima de una ciudad. Se han producido escenarios para el crecimiento de Estocolmo hasta 2030 y 2050, utilizando el verano de 2014 como punto de referencia. Estos escenarios no tienen en cuenta el cambio climático en curso. En cambio, simplemente muestran cómo se puede esperar que la densificación y el crecimiento de Estocolmo afecten la temperatura del aire.<br/>La principal conclusión de los escenarios es que el impacto de la densificación en la temperatura del aire es relativamente local. No se observa ningún efecto significativo sobre la temperatura promedio durante el verano a una distancia de más de aproximadamente 2 km, a pesar de la extensa densificación en grandes áreas. Esto se puede observar, por ejemplo, en las zonas más céntricas de Estocolmo, que ya están construidas y en las que no se puede esperar una reducción significativa de los espacios verdes, y en estas zonas no se observa ningún cambio significativo en la temperatura del aire.<br/>Una de las razones por las que la densificación y expansión de Estocolmo no ha tenido ningún impacto significativo en la temperatura del aire es el intercambio de aire relativamente rápido con extensiones cercanas de agua y campo. Dentro de aquellas zonas que se están densificando, se están viendo aumentos medios de temperatura de verano de hasta alrededor de 1,5 ° C. Como era de esperar, los mayores aumentos de temperatura se observan cuando se construyen entornos naturales o áreas verdes.<br/>Medidas en el ámbito local<br/>Una consecuencia del efecto localmente limitado de los cambios en el entorno urbano es que las medidas deben centrarse principalmente en los efectos directos dentro del área local. Ejemplos de tales medidas incluyen árboles sombreados de la calle y la proximidad a los espacios verdes. Por la misma razón, se puede esperar que medidas como los techos verdes que solo afectan indirectamente la temperatura del aire en el entorno de la calle tengan un impacto menos significativo.<br/>Se puede usar un índice de confort para resumir el efecto de varios parámetros climáticos. Un ejemplo de tal índice es el índice de clima térmico universal (UTCI). Esto implica un mayor nivel de ambición en relación con la forma en que la planificación climática a menudo se lleva a cabo en los procesos de planificación actuales. |
