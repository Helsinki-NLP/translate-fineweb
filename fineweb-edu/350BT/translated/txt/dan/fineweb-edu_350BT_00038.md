| original | translation |
|----------|-------------|
| Artificial intelligence (AI), the computerized capability of doing tasks, which until recently was thought to be the exclusive domain of human intelligence, has demonstrated great strides in the past decade. The abilities to play games, provide piloting for an automobile, and respond to spoken language are remarkable successes. How are the challenges and opportunities of medicine different from these challenges and how can we best apply these data-driven techniques to patient care and outcomes? A New England Journal of Medicine paper published in 1980 suggested that more well-defined “specialized” tasks of medical care were more amenable to computer assistance, while the breadth of approach required for defining a problem and narrowing down the problem space was less so, and perhaps, unachievable. On the other hand, one can argue that the modern version of AI, which uses data-driven approaches, will be the most useful in tackling tasks such as outcome prediction that are often difficult for clinicians and patients. The ability today to collect large volumes of data about a single individual (eg, through a wearable device) and the accumulation of large datasets about multiple persons receiving medical care has the potential to apply to the care of individuals. As these techniques of analysis, enumeration, aggregation, and presentation are brought to bear in medicine, the question arises as to their utility and applicability in that domain. Early efforts in decision support were found to be helpful; as the systems proliferated, later experiences have shown difficulties such as alert fatigue and physician burnout becoming more prevalent. Will something similar arise from data-driven predictions? Will empowering patients by equipping them with information gained from data analysis help? Patients, providers, technology, and policymakers each have a role to play in the development and utilization of AI in medicine. Some of the challenges, opportunities, and tradeoffs implicit here are presented as a dialog between a clinician (SJN) and an informatician (QZT).J Med Internet Res 2019;21(11):e16272<br/>Drs Nelson and Zeng-Treitler work together at the Biomedical Informatics Center at George Washington University. In the following we present a hypothetical dialogue which grew out of discussions they had as they considered their differing viewpoints of how artificial intelligence (AI) has developed and where it is going. While Dr Zeng-Treitler’s view of the future of AI is highly optimistic, Dr Nelson's opinion is more cautious. Dr Nelson was a practicing academic internist who became involved in informatics many years ago. He collaborated with Scott Blois on RECONSIDER (an early clinical decision support system) and on the Unified Medical Language System (UMLS) project. He eventually moved to the National Library of Medicine as Head of Medical Subject Headings. While at the National Library of Medicine, he fathered RxNorm, while continuing his work on UMLS and projects involving UMLS. Dr Zeng-Treitler has a background in computer science and obtained her PhD in medical informatics from Columbia University. She has led a number of projects in clinical data mining, natural language processing, and consumer health informatics. During the past few years, her team has been actively investigating the use of AI techniques in clinical research including development of a novel explainable deep learning approach.<br/>Dr Zeng-Treitler (The "Optimist"):<br/>After decades of promises and disappointment, thanks to the seemingly unbounded computing resources and novel, data-driven methods, AI technology has finally arrived. From Jeopardy and Siri to face identification and autonomous vehicles, data-driven approaches have made the leap from laboratory experiments to applications that are transforming our lives outside health care. In some cases, these approaches have come close to passing the Turing Test—a test of a machine’s ability to exhibit supposed human-like intelligence; machines can now perform some complex tasks such as image recognition and authentic game play as well as or better than humans would. Some would argue that the requisite approach is decidedly nonhuman. However, whatever the means to achieving these innovations, such successes have not been followed by analogous successes in health care.<br/>One dramatic example of this disparity of accomplishment is AlphaZero, a computer game engine that mastered chess, Shogi, and Go. Even before the arrival of the current generation of data-driven artifacts, chess engines have been shown to be able to play at a level superior to that of chess champions. Players of Go (a board game that is thought to be much more complex than chess), however, believed that computers were no match for high-level professionals in this game. This belief was shattered first by AlphaGo, which soundly defeated the reigning world champion of Go. Then came AlphaZero. The news is no longer that such approaches can beat the champions of Go, chess, or Shogi. Rather, the remarkable fact is that AlphaZero did not learn from human experiences and that it defeated the best prior chess engines such as Stockfish. AlphaZero triumphed by playing more games against itself than had ever been played by all human players. This is not an approach we could readily duplicate in health care.<br/>Dr Nelson (The "Cautious" One):<br/>Is winning a game, with defined rules and objectives, really the best test of human intelligence? In hindsight, the answer is “No.” For example, sophisticated chess playing programs have existed for nearly 50 years; from such programs, we learned how to organize computing resources to apply simple algorithms in a scalable way. Put differently, we did not learn anything about chess or how humans, even experts, play it. Instead, we learned that a supposed intelligence-requiring task was susceptible to a computational approach. We need to ask where and how such an approach is applicable in health care.<br/>For example, when doing tasks that are generally thought to be human and creative, can the machine recognize when it is out of its depth? Sometimes, humans have the ability to do so. However, if we can define the realm closely enough, I agree that the machines can do wonders. So, how do we define the realm?<br/>In Blois’ seminal paper on Clinical Judgment and Computers , he described the world of a physician’s thought process when seeing a patient, with the diagram shown in . Point A for a physician would be where the patient walks in the door to be seen for the first time. The nature of the complaint, the context in which the complaint occurs, and all of the myriad possibilities are present. As the problem definition moves toward Point B, a computer is better able to manage the information and knowledge necessary for high-quality care. One way in which we can think about defining the realm is that we are moving toward Point B. Some computer scientists have argued that Point A is just about managing facts, but, as Blois observed, it is more about relevance—something that has proven difficult to replicate computationally.<br/>It is indeed important to define the realm for an AI application. Many tasks in health care are much more complex than game play, and we have not witnessed the triumphs of analogous approaches in the biomedical domain as have been achieved in game play. Quite a few studies have been applying the latest deep learning technology (a key AI method) to biomedical datasets [- ]. The specific applications included image processing, natural language processing, and risk prediction. Deep learning, compared with traditional statistical and machine learning methods, has often shown modest improvements rather than breakthroughs [ - ].<br/>Whatever the details of these approaches, they apply nearly unbounded computing resources to very large amounts of data, something that has yet to happen in health care. Therefore, these approaches might prove helpful, but we do not know for sure yet.<br/>For example, a simple question posed by a colleague is beyond our current capabilities: Given a patient who starts out with a feature of metabolic syndrome, which feature of the syndrome will he or she tend to exhibit next? Simplistically, this is exactly the kind of challenge that a data-driven approach should help with, and yet, it is currently “over the horizon” due to the insufficient data that were collected in the past.<br/>Data are a key challenge when applying data-driven approaches to patient care. To begin with, biomedical data are highly complex. There many different types of data including image, text, numerical values, categorical classifications, and DNA sequences, representing tens of thousands of lab tests, procedures, diagnoses, medications, genetic markers, etc. Each data type also has its own characteristics; for example, a laboratory test value may need to be interpreted in the context of age, gender, and current conditions. However, diagnostic codes for different diseases have varying levels of accuracies.<br/>In biomedical data analysis, there is also the paradox of having too much and not enough data at the same time. On one hand, there are a tremendous amount of medical record, social media, and literature data. Efforts like the Million Veterans Project  have also collected a huge amount of DNA data. Using devices for tasks like activity tracking and continuous glucose monitoring generates more data than our current medical record systems can digest. On the other hand, the health record of a patient is an open system with much missing information in contrast with the closed system of a chess or Go game, where all data are available. Patients are observed at irregular intervals (eg, at clinic visits or during hospitalization) and are never subjected to all possible tests or treatments. Sometimes, death is the only definitive outcome.<br/>I agree that data types are multiple and complex. Simple solutions are insufficient, and the proliferation of irrelevant data in a record, not to mention the current cut-and-paste or fill-in-the-template fad, obscures what is important.<br/>One of the major difficulties with medical data is not just that it is not enough, but also that it is theory laden, that is, very few pieces of data are recorded routinely. A lot of data in observations are gathered only when the clinician has thought it is appropriate, that is, when diseases are tested for their absence or presence. If there is no reason to do the test, the test is not performed. Only a few tests are ever performed routinely; a transcribed set of physical observations (as is done in physical examination) is rarely recorded in enough detail (not to mention the failure to observe, which often occurs) to provide sufficient data for a more comprehensive analysis. For that reason alone, studies based on the recorded observations are often incomplete and potentially misleading. However, for predictions, observations not made may be the critical ones. Think about the patient with metabolic syndrome mentioned above. What data are we missing?<br/>Similarly, the results of clinical trials are not a complete picture. Even though participants have been selected, often excluding many individuals because of complicating conditions, the data collected on the participants are designed for testing certain hypotheses, with narrowly defined outcomes. A common criticism is that such trials are so artificial that they are irrelevant.<br/>The lack of integrated and standardized datasets is another issue. Although we can find many large datasets, they are often incomplete and difficult to link to other information. For example, environmental exposure, diet, physical activity, and genetic profile are among the common missing pieces of information when we examine the records about an individual patient. Detailed clinical trial datasets tend to lack long-term follow-up. Privacy issues and monetary incentives are also obstacles in data integration efforts.<br/>Real semantic interoperability to integrate and standardize datasets requires support in both terminology and how that terminology is used. Currently, human intervention is often required to interpret what one system is saying for use in another system. This situation is unfortunate; we can hope that over time, the necessary connections will take place (think of how the United States went from operator assistance on every telephone call to the automatic switching that takes place today). Such a change can only happen when many people see the need for and implement a common standard.<br/>In addition, the notion of “large” in the context of health care data is only relative. Think, instead, of many experiments undertaken by Google; if they desire, the amount of data that can be used to develop and test a model is orders of magnitude greater than that available in health care.<br/>In the domains where data-driven approaches have demonstrated success, there are outcomes that can be judged by human experts or machines themselves. For example, bilingual speakers can tell if natural language translation is working well, and the outcome of board or computer games can be easily determined. This allows easier simulation or annotation of data for machine learning. Such a task is much harder in the biomedical domains; investigation of causes or treatments of diseases in humans involve costly and long-term studies. In some cases, ethical concerns prohibit the experiments; for example, the introduction of potentially harmful genetic mutations into healthy human subjects is out of the question. We lack long-term outcome data for many treatments.<br/>I am not sure that there ever will be such a gold standard without a completely arbitrary definition. Variation between individuals is also a major obstacle. Although we perform studies using multiple subjects to account for biologic variability, our results are only approximate in their relevance to a given individual. For example, assuring genetic diversity in clinical trials is challenging, to say the least. Even the simplest tasks can be staggeringly multifactorial; for example, the information content of genetic testing for warfarin metabolism can be outweighed by whether the patient had lettuce for lunch.<br/>To expand on this observation, suppose you have an automobile that is not working appropriately. Today, you consult the sensors and the computer readout to give you very precise information about what is going wrong. The automobile has a specific design, with specific parameters that can be measured. All of the vehicles of the same year make and model can be assumed to be alike in those important aspects. It is important to realize that every human (with the exception of identical twins) is genetically unique. In that way, people are very different from automobiles or other mechanical devices. To compound the complexity with which the cause of a human problem can be addressed, what the individual experiences throughout their life is unique. Although we have nice abstractions or methods of identifying individuals who share some common characteristics (whether the presence or absence of a disease, the response or lack thereof to a medication, the similar environment, or other considerations), these are only a shorthand notation. With 7 billion persons currently living in this world, the problem appears almost open-ended. Too often in data analysis, we look at diagnostic codes as having a deep meaning. These are accepted without any recognition of the degree of uncertainty of the diagnosis. All our data may be helpful and useful, but we need to continue to view them with a large grain of salt. The fact that Google Translate works as well as it does gives us hope, but as complex as natural language translation is, it is simpler than some clinical tasks.<br/>Despite these challenges, applying data-driven approaches has the potential to transform health care. Today’s health care is labor intensive, from scheduling and triage to diagnosis and treatment. Many tasks currently undertaken by humans can be carried out by intelligent software solutions supported by sufficient data. For instance, improved voice recognition and summarization technology might help reduce the amount of time patients and clinicians spend on paperwork. Improved decision support tools ought to be able to help patients decide about the appropriateness of seeking care. An accurate assessment of short- and long-term risks and benefits will inform treatment selection and lifestyle changes.<br/>To provide another use case, there is evidence that type II diabetes may be reversible, but it is hard to apply this knowledge to an individual patient. Given the patient in front of me, what should I do, or recommend, and with what expectation? Demographics, genomics, comorbidities, psyche, competing risks, and other medications, all play a role. How, in a given person, do I reconcile all the possibilities?<br/>To develop these useful AI tools, we need better data, technology, and policy. To accumulate comprehensive, life-time data, patients must be in control and should be incentivized to share their data for research and care. Insurance, pharmaceutical, and medical institutions change over time. Currently, there are barriers for individuals to be the center of collecting the data on themselves. The barriers are present in data entry, collection, and storage; for example, some personalized health record products are tethered to an institution, while others require extensive transcribing efforts by patients or caregivers. Nevertheless, without patient consent and collaboration, gathering and linking longitudinal environmental, genetic, clinical, and behavioral data are neither feasible nor ethical. The current conditions are a huge barrier to any attempt to use data-driven approaches that have worked outside health care.<br/>Efforts including PatienstLikeMe  and the All of Us Research Project of the National Institutes of Health [ ] are examples of innovative approaches to curate bigger and better datasets. Most patients, however, are not engaged in such efforts. Patients are inherently motivated to improve their own health, but naturally have concerns regarding privacy and often do not see immediate benefits of participating in long-term studies. Appropriate incentives (eg, discounts for routine preventive care) coupled with security and authentication technologies are needed to entice a large and diverse population of patients to gather and share their data. The health care industry today owns parts of patient data and has limited motivation to purchase data from their customers. As the value of data increases, patients will become more valued as a partner.<br/>I agree that patients will need to assume the responsibility of carrying and sharing the information about themselves. However, experience tells us that not everyone is able or willing to do so. It will need cultural and political climate changes to encourage that development.<br/>When we can collect data that are not directly what the philosophers would call “theory-laden,” we may be able to refine our crude methods of patient diagnosis and care. I look forward to that day. If patients are the carrier of those data, it will be easier to obtain and use for analysis.<br/>We also need to design and implement methods specifically for handling very large and “messy” clinical data. For example, we need to understand the context of missing data and errors to get a better picture of ground truth. A lab result may be missed because there is no indication for it, practice preference, an alternative method of assessing, or a failure of data entry. Imagine how much more difficult a chess game will be, if a human player or a chess engine could only observe some squares on the board at irregular time intervals with some error or distortion of the observation.<br/>Further, we do not have an operational definition of “ground truth” in health care; a simple proposal is that one feature of ground truth is that it has predictive value—something that will be valued by clinicians and patients alike.<br/>Google has demonstrated that they can use lots of data to predict likely values for missing data in other areas ; however, it is yet to be determined whether this might work in medicine, but it is probably worth a trial. Irrespective of whether we can use large volumes of data to impute missing values, exploring how to handle the problem of absent observations is crucial, especially whenever we try to apply the results of data-driven approaches to individual patients.<br/>Another thought is that data that are missing, for any reason, are an observation in itself; the fact that the data were not obtained and recorded may be important. Think of the finding that the day and time of a test were more predictive of outcome than the result of the test . We know that the data that are missing will have some predictive value.<br/>On a different note, explanation of the data-driven models is critical to not only their adoption but also their impact . Predicting that a patient will have certain adverse events in the next several days or years is desirable. It may be argued that it is even more important to know the modifiable factors that can reduce risk and enhance outcome. Since deep learning models can be highly nonlinear, we have the opportunity to discover novel and complex patterns.<br/>I agree that explaining the prediction is critical; it is something that separates health care from, say, recognizing whether an image is a dog or a cat. However, I think you meant to say predicting a patient will probably have some adverse outcome. Nothing in life is certain except that it will end. However, we can say “it appears this behavior or finding will likely have an effect on your future” and hopefully be able to express some degree of confidence in that prediction.<br/>Learning how to express the confidence in a prediction is also important. How many folks really understand the statistics behind the predictions that occur today? What are the underlying assumptions behind any probabilistic model? It is more likely that with more frequent use and familiarity with the use of measures derived for AI models will lead to their acceptance.<br/>I agree. These are all steps to be taken in order to optimize the use of big data through AI to improve medical care.<br/>As a parting thought, we need to be cautious about how intrusive data-driven approaches might be in the care process. Although McDonald  demonstrated that performance in care improves with reminders [ ], the later experience has been one of too many reminders, leading to alert fatigue. When caregivers choose to override and ignore helpful information because of overload, have we accomplished anything?<br/>I hope that careful design of systems and consideration of clinical workflow will alleviate the problem of excessive intrusiveness. Although it is tempting to just “let AI do it,” the recent experiences with the Boeing 737 MAX demonstrate that there is danger in doing so. Neither AI nor a pilot alone is the optimal strategy in flying. In health care, involving patients more extensively in their care, together with AI and providers, may ultimately be an approach that works.<br/>Conflicts of Interest<br/>- Blois MS. Clinical Judgment and Computers. N Engl J Med 1980 Jul 24;303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Deep learning for healthcare: review, opportunities and challenges. Brief Bioinform 2018 Nov 27;19(6):1236-1246 [FREE Full text] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. Can machine-learning improve cardiovascular risk prediction using routine clinical data? PLoS ONE 2017 Apr 4;12(4):e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT. Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records. Sci Rep 2016 May 17;6(1):26094 [FREE Full text] [CrossRef] [Medline]<br/>- Quach K. The register. 2019. IBM Watson Health cuts back drug discovery 'artificial intelligence' after lackluster sales URL: https://www.theregister.co.uk/2019/04/18/ibm_watson_health [accessed 2019-10-23]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Scalable and accurate deep learning with electronic health records. NPJ Digit Med 2018 May 8;1(1):18 [FREE Full text] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, et al. Deep Learning in Medical Imaging: General Overview. Korean J Radiol 2017;18(4):570. [CrossRef]<br/>- U.S Department of Veterans Affairs. Million Veteran Program (MVP) URL: https://www.research.va.gov/mvp/ [accessed 2019-10-23]<br/>- Patientslikeme. URL: https://www.patientslikeme.com [accessed 2019-10-23]<br/>- All of Us Research Program. URL: https://allofus.nih.gov [accessed 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. The unreasonable effectiveness of data. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Biases in electronic health record data due to processes within the healthcare system: retrospective observational study. BMJ 2018 Apr 30:k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, Müller H. Causability and explainabilty of artificial intelligence in medicine. WIREs Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Protocol-Based Computer Reminders, the Quality of Care and the Non-Perfectibility of Man. N Engl J Med 1976 Dec 09;295(24):1351-1355. [CrossRef]<br/>&#124;AI: artificial intelligence&#124;<br/>&#124;UMLS: Unified Medical Language System&#124;<br/>Edited by G Eysenbach; submitted 15.09.19; peer-reviewed by A Holzinger; comments to author 14.10.19; revised version received 15.10.19; accepted 20.10.19; published 27.11.19Copyright<br/>©Qing Zeng-Treitler, Stuart J Nelson. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included. | Kunstig intelligens (AI), den computeriserede evne til at udføre opgaver, som indtil for nylig blev anset for at være det eksklusive domæne for menneskelig intelligens, har vist store fremskridt i det sidste årti. Evnerne til at spille spil, give lodsning for en bil, og reagere på talesprog er bemærkelsesværdige succeser. Hvordan adskiller medicinens udfordringer og muligheder sig fra disse udfordringer, og hvordan kan vi bedst anvende disse datadrevne teknikker til patientpleje og resultater? En New England Journal of Medicine papir offentliggjort i 1980 foreslog, at mere veldefinerede "specialiserede" opgaver i lægehjælp var mere modtagelige for computer assistance, mens bredden af tilgang, der kræves for at definere et problem og indsnævre problemet rummet var mindre så, og måske, uopnåelig. På den anden side kan man argumentere for, at den moderne version af AI, der bruger datadrevne tilgange, vil være den mest nyttige til at tackle opgaver som resultatforudsigelse, der ofte er vanskelige for klinikere og patienter. Evnen i dag til at indsamle store mængder data om en enkelt person (f.eks. gennem en bærbar enhed) og ophobning af store datasæt om flere personer, der modtager lægehjælp, har potentiale til at gælde for pleje af enkeltpersoner. Da disse teknikker til analyse, optælling, aggregering og præsentation bringes til at bære i medicin, opstår spørgsmålet om deres anvendelighed og anvendelighed i dette domæne. Tidlige bestræbelser på beslutningsstøtte viste sig at være nyttige; da systemerne spredte sig, har senere erfaringer vist vanskeligheder som alarm træthed og læge udbrændthed bliver mere udbredt. Vil noget lignende opstå fra data-drevne forudsigelser? Vil styrke patienter ved at udstyre dem med oplysninger fra dataanalyse hjælp? Patienter, udbydere, teknologi og politikere har hver en rolle at spille i udviklingen og udnyttelsen af AI i medicin. Nogle af de udfordringer, muligheder og afvejninger, der er implicitte her, præsenteres som en dialog mellem en kliniker (SJN) og en informatiker (QZT). J Med Internet Res 2019;21(11):e16272<br/>Dr. Nelson og Zeng-Treitler arbejder sammen på Biomedical Informatics Center ved George Washington University. I det følgende præsenterer vi en hypotetisk dialog, der voksede ud af diskussioner, de havde, da de overvejede deres forskellige synspunkter om, hvordan kunstig intelligens (AI) har udviklet sig, og hvor det går. Mens Dr. Zeng-Treitlers syn på fremtiden for AI er meget optimistisk, er Dr. Nelsons mening mere forsigtig. Dr. Nelson var en praktiserende akademisk internist, der blev involveret i informatik for mange år siden. Han samarbejdede med Scott Blois om RECONSIDER (et tidligt klinisk beslutningsstøttesystem) og om Unified Medical Language System (UMLS) -projektet. Han flyttede til sidst til National Library of Medicine som leder af medicinske emneoverskrifter. Mens han var på National Library of Medicine, blev han far til RxNorm, mens han fortsatte sit arbejde med UMLS og projekter, der involverer UMLS. Dr. Zeng-Treitler har en baggrund i datalogi og fik sin ph.d. i medicinsk informatik fra Columbia University. Hun har ledet en række projekter inden for klinisk data mining, naturlig sprogbehandling og forbrugersundhedsinformatik. I løbet af de sidste par år har hendes team aktivt undersøgt brugen af AI-teknikker i klinisk forskning, herunder udvikling af en ny forklarlig dyb læringstilgang.<br/>Dr. Zeng-Treitler (optimisten):<br/>Efter årtier med løfter og skuffelser, takket være de tilsyneladende ubegrænsede computerressourcer og nye, datadrevne metoder, er AI-teknologien endelig ankommet. Fra Jeopardy og Siri til ansigtsidentifikation og autonome køretøjer har datadrevne tilgange gjort springet fra laboratorieforsøg til applikationer, der omdanner vores liv uden for sundhedsvæsenet. I nogle tilfælde er disse tilgange kommet tæt på at bestå Turing-testen - en test af en maskines evne til at udvise formodet menneskelignende intelligens; maskiner kan nu udføre nogle komplekse opgaver som billedgenkendelse og autentisk spil samt eller bedre end mennesker ville. Nogle vil hævde, at den nødvendige tilgang er afgjort ikke-menneskelig. Men uanset midlerne til at opnå disse innovationer, er sådanne succeser ikke blevet efterfulgt af tilsvarende succeser i sundhedsvæsenet.<br/>Et dramatisk eksempel på denne forskel i præstation er AlphaZero, en computerspilmotor, der mestrer skak, Shogi og Go. Selv før ankomsten af den nuværende generation af data-drevne artefakter, har skak motorer vist sig at være i stand til at spille på et niveau, der er bedre end skak mestre. Players of Go (et brætspil, der menes at være meget mere komplekst end skak), mente dog, at computere ikke var noget match for professionelle på højt niveau i dette spil. Denne tro blev først knust af AlphaGo, som besejrede den regerende verdensmester i Go. Så kom AlphaZero. Nyheden er ikke længere, at sådanne tilgange kan slå mestrene i Go, skak eller Shogi. Snarere er det bemærkelsesværdige faktum, at AlphaZero ikke lærte af menneskelige erfaringer, og at det besejrede de bedste tidligere skakmotorer som Stockfish. AlphaZero triumferede ved at spille flere spil mod sig selv, end der nogensinde var blevet spillet af alle menneskelige spillere. Dette er ikke en tilgang, vi let kunne kopiere i sundhedsvæsenet.<br/>Dr. Nelson (Den "Forsigtige")<br/>Er at vinde et spil, med definerede regler og mål, virkelig den bedste test af menneskelig intelligens? Set i bakspejlet er svaret "Nej." For eksempel har sofistikerede skakspilsprogrammer eksisteret i næsten 50 år; fra sådanne programmer lærte vi at organisere computerressourcer til at anvende enkle algoritmer på en skalerbar måde. Sagt på en anden måde lærte vi ikke noget om skak eller hvordan mennesker, selv eksperter, spiller det. I stedet lærte vi, at en formodet intelligenskrævende opgave var modtagelig for en beregningsmæssig tilgang. Vi er nødt til at spørge, hvor og hvordan en sådan tilgang finder anvendelse i sundhedsvæsenet.<br/>Kan maskinen for eksempel, når den udfører opgaver der generelt menes at være menneskelige og kreative, genkende når den er ude af sin dybde? Men hvis vi kan definere riget tæt nok, er jeg enig i, at maskinerne kan gøre underværker. Så hvordan definerer vi riget?<br/>I Blois' skelsættende papir om klinisk dom og computere, beskrev han verden af en læges tankeproces, når man ser en patient, med diagrammet vist i. Punkt A for en læge ville være, hvor patienten går i døren for at blive set for første gang. Klagens karakter, den sammenhæng, hvori klagen opstår, og alle de utallige muligheder er til stede. Da problemdefinitionen bevæger sig mod punkt B, er en computer bedre i stand til at styre den information og viden, der er nødvendig for pleje af høj kvalitet. En måde, hvorpå vi kan tænke på at definere riget, er, at vi bevæger os mod punkt B. Nogle computerforskere har hævdet, at punkt A kun handler om at styre fakta, men som Blois observerede, handler det mere om relevans - noget, der har vist sig vanskeligt at replikere beregningsmæssigt.<br/>Det er faktisk vigtigt at definere riget for en AI-applikation. Mange opgaver i sundhedsvæsenet er meget mere komplekse end spil, og vi har ikke været vidne til triumfer af analoge tilgange i det biomedicinske domæne, som er opnået i spil. En hel del undersøgelser har anvendt den nyeste dybe læringsteknologi (en vigtig AI-metode) til biomedicinske datasæt [- ]. De specifikke applikationer omfattede billedbehandling, naturlig sprogbehandling og risikoforudsigelse. Deep learning, sammenlignet med traditionelle statistiske og machine learning metoder, har ofte vist beskedne forbedringer snarere end gennembrud.<br/>Uanset detaljerne i disse tilgange anvender de næsten ubegrænsede computerressourcer til meget store mængder data, noget der endnu ikke er sket i sundhedsvæsenet. Derfor kan disse tilgange vise sig at være nyttige, men vi ved ikke med sikkerhed endnu.<br/>For eksempel er et simpelt spørgsmål stillet af en kollega ud over vores nuværende evner: Givet en patient, der starter med et træk ved metabolisk syndrom, hvilket træk ved syndromet vil han eller hun have tendens til at udstille næste? Simpelthen er dette præcis den slags udfordring, som en datadrevet tilgang skal hjælpe med, og alligevel er det i øjeblikket "over horisonten" på grund af de utilstrækkelige data, der blev indsamlet tidligere.<br/>Data er en vigtig udfordring, når man anvender datadrevne tilgange til patientpleje. Til at begynde med er biomedicinske data meget komplekse. Der er mange forskellige typer data, herunder billede, tekst, numeriske værdier, kategoriske klassifikationer og DNA-sekvenser, der repræsenterer titusinder af laboratorieprøver, procedurer, diagnoser, medicin, genetiske markører osv. Hver datatype har også sine egne karakteristika; for eksempel kan en laboratorietestværdi skal fortolkes i sammenhæng med alder, køn og aktuelle forhold. Men diagnostiske koder for forskellige sygdomme har forskellige niveauer af nøjagtighed.<br/>I biomedicinsk dataanalyse er der også paradokset ved at have for meget og ikke nok data på samme tid. På den ene side er der en enorm mængde medicinske journaler, sociale medier og litteraturdata. Indsatser som Million Veterans Project har også indsamlet en enorm mængde DNA-data. Brug af enheder til opgaver som aktivitetssporing og kontinuerlig glukoseovervågning genererer flere data, end vores nuværende journalsystemer kan fordøje. På den anden side er patientjournalen et åbent system med meget manglende information i modsætning til det lukkede system i et skak- eller Go-spil, hvor alle data er tilgængelige. Patienter observeres med uregelmæssige intervaller (f.eks. Ved klinikbesøg eller under hospitalsindlæggelse) og udsættes aldrig for alle mulige tests eller behandlinger. Nogle gange er døden det eneste endelige resultat.<br/>Jeg er enig i, at datatyper er flere og komplekse. Enkle løsninger er utilstrækkelige, og spredningen af irrelevante data i en post, for ikke at nævne den nuværende cut-and-paste eller fill-in-the-template fad, skjuler, hvad der er vigtigt.<br/>En af de store vanskeligheder med medicinske data er ikke kun, at det ikke er nok, men også at det er teori lastet, det vil sige, meget få stykker data registreres rutinemæssigt. En masse data i observationer indsamles kun, når klinikeren har fundet det passende, det vil sige, når sygdomme testes for deres fravær eller tilstedeværelse. Hvis der ikke er grund til at udføre testen, udføres testen ikke. Kun nogle få tests udføres nogensinde rutinemæssigt; et transskriberet sæt fysiske observationer (som det gøres i fysisk undersøgelse) registreres sjældent tilstrækkeligt detaljeret (for ikke at nævne den manglende observation, som ofte forekommer) for at give tilstrækkelige data til en mere omfattende analyse. Alene af den grund er undersøgelser baseret på de registrerede observationer ofte ufuldstændige og potentielt vildledende. Men for forudsigelser kan observationer, der ikke er foretaget, være de kritiske. Tænk på patienten med metabolisk syndrom, der er nævnt ovenfor. Hvilke data mangler vi?<br/>Tilsvarende er resultaterne af kliniske forsøg ikke et komplet billede. Selvom deltagerne er blevet udvalgt, ofte udelukker mange individer på grund af komplicerende forhold, er de indsamlede data om deltagerne designet til at teste visse hypoteser med snævert definerede resultater. En almindelig kritik er, at sådanne forsøg er så kunstige, at de er irrelevante.<br/>Manglen på integrerede og standardiserede datasæt er et andet problem. Selvom vi kan finde mange store datasæt, er de ofte ufuldstændige og vanskelige at linke til andre oplysninger. For eksempel er miljøeksponering, kost, fysisk aktivitet og genetisk profil blandt de fælles manglende oplysninger, når vi undersøger optegnelserne om en enkelt patient. Detaljerede kliniske forsøgsdatasæt har tendens til at mangle langsigtet opfølgning. Spørgsmål om privatlivets fred og monetære incitamenter er også hindringer i dataintegrationsindsatsen.<br/>Reel semantisk interoperabilitet til at integrere og standardisere datasæt kræver støtte i både terminologi og hvordan denne terminologi bruges. I øjeblikket er menneskelig indgriben ofte påkrævet for at fortolke, hvad et system siger til brug i et andet system. Denne situation er uheldig; vi kan håbe, at de nødvendige forbindelser vil finde sted over tid (tænk på, hvordan USA gik fra operatørassistance ved hvert telefonopkald til det automatiske skift, der finder sted i dag). En sådan ændring kan kun ske, når mange mennesker ser behovet for og gennemfører en fælles standard.<br/>Desuden er begrebet "stor" i forbindelse med sundhedsdata kun relativt. Tænk i stedet for mange eksperimenter foretaget af Google; hvis de ønsker, er mængden af data, der kan bruges til at udvikle og teste en model, større end den, der er tilgængelig i sundhedsvæsenet.<br/>På de områder, hvor datadrevne tilgange har vist succes, er der resultater, der kan bedømmes af menneskelige eksperter eller maskiner selv. For eksempel kan tosprogede højttalere fortælle, om naturlig sprogoversættelse fungerer godt, og resultatet af bræt- eller computerspil kan let bestemmes. Dette giver lettere simulering eller anmærkning af data til maskinindlæring. En sådan opgave er meget sværere på de biomedicinske områder; undersøgelse af årsager eller behandling af sygdomme hos mennesker involverer dyre og langsigtede undersøgelser. I nogle tilfælde forbyder etiske bekymringer eksperimenterne; for eksempel er indførelsen af potentielt skadelige genetiske mutationer i raske mennesker udelukket. Vi mangler langsigtede resultatdata for mange behandlinger.<br/>Jeg er ikke sikker på, at der nogensinde vil være en sådan guldstandard uden en helt vilkårlig definition. Variation mellem individer er også en stor hindring. Selvom vi udfører undersøgelser ved hjælp af flere forsøgspersoner for at tage højde for biologisk variabilitet, er vores resultater kun omtrentlige i deres relevans for et givet individ. For eksempel er det at sikre genetisk mangfoldighed i kliniske forsøg mildt sagt udfordrende. Selv de enkleste opgaver kan være svimlende multifaktorielle; for eksempel kan informationsindholdet i genetisk testning for warfarinmetabolisme opvejes af, om patienten havde salat til frokost.<br/>Lad os sige at du har en bil der ikke fungerer som den skal, og at du i dag konsulterer sensorerne og computerens udlæsning for at få meget præcise oplysninger om hvad der går galt. Bilen har et specifikt design, med specifikke parametre, der kan måles. Alle køretøjer af samme år fabrikat og model kan antages at være ens i disse vigtige aspekter. Det er vigtigt at indse, at hvert menneske (med undtagelse af identiske tvillinger) er genetisk unik. På den måde er folk meget forskellige fra biler eller andre mekaniske enheder. At sammensætte den kompleksitet, som årsagen til et menneskeligt problem kan løses, hvad de enkelte erfaringer gennem hele deres liv er unikke. Selvom vi har pæne abstraktioner eller metoder til at identificere personer, der deler nogle fælles karakteristika (uanset om tilstedeværelsen eller fraværet af en sygdom, reaktionen eller manglen på en medicin, det lignende miljø eller andre overvejelser), er disse kun en stenografi. Med 7 milliarder mennesker, der i øjeblikket bor i denne verden, forekommer problemet næsten åbent. Alt for ofte i dataanalyse ser vi på diagnostiske koder som at have en dyb betydning. Disse accepteres uden nogen anerkendelse af graden af usikkerhed om diagnosen. Alle vores data kan være nyttige og nyttige, men vi skal fortsætte med at se dem med et stort saltkorn. Det faktum, at Google Translate fungerer så godt som det gør, giver os håb, men så kompleks som naturlig sprogoversættelse er, er det enklere end nogle kliniske opgaver.<br/>På trods af disse udfordringer har anvendelse af datadrevne tilgange potentiale til at omdanne sundhedspleje. Dagens sundhedspleje er arbejdsintensiv, fra planlægning og triage til diagnose og behandling. Mange opgaver, der i øjeblikket udføres af mennesker, kan udføres af intelligente softwareløsninger, der understøttes af tilstrækkelige data. For eksempel kan forbedret stemmegenkendelse og opsummeringsteknologi hjælpe med at reducere den tid, patienter og klinikere bruger på papirarbejde. Forbedrede beslutningsstøtteværktøjer bør kunne hjælpe patienter med at beslutte, om det er hensigtsmæssigt at søge pleje. En nøjagtig vurdering af kort- og langsigtede risici og fordele vil informere behandlingsvalg og livsstilsændringer.<br/>For at give et andet brugstilfælde er der tegn på, at type II diabetes kan være reversibel, men det er svært at anvende denne viden til en individuel patient. I betragtning af patienten foran mig, hvad skal jeg gøre eller anbefale, og med hvilken forventning? Demografi, genomik, komorbiditeter, psyke, konkurrerende risici og andre medikamenter spiller alle en rolle. Hvordan forener jeg alle mulighederne i en given person?<br/>For at udvikle disse nyttige AI-værktøjer har vi brug for bedre data, teknologi og politik. For at akkumulere omfattende, levetidsdata skal patienterne være i kontrol og bør tilskyndes til at dele deres data til forskning og pleje. Forsikring, farmaceutiske og medicinske institutioner ændrer sig over tid. I øjeblikket er der barrierer for enkeltpersoner at være centrum for at indsamle data om sig selv. Barriererne er til stede i dataindtastning, indsamling og opbevaring; for eksempel er nogle personlige patientjournalprodukter bundet til en institution, mens andre kræver omfattende transkriberingsindsats af patienter eller plejere. Ikke desto mindre, uden patientens samtykke og samarbejde, indsamling og sammenkædning langsgående miljømæssige, genetiske, kliniske og adfærdsmæssige data er hverken muligt eller etisk. De nuværende forhold er en enorm barriere for ethvert forsøg på at bruge datadrevne tilgange, der har fungeret uden for sundhedsvæsenet.<br/>Indsats, herunder PatienstLikeMe og All of Us Research Project of the National Institutes of Health [ ] er eksempler på innovative tilgange til at kurere større og bedre datasæt. De fleste patienter er dog ikke involveret i en sådan indsats. Patienterne er i sagens natur motiveret til at forbedre deres eget helbred, men har naturligvis bekymringer om privatlivets fred og ser ofte ikke umiddelbare fordele ved at deltage i langsigtede undersøgelser. Passende incitamenter (f.eks. rabatter for rutinemæssig forebyggende pleje) kombineret med sikkerheds- og autentificeringsteknologier er nødvendige for at lokke en stor og forskelligartet patientpopulation til at indsamle og dele deres data. Sundhedsindustrien ejer i dag dele af patientdata og har begrænset motivation til at købe data fra deres kunder. Efterhånden som værdien af data stiger, vil patienterne blive mere værdsat som en partner.<br/>Jeg er enig i, at patienterne bliver nødt til at påtage sig ansvaret for at bære og dele oplysninger om sig selv. Men erfaringen fortæller os, at ikke alle er i stand til eller villige til at gøre det. Det vil kræve kulturelle og politiske klimaændringer for at fremme denne udvikling.<br/>Når vi kan indsamle data, der ikke er direkte, hvad filosofferne ville kalde "teori-laden", kan vi måske forfine vores rå metoder til patientdiagnose og pleje. Jeg ser frem til den dag. Hvis patienterne er bærere af disse data, vil det være lettere at opnå og bruge til analyse.<br/>Vi skal også designe og implementere metoder specifikt til håndtering af meget store og "messy" kliniske data. For eksempel skal vi forstå konteksten af manglende data og fejl for at få et bedre billede af jorden sandhed. Et laboratorium resultat kan gå glip af, fordi der ikke er nogen indikation for det, praksis præference, en alternativ metode til at vurdere, eller en fejl i dataindtastning. Forestil dig, hvor meget sværere et skakspil vil være, hvis en menneskelig spiller eller en skakmaskine kun kunne observere nogle firkanter på brættet med uregelmæssige tidsintervaller med en fejl eller forvrængning af observationen.<br/>Desuden har vi ikke en operationel definition af "grundsandhed" i sundhedsvæsenet; et simpelt forslag er, at et træk ved grundsandhed er, at det har prædiktiv værdi - noget der vil blive værdsat af klinikere og patienter.<br/>Google har vist, at de kan bruge masser af data til at forudsige sandsynlige værdier for manglende data på andre områder; Det er dog endnu ikke bestemt, om dette kan fungere i medicin, men det er nok værd at prøve. Uanset om vi kan bruge store mængder data til at beregne manglende værdier, er det afgørende at undersøge, hvordan man håndterer problemet med manglende observationer, især når vi forsøger at anvende resultaterne af datadrevne tilgange til individuelle patienter.<br/>En anden tanke er, at data, der af en eller anden grund mangler, er en observation i sig selv; det faktum, at dataene ikke blev opnået og registreret, kan være vigtigt. Tænk på konstateringen af, at dagen og tidspunktet for en test var mere forudsigeligt for resultatet end resultatet af testen. Vi ved, at de data, der mangler, vil have en prædiktiv værdi.<br/>På en anden note, forklaring af de data-drevne modeller er afgørende for ikke kun deres vedtagelse, men også deres indvirkning. Forudsige, at en patient vil have visse bivirkninger i de næste flere dage eller år er ønskeligt. Det kan hævdes, at det er endnu vigtigere at kende de modificerbare faktorer, der kan reducere risikoen og forbedre resultatet. Da deep learning modeller kan være meget ikke-lineære, har vi mulighed for at opdage nye og komplekse mønstre.<br/>Jeg er enig i, at forklare forudsigelsen er kritisk; Det er noget, der adskiller sundhedspleje fra, siger, at anerkende, om et billede er en hund eller en kat. Jeg tror dog, du mente at sige, at forudsige en patient vil sandsynligvis have nogle negative resultater. Intet i livet er sikkert, bortset fra at det vil ende. Vi kan dog sige "det ser ud til, at denne adfærd eller fund sandsynligvis vil have en effekt på din fremtid" og forhåbentlig være i stand til at udtrykke en vis grad af tillid til den forudsigelse.<br/>At lære at udtrykke tillid til en forudsigelse er også vigtigt. Hvor mange mennesker forstår virkelig statistikkerne bag de forudsigelser, der opstår i dag? Hvad er de underliggende antagelser bag enhver probabilistisk model? Det er mere sandsynligt, at med hyppigere brug og kendskab til brugen af foranstaltninger afledt til AI-modeller vil føre til deres accept.<br/>Jeg er enig. Det er alle skridt, der skal tages for at optimere brugen af big data gennem AI for at forbedre lægehjælpen.<br/>Som en afskedstanke skal vi være forsigtige med, hvordan påtrængende datadrevne tilgange kan være i plejeprocessen. Selvom McDonald viste, at ydeevnen i pleje forbedres med påmindelser [ ], har den senere oplevelse været en af for mange påmindelser, hvilket fører til alarm træthed. Når omsorgspersoner vælger at tilsidesætte og ignorere nyttige oplysninger på grund af overbelastning, har vi opnået noget?<br/>Jeg håber, at omhyggeligt design af systemer og overvejelse af klinisk workflow vil afhjælpe problemet med overdreven indgriben. Selvom det er fristende at bare "lade AI gøre det," viser de seneste erfaringer med Boeing 737 MAX, at der er fare ved at gøre det. Hverken AI eller en pilot alene er den optimale strategi i flyvning. I sundhedsvæsenet, der involverer patienter mere udførligt i deres pleje, sammen med AI og udbydere, kan i sidste ende være en tilgang, der virker.<br/>Interessekonflikter<br/>- Blois MS. Klinisk dom og computere. N Engl J Med 1980 Jul 24;303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Deep learning for sundhedspleje: gennemgang, muligheder og udfordringer. Brief Bioinform 2018 Nov 27;19(6):1236-1246 [GRATIS Fuld tekst] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. Kan maskinlæring forbedre kardiovaskulær risikoforudsigelse ved hjælp af rutinemæssige kliniske data? PLoS ONE 2017 Apr 4;12(4):e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT. Dyb patient: En uovervåget repræsentation for at forudsige fremtiden for patienter fra de elektroniske patientjournaler. Sci Rep 2016 Maj 17;6(1):26094 [GRATIS Fuld tekst] [CrossRef] [Medline]<br/>- Quach K. Registret. 2019. IBM Watson Health skærer tilbage lægemiddelopdagelsen 'kunstig intelligens' efter mangelfuld salgswebadresse: https://www.theregister.co.uk/2019/04/18/ibm_watson_health [adgang 2019-10-23]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Skalerbar og præcis dyb læring med elektroniske patientjournaler. NPJ Digit Med 2018 Maj 8;1(1):18 [GRATIS Fuld tekst] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, et al. Dyb læring i medicinsk billeddannelse: Generel oversigt. Koreansk J Radiol 2017;18(4):570. [CrossRef]<br/>- US Department of Veterans Affairs. Million Veteran Program (MVP) URL: https://www.research.va.gov/mvp/ [adgang 2019-10-23]<br/>- Patientslikeme. URL: https://www.patientslikeme.com [adgang 2019-10-23]<br/>- Alle os forskningsprogram. URL: https://allofus.nih.gov [adgang 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. Den urimelige effektivitet af data. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Biaser i elektroniske patientjournaldata på grund af processer inden for sundhedssystemet: retrospektiv observationsundersøgelse. BMJ 2018 Apr 30:k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, Muller H. Årsagsevne og forklaringsevne af kunstig intelligens i medicin. WIREs Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Protokolbaserede computerpåmindelser, kvaliteten af pleje og menneskets ufuldkommenhed. N Engl J Med 1976 Dec 09;295(24):1351-1355. [CrossRef]<br/>AI: kunstig intelligens<br/>Det forenede medicinske sprogsystem (UMLS)<br/>Redigeret af G Eysenbach; indsendt 15.09.19; peer-reviewed af A Holzinger; kommentarer til forfatter 14.10.19; revideret version modtaget 15.10.19; accepteret 20.10.19; offentliggjort 27.11.19Copyright<br/>Qing Zeng-Treitler, Stuart J Nelson. Oprindeligt offentliggjort i Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>Dette er en open-access artikel distribueret under betingelserne i Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), som tillader ubegrænset brug, distribution og reproduktion i ethvert medium, forudsat at det originale værk, først offentliggjort i Journal of Medical Internet Research, er korrekt citeret. De fuldstændige bibliografiske oplysninger, et link til den oprindelige publikation på http://www.jmir.org/, samt disse oplysninger om ophavsret og licens skal medtages. |
| The Story of Selena Quintanilla: A Biography Book for Young Readers (The Story Of: A Biography Series for New Readers) (Paperback)<br/>Most titles are on our shelves or available within 1-5 days.<br/>Discover the life Selena Quintanilla—a story about breaking down barriers in music, for kids ages 6 to 9<br/>Selena Quintanilla was the queen of Tejano music. Before she became a star, Selena was a charismatic young girl who loved singing and performing. She made a lot of sacrifices to become a famous musician, rehearsing her songs and dance moves for hours at a time. Her hard work paid off—she became the first 15-year-old girl to win a Tejano music award and went on to break many records during her career. This Selena biography explores how she went from being a talented girl growing up in Texas to a fashion icon and a world-famous singer.<br/>What sets this Selena book apart:<br/>- Core curriculum—Kids will learn the Who, What, Where, When, Why, and How of Selena’s life, and take a quick quiz to test their knowledge.<br/>- Short chapters—This Selena kids’ book is broken up into brief chapters that make it fun and easy for new readers to discover details about the singer’s life.<br/>- Her lasting legacy—Kids will find out how Selena changed the world of music and why she continues to be a role model for many women and people of color around the globe.<br/>How will Selena’s big spirit and passion for music inspire the child in your life?<br/>About the Author<br/>GLORIA ARJONA teaches Spanish at the California Institute of Technology and is the author of Posadas Unknown Calaveras and ¡Lotería!. She’s also a musician who sings and plays guitar. Learn more at GloriaArjona.com.<br/>“Finally, a Selena book for new readers, one that is told concisely and honestly, and is eminently readable” —Joe Nick Patoski, author of Selena: Como La Flor<br/>“What a wonderful story to inspire girls to follow their dreams. A story that many girls will identify with, especially those from traditional and multicultural families. I liked all the little sidebar lessons throughout the book. Gloria is a very talented teacher.” —Genevieve B. Southgate, director of community programs, Bowers Museum<br/>“Selena Quintanilla’s youthful talent and positive drive are brought to life in Prof. Arjona’s latest book, this one geared to young readers. A highly appealing read highlighting Selena’s flexibility in overcoming obstacles to achieving her dreams and her trailblazing contributions to music and her community. The Callisto Media format of encouraging critical, organized thought via questions, maps, timelines, and a glossary make this an enjoyable learning experience.” —Martin E. Delgado, community library manager<br/>“This is the story of Selena Quintanilla, and what a story it is! In a time where young readers, and young women, need role models more than ever, this book brilliantly depicts the profound humanity, bravery, and talent of a deeply inspiring Latina woman who relentlessly fought for her dream.” —Maite Zubiaurre, UCLA professor | Historien om Selena Quintanilla: En biografibog for unge læsere (Historien om: En biografiserie for nye læsere)<br/>De fleste titler er på vores hylder eller tilgængelige inden for 1-5 dage.<br/>Oplev livet Selena Quintanilla - en historie om at nedbryde barrierer i musik, for børn i alderen 6 til 9<br/>Selena Quintanilla var dronningen af Tejano musik. Før hun blev en stjerne, Selena var en karismatisk ung pige, der elskede at synge og udføre. Hun gjorde en masse ofre for at blive en berømt musiker, øve sine sange og dansetrin i timevis ad gangen. Hendes hårde arbejde betalte sig - hun blev den første 15-årige pige til at vinde en Tejano-musikpris og fortsatte med at bryde mange plader i løbet af sin karriere. Denne Selena-biografi udforsker, hvordan hun gik fra at være en talentfuld pige, der voksede op i Texas, til et modeikon og en verdensberømt sanger.<br/>Hvad adskiller denne Selena bog:<br/>- Core pensum - Børn vil lære hvem, hvad, hvor, hvornår, hvorfor og hvordan af Selena liv, og tage en hurtig quiz for at teste deres viden.<br/>Denne Selena børnebog er opdelt i korte kapitler, der gør det sjovt og nemt for nye læsere at opdage detaljer om sangerens liv.<br/>- Hendes varige arv - Børn vil finde ud af, hvordan Selena ændrede musikverdenen, og hvorfor hun fortsætter med at være en rollemodel for mange kvinder og farvede mennesker rundt om i verden.<br/>Hvordan vil Selenas store ånd og passion for musik inspirere barnet i dit liv?<br/>Om forfatteren<br/>GLORIA ARJONA underviser i spansk på California Institute of Technology og er forfatter til Posadas Unknown Calaveras og 'Lotería!. Hun er også en musiker, der synger og spiller guitar. Læs mere på GloriaArjona.com.<br/>"Endelig, en Selena bog for nye læsere, en, der er fortalt kortfattet og ærligt, og er yderst læsbar" - Joe Nick Patoski, forfatter til Selena: Como La Flor<br/>"Hvilken vidunderlig historie at inspirere piger til at følge deres drømme. En historie, som mange piger vil identificere sig med, især dem fra traditionelle og multikulturelle familier. Jeg kunne godt lide alle de små sidebar lektioner i hele bogen. Gloria er en meget talentfuld lærer." -Genevieve B. Southgate, direktør for samfundsprogrammer, Bowers Museum<br/>Selena Quintanillas ungdommelige talent og positive drive vækkes til live i professor Arjonas seneste bog, som er rettet mod unge læsere. En meget tiltalende læsning, der fremhæver Selenas fleksibilitet i at overvinde forhindringer for at opnå sine drømme og hendes banebrydende bidrag til musik og hendes samfund. Callisto Media-formatet med at opmuntre til kritisk, organiseret tænkning via spørgsmål, kort, tidslinjer og en ordliste gør dette til en fornøjelig læringsoplevelse." - Martin E. Delgado, community library manager<br/>"Dette er historien om Selena Quintanilla, og hvilken historie det er! I en tid, hvor unge læsere og unge kvinder har mere end nogensinde brug for rollemodeller, skildrer denne bog på glimrende vis den dybe menneskelighed, tapperhed og talent hos en dybt inspirerende latinsk kvinde, der ubarmhjertigt kæmpede for sin drøm. Maite Zubiaurre, professor ved UCLA |
| Here's another reason for men to avoid packing on extra pounds over the holidays: A new study has found that losing weight reduces the risk of an aggressive form of prostate cancer.<br/>After tracking the weight of nearly 70,000 men between 1982 and 1992, researchers from the American Cancer Society and the Duke University Prostate Center found that men who lost more than 11 pounds had a lower risk for aggressive prostate cancer than men whose weight remained the same over a decade.<br/>Previous studies have found that obese men have a higher risk of developing aggressive prostate cancer. This study appears to be the first to indicate that recent weight loss can decrease that risk.<br/>In the study reported this month in Cancer Epidemiology, Biomarkers & Prevention, researchers analyzed the height and weight of the men in 1982 and 1992 and every three years after that until 2003. At that time, more than 5,200 of the men — more than 7 percent — had prostate cancer.<br/>Among those cases, about one in eight had a form of cancer that was aggressive but had not spread to other areas of the body. The study's major finding focused on those aggressive cases, with researchers concluding that those who lost 11 or more pounds were 42 percent less likely to develop that form of prostate cancer than those whose weight remained the same.<br/>"Whether it's exactly 40 percent, we don't know, but they lower their risk when they lose 11-plus pounds. We feel confident, at least in this population, that was real," said lead researcher Dr. Carmen Rodriguez.<br/>More than seven times as many men whose weight remained the same developed aggressive prostate cancer compared to those who lost 11 or more pounds.<br/>"No significant associations" were found regarding the effect of weight gain or loss on the most severe forms of prostate cancer, those that spread throughout the body, the study said.<br/>The number studied was small, the researchers acknowledged, because fewer than 15,000 men lost weight over the time period, and only 1,000 of those developed some form of prostate cancer.<br/>The 69,991 participants were part of a bigger cancer society study of 1.2 million Americans that began in 1982.<br/>Rodriguez said men should avoid putting on extra weight as they get older.<br/>"The main message for men is to not get overweight. If they are overweight, that's another reason to try to lose weight, just to decrease the risk for prostate cancer," said Rodriguez, who works for the Atlanta-based cancer society.<br/>Other than skin cancer, prostate cancer is the most commonly diagnosed cancer for men, and about one in six will get it during his lifetime. It is the second leading cause of cancer death for U.S. men.<br/>The study is considered the first of its kind to examine the role of weight change in the development of prostate cancer, said Dr. Ronald Ennis, director of radiation oncology at St. Luke's-Roosevelt Hospital Center in New York, who was not involved in the study.<br/>"This is one of the best studies" examining the role of weight on prostate cancer, Ennis said. "It does seem to be true that if you are overweight, you are at risk of getting more aggressive forms of prostate cancer and if you lose weight, you can decrease the risk." | Her er en anden grund til, at mænd skal undgå at pakke på ekstra pund i løbet af ferien: En ny undersøgelse har fundet ud af, at vægttab reducerer risikoen for en aggressiv form for prostatakræft.<br/>Efter at have sporet vægten af næsten 70.000 mænd mellem 1982 og 1992 fandt forskere fra American Cancer Society og Duke University Prostate Center, at mænd, der tabte mere end 11 pund, havde en lavere risiko for aggressiv prostatakræft end mænd, hvis vægt forblev den samme over et årti.<br/>Tidligere undersøgelser har vist, at overvægtige mænd har en højere risiko for at udvikle aggressiv prostatakræft. Denne undersøgelse synes at være den første til at indikere, at nylige vægttab kan mindske denne risiko.<br/>I undersøgelsen, der blev rapporteret i denne måned i Cancer Epidemiology, Biomarkers & Prevention, analyserede forskerne mændenes højde og vægt i 1982 og 1992 og hvert tredje år derefter indtil 2003. På det tidspunkt havde mere end 5.200 af mændene - mere end 7 procent - prostatakræft.<br/>Blandt disse tilfælde havde omkring en ud af otte en form for kræft, der var aggressiv, men ikke havde spredt sig til andre områder af kroppen. Undersøgelsens store fund fokuserede på de aggressive tilfælde, hvor forskerne konkluderede, at de, der tabte 11 eller flere pund, var 42 procent mindre tilbøjelige til at udvikle den form for prostatakræft end dem, hvis vægt forblev den samme.<br/>"Om det er præcis 40 procent, ved vi ikke, men de sænker deres risiko, når de taber 11-plus pund. Vi føler os trygge, i hvert fald i denne befolkning, det var ægte," sagde ledende forsker Dr. Carmen Rodriguez.<br/>Mere end syv gange så mange mænd, hvis vægt forblev den samme, udviklede aggressiv prostatakræft sammenlignet med dem, der tabte 11 eller flere pund.<br/>"Ingen signifikante foreninger" blev fundet med hensyn til effekten af vægtøgning eller tab på de mest alvorlige former for prostatakræft, dem, der spredte sig i hele kroppen, sagde undersøgelsen.<br/>Antallet af undersøgte var lille, erkendte forskerne, fordi færre end 15.000 mænd tabte sig i løbet af perioden, og kun 1.000 af dem udviklede en form for prostatakræft.<br/>De 69.991 deltagere var en del af en større kræft samfund undersøgelse af 1,2 millioner amerikanere, der begyndte i 1982.<br/>Rodriguez sagde, at mænd bør undgå at lægge på ekstra vægt, når de bliver ældre.<br/>"Hovedbudskabet for mænd er ikke at blive overvægtige. Hvis de er overvægtige, er det en anden grund til at forsøge at tabe sig, bare for at mindske risikoen for prostatakræft," siger Rodriguez, der arbejder for Atlanta-baserede kræft samfund.<br/>Bortset fra hudkræft, prostatakræft er den mest almindeligt diagnosticeret kræft for mænd, og omkring en ud af seks vil få det i løbet af sin levetid. Det er den næststørste årsag til kræftdød for amerikanske mænd.<br/>Undersøgelsen betragtes som den første af sin art til at undersøge vægtændringens rolle i udviklingen af prostatakræft, siger Dr. Ronald Ennis, direktør for strålings onkologi på St. Luke's-Roosevelt Hospital Center i New York, som ikke var involveret i undersøgelsen.<br/>"Dette er en af de bedste undersøgelser", der undersøger vægtens rolle på prostatakræft, sagde Ennis. "Det ser ud til at være sandt, at hvis du er overvægtig, er du i risiko for at få mere aggressive former for prostatakræft, og hvis du taber dig, kan du reducere risikoen." |
| If you have studied the OSI model with its 7 Layers that describe communication on computer network systems, you should know that the Ethernet standard lies in Layer 1 (Physical) and Layer 2 (Data-Link) of the OSI model.<br/>In this article we will focus on the physical (Layer 1) part of Ethernet, which mainly focuses on the wired physical medium (cabling) that is used to transport Ethernet frames in a network.<br/>Ethernet cables connect devices to computer networks, the “heart” of which is usually an Ethernet switch which has several interface ports for “plugging-in” the cables.<br/>Most of these Ethernet cables feature the standard RJ45 connector for plugging-in to a switch. However, Ethernet communication can be implemented also using Fiber-optic cabling which uses different types of connectors.<br/>Moreover, there are different types of Ethernet cables with varying bandwidths, speeds and types of construction. In this article we will discuss the “copper-made” cables which are the most popular ones in computer networks.<br/>The cables have labels indicating the standard used for manufacturing, ranging from category (cat) 3 to 7.<br/>Ethernet cables consist of several (usually 8) smaller wires (inside the main cable) which are separated in Twisted-pairs. This setup helps in cancelling-out electromagnetic interference between wires, thus allowing signals to travel longer distances inside the wires.<br/>Without the right cable (and of course without the right type of switch), you may experience slower speeds in the network between devices.<br/>Let’s now describe each Category of Ethernet Cables with their characteristics:<br/>&#124;Max Length&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m&#124;&#124;100 m<br/>(55 m for 10Gbps)<br/>&#124;100 m&#124;&#124;100 m&#124;<br/>&#124;Max Speed&#124;&#124;10 Mbps&#124;&#124;100 Mbps&#124;&#124;1 Gbps&#124;&#124;10 Gbps&#124;&#124;10 Gbps&#124;&#124;>10 Gbps&#124;<br/>&#124;Frequency Bandwidth&#124;&#124;16 MHz&#124;&#124;100 MHz&#124;&#124;100 MHz&#124;&#124;250 MHz&#124;&#124;500 MHz&#124;&#124;600 MHz&#124;<br/>&#124;Shielded / Unshielded&#124;&#124;Unshielded&#124;&#124;Unshielded&#124;&#124;Unshielded&#124;&#124;Shielded or Unshielded&#124;&#124;Shielded&#124;&#124;Shielded&#124;<br/>1) Cat 3<br/>One of the oldest Ethernet cabling standards is category (cat) 3 (TIA/EIA-568-B). These cables allowed 10 Mbps transmission speeds with 16 MHz max bandwidth.<br/>Cat 3 ethernet cables feature unshielded twisted pair (UTP) cabling. With UTP cables, manufacturers twist insulated copper wires together inside a polyethylene jacket. Compared to shielded ethernet cables, UTP cables tend to include more crosstalk.<br/>Network connections commonly featured category 3 ethernet cables until the early 1990s, when category 5 cables replaced cat 3. While some older telephone systems may still use cat 3 cables, they have mostly become obsolete in the networking industry.<br/>2) Cat 5<br/>Cat 5 cables increased the bandwidth of Ethernet connections up to 100 MHz and offered transmission speeds up to 100 Mbps. With Cat 5 ethernet cables, users could access 100BASE-TX ethernet systems, referred to as fast ethernet.<br/>As with the category 3 cables, cat 5 cables still feature crosstalk and interference, due to the UTP design. These cables include four pairs of twisted wires (for a total of 8 wires).<br/>While cat 5 cables primarily provide connections for Ethernet applications, these cables also provide solutions for carrying other data signals, such as video and telephone. In fact, a single cat 5 cable can carry two standard phone lines and a 100BASE-TX connection.<br/>3) Cat 5e<br/>In 2001, the category 5e standard replaced category 5. The letter “e” in the name stands for enhanced.<br/>The cabling still uses unshielded twisted pairs. There are no physical differences between cat 5 and cat 5e cables. However, stricter standards in manufacturing Cat5e cables help minimize crosstalk and allow higher data transmissions than Cat5.<br/>Cat 5e cables also utilize two sets of twisted pairs of wires, resulting in faster speeds. While cat 5e ethernet cable still features 100 MHz bandwidth, these cables allow speeds up to 1000 Mbps (1 Gbps).<br/>While several additional standards have come after cat 5e, these cables remain in production. In fact, due to the lower cost of production and support for gigabit ethernet, cat 5e cables are the most used for network applications throughout the world.<br/>4) Cat 6<br/>Cat 6 ethernet cables helped address issues related to interference and crosstalk. These cables use thinner wires and superior insulation, resulting in a better signal-to-noise ratio.<br/>With these features, cat 6 cables provide a more effective option for adding cable in areas with more electromagnetic interference, such as a crowded server room.<br/>Thanks to the superior design, cat 6 provides improved bandwidth. These cables have a max bandwidth of 250 MHz and max transmission speeds up to 1000 Mbps (1 Gbps) at the 100m range. However, 10Gbps can be achieved in Cat6 in smaller distances (up to 55m).<br/>Some cat 6 cables include shielding while others remain unshielded. With shielding, these cables can provide transmission speeds up to 10 Gbps, but only for short distances as we said above.<br/>5) Cat 6a<br/>Category 6a ethernet cables improve the design of the cat 6 cables. The letter “a” stands for augmented. Unlike cat 6 cables, all cat 6a cables feature shielded cabling for reduced interference.<br/>With the enhancements to the design specifications, cat 6a cables maintain higher transmission speeds and 500 MHz max bandwidth, allowing speeds up to 10000 Mbps (10 Gbps) across longer cables.<br/>While these cables provide faster speeds, the design makes them less flexible. To eliminate crosstalk, these cables feature thicker sheathing, making the cables stiffer and more difficult to work.<br/>6) Cat 7<br/>One of the latest developments is Cat 7 Ethernet cables. Also called class F channel cables, these cables include stricter standards compared to previous categories. The individual wire pairs now include their own shielding, in addition to the outer shielding<br/>With these cables, you get 600 MHz max bandwidth and 10000 Mbps (10 Gbps) transmission speeds. However, by almost completely getting rid of crosstalk, cat 7 ethernet cables offer even greater reliability for 10 Gbps Ethernet connections.<br/>With connections less than 15 meters, cat 7 can support transmission speeds up to 100 Gbps. While the industry has released several new standards since cat 7, these cables are currently the top of the line option for demanding networking applications.<br/>- What is OSPF NSSA (Not So Stubby Area) and How is it Configured?<br/>- Comparison of BOOTP vs DHCP Protocols in Computer Networks<br/>- Pros and Cons of SD-WAN in Networks – Description and Discussion<br/>- Comparison of GNS3 vs EVE-NG vs Packet Tracer for Networks Simulation<br/>- Subnetting vs Supernetting – What’s the Difference? (Explanation Guide) | Hvis du har studeret OSI-modellen med dens 7 lag, der beskriver kommunikation på computernetværkssystemer, skal du vide, at Ethernet-standarden ligger i lag 1 (fysisk) og lag 2 (Data-Link) af OSI-modellen.<br/>I denne artikel vil vi fokusere på den fysiske (Layer 1) del af Ethernet, som hovedsageligt fokuserer på det kablede fysiske medium (kabling), der bruges til at transportere Ethernet-rammer i et netværk.<br/>Ethernet-kabler forbinder enheder til computernetværk, hvis "hjerte" normalt er en Ethernet-switch, som har flere grænsefladeporte til "tilslutning" kablerne.<br/>De fleste af disse Ethernet-kabler har standard RJ45-stik til tilslutning til en switch. Ethernet-kommunikation kan dog også implementeres ved hjælp af fiberoptisk kabelføring, som bruger forskellige typer stik.<br/>Desuden er der forskellige typer af Ethernet-kabler med varierende båndbredder, hastigheder og typer af konstruktion. I denne artikel vil vi diskutere de "kobber-made" kabler, som er de mest populære i computernetværk.<br/>Kablerne har etiketter, der angiver den standard, der anvendes til fremstilling, lige fra kategori (kat) 3 til 7.<br/>Ethernet-kabler består af flere (normalt 8) mindre ledninger (inde i hovedkablet), som er adskilt i Twisted-par. Denne opsætning hjælper med at annullere elektromagnetisk interferens mellem ledninger, hvilket gør det muligt for signaler at rejse længere afstande inde i ledningerne.<br/>Uden det rigtige kabel (og selvfølgelig uden den rigtige type switch), kan du opleve langsommere hastigheder i netværket mellem enheder.<br/>Lad os nu beskrive hver kategori af Ethernet-kabler med deres egenskaber:<br/>Max Længde 100 m 100 m 100 m 100 m<br/>(55 m for 10 Gbps)<br/>Ø100 mØ100 mØ<br/>Max Hastighed 10 Mbps 100 Mbps 1 Gbps 10 Gbps 10 Gbps 10 Gbps 10 Gbps<br/>Frekvensbåndbredde 16 MHz 100 MHz 100 MHz 250 MHz 500 MHz 600 MHz<br/>"Skjult / uskærmet" "Unshielded" "Unshielded" "Unshielded" "Shielded" "Unshielded" "Unshielded" "Unshielded" "Unshielded" "Unshielded" "Unshielded" "Shielded" "Unshielded" "Unshielded"<br/>1) Kat 3<br/>En af de ældste Ethernet-kablingsstandarder er kategori (cat) 3 (TIA / EIA-568-B). Disse kabler tillod 10 Mbps transmissionshastigheder med 16 MHz max båndbredde.<br/>Cat 3 ethernet kabler har uafskærmet snoet par (UTP) kabelføring. Med UTP kabler, producenter twist isolerede kobber ledninger sammen inde i en polyethylen jakke. Sammenlignet med afskærmede ethernet kabler, UTP kabler tendens til at omfatte mere crosstalk.<br/>Netværksforbindelser almindeligt fremhævede kategori 3 ethernet kabler indtil begyndelsen af 1990'erne, da kategori 5 kabler erstattet kat 3. Mens nogle ældre telefonsystemer kan stadig bruge kat 3 kabler, de er for det meste blevet forældet i netværksbranchen.<br/>2) Kat 5<br/>Cat 5-kabler øgede båndbredden af Ethernet-forbindelser op til 100 MHz og tilbød transmissionshastigheder på op til 100 Mbps. Med Cat 5-ethernet-kabler kunne brugerne få adgang til 100BASE-TX-ethernet-systemer, kaldet hurtig ethernet.<br/>Som med kategori 3-kabler har cat 5-kabler stadig crosstalk og interferens på grund af UTP-designet. Disse kabler omfatter fire par snoede ledninger (i alt 8 ledninger).<br/>Mens cat 5-kabler primært giver forbindelser til Ethernet-applikationer, giver disse kabler også løsninger til at bære andre datasignaler, såsom video og telefon. Faktisk kan et enkelt cat 5-kabel bære to standard telefonlinjer og en 100BASE-TX-forbindelse.<br/>3) Kat 5e<br/>I 2001 erstattede kategori 5e-standarden kategori 5. Bogstavet "e" i navnet står for forbedret.<br/>Kablerne bruger stadig uafskærmede snoede par. Der er ingen fysiske forskelle mellem cat 5 og cat 5e kabler. Men strengere standarder i fremstillingen af Cat5e kabler hjælper med at minimere krydstale og tillade højere datatransmissioner end Cat5.<br/>Cat 5e kabler bruger også to sæt snoede par ledninger, hvilket resulterer i hurtigere hastigheder. Mens Cat 5e ethernet kabel stadig har 100 MHz båndbredde, tillader disse kabler hastigheder op til 1000 Mbps (1 Gbps).<br/>Mens flere yderligere standarder er kommet efter cat 5e, forbliver disse kabler i produktion. Faktisk på grund af de lavere produktionsomkostninger og støtte til gigabit ethernet, er cat 5e kabler de mest anvendte til netværksapplikationer over hele verden.<br/>4) Kat 6<br/>Cat 6 ethernet-kabler hjalp med at løse problemer relateret til interferens og krydstale. Disse kabler bruger tyndere ledninger og overlegen isolering, hvilket resulterer i et bedre signal-til-støj-forhold.<br/>Med disse funktioner giver cat 6-kabler en mere effektiv mulighed for at tilføje kabel i områder med mere elektromagnetisk interferens, såsom et overfyldt serverrum.<br/>Takket være det overlegne design giver cat 6 forbedret båndbredde. Disse kabler har en maksimal båndbredde på 250 MHz og maksimale transmissionshastigheder op til 1000 Mbps (1 Gbps) ved 100m rækkevidde. Imidlertid kan 10Gbps opnås i Cat6 i mindre afstande (op til 55m).<br/>Nogle cat 6 kabler inkluderer afskærmning, mens andre forbliver uafskærmede. Med afskærmning kan disse kabler give transmissionshastigheder op til 10 Gbps, men kun for korte afstande som vi sagde ovenfor.<br/>5) Kat 6a<br/>Kategori 6a ethernet kabler forbedre udformningen af cat 6 kabler. Bogstavet "a" står for augmented. I modsætning til cat 6 kabler, alle cat 6a kabler har afskærmet kabler for reduceret interferens.<br/>Med forbedringerne af designspecifikationerne opretholder cat 6a-kabler højere transmissionshastigheder og 500 MHz maksimal båndbredde, hvilket giver hastigheder på op til 10000 Mbps (10 Gbps) på tværs af længere kabler.<br/>Mens disse kabler giver hurtigere hastigheder, gør designet dem mindre fleksible. For at eliminere krydstale har disse kabler tykkere beklædning, hvilket gør kablerne stivere og vanskeligere at arbejde.<br/>6) Kat 7<br/>En af de seneste udviklinger er Cat 7 Ethernet-kabler. Også kaldet klasse F-kanalkabler, disse kabler omfatter strengere standarder i forhold til tidligere kategorier. De enkelte trådpar har nu deres egen afskærmning, ud over den ydre afskærmning<br/>Med disse kabler får du 600 MHz maksimal båndbredde og 10000 Mbps (10 Gbps) transmissionshastigheder. Men ved næsten helt at slippe af med krydstale giver cat 7 ethernet-kabler endnu større pålidelighed til 10 Gbps Ethernet-forbindelser.<br/>Med forbindelser mindre end 15 meter kan cat 7 understøtte transmissionshastigheder på op til 100 Gbps. Mens branchen har udgivet flere nye standarder siden cat 7, er disse kabler i øjeblikket den øverste mulighed for krævende netværksapplikationer.<br/>- Hvad er OSPF NSSA (Not So Stubby Area), og hvordan er det konfigureret?<br/>- Sammenligning af BOOTP vs DHCP-protokoller i computernetværk<br/>- Fordele og ulemper ved SD-WAN i netværk - Beskrivelse og diskussion<br/>- Sammenligning af GNS3 vs EVE-NG vs pakke Tracer for netværk Simulering<br/>- Subnetting vs Supernetting - Hvad er forskellen? (Forklaring Guide) |
| Views: 4 Author: Site Editor Publish Time: 2022-06-09 Origin: Site<br/>So why should workers wear a portable gas detector and what does it do?<br/>In many industrial environments, workers need to be highly aware of exposure to toxic or combustible gases and vapours or a lack of oxygen. That’s why portable gas detectors and analysers are essential – so they can detect, measure, monitor and react to any gases in the immediate area around them. KELISAIKE SAFETY offers both single- and multi-gas mobile gas monitors that reliably detect a wide range of gases. All of our portable gas detectors and software are designed to make compliance and asset management as intuitive as possible, so you can implement a complete product solution that helps ensure safety at all times.<br/>Portable gas detectors are classed as a type of Personal Protective Equipment (PPE)<br/>They monitor gases in the workers breathing zone by displaying real-time gas levels of a variety of toxic, combustible, flammable gases<br/>They alert the worker of any possible threats which include combustion and oxygen displacement<br/>While portable gas detectors are available with various sensor configurations and features, they are all built with the same purpose - to protect human life! | Visninger: 4 Forfatter: Site Editor Udgiv tid: 2022-06-09 Oprindelse: Site<br/>Så hvorfor skal arbejdstagere bære en bærbar gasdetektor, og hvad gør den?<br/>I mange industrielle miljøer skal arbejdstagerne være meget opmærksomme på eksponering for giftige eller brændbare gasser og dampe eller mangel på ilt. Derfor er bærbare gasdetektorer og -analysatorer vigtige – så de kan registrere, måle, overvåge og reagere på eventuelle gasser i det umiddelbare område omkring dem. KELISAIKE SAFETY tilbyder både enkelt- og multi-gas mobile gasmonitorer, der pålideligt registrerer en bred vifte af gasser. Alle vores bærbare gasdetektorer og software er designet til at gøre compliance og asset management så intuitivt som muligt, så du kan implementere en komplet produktløsning, der hjælper med at sikre sikkerheden til enhver tid.<br/>Bærbare gasdetektorer er klassificeret som en type personligt beskyttelsesudstyr (PPE)<br/>De overvåger gasser i arbejdernes åndedrætszone ved at vise realtidsgasniveauer af en række giftige, brændbare, brandfarlige gasser<br/>De advarer arbejdstageren om eventuelle trusler, som omfatter forbrænding og iltforskydning.<br/>Mens bærbare gasdetektorer er tilgængelige med forskellige sensorkonfigurationer og funktioner, er de alle bygget med det samme formål - at beskytte menneskeliv! |
| Salvador Dalí Biography<br/>The prints of Salvador Dalí are rooted in a rich past. In actuality, Dalí’s prints have a history that dates back to his early years of art school. The young Dalí was taught the fine art of engraving and etching by his mentor. Dalí gained a respect for the technical details of printmaking, a respect he would maintain throughout the rest of his life. The connection between Dalí and graphic prints is in fact intricate and protracted. In his lifetime, Dalí produced just around 1,700 graphic prints. A large number of them are hand-signed, limited-edition editions. Some are regarded as some of the best prints created in the 20th century.<br/>Dalí had the ability to experiment with a wide range of subjects through his print work, including etchings, engravings, mixed media, lithographs, and photo-litho. Dalí would produce beautiful suites or single prints. These suites frequently feature a book motif, with the prints acting as the artwork. Among the literary works Dal illustrated were Alice in Wonderland, Hamlet, and The Old Man and the Sea. Other times, similar suites would focus on different subjects, such as flowers (FlorDal), science fiction (Conquest of the Cosmos), or fine print production (Currier and Ives). Dal also produced single prints that showcased his flawless printmaking skills. Prints by Dalí that are among his best include Flower Man, Symphony Bicyclette, Dream Passage, and The Studio of Dalí.<br/>Although it might be speculated that Dalí produced many more prints than the “approved” ones we attribute to him today, Dal’s first prints appeared in the 1920s. His superb craftsmanship is seen in works like Head of a Young Girl and Immaculate Conception. The graphic piece Les Chants de Maldoror is among Dal’s best-known creations. The stories that separate the suites are a perfect match for the pre-surrealistic aspects of the book. A complete set of this suite is now in high demand. The majority of these early works were etchings and engravings; as Dalí’s printing skills improved, he expanded the range of his mediums and themes.<br/>The 1960s are often referred to as the “Golden Age” of Dalí’s prints. In fact, Dalí produced some of his most creative pieces during this decade. For an edition of The Divine Comedy, he finished one hundred wood block prints. This suite is regarded as a work of genius, and Dalí produced magnificent graphics to complement Virgil’s poetry. A fruitful collaboration with the American publishers Phyllis and Sidney Lucas also began throughout this decade. The Lucas’ and Dalí’s combined efforts would result in some of the most enduring Dal paintings ever. Prints like The Drawers of Memory, Fantastic Voyage, The Lucky Number of Salvador Daíi, The Studio of Dalí, and Departure of The Fishermen are examples of the prints that resulted from their collaboration. For Dalí, these were undoubtedly successful years. Over the course of this decade, Dal finished hundreds of photographs. His output was extraordinarily high. However, some of his best graphic creations remained to be seen.<br/>Dal returned to his melting clocks painting, his most well-known creation, in the 1970s. Some people believe that Dalí’s 1975 lithograph Changes In Great Masterpieces is his best creation overall. The collection consists of six images, five of which are Dalí’s interpretations of paintings by Rembrandt, Vermeer, Raphael, and Velasquez. The Persistence of Memory, Dalí’s own masterwork, is reinterpreted in the sixth picture.<br/>Together with his American publishers, Phyllis and Sidney Lucas, Mozart created this suite. Dalí updates his original piece by including a fourth melting clock. The broken clock creeps through the midst of the scene. The fourth clock, according to some, represents the fourth dimension, or time. Some people think that when Dal revised The Persistence of Memory, some 40 years after the original, he was considering his own transience and legacy and paying homage to the Dal of old.<br/>Changes in Great Masterpieces was only one of Dalí’s outstanding creations during the 1970s. In the suites Moses and Monotheism, Imagination and Objects of the Future, and Alchemy of The Philosophers, he produced some magnificent artwork. His two four-piece “puzzles,” The Rejuvenation of Time and The Puzzle of Life, are his largest lithographs. Ten Recipes of Immortality, a collection of three dimensional “pop-up” prints, is an example of how he expanded the scope of his graphic works into the third dimension. Although the 1960s may have been Dalí’s most productive decade, the 1970s appear to have been his most inventive and creative years as he explored new concepts and pushed himself even farther.<br/>In 1982, Dalí’s final prints were released. Dalí’s health had already started to deteriorate by this point, and his output had significantly decreased. However, Dalí was still able to create some excellent graphic prints despite his advanced age. Portrait of Autumn, which is bathed in gorgeous yellows, greens, and reds, is a glorification of the god Dionysus. Collectors of Dalí’s work see Chevalier Surealiste as a must-have piece, and it pays homage to one of Dalí’s heroes, Velasquez. Crucifixion is a superb example of Dalí’s artistry and a testament to his interest in Roman Catholicism.<br/>Dalí spent his entire life working as a printmaker. When evaluating his legacy, one must take into account the graphic arts creations he developed. Some of Dalí’s most artistic icons and imagery, as well as some of his best uses of his imagination, can be seen in these prints. | Salvador Dalí Biografi<br/>Aftryk af Salvador Dalí er rodfæstet i en rig fortid. I virkeligheden har Dalís aftryk en historie, der går tilbage til hans tidlige år på kunstskolen. Den unge Dalí blev undervist i kunsten at gravere og ætse af sin mentor. Dalí fik respekt for de tekniske detaljer i grafik, en respekt han ville opretholde resten af sit liv. Forbindelsen mellem Dalí og grafiske prints er faktisk indviklet og langvarig. I sin levetid producerede Dalí lige omkring 1700 grafiske tryk. Et stort antal af dem er håndsignerede udgaver i begrænset oplag. Nogle betragtes som nogle af de bedste tryk, der blev skabt i det 20. århundrede.<br/>Dalí havde evnen til at eksperimentere med en bred vifte af emner gennem sit print arbejde, herunder raderinger, graveringer, blandede medier, litografier, og foto-litho. Dalí ville producere smukke suiter eller enkelttryk. Blandt de litterære værker Dal illustrerede var Alice i Eventyrland, Hamlet og Den gamle mand og havet. Andre gange ville lignende suiter fokusere på forskellige emner, såsom blomster (FlorDal), science fiction (Conquest of the Cosmos) eller fine print produktion (Currier og Ives). Dal producerede også enkelttryk, der viste hans fejlfri printmaking færdigheder. Aftryk af Dalí, der er blandt hans bedste omfatter Flower Man, Symphony Bicyclette, Dream Passage, og The Studio of Dalí.<br/>Selv om det kan spekuleres, at Dalí produceret mange flere prints end de "godkendte" dem, vi tilskriver ham i dag, Dal første prints dukkede op i 1920'erne. Hans fremragende håndværk ses i værker som leder af en ung pige og ubesmittet undfangelse. Det grafiske stykke Les Chants de Maldoror er blandt Dals mest kendte kreationer. De historier, der adskiller suiterne, er et perfekt match til de præ-surrealistiske aspekter af bogen. Et komplet sæt af denne suite er nu i høj efterspørgsel. Størstedelen af disse tidlige værker var raderinger og graveringer; som Dalí's trykning færdigheder forbedret, han udvidet vifte af hans medier og temaer.<br/>1960'erne omtales ofte som "Golden Age" af Dalí's prints. Faktisk producerede Dalí nogle af hans mest kreative stykker i løbet af dette årti. Til en udgave af Den guddommelige komedie færdiggjorde han hundrede træblokprints. Denne suite betragtes som et genialt værk, og Dalí producerede storslået grafik til at supplere Virgils poesi. Et frugtbart samarbejde med de amerikanske forlag Phyllis og Sidney Lucas begyndte også i hele dette årti. Lucas' og Dalí's kombinerede indsats ville resultere i nogle af de mest varige Dal-malerier nogensinde. Udskrifter som The Drawers of Memory, Fantastic Voyage, The Lucky Number of Salvador Daíi, The Studio of Dalí og Departure of The Fishermen er eksempler på de udskrifter, der resulterede fra deres samarbejde. For Dalí var disse utvivlsomt succesfulde år. I løbet af dette årti afsluttede Dal hundredvis af fotografier. Hans produktion var ekstraordinært høj. Men nogle af hans bedste grafiske kreationer var at se.<br/>Dal vendte tilbage til sit smeltende urmaleri, hans mest kendte skabelse, i 1970'erne. Nogle mennesker mener, at Dalí's 1975 litografi Changes In Great Masterpieces er hans bedste skabelse samlet. Samlingen består af seks billeder, hvoraf fem er Dalís fortolkninger af malerier af Rembrandt, Vermeer, Raphael og Velasquez. Persistensen af hukommelsen, Dalis eget mesterværk, er genfortolket i det sjette billede.<br/>Sammen med sine amerikanske forlag, Phyllis og Sidney Lucas, skabte Mozart denne suite. Dalí opdaterer sit originale værk ved at inkludere et fjerde smeltende ur. Det ødelagte ur kryber gennem midten af scenen. Det fjerde ur, ifølge nogle, repræsenterer den fjerde dimension, eller tid. Nogle mennesker tror, at da Dal reviderede The Persistence of Memory, omkring 40 år efter originalen, overvejede han sin egen forgængelighed og arv og hyldede Dal af gamle.<br/>Forandringer i Great Masterpieces var kun en af Dalís enestående kreationer i 1970'erne. I suiterne Moses og Monoteisme, Fantasi og Fremtidens Objekter og Alkymi af Filosofferne producerede han nogle storslåede kunstværker. Hans to firedelte "puslespil", The Rejuvenation of Time og The Puzzle of Life, er hans største litografier. Ten Recipes of Immortality, en samling af tredimensionelle "pop-up" prints, er et eksempel på, hvordan han udvidede omfanget af sine grafiske værker til den tredje dimension. Selv om 1960'erne kan have været Dalí's mest produktive årti, 1970'erne synes at have været hans mest opfindsomme og kreative år, da han udforskede nye koncepter og skubbede sig selv endnu længere.<br/>I 1982 blev Dalí's endelige udskrifter frigivet. Dalí's helbred var allerede begyndt at forværres på dette tidspunkt, og hans output var faldet betydeligt. Dalí var dog stadig i stand til at skabe nogle fremragende grafiske udskrifter på trods af hans høje alder. Portræt af efteråret, som er badet i smukke gule, grønne og røde, er en forherligelse af guden Dionysus. Samlere af Dalís arbejde ser Chevalier Surealiste som et must-have stykke, og det hylder en af Dalis helte, Velasquez. Korsfæstelse er et glimrende eksempel på Dalís kunstneriske virke og et vidnesbyrd om hans interesse for romersk katolicisme.<br/>Dalí brugte hele sit liv på at arbejde som grafiker. Når man evaluerer hans arv, skal man tage højde for de grafiske kreationer, han udviklede. Nogle af Dalís mest kunstneriske ikoner og billedsprog, samt nogle af hans bedste anvendelser af sin fantasi, kan ses i disse tryk. |
| English Language A Level<br/>&#124;Mode of study&#124;&#124;Academic A Level&#124;<br/>&#124;Campus&#124;&#124;English Bridge Campus&#124;<br/>&#124;Start date&#124;&#124;4 September 2023&#124;<br/>&#124;Course code&#124;&#124;ENG-AL (2325)&#124;<br/>A minimum of five GCSEs at grade 4 or above, including English Language and English Literature.<br/>Please note: You can study both English A level Literature and A level English Language because the courses are sufficiently distinct that there is no overlap or repetition of content. However, you cannot study A Level English Combined and A Level English Literature, or A Level English Combined and A Level English Language.<br/>What does the course involve?<br/>English is an exciting subject and we hope you’ll enjoy the lively debate and discussion. Whichever English course you choose, you’ll gain a great deal of academic prowess and the development of transferable skills.<br/>You will be taught to think analytically, synthesise information, and develop communication skills that are a prerequisite for a wide range of career paths.<br/>The important skill of learning to write coherently and critically will aid you in your other subjects and is invaluable in higher education.<br/>Language is one of the key features that define us as human beings and, on this course, you will explore how it works: how we learn language from infancy, how we use it as a social tool, and how it has evolved over time. You will learn about the origins of English, the various forms it has taken over the centuries, how it has spread across the globe and what it might look like in the future.<br/>You will also study the research of theorists in areas of language such as speech and gender, accents and dialects, and the language of technology. You will learn about grammar in order to explore the ways writers use language to communicate meaning in texts ranging from blogs to 17th-century journalism.<br/>The NEA (coursework) unit will allow you to write creatively and to undertake an investigation into an aspect of the course you have enjoyed.<br/>How is the course assessed?<br/>80% Exam and 20% Coursework. Two coursework tasks and two externally-assessed exams.<br/>This A Level will equip you with the necessary skills to go into practical professions such as journalism and creative writing as well as academic degrees such as law and media studies. It forms a good companion to A Levels in Psychology and Sociology because there is a degree of crossover with the social sciences. If you are thinking of studying English at university, it is perfectly acceptable to take both English Language and English Literature. English can be combined with a range of other subjects at university.<br/>English provides an excellent foundation for various Higher Education courses including law, medicine, English, linguistics and education. It can be combined with a range of other subjects at university. English offers increasing employability in a range of career areas, especially those that require developed communication skills. Students have gone on to careers in law, health and medicine, commerce and industry, marketing, politics and international relations, general management, as well as leading to more predictable areas like journalism, publishing, the media, education, theatre and public relations.<br/>The student magazine produced by students is part of the enrichment opportunities led by the English Department. Trips include theatre trips to London, Manchester and Stratford-upon-Avon and international trips include a visit to battlefields in France, university taster days, residentials and creative writing workshops. These are all optional but highly recommended. Aspiring Oxford and Cambridge applicants will benefit from our extensive range of activities to support you in making a competitive application including: small group subject tuition, Oxford and Cambridge conferences, visits and contacts with our link staff, access to summer schools, application support and essay competitions, supra-curricular activities and access to free university-level Massive Open Online Courses (MOOC).<br/>What do I do next?<br/>You can apply online via the APPLY NOW button and then add an additional two or three subjects to make up your academic programme. You can also apply for a second, alternative vocational programme of study via a separate application. If after reading this factsheet, you are still undecided about the course most suitable for you, please drop in to one of our Open Evenings, ring Admissions on 01743 260401 or email email@example.com<br/>A Level English Language (Law and Drama & Theatre)<br/>Previous school: Mary Webb School<br/>I came here because it was local to me and I enjoyed the pre-enrolment days which were well organised. English Language is a good A Level to have and it is super interesting to see how language has evolved and changed through time. The teachers are a great help and the resources are brilliant; there are plenty of text books.<br/>Are you an employer?<br/>See how an apprentice can help your business. | Engelsk Sprog A Niveau<br/>Studieretning: Akademisk A-niveau<br/>www.campus.dk<br/>Startdato: 4. september 2023<br/>[Kurskode] [ENG-AL] (2325)<br/>Mindst fem GCSEs i klasse 4 eller derover, herunder engelsk sprog og engelsk litteratur.<br/>Bemærk: Du kan studere både engelsk A niveau litteratur og et niveau engelsk sprog, fordi kurserne er tilstrækkeligt forskellige, at der ikke er overlapning eller gentagelse af indhold. Du kan dog ikke studere et niveau engelsk kombineret og et niveau engelsk litteratur eller et niveau engelsk kombineret og et niveau engelsk sprog.<br/>Hvad indebærer kurset?<br/>Engelsk er et spændende emne, og vi håber, at du vil nyde den livlige debat og diskussion. Uanset hvilket engelsk kursus du vælger, får du en masse akademisk dygtighed og udvikling af overførbare færdigheder.<br/>Du vil blive undervist i at tænke analytisk, syntetisere information og udvikle kommunikationsevner, der er en forudsætning for en bred vifte af karriereveje.<br/>Den vigtige evne til at lære at skrive sammenhængende og kritisk vil hjælpe dig i dine andre fag og er uvurderlig i videregående uddannelse.<br/>Sprog er en af de vigtigste funktioner, der definerer os som mennesker, og på dette kursus vil du undersøge, hvordan det virker: hvordan vi lærer sprog fra barndommen, hvordan vi bruger det som et socialt værktøj, og hvordan det har udviklet sig over tid. Du vil lære om oprindelsen af engelsk, de forskellige former, det har taget gennem århundrederne, hvordan det har spredt sig over hele kloden, og hvordan det kan se ud i fremtiden.<br/>Du vil også studere teoretikeres forskning inden for sprogområder som tale og køn, accenter og dialekter og teknologiens sprog. Du vil lære om grammatik for at udforske de måder, forfattere bruger sprog til at kommunikere mening i tekster lige fra blogs til det 17. århundrede journalistik.<br/>NEA (kursus) -enheden giver dig mulighed for at skrive kreativt og foretage en undersøgelse af et aspekt af det kursus, du har nydt.<br/>Hvordan vurderes kurset?<br/>80% eksamen og 20% kursusarbejde. To kursusopgaver og to eksternt vurderede eksamener.<br/>Dette A-niveau vil udstyre dig med de nødvendige færdigheder til at gå ind i praktiske erhverv som journalistik og kreativ skrivning samt akademiske grader som jura og mediestudier. Det danner en god følgesvend til et niveau i psykologi og sociologi, fordi der er en grad af crossover med samfundsvidenskab. Hvis du tænker på at studere engelsk på universitetet, er det helt acceptabelt at tage både engelsk sprog og engelsk litteratur. Engelsk kan kombineres med en række andre fag på universitetet.<br/>Engelsk giver et fremragende fundament for forskellige videregående uddannelser, herunder jura, medicin, engelsk, lingvistik og uddannelse. Det kan kombineres med en række andre fag på universitetet. Engelsk tilbyder stigende beskæftigelsesegnethed i en række karriereområder, især dem, der kræver udviklede kommunikationsevner. Studerende har gået videre til en karriere inden for jura, sundhed og medicin, handel og industri, marketing, politik og internationale relationer, generel ledelse, samt fører til mere forudsigelige områder som journalistik, forlagsvirksomhed, medier, uddannelse, teater og PR.<br/>Den studerende magasin produceret af studerende er en del af berigelse muligheder ledet af den engelske afdeling. Ture omfatter teater ture til London, Manchester og Stratford-upon-Avon og internationale ture omfatter et besøg på slagmarker i Frankrig, universitet smager dage, boliger og kreativ skrivning workshops. Disse er alle valgfri, men stærkt anbefales. Aspirerende Oxford og Cambridge ansøgere vil drage fordel af vores omfattende udvalg af aktiviteter for at støtte dig i at lave en konkurrencedygtig ansøgning, herunder: lille gruppe emne undervisning, Oxford og Cambridge konferencer, besøg og kontakter med vores link personale, adgang til sommerskoler, ansøgning støtte og essay konkurrencer, supra-curricular aktiviteter og adgang til gratis universitetsniveau Massive Open Online Courses (MOOC).<br/>Hvad gør jeg nu?<br/>Du kan søge online via ANSØG NU-knappen og derefter tilføje yderligere to eller tre fag til dit akademiske program. Du kan også søge om et andet alternativt erhvervsfagligt studieprogram via en separat ansøgning. Hvis du efter at have læst dette faktablad stadig er usikker på det kursus, der passer bedst til dig, kan du komme ind på en af vores åbne aftener, ring Admissions på 01743 260401 eller e-mail email@example.com<br/>Et niveau engelsk sprog (lov og drama og teater)<br/>Tidligere skole: Mary Webb School<br/>Jeg kom her, fordi det var lokalt for mig, og jeg nød de førtilmeldingsdage, der var godt organiseret. Engelsk sprog er et godt A-niveau at have, og det er super interessant at se, hvordan sproget har udviklet sig og ændret sig gennem tiden. Lærerne er en stor hjælp, og ressourcerne er strålende; der er masser af lærebøger.<br/>Er du arbejdsgiver?<br/>Se, hvordan en lærling kan hjælpe din virksomhed. |
| In a subproject carried out together with the City of Stockholm within the HazardSupport research project, SMHI has investigated how town planning affects a city’s climate. Scenarios have been produced for Stockholm’s growth up until 2030 and 2050, using summer 2014 as a reference point. These scenarios do not take ongoing climate change into account. Instead, they simply show how the densification and growth of Stockholm can be expected to affect the air temperature.<br/>The main conclusion from the scenarios is that the impact of densification on air temperature is relatively local. No significant effect on the average temperature during the summer is seen at a distance of more than about 2 km, despite extensive densification across large areas. This can be seen in the most central parts of Stockholm, for example, which are already built-up and where no significant reduction in green spaces can therefore be expected. No significant change in air temperature is seen in these areas.<br/>One reason why the densification and expansion of Stockholm has not had any significant impact on air temperature is the relatively rapid air exchange with nearby expanses of water and countryside. Within those areas that are densifying, average summer temperature increases of up to around 1.5°C are being seen. As expected, the biggest temperature increases are observed when natural environments or green areas are built on.<br/>Measures in the local area<br/>One consequence of the locally limited effect of changes in the urban environment is that measures should primarily be focused on direct effects within the local area. Examples of such measures include shady street trees and proximity to green spaces. For the same reason, measures such as green roofs that only indirectly affect the air temperature in the street environment can be expected to have a less significant impact.<br/>A comfort index can be used to summarise the effect of various climate parameters. One example of such an index is the Universal Thermal Climate Index (UTCI). This involves a higher level of ambition in relation to how climate planning is often carried out in today’s planning processes. | I et delprojekt, der er gennemført sammen med Stockholms Kommune inden for forskningsprojektet HazardSupport, har SMHI undersøgt, hvordan byplanlægning påvirker en bys klima. Scenarier er blevet udarbejdet for Stockholms vækst frem til 2030 og 2050, ved hjælp af sommeren 2014 som referencepunkt. Disse scenarier tager ikke hensyn til igangværende klimaændringer. I stedet viser de blot, hvordan fortætningen og væksten i Stockholm kan forventes at påvirke lufttemperaturen.<br/>Hovedkonklusionen fra scenarierne er, at fortætningens indvirkning på lufttemperaturen er relativt lokal. Ingen signifikant effekt på gennemsnitstemperaturen i løbet af sommeren ses i en afstand på mere end ca. 2 km, på trods af omfattende fortætning på tværs af store områder. Det kan f.eks. ses i de mest centrale dele af Stockholm, som allerede er bebyggede, og hvor der derfor ikke kan forventes nogen væsentlig reduktion i grønne områder.<br/>En af grundene til, at fortætningen og udvidelsen af Stockholm ikke har haft nogen væsentlig indvirkning på lufttemperaturen, er den relativt hurtige luftudveksling med nærliggende vandområder og landskaber. Inden for de områder, der er tættende, ses gennemsnitlige sommertemperaturstigninger på op til omkring 1.5 ° C. Som forventet observeres de største temperaturstigninger, når naturmiljøer eller grønne områder bygges på.<br/>Foranstaltninger i lokalområdet<br/>En konsekvens af den lokalt begrænsede effekt af ændringer i bymiljøet er, at foranstaltningerne primært bør fokusere på direkte effekter inden for lokalområdet. Eksempler på sådanne foranstaltninger omfatter skyggefulde gadetræer og nærhed til grønne områder. Af samme grund kan foranstaltninger som grønne tage, der kun indirekte påvirker lufttemperaturen i gademiljøet, forventes at have en mindre betydelig indvirkning.<br/>Et komfortindeks kan bruges til at opsummere effekten af forskellige klimaparametre. Et eksempel på et sådant indeks er Universal Thermal Climate Index (UTCI). Det indebærer et højere ambitionsniveau i forhold til, hvordan klimaplanlægningen ofte foregår i nutidens planlægningsprocesser. |
