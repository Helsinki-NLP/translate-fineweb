| original | translation |
|----------|-------------|
| Artificial intelligence (AI), the computerized capability of doing tasks, which until recently was thought to be the exclusive domain of human intelligence, has demonstrated great strides in the past decade. The abilities to play games, provide piloting for an automobile, and respond to spoken language are remarkable successes. How are the challenges and opportunities of medicine different from these challenges and how can we best apply these data-driven techniques to patient care and outcomes? A New England Journal of Medicine paper published in 1980 suggested that more well-defined “specialized” tasks of medical care were more amenable to computer assistance, while the breadth of approach required for defining a problem and narrowing down the problem space was less so, and perhaps, unachievable. On the other hand, one can argue that the modern version of AI, which uses data-driven approaches, will be the most useful in tackling tasks such as outcome prediction that are often difficult for clinicians and patients. The ability today to collect large volumes of data about a single individual (eg, through a wearable device) and the accumulation of large datasets about multiple persons receiving medical care has the potential to apply to the care of individuals. As these techniques of analysis, enumeration, aggregation, and presentation are brought to bear in medicine, the question arises as to their utility and applicability in that domain. Early efforts in decision support were found to be helpful; as the systems proliferated, later experiences have shown difficulties such as alert fatigue and physician burnout becoming more prevalent. Will something similar arise from data-driven predictions? Will empowering patients by equipping them with information gained from data analysis help? Patients, providers, technology, and policymakers each have a role to play in the development and utilization of AI in medicine. Some of the challenges, opportunities, and tradeoffs implicit here are presented as a dialog between a clinician (SJN) and an informatician (QZT).J Med Internet Res 2019;21(11):e16272<br/>Drs Nelson and Zeng-Treitler work together at the Biomedical Informatics Center at George Washington University. In the following we present a hypothetical dialogue which grew out of discussions they had as they considered their differing viewpoints of how artificial intelligence (AI) has developed and where it is going. While Dr Zeng-Treitler’s view of the future of AI is highly optimistic, Dr Nelson's opinion is more cautious. Dr Nelson was a practicing academic internist who became involved in informatics many years ago. He collaborated with Scott Blois on RECONSIDER (an early clinical decision support system) and on the Unified Medical Language System (UMLS) project. He eventually moved to the National Library of Medicine as Head of Medical Subject Headings. While at the National Library of Medicine, he fathered RxNorm, while continuing his work on UMLS and projects involving UMLS. Dr Zeng-Treitler has a background in computer science and obtained her PhD in medical informatics from Columbia University. She has led a number of projects in clinical data mining, natural language processing, and consumer health informatics. During the past few years, her team has been actively investigating the use of AI techniques in clinical research including development of a novel explainable deep learning approach.<br/>Dr Zeng-Treitler (The "Optimist"):<br/>After decades of promises and disappointment, thanks to the seemingly unbounded computing resources and novel, data-driven methods, AI technology has finally arrived. From Jeopardy and Siri to face identification and autonomous vehicles, data-driven approaches have made the leap from laboratory experiments to applications that are transforming our lives outside health care. In some cases, these approaches have come close to passing the Turing Test—a test of a machine’s ability to exhibit supposed human-like intelligence; machines can now perform some complex tasks such as image recognition and authentic game play as well as or better than humans would. Some would argue that the requisite approach is decidedly nonhuman. However, whatever the means to achieving these innovations, such successes have not been followed by analogous successes in health care.<br/>One dramatic example of this disparity of accomplishment is AlphaZero, a computer game engine that mastered chess, Shogi, and Go. Even before the arrival of the current generation of data-driven artifacts, chess engines have been shown to be able to play at a level superior to that of chess champions. Players of Go (a board game that is thought to be much more complex than chess), however, believed that computers were no match for high-level professionals in this game. This belief was shattered first by AlphaGo, which soundly defeated the reigning world champion of Go. Then came AlphaZero. The news is no longer that such approaches can beat the champions of Go, chess, or Shogi. Rather, the remarkable fact is that AlphaZero did not learn from human experiences and that it defeated the best prior chess engines such as Stockfish. AlphaZero triumphed by playing more games against itself than had ever been played by all human players. This is not an approach we could readily duplicate in health care.<br/>Dr Nelson (The "Cautious" One):<br/>Is winning a game, with defined rules and objectives, really the best test of human intelligence? In hindsight, the answer is “No.” For example, sophisticated chess playing programs have existed for nearly 50 years; from such programs, we learned how to organize computing resources to apply simple algorithms in a scalable way. Put differently, we did not learn anything about chess or how humans, even experts, play it. Instead, we learned that a supposed intelligence-requiring task was susceptible to a computational approach. We need to ask where and how such an approach is applicable in health care.<br/>For example, when doing tasks that are generally thought to be human and creative, can the machine recognize when it is out of its depth? Sometimes, humans have the ability to do so. However, if we can define the realm closely enough, I agree that the machines can do wonders. So, how do we define the realm?<br/>In Blois’ seminal paper on Clinical Judgment and Computers , he described the world of a physician’s thought process when seeing a patient, with the diagram shown in . Point A for a physician would be where the patient walks in the door to be seen for the first time. The nature of the complaint, the context in which the complaint occurs, and all of the myriad possibilities are present. As the problem definition moves toward Point B, a computer is better able to manage the information and knowledge necessary for high-quality care. One way in which we can think about defining the realm is that we are moving toward Point B. Some computer scientists have argued that Point A is just about managing facts, but, as Blois observed, it is more about relevance—something that has proven difficult to replicate computationally.<br/>It is indeed important to define the realm for an AI application. Many tasks in health care are much more complex than game play, and we have not witnessed the triumphs of analogous approaches in the biomedical domain as have been achieved in game play. Quite a few studies have been applying the latest deep learning technology (a key AI method) to biomedical datasets [- ]. The specific applications included image processing, natural language processing, and risk prediction. Deep learning, compared with traditional statistical and machine learning methods, has often shown modest improvements rather than breakthroughs [ - ].<br/>Whatever the details of these approaches, they apply nearly unbounded computing resources to very large amounts of data, something that has yet to happen in health care. Therefore, these approaches might prove helpful, but we do not know for sure yet.<br/>For example, a simple question posed by a colleague is beyond our current capabilities: Given a patient who starts out with a feature of metabolic syndrome, which feature of the syndrome will he or she tend to exhibit next? Simplistically, this is exactly the kind of challenge that a data-driven approach should help with, and yet, it is currently “over the horizon” due to the insufficient data that were collected in the past.<br/>Data are a key challenge when applying data-driven approaches to patient care. To begin with, biomedical data are highly complex. There many different types of data including image, text, numerical values, categorical classifications, and DNA sequences, representing tens of thousands of lab tests, procedures, diagnoses, medications, genetic markers, etc. Each data type also has its own characteristics; for example, a laboratory test value may need to be interpreted in the context of age, gender, and current conditions. However, diagnostic codes for different diseases have varying levels of accuracies.<br/>In biomedical data analysis, there is also the paradox of having too much and not enough data at the same time. On one hand, there are a tremendous amount of medical record, social media, and literature data. Efforts like the Million Veterans Project  have also collected a huge amount of DNA data. Using devices for tasks like activity tracking and continuous glucose monitoring generates more data than our current medical record systems can digest. On the other hand, the health record of a patient is an open system with much missing information in contrast with the closed system of a chess or Go game, where all data are available. Patients are observed at irregular intervals (eg, at clinic visits or during hospitalization) and are never subjected to all possible tests or treatments. Sometimes, death is the only definitive outcome.<br/>I agree that data types are multiple and complex. Simple solutions are insufficient, and the proliferation of irrelevant data in a record, not to mention the current cut-and-paste or fill-in-the-template fad, obscures what is important.<br/>One of the major difficulties with medical data is not just that it is not enough, but also that it is theory laden, that is, very few pieces of data are recorded routinely. A lot of data in observations are gathered only when the clinician has thought it is appropriate, that is, when diseases are tested for their absence or presence. If there is no reason to do the test, the test is not performed. Only a few tests are ever performed routinely; a transcribed set of physical observations (as is done in physical examination) is rarely recorded in enough detail (not to mention the failure to observe, which often occurs) to provide sufficient data for a more comprehensive analysis. For that reason alone, studies based on the recorded observations are often incomplete and potentially misleading. However, for predictions, observations not made may be the critical ones. Think about the patient with metabolic syndrome mentioned above. What data are we missing?<br/>Similarly, the results of clinical trials are not a complete picture. Even though participants have been selected, often excluding many individuals because of complicating conditions, the data collected on the participants are designed for testing certain hypotheses, with narrowly defined outcomes. A common criticism is that such trials are so artificial that they are irrelevant.<br/>The lack of integrated and standardized datasets is another issue. Although we can find many large datasets, they are often incomplete and difficult to link to other information. For example, environmental exposure, diet, physical activity, and genetic profile are among the common missing pieces of information when we examine the records about an individual patient. Detailed clinical trial datasets tend to lack long-term follow-up. Privacy issues and monetary incentives are also obstacles in data integration efforts.<br/>Real semantic interoperability to integrate and standardize datasets requires support in both terminology and how that terminology is used. Currently, human intervention is often required to interpret what one system is saying for use in another system. This situation is unfortunate; we can hope that over time, the necessary connections will take place (think of how the United States went from operator assistance on every telephone call to the automatic switching that takes place today). Such a change can only happen when many people see the need for and implement a common standard.<br/>In addition, the notion of “large” in the context of health care data is only relative. Think, instead, of many experiments undertaken by Google; if they desire, the amount of data that can be used to develop and test a model is orders of magnitude greater than that available in health care.<br/>In the domains where data-driven approaches have demonstrated success, there are outcomes that can be judged by human experts or machines themselves. For example, bilingual speakers can tell if natural language translation is working well, and the outcome of board or computer games can be easily determined. This allows easier simulation or annotation of data for machine learning. Such a task is much harder in the biomedical domains; investigation of causes or treatments of diseases in humans involve costly and long-term studies. In some cases, ethical concerns prohibit the experiments; for example, the introduction of potentially harmful genetic mutations into healthy human subjects is out of the question. We lack long-term outcome data for many treatments.<br/>I am not sure that there ever will be such a gold standard without a completely arbitrary definition. Variation between individuals is also a major obstacle. Although we perform studies using multiple subjects to account for biologic variability, our results are only approximate in their relevance to a given individual. For example, assuring genetic diversity in clinical trials is challenging, to say the least. Even the simplest tasks can be staggeringly multifactorial; for example, the information content of genetic testing for warfarin metabolism can be outweighed by whether the patient had lettuce for lunch.<br/>To expand on this observation, suppose you have an automobile that is not working appropriately. Today, you consult the sensors and the computer readout to give you very precise information about what is going wrong. The automobile has a specific design, with specific parameters that can be measured. All of the vehicles of the same year make and model can be assumed to be alike in those important aspects. It is important to realize that every human (with the exception of identical twins) is genetically unique. In that way, people are very different from automobiles or other mechanical devices. To compound the complexity with which the cause of a human problem can be addressed, what the individual experiences throughout their life is unique. Although we have nice abstractions or methods of identifying individuals who share some common characteristics (whether the presence or absence of a disease, the response or lack thereof to a medication, the similar environment, or other considerations), these are only a shorthand notation. With 7 billion persons currently living in this world, the problem appears almost open-ended. Too often in data analysis, we look at diagnostic codes as having a deep meaning. These are accepted without any recognition of the degree of uncertainty of the diagnosis. All our data may be helpful and useful, but we need to continue to view them with a large grain of salt. The fact that Google Translate works as well as it does gives us hope, but as complex as natural language translation is, it is simpler than some clinical tasks.<br/>Despite these challenges, applying data-driven approaches has the potential to transform health care. Today’s health care is labor intensive, from scheduling and triage to diagnosis and treatment. Many tasks currently undertaken by humans can be carried out by intelligent software solutions supported by sufficient data. For instance, improved voice recognition and summarization technology might help reduce the amount of time patients and clinicians spend on paperwork. Improved decision support tools ought to be able to help patients decide about the appropriateness of seeking care. An accurate assessment of short- and long-term risks and benefits will inform treatment selection and lifestyle changes.<br/>To provide another use case, there is evidence that type II diabetes may be reversible, but it is hard to apply this knowledge to an individual patient. Given the patient in front of me, what should I do, or recommend, and with what expectation? Demographics, genomics, comorbidities, psyche, competing risks, and other medications, all play a role. How, in a given person, do I reconcile all the possibilities?<br/>To develop these useful AI tools, we need better data, technology, and policy. To accumulate comprehensive, life-time data, patients must be in control and should be incentivized to share their data for research and care. Insurance, pharmaceutical, and medical institutions change over time. Currently, there are barriers for individuals to be the center of collecting the data on themselves. The barriers are present in data entry, collection, and storage; for example, some personalized health record products are tethered to an institution, while others require extensive transcribing efforts by patients or caregivers. Nevertheless, without patient consent and collaboration, gathering and linking longitudinal environmental, genetic, clinical, and behavioral data are neither feasible nor ethical. The current conditions are a huge barrier to any attempt to use data-driven approaches that have worked outside health care.<br/>Efforts including PatienstLikeMe  and the All of Us Research Project of the National Institutes of Health [ ] are examples of innovative approaches to curate bigger and better datasets. Most patients, however, are not engaged in such efforts. Patients are inherently motivated to improve their own health, but naturally have concerns regarding privacy and often do not see immediate benefits of participating in long-term studies. Appropriate incentives (eg, discounts for routine preventive care) coupled with security and authentication technologies are needed to entice a large and diverse population of patients to gather and share their data. The health care industry today owns parts of patient data and has limited motivation to purchase data from their customers. As the value of data increases, patients will become more valued as a partner.<br/>I agree that patients will need to assume the responsibility of carrying and sharing the information about themselves. However, experience tells us that not everyone is able or willing to do so. It will need cultural and political climate changes to encourage that development.<br/>When we can collect data that are not directly what the philosophers would call “theory-laden,” we may be able to refine our crude methods of patient diagnosis and care. I look forward to that day. If patients are the carrier of those data, it will be easier to obtain and use for analysis.<br/>We also need to design and implement methods specifically for handling very large and “messy” clinical data. For example, we need to understand the context of missing data and errors to get a better picture of ground truth. A lab result may be missed because there is no indication for it, practice preference, an alternative method of assessing, or a failure of data entry. Imagine how much more difficult a chess game will be, if a human player or a chess engine could only observe some squares on the board at irregular time intervals with some error or distortion of the observation.<br/>Further, we do not have an operational definition of “ground truth” in health care; a simple proposal is that one feature of ground truth is that it has predictive value—something that will be valued by clinicians and patients alike.<br/>Google has demonstrated that they can use lots of data to predict likely values for missing data in other areas ; however, it is yet to be determined whether this might work in medicine, but it is probably worth a trial. Irrespective of whether we can use large volumes of data to impute missing values, exploring how to handle the problem of absent observations is crucial, especially whenever we try to apply the results of data-driven approaches to individual patients.<br/>Another thought is that data that are missing, for any reason, are an observation in itself; the fact that the data were not obtained and recorded may be important. Think of the finding that the day and time of a test were more predictive of outcome than the result of the test . We know that the data that are missing will have some predictive value.<br/>On a different note, explanation of the data-driven models is critical to not only their adoption but also their impact . Predicting that a patient will have certain adverse events in the next several days or years is desirable. It may be argued that it is even more important to know the modifiable factors that can reduce risk and enhance outcome. Since deep learning models can be highly nonlinear, we have the opportunity to discover novel and complex patterns.<br/>I agree that explaining the prediction is critical; it is something that separates health care from, say, recognizing whether an image is a dog or a cat. However, I think you meant to say predicting a patient will probably have some adverse outcome. Nothing in life is certain except that it will end. However, we can say “it appears this behavior or finding will likely have an effect on your future” and hopefully be able to express some degree of confidence in that prediction.<br/>Learning how to express the confidence in a prediction is also important. How many folks really understand the statistics behind the predictions that occur today? What are the underlying assumptions behind any probabilistic model? It is more likely that with more frequent use and familiarity with the use of measures derived for AI models will lead to their acceptance.<br/>I agree. These are all steps to be taken in order to optimize the use of big data through AI to improve medical care.<br/>As a parting thought, we need to be cautious about how intrusive data-driven approaches might be in the care process. Although McDonald  demonstrated that performance in care improves with reminders [ ], the later experience has been one of too many reminders, leading to alert fatigue. When caregivers choose to override and ignore helpful information because of overload, have we accomplished anything?<br/>I hope that careful design of systems and consideration of clinical workflow will alleviate the problem of excessive intrusiveness. Although it is tempting to just “let AI do it,” the recent experiences with the Boeing 737 MAX demonstrate that there is danger in doing so. Neither AI nor a pilot alone is the optimal strategy in flying. In health care, involving patients more extensively in their care, together with AI and providers, may ultimately be an approach that works.<br/>Conflicts of Interest<br/>- Blois MS. Clinical Judgment and Computers. N Engl J Med 1980 Jul 24;303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Deep learning for healthcare: review, opportunities and challenges. Brief Bioinform 2018 Nov 27;19(6):1236-1246 [FREE Full text] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. Can machine-learning improve cardiovascular risk prediction using routine clinical data? PLoS ONE 2017 Apr 4;12(4):e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT. Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records. Sci Rep 2016 May 17;6(1):26094 [FREE Full text] [CrossRef] [Medline]<br/>- Quach K. The register. 2019. IBM Watson Health cuts back drug discovery 'artificial intelligence' after lackluster sales URL: https://www.theregister.co.uk/2019/04/18/ibm_watson_health [accessed 2019-10-23]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Scalable and accurate deep learning with electronic health records. NPJ Digit Med 2018 May 8;1(1):18 [FREE Full text] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, et al. Deep Learning in Medical Imaging: General Overview. Korean J Radiol 2017;18(4):570. [CrossRef]<br/>- U.S Department of Veterans Affairs. Million Veteran Program (MVP) URL: https://www.research.va.gov/mvp/ [accessed 2019-10-23]<br/>- Patientslikeme. URL: https://www.patientslikeme.com [accessed 2019-10-23]<br/>- All of Us Research Program. URL: https://allofus.nih.gov [accessed 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. The unreasonable effectiveness of data. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Biases in electronic health record data due to processes within the healthcare system: retrospective observational study. BMJ 2018 Apr 30:k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, Müller H. Causability and explainabilty of artificial intelligence in medicine. WIREs Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Protocol-Based Computer Reminders, the Quality of Care and the Non-Perfectibility of Man. N Engl J Med 1976 Dec 09;295(24):1351-1355. [CrossRef]<br/>|AI: artificial intelligence|<br/>|UMLS: Unified Medical Language System|<br/>Edited by G Eysenbach; submitted 15.09.19; peer-reviewed by A Holzinger; comments to author 14.10.19; revised version received 15.10.19; accepted 20.10.19; published 27.11.19Copyright<br/>©Qing Zeng-Treitler, Stuart J Nelson. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included. | Kunstig intelligens (AI), den datastyrte evnen til å gjøre oppgaver, som inntil nylig ble antatt å være det eksklusive domenet til menneskelig intelligens, har vist store fremskritt i det siste tiåret. Evnene til å spille spill, gi pilotering for en bil, og svare på muntlig språk er bemerkelsesverdige suksesser. Hvordan er utfordringene og mulighetene i medisin forskjellig fra disse utfordringene, og hvordan kan vi best anvende disse datadrevne teknikkene til pasientbehandling og utfall? En New England Journal of Medicine papir publisert i 1980 foreslo at mer veldefinerte "spesialiserte" oppgaver av medisinsk behandling var mer mottagelig for datahjelp, mens bredden av tilnærming som kreves for å definere et problem og innsnevre problemet plass var mindre slik, og kanskje, uoppnåelig. På den annen side kan man argumentere for at den moderne versjonen av AI, som bruker datadrevne tilnærminger, vil være den mest nyttige i å takle oppgaver som utfallsforutsigelse som ofte er vanskelig for klinikere og pasienter. Evnen i dag til å samle store mengder data om en enkelt person (for eksempel gjennom en bærbar enhet) og akkumulering av store datasett om flere personer som mottar medisinsk behandling, har potensial til å gjelde for omsorg for enkeltpersoner. Ettersom disse teknikkene for analyse, oppregning, aggregering og presentasjon bringes til å bære i medisin, oppstår spørsmålet om deres brukbarhet og anvendelighet i det domenet. Tidlig innsats i beslutningsstøtte ble funnet å være nyttig; Etter hvert som systemene spredte seg, har senere erfaringer vist vanskeligheter som våken tretthet og lege utbrenthet blir mer utbredt. Vil noe lignende oppstå fra datadrevne spådommer? Vil styrke pasienter ved å utstyre dem med informasjon hentet fra dataanalyse hjelpe? Pasienter, leverandører, teknologi og beslutningstakere har hver en rolle å spille i utviklingen og utnyttelsen av AI i medisin. Noen av utfordringene, mulighetene og avveiningene som er implisitt her, presenteres som en dialog mellom en kliniker (SJN) og en informatiker (QZT). J Med Internet Res 2019;21(11):e16272<br/>Dr. Nelson og Dr. Zeng-Treitler jobber sammen ved Biomedical Informatics Center ved George Washington University. I det følgende presenterer vi en hypotetisk dialog som vokste ut av diskusjoner de hadde som de vurderte sine ulike synspunkter på hvordan kunstig intelligens (AI) har utviklet seg og hvor det går. Mens Dr. Zeng-Treitlers syn på fremtiden for AI er svært optimistisk, er Dr. Nelsons mening mer forsiktig. Dr. Nelson var en praktiserende akademisk internist som ble involvert i informatikk for mange år siden. Han samarbeidet med Scott Blois på RECONSIDER (et tidlig klinisk beslutningsstøttesystem) og på Unified Medical Language System (UMLS) -prosjektet. Han flyttet til slutt til Nasjonalbiblioteket for medisin som leder for medisinske fagoverskrifter. Mens han var ved National Library of Medicine, ble han far til RxNorm, mens han fortsatte sitt arbeid med UMLS og prosjekter som involverte UMLS. Dr. Zeng-Treitler har bakgrunn i informatikk og fikk sin doktorgrad i medisinsk informatikk fra Columbia University. Hun har ledet en rekke prosjekter innen klinisk datautvinning, naturlig språkbehandling og forbrukerhelseinformatikk. I løpet av de siste årene har teamet hennes aktivt undersøkt bruken av AI-teknikker i klinisk forskning, inkludert utvikling av en ny forklarlig dyp læringsmetode.<br/>Dr. Zeng-Treitler ("Optimisten"):<br/>Etter flere tiår med løfter og skuffelser, takket være de tilsynelatende ubegrensede databehandlingsressursene og nye, datadrevne metoder, har AI-teknologien endelig kommet. Fra Jeopardy og Siri til ansikt identifikasjon og autonome kjøretøy, har datadrevne tilnærminger gjort spranget fra laboratorieeksperimenter til applikasjoner som forvandler våre liv utenfor helsevesenet. I noen tilfeller har disse tilnærmingene kommet nær bestått Turing-testen - en test av en maskins evne til å vise antatt menneskelig intelligens; Maskiner kan nå utføre noen komplekse oppgaver som bildegjenkjenning og autentisk spill så vel som eller bedre enn mennesker ville. Noen vil hevde at den nødvendige tilnærmingen er desidert umenneskelig. Men uansett midlene for å oppnå disse innovasjonene, har slike suksesser ikke blitt etterfulgt av analoge suksesser i helsevesenet.<br/>Et dramatisk eksempel på denne forskjellen i prestasjon er AlphaZero, en dataspillmotor som mestret sjakk, Shogi og Go. Selv før ankomsten av den nåværende generasjonen av datadrevne gjenstander, har sjakkmotorer vist seg å være i stand til å spille på et høyere nivå enn sjakkmestere. Spillere av Go (et brettspill som antas å være mye mer komplekst enn sjakk), trodde imidlertid at datamaskiner ikke var en kamp for profesjonelle på høyt nivå i dette spillet. Denne troen ble knust først av AlphaGo, som slo den regjerende verdensmesteren i Go. Så kom AlphaZero. Nyheten er ikke lenger at slike tilnærminger kan slå mesterne i Go, sjakk eller Shogi. Snarere er det bemerkelsesverdige faktum at AlphaZero ikke lærte av menneskelige erfaringer, og at det beseiret de beste tidligere sjakkmotorer som Stockfish. AlphaZero triumferte ved å spille flere spill mot seg selv enn noen gang hadde blitt spilt av alle menneskelige spillere. Dette er ikke en tilnærming vi lett kan duplisere i helsevesenet.<br/>Dr. Nelson (den "forsiktige" en):<br/>Er det å vinne et spill, med definerte regler og mål, virkelig den beste testen av menneskelig intelligens? I ettertid er svaret "Nei." For eksempel har sofistikerte sjakkprogrammer eksistert i nesten 50 år; Fra slike programmer lærte vi å organisere databehandlingsressurser for å bruke enkle algoritmer på en skalerbar måte. Sett på en annen måte lærte vi ikke noe om sjakk eller hvordan mennesker, selv eksperter, spiller det. I stedet lærte vi at en antatt intelligenskrevende oppgave var utsatt for en beregningsmessig tilnærming. Vi må spørre hvor og hvordan en slik tilnærming er anvendelig i helsevesenet.<br/>For eksempel, når du gjør oppgaver som generelt antas å være menneskelige og kreative, kan maskinen gjenkjenne når den er ute av sin dybde? Noen ganger har mennesker muligheten til å gjøre det. Men hvis vi kan definere riket tett nok, er jeg enig i at maskinene kan gjøre underverker. Så hvordan definerer vi riket?<br/>I Blois' banebrytende artikkel om klinisk bedømmelse og datamaskiner, beskrev han verden av en leges tankeprosess når han ser en pasient, med diagrammet vist i . Punkt A for en lege ville være der pasienten går i døren for å bli sett for første gang. Arten av klagen, sammenhengen der klagen oppstår, og alle de utallige mulighetene er til stede. Etter hvert som problemdefinisjonen beveger seg mot punkt B, er en datamaskin bedre i stand til å håndtere informasjonen og kunnskapen som er nødvendig for høy kvalitet på omsorg. En måte vi kan tenke på å definere riket er at vi beveger oss mot punkt B. Noen datavitenskapere har hevdet at punkt A bare handler om å håndtere fakta, men som Blois observerte, handler det mer om relevans - noe som har vist seg vanskelig å replikere beregningsmessig.<br/>Det er faktisk viktig å definere riket for en AI-applikasjon. Mange oppgaver i helsevesenet er mye mer komplekse enn spill, og vi har ikke vært vitne til triumfene til analoge tilnærminger i det biomedisinske domenet som har blitt oppnådd i spill. Ganske mange studier har brukt den nyeste dype læringsteknologien (en nøkkel AI-metode) til biomedisinske datasett [- ]. De spesifikke applikasjonene inkluderte bildebehandling, naturlig språkbehandling og risikoforutsigelse. Dyp læring, sammenlignet med tradisjonelle statistiske og maskinlæringsmetoder, har ofte vist beskjedne forbedringer i stedet for gjennombrudd.<br/>Uansett detaljene i disse tilnærmingene, gjelder de nesten ubegrensede databehandlingsressurser til svært store mengder data, noe som ennå ikke har skjedd i helsevesenet. Derfor kan disse tilnærmingene vise seg å være nyttige, men vi vet ikke sikkert ennå.<br/>For eksempel er et enkelt spørsmål fra en kollega utenfor våre nåværende evner: Gitt en pasient som starter med en funksjon av metabolsk syndrom, hvilken funksjon av syndromet vil han eller hun ha en tendens til å vise neste? Enkelt sagt er dette akkurat den typen utfordring som en datadrevet tilnærming skal hjelpe med, og likevel er det for tiden "over horisonten" på grunn av de utilstrekkelige dataene som ble samlet inn tidligere.<br/>Data er en viktig utfordring når man bruker datadrevne tilnærminger til pasientbehandling. Til å begynne med er biomedisinske data svært komplekse. Det er mange forskjellige typer data, inkludert bilde, tekst, numeriske verdier, kategoriske klassifikasjoner og DNA-sekvenser, som representerer titusenvis av laboratorietester, prosedyrer, diagnoser, medisiner, genetiske markører, etc. Hver datatype har også sine egne egenskaper; for eksempel kan det være nødvendig å tolke en laboratorietestverdi i sammenheng med alder, kjønn og nåværende forhold. Diagnostiske koder for ulike sykdommer har imidlertid varierende nøyaktighetsnivåer.<br/>I biomedisinsk dataanalyse er det også paradokset om å ha for mye og ikke nok data på samme tid. På den ene siden er det en enorm mengde medisinsk rekord, sosiale medier og litteraturdata. Innsats som Million Veterans Project har også samlet en enorm mengde DNA-data. Ved hjelp av enheter for oppgaver som aktivitetssporing og kontinuerlig glukoseovervåking genererer mer data enn våre nåværende medisinske journalsystemer kan fordøye. På den annen side er pasientjournalen et åpent system med mye manglende informasjon i motsetning til det lukkede systemet i et sjakk- eller Go-spill, hvor alle data er tilgjengelige. Pasienter observeres med uregelmessige intervaller (for eksempel ved klinikkbesøk eller under sykehusinnleggelse) og blir aldri utsatt for alle mulige tester eller behandlinger. Noen ganger er døden det eneste definitive resultatet.<br/>Jeg er enig i at datatyper er flere og komplekse. Enkle løsninger er utilstrekkelige, og spredningen av irrelevante data i en post, for ikke å nevne dagens cut-and-paste eller fill-in-the-template fad, skjuler hva som er viktig.<br/>En av de store vanskelighetene med medisinske data er ikke bare at det ikke er nok, men også at det er teori lastet, det vil si at svært få data blir registrert rutinemessig. Mye data i observasjoner samles bare når klinikeren har funnet det hensiktsmessig, det vil si når sykdommer testes for fravær eller tilstedeværelse. Hvis det ikke er grunn til å gjøre testen, blir testen ikke utført. Bare noen få tester blir noen gang utført rutinemessig; et transkribert sett med fysiske observasjoner (som det gjøres i fysisk undersøkelse) blir sjelden registrert i tilstrekkelig detalj (for ikke å nevne manglende observasjon, som ofte oppstår) for å gi tilstrekkelige data for en mer omfattende analyse. Av den grunn alene, studier basert på de registrerte observasjoner er ofte ufullstendige og potensielt misvisende. Men for spådommer, observasjoner ikke gjort kan være de kritiske. Tenk på pasienten med metabolsk syndrom nevnt ovenfor. Hvilke data mangler vi?<br/>Tilsvarende er resultatene av kliniske studier ikke et komplett bilde. Selv om deltakerne har blitt valgt, ofte utelukker mange individer på grunn av kompliserende forhold, er dataene samlet inn på deltakerne designet for å teste visse hypoteser, med smalt definerte utfall. En vanlig kritikk er at slike forsøk er så kunstige at de er irrelevante.<br/>Mangelen på integrerte og standardiserte datasett er et annet problem. Selv om vi kan finne mange store datasett, er de ofte ufullstendige og vanskelige å koble til annen informasjon. For eksempel er miljøeksponering, kosthold, fysisk aktivitet og genetisk profil blant de vanlige manglende bitene av informasjon når vi undersøker postene om en individuell pasient. Detaljerte kliniske forsøksdatasett har en tendens til å mangle langsiktig oppfølging. Personvernspørsmål og økonomiske insentiver er også hindringer i arbeidet med dataintegrasjon.<br/>Ekte semantisk interoperabilitet for å integrere og standardisere datasett krever støtte i både terminologi og hvordan den terminologien brukes. For tiden er menneskelig inngripen ofte nødvendig for å tolke hva ett system sier for bruk i et annet system. Denne situasjonen er uheldig; Vi kan håpe at over tid, de nødvendige tilkoblinger vil finne sted (tenk på hvordan USA gikk fra operatør assistanse på hver telefonsamtale til automatisk bytte som finner sted i dag). En slik endring kan bare skje når mange ser behovet for og implementerer en felles standard.<br/>I tillegg er begrepet "stor" i sammenheng med helsevesenets data bare relativ. Tenk i stedet på mange eksperimenter utført av Google; Hvis de ønsker, er mengden data som kan brukes til å utvikle og teste en modell, størrelsesordener større enn det som er tilgjengelig i helsevesenet.<br/>I de områdene hvor datadrevne tilnærminger har vist suksess, er det utfall som kan bedømmes av menneskelige eksperter eller maskiner selv. For eksempel kan tospråklige høyttalere fortelle om naturlig språkoversettelse fungerer bra, og utfallet av brettspill eller dataspill kan lett bestemmes. Dette gjør det lettere å simulere eller annotere data for maskinlæring. En slik oppgave er mye vanskeligere i de biomedisinske domener; undersøkelse av årsaker eller behandlinger av sykdommer hos mennesker involverer kostbare og langsiktige studier. I noen tilfeller forbyr etiske bekymringer forsøkene; for eksempel er innføring av potensielt skadelige genetiske mutasjoner i friske mennesker ute av spørsmålet. Vi mangler langsiktige utfallsdata for mange behandlinger.<br/>Jeg er ikke sikker på at det noen gang vil være en slik gullstandard uten en helt vilkårlig definisjon. Variasjon mellom individer er også et stort hinder. Selv om vi utfører studier ved hjelp av flere fag for å redegjøre for biologisk variabilitet, er våre resultater bare omtrentlige i deres relevans for et gitt individ. For eksempel er det utfordrende å sikre genetisk mangfold i kliniske studier, for å si det mildt. Selv de enkleste oppgavene kan være svimlende multifaktorielle; for eksempel kan informasjonsinnholdet i genetisk testing for warfarinmetabolisme oppveies av om pasienten hadde salat til lunsj.<br/>For å utvide denne observasjonen, sett at du har en bil som ikke fungerer riktig. I dag konsulterer du sensorene og datamaskinen for å gi deg svært nøyaktig informasjon om hva som går galt. Bilen har en bestemt design, med spesifikke parametere som kan måles. Alle biler av samme år gjør og modell kan antas å være like i disse viktige aspekter. Det er viktig å innse at alle mennesker (med unntak av identiske tvillinger) er genetisk unike. På den måten er folk svært forskjellige fra biler eller andre mekaniske enheter. For å komponere kompleksiteten som årsaken til et menneskelig problem kan løses, er hva den enkelte opplever gjennom hele livet unikt. Selv om vi har fine abstraksjoner eller metoder for å identifisere personer som deler noen vanlige egenskaper (om tilstedeværelsen eller fraværet av en sykdom, responsen eller mangelen på det til en medisin, det lignende miljøet eller andre hensyn), er disse bare en kort notasjon. Med 7 milliarder mennesker som for tiden lever i denne verden, virker problemet nesten åpent. Altfor ofte i dataanalyse ser vi på diagnostiske koder som å ha en dyp mening. Disse er akseptert uten anerkjennelse av graden av usikkerhet i diagnosen. Alle våre data kan være nyttige og nyttige, men vi må fortsette å se dem med et stort saltkorn. Det faktum at Google Translate fungerer så godt som det gjør, gir oss håp, men så komplisert som naturlig språk oversettelse er, det er enklere enn noen kliniske oppgaver.<br/>Til tross for disse utfordringene har datadrevne tilnærminger potensial til å forvandle helsevesenet. Dagens helsevesen er arbeidsintensivt, fra planlegging og triage til diagnose og behandling. Mange oppgaver som for tiden utføres av mennesker, kan utføres av intelligente programvareløsninger som støttes av tilstrekkelige data. For eksempel kan forbedret talegjenkjenning og oppsummeringsteknologi bidra til å redusere mengden tid pasienter og klinikere bruker på papirarbeid. Forbedrede beslutningsstøtteverktøy bør kunne hjelpe pasienter med å avgjøre om det er hensiktsmessig å søke omsorg. En nøyaktig vurdering av kortsiktige og langsiktige risikoer og fordeler vil informere behandlingsvalg og livsstilsendringer.<br/>For å gi et annet brukstilfelle, er det bevis på at type II diabetes kan være reversibel, men det er vanskelig å anvende denne kunnskapen til en individuell pasient. Gitt pasienten foran meg, hva skal jeg gjøre eller anbefale, og med hvilken forventning? Demografi, genomikk, komorbiditeter, psyke, konkurrerende risikoer og andre medisiner spiller alle en rolle. Hvordan, i en gitt person, forener jeg alle mulighetene?<br/>For å utvikle disse nyttige AI-verktøyene trenger vi bedre data, teknologi og politikk. For å samle omfattende, livslange data, må pasientene være i kontroll og bør oppmuntres til å dele dataene sine for forskning og omsorg. Forsikring, farmasøytiske og medisinske institusjoner endres over tid. For tiden er det barrierer for enkeltpersoner å være sentrum for å samle inn dataene om seg selv. Barrierene er til stede i dataregistrering, innsamling og lagring; for eksempel er noen personlige helsejournalprodukter bundet til en institusjon, mens andre krever omfattende transkriberingsinnsats av pasienter eller omsorgspersoner. Likevel, uten pasientens samtykke og samarbeid, er innsamling og kobling av longitudinelle miljø-, genetiske, kliniske og atferdsdata verken mulig eller etisk. De nåværende forholdene er en stor barriere for ethvert forsøk på å bruke datadrevne tilnærminger som har jobbet utenfor helsevesenet.<br/>Innsats inkludert PatienstLikeMe og All of Us Research Project of the National Institutes of Health [ ] er eksempler på innovative tilnærminger for å kuratere større og bedre datasett. De fleste pasienter er imidlertid ikke engasjert i en slik innsats. Pasienter er iboende motivert til å forbedre sin egen helse, men har naturlig bekymringer om personvern og ser ofte ikke umiddelbare fordeler ved å delta i langsiktige studier. Passende insentiver (f.eks. rabatter for rutinemessig forebyggende behandling) kombinert med sikkerhets- og autentiseringsteknologier er nødvendig for å lokke en stor og mangfoldig pasientpopulasjon til å samle og dele dataene sine. Helsesektoren eier i dag deler av pasientdata og har begrenset motivasjon til å kjøpe data fra sine kunder. Etter hvert som verdien av data øker, vil pasientene bli mer verdsatt som partner.<br/>Jeg er enig i at pasientene må påta seg ansvaret for å bære og dele informasjon om seg selv, men erfaringen viser at ikke alle er i stand til eller villige til å gjøre det. Det vil være behov for kulturelle og politiske klimaendringer for å oppmuntre til denne utviklingen.<br/>Når vi kan samle inn data som ikke er direkte hva filosofene vil kalle "teori-ladet", kan vi være i stand til å avgrense våre rå metoder for pasientdiagnose og omsorg. Jeg ser frem til den dagen. Hvis pasientene er bærere av disse dataene, vil det være lettere å skaffe og bruke til analyse.<br/>Vi trenger også å designe og implementere metoder spesielt for å håndtere svært store og "rotete" kliniske data. For eksempel må vi forstå sammenhengen med manglende data og feil for å få et bedre bilde av bakken sannhet. Et laboratorieresultat kan bli savnet fordi det ikke er noen indikasjon på det, praksispreferanse, en alternativ metode for å vurdere eller en feil i dataregistrering. Tenk deg hvor mye vanskeligere et sjakkspill vil være, hvis en menneskelig spiller eller en sjakkmotor bare kunne observere noen firkanter på brettet med uregelmessige tidsintervaller med noen feil eller forvrengning av observasjonen.<br/>Videre har vi ikke en operativ definisjon av "grunnsannhet" i helsevesenet; et enkelt forslag er at en funksjon av grunnsannhet er at den har prediktiv verdi - noe som vil bli verdsatt av både klinikere og pasienter.<br/>Google har vist at de kan bruke mye data for å forutsi sannsynlige verdier for manglende data på andre områder; Det er imidlertid ennå ikke bestemt om dette kan fungere i medisin, men det er sannsynligvis verdt et forsøk. Uavhengig av om vi kan bruke store mengder data for å imputere manglende verdier, er det avgjørende å utforske hvordan man skal håndtere problemet med manglende observasjoner, spesielt når vi prøver å anvende resultatene av datadrevne tilnærminger til individuelle pasienter.<br/>En annen tanke er at data som mangler, av en eller annen grunn, er en observasjon i seg selv; det faktum at dataene ikke ble innhentet og registrert kan være viktig. Tenk på funnet at dagen og tidspunktet for en test var mer prediktiv for utfallet enn resultatet av testen . Vi vet at dataene som mangler, vil ha noen prediktiv verdi.<br/>På en annen notat, forklaring av data-drevne modeller er avgjørende for ikke bare deres adopsjon, men også deres innvirkning . Forutsi at en pasient vil ha visse bivirkninger i de neste dagene eller årene er ønskelig. Det kan hevdes at det er enda viktigere å kjenne de modifiserbare faktorene som kan redusere risiko og forbedre utfallet. Siden dype læringsmodeller kan være svært ikke-lineære, har vi mulighet til å oppdage nye og komplekse mønstre.<br/>Jeg er enig i at det å forklare prediksjonen er kritisk; det er noe som skiller helsevesenet fra for eksempel å gjenkjenne om et bilde er en hund eller en katt. Jeg tror imidlertid at du mente å si å forutsi en pasient vil sannsynligvis ha noe negativt utfall. Ingenting i livet er sikkert, bortsett fra at det vil ende. Vi kan imidlertid si "det ser ut til at denne oppførselen eller funnet sannsynligvis vil ha en effekt på fremtiden" og forhåpentligvis kunne uttrykke en viss grad av tillit til den spådommen.<br/>Å lære å uttrykke tillit til en prediksjon er også viktig. Hvor mange mennesker forstår virkelig statistikken bak spådommene som oppstår i dag? Hva er de underliggende forutsetningene bak en sannsynlighetsmodell? Det er mer sannsynlig at hyppigere bruk og kjennskap til bruk av tiltak avledet for AI-modeller vil føre til aksept.<br/>Jeg er enig. Dette er alle skritt som skal tas for å optimalisere bruken av store data gjennom AI for å forbedre medisinsk behandling.<br/>Som en avskjedstanke må vi være forsiktige med hvor påtrengende datadrevne tilnærminger kan være i omsorgsprosessen. Selv om McDonald viste at ytelsen i omsorg forbedrer seg med påminnelser, har den senere opplevelsen vært en av for mange påminnelser, noe som fører til tretthet. Når omsorgspersoner velger å overstyre og ignorere nyttig informasjon på grunn av overbelastning, har vi oppnådd noe?<br/>Jeg håper at forsiktig utforming av systemer og vurdering av klinisk arbeidsflyt vil lindre problemet med overdreven påtrengelse. Selv om det er fristende å bare "la AI gjøre det", viser de siste erfaringene med Boeing 737 MAX at det er fare i å gjøre det. Verken AI eller en pilot alene er den optimale strategien for å fly. I helsevesenet, som involverer pasienter i større grad i deres omsorg, sammen med AI og leverandører, kan til slutt være en tilnærming som fungerer.<br/>Interessekonflikter<br/>- Blois MS. Klinisk dom og datamaskiner. N Engl J Med 1980 Jul 24;303(4):192-197. [CrossRef]<br/>- Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Dyp læring for helsetjenester: gjennomgang, muligheter og utfordringer. Kort Bioinform 2018 Nov 27;19(6):1236-1246 [FREE Full text] [CrossRef] [Medline]<br/>- Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N. Kan maskinlæring forbedre kardiovaskulær risikoforutsigelse ved hjelp av rutinemessige kliniske data? PLoS ONE 2017 Apr 4;12(4): e0174944. [CrossRef]<br/>- Miotto R, Li L, Kidd BA, Dudley JT. Dyp pasient: En uovervåket representasjon for å forutsi fremtiden for pasienter fra de elektroniske helseregistrene. Sci Rep 2016 mai 17;6(1):26094 [FREE Full text] [CrossRef] [Medline]<br/>- Quach K. Registeret. 2019. IBM Watson Health kutter tilbake narkotikaoppdagelsen "kunstig intelligens" etter mangel på salg URL: https://www.theregister.co.uk/2019/04/18/ibm_watson_health [tilgang 2019-10-23]<br/>- Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Skalerbar og nøyaktig dyp læring med elektroniske helsejournaler. NPJ Digit Med 2018 May 8;1(1):18 [GRATIS Fulltekst] [CrossRef] [Medline]<br/>- Lee J, Jun S, Cho Y, Lee H, Kim GB, Seo JB, et al. Dyp læring i medisinsk bildebehandling: Generell oversikt. Koreansk J Radiol 2017;18(4):570. [CrossRef]<br/>- US Department of Veterans Affairs. Million Veteran Program (MVP) URL: https://www.research.va.gov/mvp/ [tilgang 2019-10-23]<br/>- Pasientlikeme. URL: https://www.patientslikeme.com [accessed 2019-10-23]<br/>- Alle av oss forskningsprogram. URL: https://allofus.nih.gov [accessed 2019-10-23]<br/>- Halevy A, Norvig P, Pereira F. Den urimelige effektiviteten av data. IEEE Intell Syst 2009 Mar;24(2):8-12. [CrossRef]<br/>- Agniel D, Kohane IS, Weber GM. Biaser i elektroniske helsejournaldata på grunn av prosesser i helsevesenet: retrospektiv observasjonsstudie. BMJ 2018 Apr 30: k1479. [CrossRef]<br/>- Holzinger A, Langs G, Denk H, Zatloukal K, Müller H. Årsak og forklaring av kunstig intelligens i medisin. WIREs Data Mining Knowl Discov 2019 Apr 02:e1312. [CrossRef]<br/>- McDonald CJ. Protokollbaserte datamaskinpåminnelser, kvaliteten på omsorg og ikke-perfeksjonaliteten til mannen. N Engl J Med 1976 desember 09; 295 (24):1351-1355. [CrossRef]<br/>|AI: kunstig intelligens |<br/>|UMLS: Unified Medical Language System<br/>Redigert av G Eysenbach; innsendt 15.09.19; fagfellevurdert av A Holzinger; kommentarer til forfatteren 14.10.19; revidert versjon mottatt 15.10.19; akseptert 20.10.19; publisert 27.11.19Opphavsrett<br/>©Qing Zeng-Treitler, Stuart J Nelson. Opprinnelig publisert i Journal of Medical Internet Research (http://www.jmir.org), 27.11.2019.<br/>Dette er en åpen tilgangsartikkel distribuert under betingelsene i Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), som tillater ubegrenset bruk, distribusjon og reproduksjon i ethvert medium, forutsatt at originalverket, først publisert i Journal of Medical Internet Research, er korrekt sitert. Den fullstendige bibliografiske informasjonen, en lenke til den opprinnelige publikasjonen på http://www.jmir.org/, samt denne opphavsretts- og lisensinformasjonen må inkluderes. |
| The Story of Selena Quintanilla: A Biography Book for Young Readers (The Story Of: A Biography Series for New Readers) (Paperback)<br/>Most titles are on our shelves or available within 1-5 days.<br/>Discover the life Selena Quintanilla—a story about breaking down barriers in music, for kids ages 6 to 9<br/>Selena Quintanilla was the queen of Tejano music. Before she became a star, Selena was a charismatic young girl who loved singing and performing. She made a lot of sacrifices to become a famous musician, rehearsing her songs and dance moves for hours at a time. Her hard work paid off—she became the first 15-year-old girl to win a Tejano music award and went on to break many records during her career. This Selena biography explores how she went from being a talented girl growing up in Texas to a fashion icon and a world-famous singer.<br/>What sets this Selena book apart:<br/>- Core curriculum—Kids will learn the Who, What, Where, When, Why, and How of Selena’s life, and take a quick quiz to test their knowledge.<br/>- Short chapters—This Selena kids’ book is broken up into brief chapters that make it fun and easy for new readers to discover details about the singer’s life.<br/>- Her lasting legacy—Kids will find out how Selena changed the world of music and why she continues to be a role model for many women and people of color around the globe.<br/>How will Selena’s big spirit and passion for music inspire the child in your life?<br/>About the Author<br/>GLORIA ARJONA teaches Spanish at the California Institute of Technology and is the author of Posadas Unknown Calaveras and ¡Lotería!. She’s also a musician who sings and plays guitar. Learn more at GloriaArjona.com.<br/>“Finally, a Selena book for new readers, one that is told concisely and honestly, and is eminently readable” —Joe Nick Patoski, author of Selena: Como La Flor<br/>“What a wonderful story to inspire girls to follow their dreams. A story that many girls will identify with, especially those from traditional and multicultural families. I liked all the little sidebar lessons throughout the book. Gloria is a very talented teacher.” —Genevieve B. Southgate, director of community programs, Bowers Museum<br/>“Selena Quintanilla’s youthful talent and positive drive are brought to life in Prof. Arjona’s latest book, this one geared to young readers. A highly appealing read highlighting Selena’s flexibility in overcoming obstacles to achieving her dreams and her trailblazing contributions to music and her community. The Callisto Media format of encouraging critical, organized thought via questions, maps, timelines, and a glossary make this an enjoyable learning experience.” —Martin E. Delgado, community library manager<br/>“This is the story of Selena Quintanilla, and what a story it is! In a time where young readers, and young women, need role models more than ever, this book brilliantly depicts the profound humanity, bravery, and talent of a deeply inspiring Latina woman who relentlessly fought for her dream.” —Maite Zubiaurre, UCLA professor | Historien om Selena Quintanilla: En biografibok for unge lesere (Historien om: En biografiserie for nye lesere)<br/>De fleste titlene er på våre hyller eller tilgjengelig innen 1-5 dager.<br/>Oppdag livet Selena Quintanilla - en historie om å bryte ned barrierer i musikk, for barn i alderen 6 til 9<br/>Selena Quintanilla var dronningen av Tejano musikk. Før hun ble en stjerne, var Selena en karismatisk ung jente som elsket å synge og utføre. Hun gjorde mange ofre for å bli en berømt musiker, øvde på sangene og dansetrinnene sine i flere timer om gangen. Hennes harde arbeid betalte seg - hun ble den første 15-årige jenta som vant en Tejano-musikkpris og fortsatte å bryte mange poster i løpet av karrieren. Denne Selena-biografien utforsker hvordan hun gikk fra å være en talentfull jente som vokste opp i Texas til et moteikon og en verdensberømt sanger.<br/>Hva skiller denne Selena-boken fra andre bøker:<br/>- Kjerne pensum-Barn vil lære hvem, hva, hvor, når, hvorfor, og hvordan av Selena liv, og ta en rask quiz for å teste sine kunnskaper.<br/>- Korte kapitler - Denne Selena barnebok er delt inn i korte kapitler som gjør det morsomt og enkelt for nye lesere å oppdage detaljer om sangerens liv.<br/>Barna vil finne ut hvordan Selena forandret musikkverdenen og hvorfor hun fortsetter å være et forbilde for mange kvinner og fargede mennesker rundt om i verden.<br/>Hvordan vil Selenas store ånd og lidenskap for musikk inspirere barnet i livet ditt?<br/>Om redaktøren<br/>GLORIA ARJONA underviser i spansk ved California Institute of Technology og er forfatter av Posadas Unknown Calaveras og ¡Lotería!. Hun er også en musiker som synger og spiller gitar. Lær mer på GloriaArjona.com.<br/>"Endelig, en Selena bok for nye lesere, en som er fortalt kortfattet og ærlig, og er eminent lesbar." - Joe Nick Patoski, forfatter av Selena: Como La Flor<br/>"Hva en fantastisk historie å inspirere jenter til å følge sine drømmer. En historie som mange jenter vil identifisere seg med, spesielt de fra tradisjonelle og flerkulturelle familier. Jeg likte alle de små sidebar leksjoner gjennom hele boken. Gloria er en veldig talentfull lærer.» – Genevieve B. Southgate, direktør for samfunnsprogrammer, Bowers Museum<br/>"Selena Quintanillas ungdommelige talent og positive drivkraft blir brakt til liv i Prof. Arjonas nyeste bok, denne rettet mot unge lesere. En svært tiltalende lesning som fremhever Selenas fleksibilitet i å overvinne hindringer for å oppnå sine drømmer og hennes banebrytende bidrag til musikk og hennes samfunn. Callisto Media-formatet for å oppmuntre til kritisk, organisert tenkning via spørsmål, kart, tidslinjer og en ordliste gjør dette til en hyggelig læringsopplevelse.» – Martin E. Delgado, biblioteksjef i lokalsamfunnet<br/>Dette er historien om Selena Quintanilla, og for en historie det er! I en tid hvor unge lesere, og unge kvinner, trenger rollemodeller mer enn noen gang, skildrer denne boken briljant den dype menneskeheten, motet og talentet til en dypt inspirerende Latina-kvinne som ubarmhjertig kjempet for sin drøm. —Maite Zubiaurre, UCLA-professor |
| Here's another reason for men to avoid packing on extra pounds over the holidays: A new study has found that losing weight reduces the risk of an aggressive form of prostate cancer.<br/>After tracking the weight of nearly 70,000 men between 1982 and 1992, researchers from the American Cancer Society and the Duke University Prostate Center found that men who lost more than 11 pounds had a lower risk for aggressive prostate cancer than men whose weight remained the same over a decade.<br/>Previous studies have found that obese men have a higher risk of developing aggressive prostate cancer. This study appears to be the first to indicate that recent weight loss can decrease that risk.<br/>In the study reported this month in Cancer Epidemiology, Biomarkers & Prevention, researchers analyzed the height and weight of the men in 1982 and 1992 and every three years after that until 2003. At that time, more than 5,200 of the men — more than 7 percent — had prostate cancer.<br/>Among those cases, about one in eight had a form of cancer that was aggressive but had not spread to other areas of the body. The study's major finding focused on those aggressive cases, with researchers concluding that those who lost 11 or more pounds were 42 percent less likely to develop that form of prostate cancer than those whose weight remained the same.<br/>"Whether it's exactly 40 percent, we don't know, but they lower their risk when they lose 11-plus pounds. We feel confident, at least in this population, that was real," said lead researcher Dr. Carmen Rodriguez.<br/>More than seven times as many men whose weight remained the same developed aggressive prostate cancer compared to those who lost 11 or more pounds.<br/>"No significant associations" were found regarding the effect of weight gain or loss on the most severe forms of prostate cancer, those that spread throughout the body, the study said.<br/>The number studied was small, the researchers acknowledged, because fewer than 15,000 men lost weight over the time period, and only 1,000 of those developed some form of prostate cancer.<br/>The 69,991 participants were part of a bigger cancer society study of 1.2 million Americans that began in 1982.<br/>Rodriguez said men should avoid putting on extra weight as they get older.<br/>"The main message for men is to not get overweight. If they are overweight, that's another reason to try to lose weight, just to decrease the risk for prostate cancer," said Rodriguez, who works for the Atlanta-based cancer society.<br/>Other than skin cancer, prostate cancer is the most commonly diagnosed cancer for men, and about one in six will get it during his lifetime. It is the second leading cause of cancer death for U.S. men.<br/>The study is considered the first of its kind to examine the role of weight change in the development of prostate cancer, said Dr. Ronald Ennis, director of radiation oncology at St. Luke's-Roosevelt Hospital Center in New York, who was not involved in the study.<br/>"This is one of the best studies" examining the role of weight on prostate cancer, Ennis said. "It does seem to be true that if you are overweight, you are at risk of getting more aggressive forms of prostate cancer and if you lose weight, you can decrease the risk." | Her er en annen grunn for menn å unngå å pakke på ekstra pounds i løpet av ferien: En ny studie har funnet ut at å miste vekt reduserer risikoen for en aggressiv form for prostatakreft.<br/>Etter å ha sporet vekten av nesten 70.000 menn mellom 1982 og 1992, fant forskere fra American Cancer Society og Duke University Prostate Center at menn som mistet mer enn 11 pounds hadde en lavere risiko for aggressiv prostatakreft enn menn hvis vekt forble den samme over et tiår.<br/>Tidligere studier har funnet at overvektige menn har en høyere risiko for å utvikle aggressiv prostatakreft. Denne studien ser ut til å være den første som indikerer at nylig vekttap kan redusere den risikoen.<br/>I studien som ble rapportert denne måneden i Cancer Epidemiology, Biomarkers & Prevention, analyserte forskere høyden og vekten av mennene i 1982 og 1992 og hvert tredje år etter det til 2003. På den tiden hadde mer enn 5200 av mennene - mer enn 7 prosent - prostatakreft.<br/>Blant disse tilfellene hadde omtrent en av åtte en form for kreft som var aggressiv, men hadde ikke spredt seg til andre områder av kroppen. Studiens store funn fokuserte på de aggressive tilfellene, med forskere som konkluderte med at de som mistet 11 pund eller mer, var 42 prosent mindre tilbøyelige til å utvikle den form for prostatakreft enn de som hadde vekt forble den samme.<br/>"Om det er nøyaktig 40 prosent, vet vi ikke, men de reduserer risikoen når de mister 11-pluss pounds. Vi føler oss trygge, i hvert fall i denne befolkningen, det var ekte, " sa lederforsker Dr. Carmen Rodriguez.<br/>Mer enn syv ganger så mange menn hvis vekt forble den samme utviklet aggressiv prostatakreft sammenlignet med de som mistet 11 eller flere pounds.<br/>"Ingen signifikante foreninger" ble funnet om effekten av vektøkning eller tap på de mest alvorlige former for prostatakreft, de som spredte seg gjennom kroppen, sa studien.<br/>Antallet som ble studert var lite, forskerne erkjente, fordi færre enn 15.000 menn mistet vekt over tid, og bare 1000 av dem utviklet noen form for prostatakreft.<br/>De 69.991 deltakerne var en del av en større kreftsamfunnsstudie av 1,2 millioner amerikanere som begynte i 1982.<br/>Rodriguez sa at menn bør unngå å legge på seg ekstra vekt når de blir eldre.<br/>"Hovedbudskapet for menn er ikke å bli overvektige. Hvis de er overvektige, er det en annen grunn til å prøve å gå ned i vekt, bare for å redusere risikoen for prostatakreft," sier Rodriguez, som jobber for Atlanta-baserte kreftsamfunnet.<br/>Bortsett fra hudkreft, er prostatakreft den vanligste diagnostisert kreft for menn, og om lag en av seks vil få det i løpet av sin levetid. Det er den nest ledende årsaken til kreftdødsfall for amerikanske menn.<br/>Studien regnes som den første i sitt slag for å undersøke rollen som vektendring i utviklingen av prostatakreft, sa Dr. Ronald Ennis, direktør for stråling onkologi ved St. Luke's-Roosevelt Hospital Center i New York, som ikke var involvert i studien.<br/>"Dette er en av de beste studiene" som undersøker rollen som vekt på prostatakreft, sa Ennis. "Det ser ut til å være sant at hvis du er overvektig, er du i fare for å få mer aggressive former for prostatakreft, og hvis du mister vekt, kan du redusere risikoen." |
| If you have studied the OSI model with its 7 Layers that describe communication on computer network systems, you should know that the Ethernet standard lies in Layer 1 (Physical) and Layer 2 (Data-Link) of the OSI model.<br/>In this article we will focus on the physical (Layer 1) part of Ethernet, which mainly focuses on the wired physical medium (cabling) that is used to transport Ethernet frames in a network.<br/>Ethernet cables connect devices to computer networks, the “heart” of which is usually an Ethernet switch which has several interface ports for “plugging-in” the cables.<br/>Most of these Ethernet cables feature the standard RJ45 connector for plugging-in to a switch. However, Ethernet communication can be implemented also using Fiber-optic cabling which uses different types of connectors.<br/>Moreover, there are different types of Ethernet cables with varying bandwidths, speeds and types of construction. In this article we will discuss the “copper-made” cables which are the most popular ones in computer networks.<br/>The cables have labels indicating the standard used for manufacturing, ranging from category (cat) 3 to 7.<br/>Ethernet cables consist of several (usually 8) smaller wires (inside the main cable) which are separated in Twisted-pairs. This setup helps in cancelling-out electromagnetic interference between wires, thus allowing signals to travel longer distances inside the wires.<br/>Without the right cable (and of course without the right type of switch), you may experience slower speeds in the network between devices.<br/>Let’s now describe each Category of Ethernet Cables with their characteristics:<br/>|Max Length||100 m||100 m||100 m||100 m<br/>(55 m for 10Gbps)<br/>|100 m||100 m|<br/>|Max Speed||10 Mbps||100 Mbps||1 Gbps||10 Gbps||10 Gbps||>10 Gbps|<br/>|Frequency Bandwidth||16 MHz||100 MHz||100 MHz||250 MHz||500 MHz||600 MHz|<br/>|Shielded / Unshielded||Unshielded||Unshielded||Unshielded||Shielded or Unshielded||Shielded||Shielded|<br/>1) Cat 3<br/>One of the oldest Ethernet cabling standards is category (cat) 3 (TIA/EIA-568-B). These cables allowed 10 Mbps transmission speeds with 16 MHz max bandwidth.<br/>Cat 3 ethernet cables feature unshielded twisted pair (UTP) cabling. With UTP cables, manufacturers twist insulated copper wires together inside a polyethylene jacket. Compared to shielded ethernet cables, UTP cables tend to include more crosstalk.<br/>Network connections commonly featured category 3 ethernet cables until the early 1990s, when category 5 cables replaced cat 3. While some older telephone systems may still use cat 3 cables, they have mostly become obsolete in the networking industry.<br/>2) Cat 5<br/>Cat 5 cables increased the bandwidth of Ethernet connections up to 100 MHz and offered transmission speeds up to 100 Mbps. With Cat 5 ethernet cables, users could access 100BASE-TX ethernet systems, referred to as fast ethernet.<br/>As with the category 3 cables, cat 5 cables still feature crosstalk and interference, due to the UTP design. These cables include four pairs of twisted wires (for a total of 8 wires).<br/>While cat 5 cables primarily provide connections for Ethernet applications, these cables also provide solutions for carrying other data signals, such as video and telephone. In fact, a single cat 5 cable can carry two standard phone lines and a 100BASE-TX connection.<br/>3) Cat 5e<br/>In 2001, the category 5e standard replaced category 5. The letter “e” in the name stands for enhanced.<br/>The cabling still uses unshielded twisted pairs. There are no physical differences between cat 5 and cat 5e cables. However, stricter standards in manufacturing Cat5e cables help minimize crosstalk and allow higher data transmissions than Cat5.<br/>Cat 5e cables also utilize two sets of twisted pairs of wires, resulting in faster speeds. While cat 5e ethernet cable still features 100 MHz bandwidth, these cables allow speeds up to 1000 Mbps (1 Gbps).<br/>While several additional standards have come after cat 5e, these cables remain in production. In fact, due to the lower cost of production and support for gigabit ethernet, cat 5e cables are the most used for network applications throughout the world.<br/>4) Cat 6<br/>Cat 6 ethernet cables helped address issues related to interference and crosstalk. These cables use thinner wires and superior insulation, resulting in a better signal-to-noise ratio.<br/>With these features, cat 6 cables provide a more effective option for adding cable in areas with more electromagnetic interference, such as a crowded server room.<br/>Thanks to the superior design, cat 6 provides improved bandwidth. These cables have a max bandwidth of 250 MHz and max transmission speeds up to 1000 Mbps (1 Gbps) at the 100m range. However, 10Gbps can be achieved in Cat6 in smaller distances (up to 55m).<br/>Some cat 6 cables include shielding while others remain unshielded. With shielding, these cables can provide transmission speeds up to 10 Gbps, but only for short distances as we said above.<br/>5) Cat 6a<br/>Category 6a ethernet cables improve the design of the cat 6 cables. The letter “a” stands for augmented. Unlike cat 6 cables, all cat 6a cables feature shielded cabling for reduced interference.<br/>With the enhancements to the design specifications, cat 6a cables maintain higher transmission speeds and 500 MHz max bandwidth, allowing speeds up to 10000 Mbps (10 Gbps) across longer cables.<br/>While these cables provide faster speeds, the design makes them less flexible. To eliminate crosstalk, these cables feature thicker sheathing, making the cables stiffer and more difficult to work.<br/>6) Cat 7<br/>One of the latest developments is Cat 7 Ethernet cables. Also called class F channel cables, these cables include stricter standards compared to previous categories. The individual wire pairs now include their own shielding, in addition to the outer shielding<br/>With these cables, you get 600 MHz max bandwidth and 10000 Mbps (10 Gbps) transmission speeds. However, by almost completely getting rid of crosstalk, cat 7 ethernet cables offer even greater reliability for 10 Gbps Ethernet connections.<br/>With connections less than 15 meters, cat 7 can support transmission speeds up to 100 Gbps. While the industry has released several new standards since cat 7, these cables are currently the top of the line option for demanding networking applications.<br/>- What is OSPF NSSA (Not So Stubby Area) and How is it Configured?<br/>- Comparison of BOOTP vs DHCP Protocols in Computer Networks<br/>- Pros and Cons of SD-WAN in Networks – Description and Discussion<br/>- Comparison of GNS3 vs EVE-NG vs Packet Tracer for Networks Simulation<br/>- Subnetting vs Supernetting – What’s the Difference? (Explanation Guide) | Hvis du har studert OSI-modellen med sine 7 lag som beskriver kommunikasjon på datanettverkssystemer, bør du vite at Ethernet-standarden ligger i lag 1 (fysisk) og lag 2 (data-link) av OSI-modellen.<br/>I denne artikkelen vil vi fokusere på den fysiske (Layer 1) delen av Ethernet, som hovedsakelig fokuserer på det kablede fysiske mediet (kabling) som brukes til å transportere Ethernet-rammer i et nettverk.<br/>Ethernet-kabler kobler enheter til datanettverk, hvor "hjertet" vanligvis er en Ethernet-bryter som har flere grensesnittporter for å "plugge inn" kablene.<br/>De fleste av disse Ethernet-kablene har standard RJ45-kontakt for tilkobling til en bryter. Ethernet-kommunikasjon kan imidlertid også implementeres ved hjelp av fiberoptisk kabling som bruker forskjellige typer kontakter.<br/>Videre er det forskjellige typer Ethernet-kabler med varierende båndbredder, hastigheter og typer konstruksjon. I denne artikkelen vil vi diskutere de "kobberlagde" kablene som er de mest populære i datanettverk.<br/>Kablene har etiketter som angir standarden som brukes til produksjon, alt fra kategori (katt) 3 til 7.<br/>Ethernet-kabler består av flere (vanligvis 8) mindre ledninger (inne i hovedkabelen) som er separert i Twisted-par. Dette oppsettet bidrar til å kansellere ut elektromagnetisk interferens mellom ledninger, og dermed tillater signaler å reise lengre avstander inne i ledningene.<br/>Uten riktig kabel (og selvfølgelig uten riktig type bryter), kan du oppleve tregere hastigheter i nettverket mellom enheter.<br/>La oss nå beskrive hver kategori av Ethernet-kabler med sine egenskaper:<br/>|Max Length ||100 m ||100 m ||100 m ||100 m<br/>(55 m for 10 Gbps)<br/>|100 m ||100 m |<br/>|Max Speed ||10 Mbps ||100 Mbps ||1 Gbps ||10 Gbps |||10 Gbps ||>10 Gbps |<br/>|Frekvens Båndbredde ||16 MHz ||100 MHz ||100 MHz ||250 MHz | |500 MHz | |600 MHz |<br/>|Shielded / Unshielded ||Unshielded ||Unshielded ||Shielded eller Unshielded ||Shielded ||Shielded |<br/>1) Kategori 3<br/>En av de eldste Ethernet kabling standarder er kategori (cat) 3 (TIA/EIA-568-B). Disse kablene tillatt 10 Mbps overføringshastigheter med 16 MHz maks båndbredde.<br/>Cat 3 Ethernet-kabler har uskjermet vridd par (UTP) kabling. Med UTP-kabler vrir produsenter isolerte kobberledninger sammen inne i en polyetylenjakke. Sammenlignet med skjermede Ethernet-kabler, har UTP-kabler en tendens til å inkludere mer krysstale.<br/>Nettverkstilkoblinger inneholdt vanligvis kategori 3 Ethernet-kabler til tidlig på 1990-tallet, da kategori 5-kabler erstattet kat 3. Mens noen eldre telefonsystemer fortsatt kan bruke kat 3-kabler, har de for det meste blitt foreldet i nettverksindustrien.<br/>2) Kategori 5<br/>Cat 5-kabler økte båndbredden til Ethernet-tilkoblinger opp til 100 MHz og tilbød overføringshastigheter på opptil 100 Mbps. Med Cat 5-ethernet-kabler kunne brukerne få tilgang til 100BASE-TX ethernet-systemer, referert til som raske ethernet.<br/>Som med kategori 3 kabler, cat 5 kabler har fortsatt crosstalk og interferens, på grunn av UTP design. Disse kablene inkluderer fire par vridd ledninger (for totalt 8 ledninger).<br/>Mens Cat 5-kabler primært gir tilkoblinger for Ethernet-applikasjoner, gir disse kablene også løsninger for å bære andre datasignaler, for eksempel video og telefon. Faktisk kan en enkelt katt 5-kabel bære to standard telefonlinjer og en 100BASE-TX-tilkobling.<br/>3) Cat 5e<br/>I 2001 erstattet kategori 5e-standarden kategori 5. Bokstaven "e" i navnet står for forsterket.<br/>Kablingen bruker fortsatt uskjermede vridde par. Det er ingen fysiske forskjeller mellom kat 5 og kat 5e-kabler. Strengere standarder i produksjon av Cat5e-kabler bidrar imidlertid til å minimere krysstale og tillate høyere dataoverføringer enn Cat5.<br/>Cat 5e-kabler bruker også to sett med vridde par ledninger, noe som resulterer i raskere hastigheter. Mens Cat 5e Ethernet-kabelen fortsatt har 100 MHz båndbredde, tillater disse kablene hastigheter på opptil 1000 Mbps (1 Gbps).<br/>Mens flere tilleggsstandarder har kommet etter kat 5e, forblir disse kablene i produksjon. Faktisk, på grunn av de lavere produksjonskostnadene og støtten for gigabit ethernet, er kat 5e-kabler de mest brukte for nettverksapplikasjoner over hele verden.<br/>4) Katt 6<br/>Cat 6 Ethernet-kabler bidro til å løse problemer knyttet til forstyrrelser og krysstale. Disse kablene bruker tynnere ledninger og overlegen isolasjon, noe som resulterer i et bedre signal-til-støy-forhold.<br/>Med disse funksjonene gir kat 6-kabler et mer effektivt alternativ for å legge til kabel i områder med mer elektromagnetisk interferens, for eksempel et overfylt serverrom.<br/>Takket være den overlegne designen gir cat 6 forbedret båndbredde. Disse kablene har en maksimal båndbredde på 250 MHz og maksimale overføringshastigheter opp til 1000 Mbps (1 Gbps) ved 100m-området. Imidlertid kan 10Gbps oppnås i Cat6 på mindre avstander (opptil 55m).<br/>Noen kat 6 kabler inkluderer skjerming mens andre forblir uskjermet. Med skjerming kan disse kablene gi overføringshastigheter opp til 10 Gbps, men bare for korte avstander som vi sa ovenfor.<br/>5) Kategori 6a<br/>Kategori 6a ethernet kabler forbedre utformingen av cat 6 kabler. Bokstaven "a" står for utvidet. I motsetning til cat 6 kabler, alle cat 6a kabler har skjermet kabling for redusert interferens.<br/>Med forbedringene til designspesifikasjonene opprettholder kat 6a-kabler høyere overføringshastigheter og 500 MHz maksimal båndbredde, slik at hastigheter på opptil 10000 Mbps (10 Gbps) over lengre kabler.<br/>Selv om disse kablene gir raskere hastigheter, gjør designen dem mindre fleksible. For å eliminere krysstale, har disse kablene tykkere kappe, noe som gjør kablene stivere og vanskeligere å jobbe.<br/>6) Kategori 7<br/>En av de siste utviklingene er Cat 7 Ethernet-kabler. Også kalt klasse F-kanalkabler, disse kablene har strengere standarder sammenlignet med tidligere kategorier. De enkelte trådparene inkluderer nå sin egen skjerming, i tillegg til den ytre skjermingen.<br/>Med disse kablene får du 600 MHz maksimal båndbredde og 10000 Mbps (10 Gbps) overføringshastigheter. Men ved nesten helt å bli kvitt crosstalk, Cat 7 Ethernet-kabler tilbyr enda større pålitelighet for 10 Gbps Ethernet-tilkoblinger.<br/>Med tilkoblinger på mindre enn 15 meter kan cat 7 støtte overføringshastigheter på opptil 100 Gbps. Selv om bransjen har gitt ut flere nye standarder siden cat 7, er disse kablene for tiden det beste alternativet for krevende nettverksapplikasjoner.<br/>Hva er OSPF NSSA (Not So Stubby Area) og hvordan er det konfigurert?<br/>- Sammenligning av BOOTP vs DHCP-protokoller i datanettverk<br/>- Fordeler og ulemper med SD-WAN i nettverk - Beskrivelse og diskusjon<br/>- Sammenligning av GNS3 vs EVE-NG vs Packet Tracer for Networks Simulering<br/>- Subnetting vs Supernetting - Hva er forskjellen? (Forklaring Guide) |
| Views: 4 Author: Site Editor Publish Time: 2022-06-09 Origin: Site<br/>So why should workers wear a portable gas detector and what does it do?<br/>In many industrial environments, workers need to be highly aware of exposure to toxic or combustible gases and vapours or a lack of oxygen. That’s why portable gas detectors and analysers are essential – so they can detect, measure, monitor and react to any gases in the immediate area around them. KELISAIKE SAFETY offers both single- and multi-gas mobile gas monitors that reliably detect a wide range of gases. All of our portable gas detectors and software are designed to make compliance and asset management as intuitive as possible, so you can implement a complete product solution that helps ensure safety at all times.<br/>Portable gas detectors are classed as a type of Personal Protective Equipment (PPE)<br/>They monitor gases in the workers breathing zone by displaying real-time gas levels of a variety of toxic, combustible, flammable gases<br/>They alert the worker of any possible threats which include combustion and oxygen displacement<br/>While portable gas detectors are available with various sensor configurations and features, they are all built with the same purpose - to protect human life! | Visninger: 4 Forfatter: Nettstedsredaktør Publiseringstid: 2022-06-09 Opprinnelse: Nettsted<br/>Så hvorfor skal arbeidstakere bruke en bærbar gassdetektor og hva gjør den?<br/>I mange industrielle miljøer må arbeidstakere være svært oppmerksomme på eksponering for giftige eller brennbare gasser og damper eller mangel på oksygen. Derfor er bærbare gassdetektorer og analysatorer avgjørende – slik at de kan oppdage, måle, overvåke og reagere på gasser i nærområdet rundt dem. KELISAIKE SAFETY tilbyr både mobile gassmonitorer med én og flere gasser som pålitelig registrerer et bredt spekter av gasser. Alle våre bærbare gassdetektorer og programvare er designet for å gjøre samsvar og kapitalforvaltning så intuitivt som mulig, slik at du kan implementere en komplett produktløsning som bidrar til å sikre sikkerhet til enhver tid.<br/>Bærbare gassdetektorer er klassifisert som en type personlig verneutstyr (PPE)<br/>De overvåker gasser i arbeidernes pustesone ved å vise sanntids gassnivåer av en rekke giftige, brennbare, brennbare gasser<br/>De varsler arbeideren om mulige trusler som inkluderer forbrenning og oksygenforskyvning.<br/>Mens bærbare gassdetektorer er tilgjengelige med ulike sensorkonfigurasjoner og funksjoner, er de alle bygget med samme formål - for å beskytte menneskeliv! |
| Salvador Dalí Biography<br/>The prints of Salvador Dalí are rooted in a rich past. In actuality, Dalí’s prints have a history that dates back to his early years of art school. The young Dalí was taught the fine art of engraving and etching by his mentor. Dalí gained a respect for the technical details of printmaking, a respect he would maintain throughout the rest of his life. The connection between Dalí and graphic prints is in fact intricate and protracted. In his lifetime, Dalí produced just around 1,700 graphic prints. A large number of them are hand-signed, limited-edition editions. Some are regarded as some of the best prints created in the 20th century.<br/>Dalí had the ability to experiment with a wide range of subjects through his print work, including etchings, engravings, mixed media, lithographs, and photo-litho. Dalí would produce beautiful suites or single prints. These suites frequently feature a book motif, with the prints acting as the artwork. Among the literary works Dal illustrated were Alice in Wonderland, Hamlet, and The Old Man and the Sea. Other times, similar suites would focus on different subjects, such as flowers (FlorDal), science fiction (Conquest of the Cosmos), or fine print production (Currier and Ives). Dal also produced single prints that showcased his flawless printmaking skills. Prints by Dalí that are among his best include Flower Man, Symphony Bicyclette, Dream Passage, and The Studio of Dalí.<br/>Although it might be speculated that Dalí produced many more prints than the “approved” ones we attribute to him today, Dal’s first prints appeared in the 1920s. His superb craftsmanship is seen in works like Head of a Young Girl and Immaculate Conception. The graphic piece Les Chants de Maldoror is among Dal’s best-known creations. The stories that separate the suites are a perfect match for the pre-surrealistic aspects of the book. A complete set of this suite is now in high demand. The majority of these early works were etchings and engravings; as Dalí’s printing skills improved, he expanded the range of his mediums and themes.<br/>The 1960s are often referred to as the “Golden Age” of Dalí’s prints. In fact, Dalí produced some of his most creative pieces during this decade. For an edition of The Divine Comedy, he finished one hundred wood block prints. This suite is regarded as a work of genius, and Dalí produced magnificent graphics to complement Virgil’s poetry. A fruitful collaboration with the American publishers Phyllis and Sidney Lucas also began throughout this decade. The Lucas’ and Dalí’s combined efforts would result in some of the most enduring Dal paintings ever. Prints like The Drawers of Memory, Fantastic Voyage, The Lucky Number of Salvador Daíi, The Studio of Dalí, and Departure of The Fishermen are examples of the prints that resulted from their collaboration. For Dalí, these were undoubtedly successful years. Over the course of this decade, Dal finished hundreds of photographs. His output was extraordinarily high. However, some of his best graphic creations remained to be seen.<br/>Dal returned to his melting clocks painting, his most well-known creation, in the 1970s. Some people believe that Dalí’s 1975 lithograph Changes In Great Masterpieces is his best creation overall. The collection consists of six images, five of which are Dalí’s interpretations of paintings by Rembrandt, Vermeer, Raphael, and Velasquez. The Persistence of Memory, Dalí’s own masterwork, is reinterpreted in the sixth picture.<br/>Together with his American publishers, Phyllis and Sidney Lucas, Mozart created this suite. Dalí updates his original piece by including a fourth melting clock. The broken clock creeps through the midst of the scene. The fourth clock, according to some, represents the fourth dimension, or time. Some people think that when Dal revised The Persistence of Memory, some 40 years after the original, he was considering his own transience and legacy and paying homage to the Dal of old.<br/>Changes in Great Masterpieces was only one of Dalí’s outstanding creations during the 1970s. In the suites Moses and Monotheism, Imagination and Objects of the Future, and Alchemy of The Philosophers, he produced some magnificent artwork. His two four-piece “puzzles,” The Rejuvenation of Time and The Puzzle of Life, are his largest lithographs. Ten Recipes of Immortality, a collection of three dimensional “pop-up” prints, is an example of how he expanded the scope of his graphic works into the third dimension. Although the 1960s may have been Dalí’s most productive decade, the 1970s appear to have been his most inventive and creative years as he explored new concepts and pushed himself even farther.<br/>In 1982, Dalí’s final prints were released. Dalí’s health had already started to deteriorate by this point, and his output had significantly decreased. However, Dalí was still able to create some excellent graphic prints despite his advanced age. Portrait of Autumn, which is bathed in gorgeous yellows, greens, and reds, is a glorification of the god Dionysus. Collectors of Dalí’s work see Chevalier Surealiste as a must-have piece, and it pays homage to one of Dalí’s heroes, Velasquez. Crucifixion is a superb example of Dalí’s artistry and a testament to his interest in Roman Catholicism.<br/>Dalí spent his entire life working as a printmaker. When evaluating his legacy, one must take into account the graphic arts creations he developed. Some of Dalí’s most artistic icons and imagery, as well as some of his best uses of his imagination, can be seen in these prints. | Salvador Dalí<br/>Salvador Dalis utskrifter er forankret i en rik fortid. I virkeligheten har Dalis utskrifter en historie som går tilbake til hans tidlige år på kunstskolen. Den unge Dalí ble lært kunsten å gravere og etse av sin mentor. Dalí fikk respekt for de tekniske detaljene i grafikken, en respekt han ville opprettholde resten av livet. Forbindelsen mellom Dalí og grafiske utskrifter er faktisk intrikat og langvarig. I løpet av sin levetid produserte Dalí rundt 1700 grafiske trykk. Et stort antall av dem er håndsignerte, limited edition-utgaver. Noen regnes som noen av de beste trykkene laget i det 20. århundre.<br/>Dalí hadde evnen til å eksperimentere med et bredt spekter av emner gjennom sitt utskriftsarbeid, inkludert etsninger, graveringer, blandede medier, litografier og foto-litho. Dalí ville produsere vakre suiter eller enkelttrykk. Disse suitene har ofte et bokmotiv, med trykkene som kunstverk. Blant de litterære verkene Dal illustrerte var Alice i Eventyrland, Hamlet, og Den gamle mannen og havet. Andre ganger ville lignende suiter fokusere på forskjellige emner, som blomster (FlorDal), science fiction (Conquest of the Cosmos), eller fintrykkproduksjon (Currier og Ives). Dal produserte også enkelttrykk som viste sine feilfrie utskriftsferdigheter. Trykk av Dalí som er blant hans beste inkluderer Flower Man, Symphony Bicyclette, Dream Passage og The Studio of Dalí.<br/>Selv om det kan spekuleres i at Dalí produserte mange flere utskrifter enn de "godkjente" vi tilskriver ham i dag, dukket Dals første utskrifter opp på 1920-tallet. Hans ypperlige håndverk er sett i verk som Head of a Young Girl og Immaculate Conception. Det grafiske stykket Les Chants de Maldoror er blant Dals mest kjente kreasjoner. Historiene som skiller suitene er en perfekt kamp for de pre-surrealistiske aspektene av boken. Et komplett sett av denne suiten er nå i høy etterspørsel. De fleste av disse tidlige verkene var etsninger og graveringer; etter hvert som Dalís trykkeferdigheter forbedret seg, utvidet han omfanget av sine medier og temaer.<br/>1960-tallet er ofte referert til som "Golden Age" av Dalis utskrifter. Faktisk produserte Dalí noen av sine mest kreative stykker i løpet av dette tiåret. For en utgave av The Divine Comedy fullførte han hundre treblokktrykk. Denne suiten er ansett som et verk av geni, og Dalí produserte storslått grafikk for å utfylle Virgils poesi. Et fruktbart samarbeid med de amerikanske utgiverne Phyllis og Sidney Lucas begynte også i løpet av dette tiåret. Lucas og Dalis kombinerte innsats ville resultere i noen av de mest varige Dal-maleriene noensinne. Utskrifter som The Drawers of Memory, Fantastic Voyage, The Lucky Number of Salvador Daíi, The Studio of Dalí og Departure of The Fishermen er eksempler på utskrifter som resulterte fra deres samarbeid. For Dalí var disse utvilsomt vellykkede år. I løpet av dette tiåret fullførte Dal hundrevis av fotografier. Hans produksjon var ekstraordinært høy. Imidlertid var noen av hans beste grafiske kreasjoner fortsatt å bli sett.<br/>Dal vendte tilbake til sitt smeltende klokkemaleri, hans mest kjente kreasjon, på 1970-tallet. Noen tror at Dalí's 1975 litografi Changes In Great Masterpieces er hans beste kreasjon generelt. Samlingen består av seks bilder, hvorav fem er Dalís tolkninger av malerier av Rembrandt, Vermeer, Raphael og Velasquez. Minnets utholdenhet, Dalís eget mesterverk, er tolket på nytt i det sjette bildet.<br/>Sammen med sine amerikanske forleggere, Phyllis og Sidney Lucas, skapte Mozart denne suiten. Dalí oppdaterer sitt originale stykke ved å inkludere en fjerde smelteklokke. Den ødelagte klokken kryper gjennom midten av scenen. Den fjerde klokken, ifølge noen, representerer den fjerde dimensjonen, eller tiden. Noen tror at da Dal reviderte The Persistence of Memory, omtrent 40 år etter originalen, vurderte han sin egen forbigående og arv og betalte hyllest til den gamle Dal.<br/>Endringer i store mesterverk var bare en av Dalís fremragende kreasjoner i løpet av 1970-tallet. I suitene Moses og Monoteisme, Imagination and Objects of the Future, og Alchemy of The Philosophers, produserte han noen fantastiske kunstverk. Hans to firedelte "puslespill", The Rejuvenation of Time og The Puzzle of Life, er hans største litografier. Ti oppskrifter på udødelighet, en samling av tredimensjonale "pop-up" utskrifter, er et eksempel på hvordan han utvidet omfanget av sine grafiske verker inn i den tredje dimensjonen. Selv om 1960-tallet kan ha vært Dalis mest produktive tiår, synes 1970-tallet å ha vært hans mest oppfinnsomme og kreative år da han utforsket nye konsepter og presset seg enda lenger.<br/>I 1982 ble Dalís endelige utskrifter utgitt. Dalís helse hadde allerede begynt å forverres ved dette punktet, og hans produksjon hadde betydelig redusert. Imidlertid var Dalí fortsatt i stand til å lage noen gode grafiske utskrifter til tross for sin høye alder. Portrett av høsten, som er badet i nydelige gule, grønne og røde, er en forherligelse av guden Dionysos. Samlere av Dalis arbeid ser Chevalier Surealist som et must-have stykke, og det betaler hyllest til en av Dalis helter, Velasquez. Korsfestelsen er et ypperlig eksempel på Dalís kunst og et vitnesbyrd om hans interesse for katolisismen.<br/>Dalí tilbrakte hele sitt liv som grafiker, og når man vurderer hans arv, må man ta hensyn til de grafiske kreasjonene han utviklet. Noen av Dalís mest kunstneriske ikoner og bilder, samt noen av hans beste bruk av hans fantasi, kan sees i disse utskriftene. |
| English Language A Level<br/>|Mode of study||Academic A Level|<br/>|Campus||English Bridge Campus|<br/>|Start date||4 September 2023|<br/>|Course code||ENG-AL (2325)|<br/>A minimum of five GCSEs at grade 4 or above, including English Language and English Literature.<br/>Please note: You can study both English A level Literature and A level English Language because the courses are sufficiently distinct that there is no overlap or repetition of content. However, you cannot study A Level English Combined and A Level English Literature, or A Level English Combined and A Level English Language.<br/>What does the course involve?<br/>English is an exciting subject and we hope you’ll enjoy the lively debate and discussion. Whichever English course you choose, you’ll gain a great deal of academic prowess and the development of transferable skills.<br/>You will be taught to think analytically, synthesise information, and develop communication skills that are a prerequisite for a wide range of career paths.<br/>The important skill of learning to write coherently and critically will aid you in your other subjects and is invaluable in higher education.<br/>Language is one of the key features that define us as human beings and, on this course, you will explore how it works: how we learn language from infancy, how we use it as a social tool, and how it has evolved over time. You will learn about the origins of English, the various forms it has taken over the centuries, how it has spread across the globe and what it might look like in the future.<br/>You will also study the research of theorists in areas of language such as speech and gender, accents and dialects, and the language of technology. You will learn about grammar in order to explore the ways writers use language to communicate meaning in texts ranging from blogs to 17th-century journalism.<br/>The NEA (coursework) unit will allow you to write creatively and to undertake an investigation into an aspect of the course you have enjoyed.<br/>How is the course assessed?<br/>80% Exam and 20% Coursework. Two coursework tasks and two externally-assessed exams.<br/>This A Level will equip you with the necessary skills to go into practical professions such as journalism and creative writing as well as academic degrees such as law and media studies. It forms a good companion to A Levels in Psychology and Sociology because there is a degree of crossover with the social sciences. If you are thinking of studying English at university, it is perfectly acceptable to take both English Language and English Literature. English can be combined with a range of other subjects at university.<br/>English provides an excellent foundation for various Higher Education courses including law, medicine, English, linguistics and education. It can be combined with a range of other subjects at university. English offers increasing employability in a range of career areas, especially those that require developed communication skills. Students have gone on to careers in law, health and medicine, commerce and industry, marketing, politics and international relations, general management, as well as leading to more predictable areas like journalism, publishing, the media, education, theatre and public relations.<br/>The student magazine produced by students is part of the enrichment opportunities led by the English Department. Trips include theatre trips to London, Manchester and Stratford-upon-Avon and international trips include a visit to battlefields in France, university taster days, residentials and creative writing workshops. These are all optional but highly recommended. Aspiring Oxford and Cambridge applicants will benefit from our extensive range of activities to support you in making a competitive application including: small group subject tuition, Oxford and Cambridge conferences, visits and contacts with our link staff, access to summer schools, application support and essay competitions, supra-curricular activities and access to free university-level Massive Open Online Courses (MOOC).<br/>What do I do next?<br/>You can apply online via the APPLY NOW button and then add an additional two or three subjects to make up your academic programme. You can also apply for a second, alternative vocational programme of study via a separate application. If after reading this factsheet, you are still undecided about the course most suitable for you, please drop in to one of our Open Evenings, ring Admissions on 01743 260401 or email email@example.com<br/>A Level English Language (Law and Drama & Theatre)<br/>Previous school: Mary Webb School<br/>I came here because it was local to me and I enjoyed the pre-enrolment days which were well organised. English Language is a good A Level to have and it is super interesting to see how language has evolved and changed through time. The teachers are a great help and the resources are brilliant; there are plenty of text books.<br/>Are you an employer?<br/>See how an apprentice can help your business. | Engelsk språk A-nivå<br/>|Studieform ||Akademisk A-nivå |<br/>|Campus||Engelsk Bridge Campus|<br/>|Startdato||4. september 2023|<br/>|Kurskode||ENG-AL (2325)|<br/>Minst fem GCSEs på klasse 4 eller høyere, inkludert engelsk språk og engelsk litteratur.<br/>Vennligst merk: Du kan studere både engelsk A-nivå litteratur og A-nivå engelsk språk fordi kursene er tilstrekkelig tydelige at det ikke er overlapping eller repetisjon av innhold. Du kan imidlertid ikke studere et nivå engelsk kombinert og et nivå engelsk litteratur, eller et nivå engelsk kombinert og et nivå engelsk språk.<br/>Hva innebærer kurset?<br/>Engelsk er et spennende emne, og vi håper du vil nyte den livlige debatten og diskusjonen. Uansett hvilket engelskkurs du velger, får du mye akademisk dyktighet og utvikling av overførbare ferdigheter.<br/>Du vil bli lært å tenke analytisk, syntetisere informasjon og utvikle kommunikasjonsevner som er en forutsetning for et bredt spekter av karriereveier.<br/>Den viktige ferdigheten til å lære å skrive sammenhengende og kritisk vil hjelpe deg i dine andre fag og er uvurderlig i høyere utdanning.<br/>Språk er en av de viktigste funksjonene som definerer oss som mennesker, og på dette kurset vil du utforske hvordan det fungerer: hvordan vi lærer språk fra barndommen, hvordan vi bruker det som et sosialt verktøy, og hvordan det har utviklet seg over tid. Du vil lære om opprinnelsen til engelsk, de ulike former det har tatt gjennom århundrene, hvordan det har spredt seg over hele verden og hvordan det kan se ut i fremtiden.<br/>Du vil også studere forskning av teoretikere i områder av språk som tale og kjønn, aksenter og dialekter, og språket av teknologi. Du vil lære om grammatikk for å utforske hvordan forfattere bruker språket til å kommunisere mening i tekster som spenner fra blogger til journalistikk fra det 17. århundre.<br/>NEA (kursarbeid) enheten vil tillate deg å skrive kreativt og å gjennomføre en undersøkelse i et aspekt av kurset du har hatt.<br/>Hvordan vurderes kurset?<br/>80% Eksamen og 20% Kurs. To kursoppgaver og to eksternt vurderte eksamener.<br/>Dette A-nivå vil utstyre deg med de nødvendige ferdighetene til å gå inn i praktiske yrker som journalistikk og kreativ skriving, samt akademiske grader som lov og mediestudier. Det danner en god følgesvenn til A-nivåer i psykologi og sosiologi fordi det er en grad av crossover med samfunnsvitenskapene. Hvis du tenker på å studere engelsk på universitetet, er det helt akseptabelt å ta både engelsk språk og engelsk litteratur. Engelsk kan kombineres med en rekke andre fag på universitetet.<br/>Engelsk gir et utmerket grunnlag for ulike høyere utdanningskurs, inkludert lov, medisin, engelsk, lingvistikk og utdanning. Det kan kombineres med en rekke andre fag ved universitetet. Engelsk tilbyr økende arbeidsevne i en rekke karriereområder, spesielt de som krever utviklet kommunikasjonsevner. Studentene har gått videre til karriere innen lov, helse og medisin, handel og industri, markedsføring, politikk og internasjonale relasjoner, generell ledelse, samt fører til mer forutsigbare områder som journalistikk, publisering, media, utdanning, teater og PR.<br/>Studentmagasinet produsert av studenter er en del av berikelsesmulighetene ledet av den engelske avdelingen. Turer inkluderer teaterturer til London, Manchester og Stratford-upon-Avon og internasjonale turer inkluderer et besøk til slagmarker i Frankrike, universitetssmaksdager, boliger og kreative skriveverksteder. Disse er alle valgfrie, men sterkt anbefalt. Aspiring Oxford og Cambridge søkere vil dra nytte av vårt omfattende utvalg av aktiviteter for å støtte deg i å lage en konkurransedyktig søknad, inkludert: liten gruppe fagundervisning, Oxford og Cambridge konferanser, besøk og kontakter med våre link ansatte, tilgang til sommerskoler, søknadsstøtte og essay konkurranser, supra-curricular aktiviteter og tilgang til gratis universitetsnivå Massive Open Online Courses (MOOC).<br/>Hva gjør jeg nå?<br/>Du kan søke online via APPLY NOW-knappen og deretter legge til ytterligere to eller tre fag for å gjøre opp ditt faglige program. Du kan også søke om et annet, alternativt yrkesfaglig studieprogram via en egen søknad. Hvis du etter å ha lest dette faktaarket, er du fortsatt usikker på hvilket kurs som passer best for deg, vennligst gå inn på en av våre åpne kvelder, ring Opptak på 01743 260401 eller e-post email@example.com<br/>Et nivå engelsk språk (lov og drama og teater)<br/>Tidligere skole: Mary Webb School<br/>Jeg kom hit fordi det var lokalt for meg, og jeg likte dagene før påmelding som var godt organisert. Engelsk språk er et godt A-nivå å ha, og det er super interessant å se hvordan språket har utviklet seg og endret seg gjennom tiden. Lærerne er en stor hjelp og ressursene er strålende; det er mange lærebøker.<br/>Er du arbeidsgiver?<br/>Se hvordan en lærling kan hjelpe virksomheten din. |
| In a subproject carried out together with the City of Stockholm within the HazardSupport research project, SMHI has investigated how town planning affects a city’s climate. Scenarios have been produced for Stockholm’s growth up until 2030 and 2050, using summer 2014 as a reference point. These scenarios do not take ongoing climate change into account. Instead, they simply show how the densification and growth of Stockholm can be expected to affect the air temperature.<br/>The main conclusion from the scenarios is that the impact of densification on air temperature is relatively local. No significant effect on the average temperature during the summer is seen at a distance of more than about 2 km, despite extensive densification across large areas. This can be seen in the most central parts of Stockholm, for example, which are already built-up and where no significant reduction in green spaces can therefore be expected. No significant change in air temperature is seen in these areas.<br/>One reason why the densification and expansion of Stockholm has not had any significant impact on air temperature is the relatively rapid air exchange with nearby expanses of water and countryside. Within those areas that are densifying, average summer temperature increases of up to around 1.5°C are being seen. As expected, the biggest temperature increases are observed when natural environments or green areas are built on.<br/>Measures in the local area<br/>One consequence of the locally limited effect of changes in the urban environment is that measures should primarily be focused on direct effects within the local area. Examples of such measures include shady street trees and proximity to green spaces. For the same reason, measures such as green roofs that only indirectly affect the air temperature in the street environment can be expected to have a less significant impact.<br/>A comfort index can be used to summarise the effect of various climate parameters. One example of such an index is the Universal Thermal Climate Index (UTCI). This involves a higher level of ambition in relation to how climate planning is often carried out in today’s planning processes. | I et delprosjekt som er gjennomført sammen med Stockholm by innenfor forskningsprosjektet HazardSupport, har SMHI undersøkt hvordan byplanlegging påvirker en bys klima. Det er utarbeidet scenarier for Stockholms vekst frem til 2030 og 2050, med sommeren 2014 som referansepunkt. Disse scenariene tar ikke hensyn til pågående klimaendringer. I stedet viser de bare hvordan fortetningen og veksten i Stockholm kan forventes å påvirke lufttemperaturen.<br/>Hovedkonklusjonen fra scenariene er at effekten av fortetting på lufttemperaturen er relativt lokal. Ingen signifikant effekt på gjennomsnittstemperaturen i løpet av sommeren er sett på en avstand på mer enn ca 2 km, til tross for omfattende fortetting over store områder. Dette kan for eksempel sees i de mest sentrale delene av Stockholm, som allerede er bebygd og hvor det derfor ikke kan forventes noen betydelig reduksjon i grønne områder. Ingen signifikant endring i lufttemperatur er sett i disse områdene.<br/>En grunn til at tettheten og utvidelsen av Stockholm ikke har hatt noen betydelig innvirkning på lufttemperaturen, er den relativt raske luftutvekslingen med nærliggende ekspansjoner av vann og landskap. I de områdene som blir tettere, ser man gjennomsnittlige temperaturøkninger på opptil 1,5 °C. Som forventet observeres de største temperaturøkningene når naturmiljøer eller grønne områder bygges på.<br/>Tiltak i lokalområdet<br/>En konsekvens av den lokalt begrensede effekten av endringer i bymiljøet er at tiltak først og fremst bør rettes mot direkte effekter i nærområdet. Eksempler på slike tiltak er skyggefulle gatetrær og nærhet til grønne områder. Av samme grunn kan tiltak som grønne tak som bare indirekte påvirker lufttemperaturen i gatemiljøet forventes å ha en mindre signifikant innvirkning.<br/>En komfortindeks kan brukes til å oppsummere effekten av ulike klimaparametere. Et eksempel på en slik indeks er Universal Thermal Climate Index (UTCI). Dette innebærer et høyere ambisjonsnivå i forhold til hvordan klimaplanlegging ofte gjennomføres i dagens planleggingsprosesser. |
